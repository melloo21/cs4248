{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics as stats\n",
    "\n",
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import BertRegressor\n",
    "from bert_sklearn import BertTokenClassifier\n",
    "from bert_sklearn import load_model\n",
    "\n",
    "def read_tsv(filename, quotechar=None):\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))   \n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 train data size: 67349 \n",
      "SST-2 dev data size: 872 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1\n",
       "3  remains utterly satisfied to remain the same t...      0\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SST-2 train data size: 67349 \n",
    "SST-2 dev data size: 872 \n",
    "\"\"\"\n",
    "DATADIR = 'xxx'\n",
    "\n",
    "def get_sst_data(train_file=DATADIR + '/train.txt',\n",
    "                 dev_file=DATADIR + '/dev.txt'):\n",
    "\n",
    "    train = pd.read_csv(train_file, sep='\\t', encoding='utf8', keep_default_na=False)\n",
    "    train.columns=['text', 'label']\n",
    "    print(\"SST-2 train data size: %d \"%(len(train)))\n",
    "    \n",
    "    dev = pd.read_csv(dev_file, sep='\\t', encoding='utf8', keep_default_na=False)\n",
    "    dev.columns=['text', 'label']\n",
    "    print(\"SST-2 dev data size: %d \"%(len(dev)))\n",
    "    label_list = np.unique(train['label'])\n",
    "\n",
    "    return train, dev, label_list\n",
    "\n",
    "train, dev, label_list = get_sst_data()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample data \n",
    "n = 1000\n",
    "train = train.sample(n, random_state=42)\n",
    "\n",
    "X_train = train['text']\n",
    "y_train = train['label']\n",
    "\n",
    "# use the dev set for testing\n",
    "test = dev\n",
    "X_test = test['text']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(bert_config_json=None, bert_model='bert-base-uncased',\n",
       "        bert_vocab=None, do_lower_case=None, epochs=3, eval_batch_size=8,\n",
       "        fp16=False, from_tf=False, gradient_accumulation_steps=1,\n",
       "        ignore_label=None, label_list=None, learning_rate=2e-05,\n",
       "        local_rank=-1, logfile='bert_sklearn.log', loss_scale=0,\n",
       "        max_seq_length=64, num_mlp_hiddens=500, num_mlp_layers=0,\n",
       "        random_state=42, restore_file=None, train_batch_size=16,\n",
       "        use_cuda=True, validation_fraction=0.1, warmup_proportion=0.1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 57/57 [00:15<00:00,  4.17it/s, loss=0.529]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.5295, Val loss: 0.4408, Val accy: 81.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:15<00:00,  4.16it/s, loss=0.167]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.1668, Val loss: 0.4380, Val accy: 87.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:15<00:00,  4.16it/s, loss=0.0434]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 22.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.0434, Val loss: 0.5512, Val accy: 86.00%\n",
      "CPU times: user 36.1 s, sys: 16.5 s, total: 52.6 s\n",
      "Wall time: 54.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 109/109 [00:03<00:00, 27.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3717, Accuracy: 88.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 109/109 [00:03<00:00, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class prob estimates:\n",
      " [[0.00176739 0.9982326 ]\n",
      " [0.978774   0.02122599]\n",
      " [0.00462427 0.99537575]\n",
      " ...\n",
      " [0.96313787 0.03686218]\n",
      " [0.1856012  0.81439877]\n",
      " [0.00501524 0.99498475]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|██████████| 109/109 [00:03<00:00, 27.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.07%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       428\n",
      "    positive       0.88      0.89      0.88       444\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       872\n",
      "   macro avg       0.88      0.88      0.88       872\n",
      "weighted avg       0.88      0.88      0.88       872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# score model\n",
    "accy = model.score(X_test, y_test)\n",
    "\n",
    "# make class probability predictions\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print(\"class prob estimates:\\n\", y_prob)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: %0.2f%%\"%(metrics.accuracy_score(y_pred, y_test) * 100))\n",
    "\n",
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /data/test.bin...\n",
      "Defaulting to linear classifier/regressor\n",
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 109/109 [00:03<00:00, 27.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3717, Accuracy: 88.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#save model to disk\n",
    "savefile = '/data/test.bin'\n",
    "model.save(savefile)\n",
    "\n",
    "# load model from disk\n",
    "new_model = load_model(savefile)\n",
    "\n",
    "# predict with new model\n",
    "accy = new_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  4.04it/s, loss=0.502]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.5023, Val loss: 0.5222, Val accy: 81.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  4.10it/s, loss=0.184]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.1842, Val loss: 0.4111, Val accy: 87.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  3.99it/s, loss=0.0377]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.0377, Val loss: 0.5228, Val accy: 88.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 109/109 [00:04<00:00, 28.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3578, Accuracy: 88.07%\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  3.73it/s, loss=0.533]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 20.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.5332, Val loss: 0.2840, Val accy: 86.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  3.94it/s, loss=0.204]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.2042, Val loss: 0.2330, Val accy: 91.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  3.98it/s, loss=0.0656]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.0656, Val loss: 0.2525, Val accy: 91.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 109/109 [00:04<00:00, 27.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4295, Accuracy: 85.89%\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  4.10it/s, loss=0.585]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.5846, Val loss: 0.4408, Val accy: 76.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  3.94it/s, loss=0.291]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 20.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.2907, Val loss: 0.2925, Val accy: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:17<00:00,  3.86it/s, loss=0.0896]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 20.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.0896, Val loss: 0.2609, Val accy: 91.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 109/109 [00:04<00:00, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4628, Accuracy: 84.75%\n",
      "CPU times: user 1min 58s, sys: 55.7 s, total: 2min 54s\n",
      "Wall time: 2min 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []; \n",
    "for seed in [4, 27, 33]:\n",
    "    model.random_state = seed\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88.0733945  85.89449541 84.74770642 88.0733945 ]\n",
      "86.70% (+/-3.313)\n"
     ]
    }
   ],
   "source": [
    "# lets add the accy from our earlier run as well that uses the default seed=42\n",
    "scores = np.array(scores + [accy])\n",
    "print(scores)\n",
    "print(\"%0.2f%% (+/-%0.03f)\"% (stats.mean(scores), stats.stdev(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQP train data size: 363849 \n",
      "QQP dev data size: 40430 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                              text_b label  \n",
       "0  Which level of prepration is enough for the ex...     0  \n",
       "1                 How do you control your horniness?     1  \n",
       "2  What can cause stool to come out as little balls?     0  \n",
       "3                       What do i do after my MBBS ?     1  \n",
       "4  Would a second airport in Sydney, Australia be...     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "QQP train data size: 363849 \n",
    "QQP dev data size: 40430 \n",
    "\"\"\"\n",
    "\n",
    "DATADIR = './glue_examples/glue_data'\n",
    "\n",
    "def get_quora_df(filename):\n",
    "    rows = read_tsv(filename)\n",
    "    df=pd.DataFrame(rows[1:], columns=rows[0])\n",
    "    df=df[['question1', 'question2', 'is_duplicate']]\n",
    "    df = df[pd.notnull(df['is_duplicate'])]\n",
    "    df.columns=['text_a', 'text_b', 'label']\n",
    "    return df\n",
    "\n",
    "def get_quora_data(train_file=DATADIR+'/QQP/train.tsv', \n",
    "                   dev_file=DATADIR+'/QQP/dev.tsv'):\n",
    "    train = get_quora_df(train_file)\n",
    "    print(\"QQP train data size: %d \"%(len(train)))\n",
    "    dev = get_quora_df(dev_file)\n",
    "    print(\"QQP dev data size: %d \"%(len(dev)))\n",
    "\n",
    "    label_list = np.unique(train['label'].values)\n",
    "    return train, dev, label_list\n",
    "\n",
    "train, dev, label_list = get_quora_data()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample data \n",
    "n = 1000\n",
    "train = train.sample(n, random_state=42)\n",
    "dev = dev.sample(n, random_state=42)\n",
    "\n",
    "X_train = train[['text_a', 'text_b']]\n",
    "y_train = train['label']\n",
    "\n",
    "# use the dev set for testing...\n",
    "test = dev\n",
    "X_test = test[['text_a', 'text_b']]\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 57/57 [00:15<00:00,  4.18it/s, loss=0.643]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.6428, Val loss: 0.5923, Val accy: 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:16<00:00,  4.10it/s, loss=0.424]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.4240, Val loss: 0.6151, Val accy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 57/57 [00:17<00:00,  3.72it/s, loss=0.225]\n",
      "Validating: 100%|██████████| 13/13 [00:00<00:00, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.2246, Val loss: 0.7069, Val accy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 125/125 [00:05<00:00, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5384, Accuracy: 74.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|██████████| 125/125 [00:05<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.90%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not duplicate       0.85      0.72      0.78       617\n",
      " is duplicate       0.64      0.80      0.71       383\n",
      "\n",
      "    micro avg       0.75      0.75      0.75      1000\n",
      "    macro avg       0.74      0.76      0.74      1000\n",
      " weighted avg       0.77      0.75      0.75      1000\n",
      "\n",
      "CPU times: user 44 s, sys: 21.1 s, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define model\n",
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "\n",
    "# finetune model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: %0.2f%%\"%(metrics.accuracy_score(y_pred, y_test) * 100))\n",
    "\n",
    "target_names = ['not duplicate', 'is duplicate']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

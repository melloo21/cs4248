{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc000ae-418f-462b-b9e4-3d39a91dd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cdee21-1e4e-4146-b126-2e2215dfe87a",
   "metadata": {},
   "source": [
    "## Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ab5656-adbc-4f6f-8a3a-0b8b01c1a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanhon/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/allennlp/service/predictors/__init__.py:23: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\n",
      "  \"Please use allennlp.predictors.*\", FutureWarning)\n",
      "/home/kanhon/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/allennlp/service/predictors/predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\n",
      "  \" Please use allennlp.predictors.*\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.common import Params\n",
    "import os\n",
    "import logging\n",
    "from scicite.dataset_readers.citation_data_reader_scicite import SciciteDatasetReader\n",
    "from allennlp.data.instance import Instance\n",
    "\n",
    "from typing import Dict, Iterable, Tuple\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "os.environ['SEED'] = '21016'\n",
    "os.environ['PYTORCH_SEED'] = str(int(os.environ['SEED']) // 3)\n",
    "os.environ['NUMPY_SEED'] = str(int(os.environ['PYTORCH_SEED']) // 3)\n",
    "os.environ[\"elmo\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eed15e5-ffe3-44b1-be62-a7a2cb1b423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 10:05:20 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'multilabel': False, 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': False, 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.type = scicite_datasetreader\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = None\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.use_lexicon_features = False\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.use_sparse_lexicon_features = False\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.multilabel = False\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.with_elmo = true\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   dataset_reader.reader_format = flat\n"
     ]
    }
   ],
   "source": [
    "parameter_filename = \"./experiment_configs/scicite-experiment-0.05-0.05.json\"\n",
    "overrides = \"\"\n",
    "params = Params.from_file(parameter_filename, overrides)\n",
    "\n",
    "dataset_reader = DatasetReader.from_params(params.pop('dataset_reader'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a37e50-0a37-42f6-9192-e3cfe3d59b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2eb45d-1d4d-438b-91ec-a51688adcc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   validation_dataset_reader = None\n",
      "03/30/2024 10:05:20 - INFO - allennlp.common.params -   train_data_path = scicite_data/train.jsonl\n",
      "03/30/2024 10:05:20 - INFO - __main__ -   Reading training data from scicite_data/train.jsonl\n",
      "8243it [00:02, 2829.51it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_dataset_reader_params = params.pop(\"validation_dataset_reader\", None)\n",
    "validation_and_test_dataset_reader: DatasetReader = dataset_reader\n",
    "if validation_dataset_reader_params is not None:\n",
    "    logger.info(\"Using a separate dataset reader to load validation and test data.\")\n",
    "    validation_and_test_dataset_reader = DatasetReader.from_params(validation_dataset_reader_params)\n",
    "\n",
    "train_data_path = params.pop('train_data_path')\n",
    "logger.info(\"Reading training data from %s\", train_data_path)\n",
    "train_data = dataset_reader.read(train_data_path)\n",
    "\n",
    "datasets: Dict[str, Iterable[Instance]] = {\"train\": train_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e665f796-3254-4506-8f86-c59fb9e6b97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation_text': <allennlp.data.fields.text_field.TextField at 0x7f47924012e8>,\n",
       " 'labels': <allennlp.data.fields.label_field.LabelField at 0x7f47924013c8>,\n",
       " 'year_diff': <allennlp.data.fields.array_field.ArrayField at 0x7f4792401358>,\n",
       " 'citing_paper_id': <allennlp.data.fields.metadata_field.MetadataField at 0x7f4792401438>,\n",
       " 'cited_paper_id': <allennlp.data.fields.metadata_field.MetadataField at 0x7f4792401278>,\n",
       " 'citation_excerpt_index': <allennlp.data.fields.metadata_field.MetadataField at 0x7f47923fe5f8>,\n",
       " 'citation_id': <allennlp.data.fields.metadata_field.MetadataField at 0x7f47923fe400>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed8a15-a72f-4561-a85b-a73178ad1096",
   "metadata": {},
   "source": [
    "### Train_multitask_two_tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f407a77-e966-4528-96b5-4403fb445f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The `train_multitask` subcommand that can be used to train the model in the multitask fashion\n",
    "It requires a configuration file and a directory in\n",
    "which to write the results.\n",
    ".. code-block:: bash\n",
    "   $ allennlp train --help\n",
    "   usage: allennlp train [-h] -s SERIALIZATION_DIR [-r] [-o OVERRIDES]\n",
    "                         [--file-friendly-logging]\n",
    "                         [--include-package INCLUDE_PACKAGE]\n",
    "                         param_path\n",
    "   Train the specified model on the specified dataset.\n",
    "   positional arguments:\n",
    "   param_path            path to parameter file describing the model to be\n",
    "                           trained\n",
    "   optional arguments:\n",
    "   -h, --help            show this help message and exit\n",
    "   -s SERIALIZATION_DIR, --serialization-dir SERIALIZATION_DIR\n",
    "                           directory in which to save the model and its logs\n",
    "   -r, --recover         recover training from the state in serialization_dir\n",
    "   -o OVERRIDES, --overrides OVERRIDES\n",
    "                           a JSON structure used to override the experiment\n",
    "                           configuration\n",
    "   --include-package INCLUDE_PACKAGE\n",
    "                           additional packages to include\n",
    "   --file-friendly-logging\n",
    "                           outputs tqdm status on separate lines and slows tqdm\n",
    "                           refresh rate\n",
    "\"\"\"\n",
    "import random\n",
    "from typing import Dict, Iterable, Tuple\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "from allennlp.commands.evaluate import evaluate\n",
    "from allennlp.commands.subcommand import Subcommand\n",
    "from allennlp.common.checks import ConfigurationError, check_for_gpu\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.util import prepare_environment, prepare_global_logging, \\\n",
    "                                 get_frozen_and_tunable_parameter_names, dump_metrics\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.iterators.data_iterator import DataIterator\n",
    "from allennlp.models.archival import archive_model, CONFIG_NAME\n",
    "from allennlp.models.model import Model, _DEFAULT_WEIGHTS\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "# from scicite.training.multitask_trainer_two_tasks import MultiTaskTrainer2\n",
    "from scicite.training.vocabulary_multitask import VocabularyMultitask\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "\n",
    "class TrainMultiTask2(Subcommand):\n",
    "    \"\"\" Class for training the model with two scaffold tasks \"\"\"\n",
    "    def add_subparser(self, name: str, parser: argparse._SubParsersAction) -> argparse.ArgumentParser:\n",
    "        # pylint: disable=protected-access\n",
    "        description = '''Train the specified model on the specified dataset.'''\n",
    "        subparser = parser.add_parser(name, description=description, help='Train a model')\n",
    "\n",
    "        subparser.add_argument('param_path',\n",
    "                               type=str,\n",
    "                               help='path to parameter file describing the model to be trained')\n",
    "\n",
    "        subparser.add_argument('-s', '--serialization-dir',\n",
    "                               required=True,\n",
    "                               type=str,\n",
    "                               help='directory in which to save the model and its logs')\n",
    "\n",
    "        subparser.add_argument('-r', '--recover',\n",
    "                               action='store_true',\n",
    "                               default=False,\n",
    "                               help='recover training from the state in serialization_dir')\n",
    "\n",
    "        subparser.add_argument('-o', '--overrides',\n",
    "                               type=str,\n",
    "                               default=\"\",\n",
    "                               help='a JSON structure used to override the experiment configuration')\n",
    "\n",
    "        subparser.add_argument('--file-friendly-logging',\n",
    "                               action='store_true',\n",
    "                               default=False,\n",
    "                               help='outputs tqdm status on separate lines and slows tqdm refresh rate')\n",
    "\n",
    "        subparser.set_defaults(func=train_model_from_args)\n",
    "\n",
    "        return subparser\n",
    "\n",
    "def train_model_from_args(args: argparse.Namespace):\n",
    "    \"\"\"\n",
    "    Just converts from an ``argparse.Namespace`` object to string paths.\n",
    "    \"\"\"\n",
    "    train_model_from_file(args.param_path,\n",
    "                          args.serialization_dir,\n",
    "                          args.overrides,\n",
    "                          args.file_friendly_logging,\n",
    "                          args.recover)\n",
    "\n",
    "\n",
    "def train_model_from_file(parameter_filename: str,\n",
    "                          serialization_dir: str,\n",
    "                          overrides: str = \"\",\n",
    "                          file_friendly_logging: bool = False,\n",
    "                          recover: bool = False) -> Model:\n",
    "    \"\"\"\n",
    "    A wrapper around :func:`train_model` which loads the params from a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param_path : ``str``\n",
    "        A json parameter file specifying an AllenNLP experiment.\n",
    "    serialization_dir : ``str``\n",
    "        The directory in which to save results and logs. We just pass this along to\n",
    "        :func:`train_model`.\n",
    "    overrides : ``str``\n",
    "        A JSON string that we will use to override values in the input parameter file.\n",
    "    file_friendly_logging : ``bool``, optional (default=False)\n",
    "        If ``True``, we make our output more friendly to saved model files.  We just pass this\n",
    "        along to :func:`train_model`.\n",
    "    recover : ``bool`, optional (default=False)\n",
    "        If ``True``, we will try to recover a training run from an existing serialization\n",
    "        directory.  This is only intended for use when something actually crashed during the middle\n",
    "        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n",
    "    \"\"\"\n",
    "    # Load the experiment config from a file and pass it to ``train_model``.\n",
    "    params = Params.from_file(parameter_filename, overrides)\n",
    "    return train_model(params, serialization_dir, file_friendly_logging, recover)\n",
    "\n",
    "\n",
    "def datasets_from_params(params: Params) -> Tuple[Dict[str, Iterable[Instance]], Dict[str, Iterable[Instance]], Dict[str, Iterable[Instance]]]:\n",
    "    \"\"\"\n",
    "    Load all the datasets specified by the config.\n",
    "    This includes the main dataset and the two scaffold auxiliary datasets\n",
    "    \"\"\"\n",
    "    dataset_reader = DatasetReader.from_params(params.pop('dataset_reader'))\n",
    "    validation_dataset_reader_params = params.pop(\"validation_dataset_reader\", None)\n",
    "\n",
    "    validation_and_test_dataset_reader: DatasetReader = dataset_reader\n",
    "    if validation_dataset_reader_params is not None:\n",
    "        logger.info(\"Using a separate dataset reader to load validation and test data.\")\n",
    "        validation_and_test_dataset_reader = DatasetReader.from_params(validation_dataset_reader_params)\n",
    "\n",
    "    train_data_path = params.pop('train_data_path')\n",
    "    logger.info(\"Reading training data from %s\", train_data_path)\n",
    "    train_data = dataset_reader.read(train_data_path)\n",
    "\n",
    "    datasets: Dict[str, Iterable[Instance]] = {\"train\": train_data}\n",
    "\n",
    "    # 2. Auxillary training data.\n",
    "    dataset_reader_aux = DatasetReader.from_params(params.pop('dataset_reader_aux'))\n",
    "    train_data_path_aux = params.pop('train_data_path_aux')\n",
    "    logger.info(\"Reading auxiliary training data from %s\", train_data_path_aux)\n",
    "    train_data_aux = dataset_reader_aux.read(train_data_path_aux)\n",
    "\n",
    "    dataset_reader_aux2 = DatasetReader.from_params(params.pop('dataset_reader_aux2'))\n",
    "    train_data_path_aux2 = params.pop('train_data_path_aux2')\n",
    "    logger.info(\"Reading second auxiliary training data for from %s\", train_data_path_aux2)\n",
    "    train_data_aux2 = dataset_reader_aux2.read(train_data_path_aux2)\n",
    "\n",
    "    # If only using a fraction of the auxiliary data.\n",
    "    aux_sample_fraction = params.pop(\"aux_sample_fraction\", 1.0)\n",
    "    if aux_sample_fraction < 1.0:\n",
    "        sample_size = int(aux_sample_fraction * len(train_data_aux))\n",
    "        train_data_aux = random.sample(train_data_aux, sample_size)\n",
    "        train_data_aux2 = random.sample(train_data_aux2, sample_size)\n",
    "\n",
    "    # Balance the datasets by inflating the size of the smaller dataset to the size of the larger dataset.\n",
    "    train_size = len(train_data)\n",
    "    aux_train_size = len(train_data_aux)\n",
    "    aux2_train_size = len(train_data_aux2)\n",
    "\n",
    "    # Make second auxillary dataset the same size of the first auxiliary dataset\n",
    "    if aux2_train_size > aux_train_size:\n",
    "        train_data_aux2 = random.sample(train_data_aux2, aux_train_size)\n",
    "    else:\n",
    "        train_data_aux = random.sample(train_data_aux, aux2_train_size)\n",
    "\n",
    "    # inflate training size to be as large as auxiliary training data\n",
    "    if train_size > aux_train_size:\n",
    "        difference = train_size - aux_train_size\n",
    "        aux_sample = [random.choice(train_data_aux) for _ in range(difference)]\n",
    "        train_data_aux = train_data_aux + aux_sample\n",
    "        logger.info(\"Inflating auxiliary train data from {} to {} samples\".format(\n",
    "            aux_train_size, len(train_data_aux)))\n",
    "    else:\n",
    "        difference = aux_train_size - train_size\n",
    "        train_sample = [random.choice(train_data) for _ in range(difference)]\n",
    "        train_data = train_data + train_sample\n",
    "        logger.info(\"Inflating train data from {} to {} samples\".format(\n",
    "            train_size, len(train_data)))\n",
    "\n",
    "    datasets[\"train\"] = train_data\n",
    "    datasets_aux = {\"train_aux\": train_data_aux}\n",
    "    datasets_aux2 = {\"train_aux\": train_data_aux2}\n",
    "\n",
    "    validation_data_path = params.pop('validation_data_path', None)\n",
    "    if validation_data_path is not None:\n",
    "        logger.info(\"Reading validation data from %s\", validation_data_path)\n",
    "        validation_data = validation_and_test_dataset_reader.read(validation_data_path)\n",
    "        datasets[\"validation\"] = validation_data\n",
    "\n",
    "    # Auxiliary validation data.\n",
    "    validation_data_path_aux = params.pop('validation_data_path_aux', None)\n",
    "    if validation_data_path_aux is not None:\n",
    "        logger.info(f\"Reading auxilliary validation data from {validation_data_path_aux}\")\n",
    "        validation_data_aux = dataset_reader_aux.read(validation_data_path_aux)\n",
    "        datasets_aux[\"validation_aux\"] = validation_data_aux\n",
    "    else:\n",
    "        validation_data_aux = None\n",
    "    validation_data_path_aux2 = params.pop('validation_data_path_aux2', None)\n",
    "    if validation_data_path_aux2 is not None:\n",
    "        logger.info(f\"Reading auxilliary validation data from {validation_data_path_aux2}\")\n",
    "        validation_data_aux2 = dataset_reader_aux2.read(validation_data_path_aux2)\n",
    "        datasets_aux2[\"validation_aux\"] = validation_data_aux2\n",
    "    else:\n",
    "        validation_data_aux2 = None\n",
    "\n",
    "    test_data_path = params.pop(\"test_data_path\", None)\n",
    "    if test_data_path is not None:\n",
    "        logger.info(\"Reading test data from %s\", test_data_path)\n",
    "        test_data = validation_and_test_dataset_reader.read(test_data_path)\n",
    "        datasets[\"test\"] = test_data\n",
    "\n",
    "    # Auxillary test data\n",
    "    test_data_path_aux = params.pop(\"test_data_path_aux\", None)\n",
    "    if test_data_path_aux is not None:\n",
    "        logger.info(f\"Reading auxiliary test data from {test_data_path_aux}\")\n",
    "        test_data_aux = dataset_reader_aux.read(test_data_path_aux)\n",
    "        datasets_aux[\"test_aux\"] = test_data_aux\n",
    "    else:\n",
    "        test_data_aux = None\n",
    "\n",
    "    test_data_path_aux2 = params.pop(\"test_data_path_aux2\", None)\n",
    "    if test_data_path_aux2 is not None:\n",
    "        logger.info(f\"Reading auxillary test data from {test_data_path_aux2}\")\n",
    "        test_data_aux2 = dataset_reader_aux2.read(test_data_path_aux2)\n",
    "        datasets_aux2[\"test_aux\"] = test_data_aux2\n",
    "    else:\n",
    "        test_data_aux2 = None\n",
    "\n",
    "    return datasets, datasets_aux, datasets_aux2\n",
    "\n",
    "def create_serialization_dir(params: Params, serialization_dir: str, recover: bool) -> None:\n",
    "    \"\"\"\n",
    "    This function creates the serialization directory if it doesn't exist.  If it already exists\n",
    "    and is non-empty, then it verifies that we're recovering from a training with an identical configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: ``Params``\n",
    "        A parameter object specifying an AllenNLP Experiment.\n",
    "    serialization_dir: ``str``\n",
    "        The directory in which to save results and logs.\n",
    "    recover: ``bool``\n",
    "        If ``True``, we will try to recover from an existing serialization directory, and crash if\n",
    "        the directory doesn't exist, or doesn't match the configuration we're given.\n",
    "    \"\"\"\n",
    "    if os.path.exists(serialization_dir) and os.listdir(serialization_dir):\n",
    "        if not recover:\n",
    "            raise ConfigurationError(f\"Serialization directory ({serialization_dir}) already exists and is \"\n",
    "                                     f\"not empty. Specify --recover to recover training from existing output.\")\n",
    "\n",
    "        logger.info(f\"Recovering from prior training at {serialization_dir}.\")\n",
    "\n",
    "        recovered_config_file = os.path.join(serialization_dir, CONFIG_NAME)\n",
    "        if not os.path.exists(recovered_config_file):\n",
    "            raise ConfigurationError(\"The serialization directory already exists but doesn't \"\n",
    "                                     \"contain a config.json. You probably gave the wrong directory.\")\n",
    "        else:\n",
    "            loaded_params = Params.from_file(recovered_config_file)\n",
    "\n",
    "            # Check whether any of the training configuration differs from the configuration we are\n",
    "            # resuming.  If so, warn the user that training may fail.\n",
    "            fail = False\n",
    "            flat_params = params.as_flat_dict()\n",
    "            flat_loaded = loaded_params.as_flat_dict()\n",
    "            for key in flat_params.keys() - flat_loaded.keys():\n",
    "                logger.error(f\"Key '{key}' found in training configuration but not in the serialization \"\n",
    "                             f\"directory we're recovering from.\")\n",
    "                fail = True\n",
    "            for key in flat_loaded.keys() - flat_params.keys():\n",
    "                logger.error(f\"Key '{key}' found in the serialization directory we're recovering from \"\n",
    "                             f\"but not in the training config.\")\n",
    "                fail = True\n",
    "            for key in flat_params.keys():\n",
    "                if flat_params.get(key, None) != flat_loaded.get(key, None):\n",
    "                    logger.error(f\"Value for '{key}' in training configuration does not match that the value in \"\n",
    "                                 f\"the serialization directory we're recovering from: \"\n",
    "                                 f\"{flat_params[key]} != {flat_loaded[key]}\")\n",
    "                    fail = True\n",
    "            if fail:\n",
    "                raise ConfigurationError(\"Training configuration does not match the configuration we're \"\n",
    "                                         \"recovering from.\")\n",
    "    else:\n",
    "        if recover:\n",
    "            raise ConfigurationError(f\"--recover specified but serialization_dir ({serialization_dir}) \"\n",
    "                                     \"does not exist.  There is nothing to recover from.\")\n",
    "        os.makedirs(serialization_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def train_model(params: Params,\n",
    "                serialization_dir: str,\n",
    "                file_friendly_logging: bool = False,\n",
    "                recover: bool = False) -> Model:\n",
    "    \"\"\"\n",
    "    Trains the model specified in the given :class:`Params` object, using the data and training\n",
    "    parameters also specified in that object, and saves the results in ``serialization_dir``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : ``Params``\n",
    "        A parameter object specifying an AllenNLP Experiment.\n",
    "    serialization_dir : ``str``\n",
    "        The directory in which to save results and logs.\n",
    "    file_friendly_logging : ``bool``, optional (default=False)\n",
    "        If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n",
    "        down tqdm's output to only once every 10 seconds.\n",
    "    recover : ``bool``, optional (default=False)\n",
    "        If ``True``, we will try to recover a training run from an existing serialization\n",
    "        directory.  This is only intended for use when something actually crashed during the middle\n",
    "        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_model: ``Model``\n",
    "        The model with the best epoch weights.\n",
    "    \"\"\"\n",
    "    prepare_environment(params)\n",
    "\n",
    "    create_serialization_dir(params, serialization_dir, recover)\n",
    "    prepare_global_logging(serialization_dir, file_friendly_logging)\n",
    "\n",
    "    check_for_gpu(params.get('trainer').get('cuda_device', -1))\n",
    "\n",
    "    params.to_file(os.path.join(serialization_dir, CONFIG_NAME))\n",
    "\n",
    "    all_datasets, all_datasets_aux, all_datasets_aux2 = datasets_from_params(params)\n",
    "    datasets_for_vocab_creation = set(params.pop(\"datasets_for_vocab_creation\", all_datasets))\n",
    "    datasets_for_vocab_creation_aux = set(params.pop(\"auxiliary_datasets_for_vocab_creation\", all_datasets_aux))\n",
    "    datasets_for_vocab_creation_aux2 = set(params.pop(\"auxiliary_datasets_for_vocab_creation_2\", all_datasets_aux2))\n",
    "\n",
    "\n",
    "    mixing_ratio = params.pop_float(\"mixing_ratio\")\n",
    "    mixing_ratio2 = params.pop_float(\"mixing_ratio2\")\n",
    "\n",
    "    cutoff_epoch = params.pop(\"cutoff_epoch\", -1)\n",
    "\n",
    "    for dataset in datasets_for_vocab_creation:\n",
    "        if dataset not in all_datasets:\n",
    "            raise ConfigurationError(f\"invalid 'dataset_for_vocab_creation' {dataset}\")\n",
    "\n",
    "    logger.info(\"From dataset instances, %s will be considered for vocabulary creation.\",\n",
    "                \", \".join(datasets_for_vocab_creation))\n",
    "    vocab_instances_aux = [\n",
    "        instance for key, dataset in all_datasets_aux.items()\n",
    "        for instance in dataset\n",
    "        if key in datasets_for_vocab_creation_aux\n",
    "    ]\n",
    "    vocab_instances_aux.extend([\n",
    "        instance for key, dataset in all_datasets_aux2.items()\n",
    "        for instance in dataset\n",
    "        if key in datasets_for_vocab_creation_aux2\n",
    "    ])\n",
    "    vocab = VocabularyMultitask.from_params(\n",
    "            params.pop(\"vocabulary\", {}),\n",
    "            (instance for key, dataset in all_datasets.items()\n",
    "             for instance in dataset\n",
    "             if key in datasets_for_vocab_creation),\n",
    "            instances_aux=vocab_instances_aux\n",
    "    )\n",
    "    model = Model.from_params(vocab=vocab, params=params.pop('model'))\n",
    "\n",
    "    # Initializing the model can have side effect of expanding the vocabulary\n",
    "    vocab.save_to_files(os.path.join(serialization_dir, \"vocabulary\"))\n",
    "    \n",
    "    iterator = DataIterator.from_params(params.pop(\"iterator\"))\n",
    "    iterator.index_with(vocab)\n",
    "\n",
    "    iterator_aux = DataIterator.from_params(params.pop(\"iterator_aux\"))\n",
    "    iterator_aux.index_with(vocab)\n",
    "\n",
    "    iterator_aux2 = DataIterator.from_params(params.pop(\"iterator_aux2\"))\n",
    "    iterator_aux2.index_with(vocab)\n",
    "\n",
    "    validation_iterator_params = params.pop(\"validation_iterator\", None)\n",
    "    if validation_iterator_params:\n",
    "        validation_iterator = DataIterator.from_params(validation_iterator_params)\n",
    "        validation_iterator.index_with(vocab)\n",
    "    else:\n",
    "        validation_iterator = None\n",
    "\n",
    "    # TODO: if validation in multi-task need to add validation iterator as above\n",
    "\n",
    "    train_data = all_datasets.get('train')\n",
    "    validation_data = all_datasets.get('validation')\n",
    "    test_data = all_datasets.get('test')\n",
    "\n",
    "    train_data_aux = all_datasets_aux.get('train_aux')\n",
    "    validation_data_aux = all_datasets_aux.get('validation_aux')\n",
    "    test_data_aux = all_datasets_aux.get('test_aux')\n",
    "\n",
    "    train_data_aux2 = all_datasets_aux2.get('train_aux')\n",
    "    validation_data_aux2 = all_datasets_aux2.get('validation_aux')\n",
    "    test_data_aux2 = all_datasets_aux2.get('test_aux')\n",
    "\n",
    "    trainer_params = params.pop(\"trainer\")\n",
    "    no_grad_regexes = trainer_params.pop(\"no_grad\", ())\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if any(re.search(regex, name) for regex in no_grad_regexes):\n",
    "            parameter.requires_grad_(False)\n",
    "\n",
    "    frozen_parameter_names, tunable_parameter_names = \\\n",
    "                   get_frozen_and_tunable_parameter_names(model)\n",
    "    logger.info(\"Following parameters are Frozen  (without gradient):\")\n",
    "    for name in frozen_parameter_names:\n",
    "        logger.info(name)\n",
    "    logger.info(\"Following parameters are Tunable (with gradient):\")\n",
    "    for name in tunable_parameter_names:\n",
    "        logger.info(name)\n",
    "\n",
    "    trainer = MultiTaskTrainer2.from_params(model=model,\n",
    "                                            serialization_dir=serialization_dir,\n",
    "                                            iterator=iterator,\n",
    "                                            iterator_aux=iterator_aux,\n",
    "                                            iterator_aux2=iterator_aux2,\n",
    "                                            train_data=train_data,\n",
    "                                            train_data_aux=train_data_aux,\n",
    "                                            train_data_aux2=train_data_aux2,\n",
    "                                            mixing_ratio=mixing_ratio,\n",
    "                                            mixing_ratio2=mixing_ratio2,\n",
    "                                            cutoff_epoch=cutoff_epoch,\n",
    "                                            validation_data_aux=validation_data_aux,\n",
    "                                            validation_data_aux2=validation_data_aux2,\n",
    "                                            validation_data=validation_data,\n",
    "                                            params=trainer_params,\n",
    "                                            validation_iterator=validation_iterator)\n",
    "    print(trainer._cuda_devices[0])\n",
    "    evaluate_on_test = params.pop_bool(\"evaluate_on_test\", False)\n",
    "    evaluate_aux_on_test = params.pop_bool(\"evaluate_aux_on_test\", False)\n",
    "    params.assert_empty('base train command')\n",
    "\n",
    "    try:\n",
    "        metrics = trainer.train()\n",
    "    except KeyboardInterrupt:\n",
    "        # if we have completed an epoch, try to create a model archive.\n",
    "        if os.path.exists(os.path.join(serialization_dir, _DEFAULT_WEIGHTS)):\n",
    "            logging.info(\"Training interrupted by the user. Attempting to create \"\n",
    "                         \"a model archive using the current best epoch weights.\")\n",
    "            archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n",
    "        raise\n",
    "\n",
    "    # Now tar up results\n",
    "    archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n",
    "\n",
    "    logger.info(\"Loading the best epoch weights.\")\n",
    "    best_model_state_path = os.path.join(serialization_dir, 'best.th')\n",
    "    best_model_state = torch.load(best_model_state_path)\n",
    "    best_model = model\n",
    "    best_model.load_state_dict(best_model_state)\n",
    "\n",
    "    if test_data and evaluate_on_test:\n",
    "        logger.info(\"The model will be evaluated using the best epoch weights.\")\n",
    "        test_metrics = evaluate(\n",
    "                best_model, test_data, validation_iterator or iterator,\n",
    "                cuda_device=trainer._cuda_devices[0] # pylint: disable=protected-access\n",
    "        )\n",
    "        for key, value in test_metrics.items():\n",
    "            metrics[\"test_\" + key] = value\n",
    "\n",
    "    elif test_data:\n",
    "        logger.info(\"To evaluate on the test set after training, pass the \"\n",
    "                    \"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\")\n",
    "\n",
    "    if test_data_aux and evaluate_aux_on_test:\n",
    "        # for instance in test_data_aux:\n",
    "        #     instance.index_fields(vocab)\n",
    "        # for instance in test_data_aux2:\n",
    "        #     instance.index_fields(vocab)\n",
    "        test_metrics_aux = evaluate(best_model, test_data_aux, iterator_aux,\n",
    "                                    cuda_device=trainer._cuda_devices[0])  # pylint: disable=protected-access\n",
    "        test_metrics_aux2 = evaluate(best_model, test_data_aux2, iterator_aux2,\n",
    "                                     cuda_device=trainer._cuda_devices[0])  # pylint: disable=protected-access\n",
    "\n",
    "        for key, value in test_metrics_aux.items():\n",
    "            metrics[\"test_aux_\" + key] = value\n",
    "        for key, value in test_metrics_aux2.items():\n",
    "            metrics[\"test_aux2_\" + key] = value\n",
    "\n",
    "    elif test_data_aux:\n",
    "        logger.info(\"To evaluate on the auxiliary test set after training, pass the \"\n",
    "                    \"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\")\n",
    "\n",
    "    dump_metrics(os.path.join(serialization_dir, \"metrics.json\"), metrics, log=True)\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544d4fc-0fe7-42a9-b3da-b9e4cdcc8fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MultiTaskTrainer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "495713dd-4a99-410e-b71a-d117b802d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module is an extended trainer based on the allennlp's default trainer to handle multitask training\n",
    "    for two auxiliary tasks\n",
    "\n",
    "A :class:`~allennlp.training.trainer.Trainer` is responsible for training a\n",
    ":class:`~allennlp.models.model.Model`.\n",
    "\n",
    "Typically you might create a configuration file specifying the model and\n",
    "training parameters and then use :mod:`~allennlp.commands.train`\n",
    "rather than instantiating a ``Trainer`` yourself.\n",
    "\"\"\"\n",
    "# pylint: disable=too-many-lines\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "import traceback\n",
    "from typing import Dict, Optional, List, Tuple, Union, Iterable, Any, Set\n",
    "\n",
    "import torch\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.nn.parallel import replicate, parallel_apply\n",
    "from torch.nn.parallel.scatter_gather import scatter_kwargs, gather\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.common.util import peak_memory_mb, gpu_memory_mb, dump_metrics\n",
    "from allennlp.common.tqdm import Tqdm\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.iterators.data_iterator import DataIterator\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.learning_rate_schedulers import LearningRateScheduler\n",
    "from allennlp.training.optimizers import Optimizer\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "\n",
    "def is_sparse(tensor):\n",
    "    return tensor.is_sparse\n",
    "\n",
    "\n",
    "def sparse_clip_norm(parameters, max_norm, norm_type=2) -> float:\n",
    "    \"\"\"Clips gradient norm of an iterable of parameters.\n",
    "\n",
    "    The norm is computed over all gradients together, as if they were\n",
    "    concatenated into a single vector. Gradients are modified in-place.\n",
    "    Supports sparse gradients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameters : ``(Iterable[torch.Tensor])``\n",
    "        An iterable of Tensors that will have gradients normalized.\n",
    "    max_norm : ``float``\n",
    "        The max norm of the gradients.\n",
    "    norm_type : ``float``\n",
    "        The type of the used p-norm. Can be ``'inf'`` for infinity norm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Total norm of the parameters (viewed as a single vector).\n",
    "    \"\"\"\n",
    "    # pylint: disable=invalid-name,protected-access\n",
    "    parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "    max_norm = float(max_norm)\n",
    "    norm_type = float(norm_type)\n",
    "    if norm_type == float('inf'):\n",
    "        total_norm = max(p.grad.data.abs().max() for p in parameters)\n",
    "    else:\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            if is_sparse(p.grad):\n",
    "                # need to coalesce the repeated indices before finding norm\n",
    "                grad = p.grad.data.coalesce()\n",
    "                param_norm = grad._values().norm(norm_type)\n",
    "            else:\n",
    "                param_norm = p.grad.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    if clip_coef < 1:\n",
    "        for p in parameters:\n",
    "            if is_sparse(p.grad):\n",
    "                p.grad.data._values().mul_(clip_coef)\n",
    "            else:\n",
    "                p.grad.data.mul_(clip_coef)\n",
    "    return total_norm\n",
    "\n",
    "\n",
    "def move_optimizer_to_cuda(optimizer):\n",
    "    \"\"\"\n",
    "    Move the optimizer state to GPU, if necessary.\n",
    "    After calling, any parameter specific state in the optimizer\n",
    "    will be located on the same device as the parameter.\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        for param in param_group['params']:\n",
    "            if param.is_cuda:\n",
    "                param_state = optimizer.state[param]\n",
    "                for k in param_state.keys():\n",
    "                    if isinstance(param_state[k], torch.Tensor):\n",
    "                        param_state[k] = param_state[k].cuda(device=param.get_device())\n",
    "\n",
    "\n",
    "class TensorboardWriter:\n",
    "    \"\"\"\n",
    "    Wraps a pair of ``SummaryWriter`` instances but is a no-op if they're ``None``.\n",
    "    Allows Tensorboard logging without always checking for Nones first.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_log: SummaryWriter = None, validation_log: SummaryWriter = None) -> None:\n",
    "        self._train_log = train_log\n",
    "        self._validation_log = validation_log\n",
    "\n",
    "    @staticmethod\n",
    "    def _item(value: Any):\n",
    "        if hasattr(value, 'item'):\n",
    "            val = value.item()\n",
    "        else:\n",
    "            val = value\n",
    "        return val\n",
    "\n",
    "    def add_train_scalar(self, name: str, value: float, global_step: int) -> None:\n",
    "        # get the scalar\n",
    "        if self._train_log is not None:\n",
    "            self._train_log.add_scalar(name, self._item(value), global_step)\n",
    "\n",
    "    def add_train_histogram(self, name: str, values: torch.Tensor, global_step: int) -> None:\n",
    "        if self._train_log is not None:\n",
    "            if isinstance(values, torch.Tensor):\n",
    "                values_to_write = values.cpu().data.numpy().flatten()\n",
    "                self._train_log.add_histogram(name, values_to_write, global_step)\n",
    "\n",
    "    def add_validation_scalar(self, name: str, value: float, global_step: int) -> None:\n",
    "\n",
    "        if self._validation_log is not None:\n",
    "            self._validation_log.add_scalar(name, self._item(value), global_step)\n",
    "\n",
    "\n",
    "def time_to_str(timestamp: int) -> str:\n",
    "    \"\"\"\n",
    "    Convert seconds past Epoch to human readable string.\n",
    "    \"\"\"\n",
    "    datetimestamp = datetime.datetime.fromtimestamp(timestamp)\n",
    "    return '{:04d}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}'.format(\n",
    "            datetimestamp.year, datetimestamp.month, datetimestamp.day,\n",
    "            datetimestamp.hour, datetimestamp.minute, datetimestamp.second\n",
    "    )\n",
    "\n",
    "\n",
    "def str_to_time(time_str: str) -> datetime.datetime:\n",
    "    \"\"\"\n",
    "    Convert human readable string to datetime.datetime.\n",
    "    \"\"\"\n",
    "    pieces: Any = [int(piece) for piece in time_str.split('-')]\n",
    "    return datetime.datetime(*pieces)\n",
    "\n",
    "\n",
    "class MultiTaskTrainer2:\n",
    "    def __init__(self,\n",
    "                 model: Model,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 iterator: DataIterator,\n",
    "                 train_dataset: Iterable[Instance],\n",
    "                 train_dataset_aux: Iterable[Instance],\n",
    "                 train_dataset_aux2: Optional[Iterable[Instance]],\n",
    "                 mixing_ratio: float = 0.17,\n",
    "                 mixing_ratio2: float = 0.17,\n",
    "                 cutoff_epoch: int = -1,\n",
    "                 validation_dataset: Optional[Iterable[Instance]] = None,\n",
    "                 validation_dataset_aux: Optional[Iterable] = None,\n",
    "                 validation_dataset_aux2: Optional[Iterable[Instance]] = None,\n",
    "                 patience: Optional[int] = None,\n",
    "                 validation_metric: str = \"-loss\",\n",
    "                 validation_iterator: DataIterator = None,\n",
    "                 shuffle: bool = True,\n",
    "                 num_epochs: int = 20,\n",
    "                 serialization_dir: Optional[str] = None,\n",
    "                 num_serialized_models_to_keep: int = 20,\n",
    "                 keep_serialized_model_every_num_seconds: int = None,\n",
    "                 model_save_interval: float = None,\n",
    "                 cuda_device: Union[int, List] = -1,\n",
    "                 grad_norm: Optional[float] = None,\n",
    "                 grad_clipping: Optional[float] = None,\n",
    "                 learning_rate_scheduler: Optional[LearningRateScheduler] = None,\n",
    "                 summary_interval: int = 100,\n",
    "                 histogram_interval: int = None,\n",
    "                 should_log_parameter_statistics: bool = True,\n",
    "                 should_log_learning_rate: bool = False,\n",
    "                 iterator_aux: Optional[DataIterator] = None,\n",
    "                 iterator_aux2: Optional[DataIterator] = None) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : ``Model``, required.\n",
    "            An AllenNLP model to be optimized. Pytorch Modules can also be optimized if\n",
    "            their ``forward`` method returns a dictionary with a \"loss\" key, containing a\n",
    "            scalar tensor representing the loss function to be optimized.\n",
    "        optimizer : ``torch.nn.Optimizer``, required.\n",
    "            An instance of a Pytorch Optimizer, instantiated with the parameters of the\n",
    "            model to be optimized.\n",
    "        iterator : ``DataIterator``, required.\n",
    "            A method for iterating over a ``Dataset``, yielding padded indexed batches.\n",
    "        train_dataset : ``Dataset``, required.\n",
    "            A ``Dataset`` to train on. The dataset should have already been indexed.\n",
    "        train_dataset_aux : ``Dataset``, required.\n",
    "            A ``Dataset`` for auxiliary task 1 to train on.\n",
    "        train_dataset_aux2 : ``Dataset``, required.\n",
    "            A ``Dataset`` for second auxiliary task to train on. The dataset should have already been indexed.\n",
    "        mixing_ratio: a float specifying the influence of the first auxiliary task on the final loss\n",
    "        mixing_ratio2: a float specifying the influence of the second auxiliary task on the final loss\n",
    "        cutoff_epoch: multitask training starts from the epoch after the epoch specified by cutoff_epoch\n",
    "        validation_dataset : ``Dataset``, optional, (default = None).\n",
    "            A ``Dataset`` to evaluate on. The dataset should have already been indexed.\n",
    "        validation_dataset_aux : a validation dataset for the first auxiliary task\n",
    "        validation_dataset_aux_2 : a validation dataset for the second auxiliary task\n",
    "        patience : Optional[int] > 0, optional (default=None)\n",
    "            Number of epochs to be patient before early stopping: the training is stopped\n",
    "            after ``patience`` epochs with no improvement. If given, it must be ``> 0``.\n",
    "            If None, early stopping is disabled.\n",
    "        validation_metric : str, optional (default=\"loss\")\n",
    "            Validation metric to measure for whether to stop training using patience\n",
    "            and whether to serialize an ``is_best`` model each epoch. The metric name\n",
    "            must be prepended with either \"+\" or \"-\", which specifies whether the metric\n",
    "            is an increasing or decreasing function.\n",
    "        validation_iterator : ``DataIterator``, optional (default=None)\n",
    "            An iterator to use for the validation set.  If ``None``, then\n",
    "            use the training `iterator`.\n",
    "        shuffle: ``bool``, optional (default=True)\n",
    "            Whether to shuffle the instances in the iterator or not.\n",
    "        num_epochs : int, optional (default = 20)\n",
    "            Number of training epochs.\n",
    "        serialization_dir : str, optional (default=None)\n",
    "            Path to directory for saving and loading model files. Models will not be saved if\n",
    "            this parameter is not passed.\n",
    "        num_serialized_models_to_keep : ``int``, optional (default=20)\n",
    "            Number of previous model checkpoints to retain.  Default is to keep 20 checkpoints.\n",
    "            A value of None or -1 means all checkpoints will be kept.\n",
    "        keep_serialized_model_every_num_seconds : ``int``, optional (default=None)\n",
    "            If num_serialized_models_to_keep is not None, then occasionally it's useful to\n",
    "            save models at a given interval in addition to the last num_serialized_models_to_keep.\n",
    "            To do so, specify keep_serialized_model_every_num_seconds as the number of seconds\n",
    "            between permanently saved checkpoints.  Note that this option is only used if\n",
    "            num_serialized_models_to_keep is not None, otherwise all checkpoints are kept.\n",
    "        model_save_interval : ``float``, optional (default=None)\n",
    "            If provided, then serialize models every ``model_save_interval``\n",
    "            seconds within single epochs.  In all cases, models are also saved\n",
    "            at the end of every epoch if ``serialization_dir`` is provided.\n",
    "        cuda_device : ``int``, optional (default = -1)\n",
    "            An integer specifying the CUDA device to use. If -1, the CPU is used.\n",
    "        grad_norm : ``float``, optional, (default = None).\n",
    "            If provided, gradient norms will be rescaled to have a maximum of this value.\n",
    "        grad_clipping : ``float``, optional (default = ``None``).\n",
    "            If provided, gradients will be clipped `during the backward pass` to have an (absolute)\n",
    "            maximum of this value.  If you are getting ``NaNs`` in your gradients during training\n",
    "            that are not solved by using ``grad_norm``, you may need this.\n",
    "        learning_rate_scheduler : ``PytorchLRScheduler``, optional, (default = None)\n",
    "            A Pytorch learning rate scheduler. The learning rate will be decayed with respect to\n",
    "            this schedule at the end of each epoch. If you use\n",
    "            :class:`torch.optim.lr_scheduler.ReduceLROnPlateau`, this will use the ``validation_metric``\n",
    "            provided to determine if learning has plateaued.  To support updating the learning\n",
    "            rate on every batch, this can optionally implement ``step_batch(batch_num_total)`` which\n",
    "            updates the learning rate given the batch number.\n",
    "        summary_interval: ``int``, optional, (default = 100)\n",
    "            Number of batches between logging scalars to tensorboard\n",
    "        histogram_interval : ``int``, optional, (default = ``None``)\n",
    "            If not None, then log histograms to tensorboard every ``histogram_interval`` batches.\n",
    "            When this parameter is specified, the following additional logging is enabled:\n",
    "                * Histograms of model parameters\n",
    "                * The ratio of parameter update norm to parameter norm\n",
    "                * Histogram of layer activations\n",
    "            We log histograms of the parameters returned by\n",
    "            ``model.get_parameters_for_histogram_tensorboard_logging``.\n",
    "            The layer activations are logged for any modules in the ``Model`` that have\n",
    "            the attribute ``should_log_activations`` set to ``True``.  Logging\n",
    "            histograms requires a number of GPU-CPU copies during training and is typically\n",
    "            slow, so we recommend logging histograms relatively infrequently.\n",
    "            Note: only Modules that return tensors, tuples of tensors or dicts\n",
    "            with tensors as values currently support activation logging.\n",
    "        should_log_parameter_statistics : ``bool``, optional, (default = True)\n",
    "            Whether to send parameter statistics (mean and standard deviation\n",
    "            of parameters and gradients) to tensorboard.\n",
    "        should_log_learning_rate : ``bool``, optional, (default = False)\n",
    "            Whether to send parameter specific learning rate to tensorboard.\n",
    "        iterator_aux : ``DataIterator``, required.\n",
    "            A method for iterating over a ``Dataset`` for the first auxiliary task, yielding padded indexed batches.\n",
    "        iterator_aux2 : ``DataIterator``, required.\n",
    "            A method for iterating over a ``Dataset`` for the second auxiliary task, yielding padded indexed batches.\n",
    "        \"\"\"\n",
    "        self._model = model\n",
    "        self._iterator = iterator\n",
    "        self._validation_iterator = validation_iterator\n",
    "        self._shuffle = shuffle\n",
    "        self._optimizer = optimizer\n",
    "        self._train_data = train_dataset\n",
    "        self._validation_data = validation_dataset\n",
    "        self._train_dataset_aux = train_dataset_aux\n",
    "        self._train_dataset_aux2 = train_dataset_aux2\n",
    "        self._validation_data_aux = validation_dataset_aux\n",
    "        self._validation_data_aux2 = validation_dataset_aux2\n",
    "\n",
    "        self._cutoff_epoch = cutoff_epoch\n",
    "        self._mixing_ratio = mixing_ratio\n",
    "        self._mixing_ratio2 = mixing_ratio2\n",
    "        self._iterator_aux = iterator_aux\n",
    "        self._iterator_aux2 = iterator_aux2\n",
    "\n",
    "        if patience is None:  # no early stopping\n",
    "            if validation_dataset:\n",
    "                logger.warning('You provided a validation dataset but patience was set to None, '\n",
    "                               'meaning that early stopping is disabled')\n",
    "        elif (not isinstance(patience, int)) or patience <= 0:\n",
    "            raise ConfigurationError('{} is an invalid value for \"patience\": it must be a positive integer '\n",
    "                                     'or None (if you want to disable early stopping)'.format(patience))\n",
    "        self._patience = patience\n",
    "        self._num_epochs = num_epochs\n",
    "\n",
    "        self._serialization_dir = serialization_dir\n",
    "        self._num_serialized_models_to_keep = num_serialized_models_to_keep\n",
    "        self._keep_serialized_model_every_num_seconds = keep_serialized_model_every_num_seconds\n",
    "        self._serialized_paths: List[Any] = []\n",
    "        self._last_permanent_saved_checkpoint_time = time.time()\n",
    "        self._model_save_interval = model_save_interval\n",
    "\n",
    "        self._grad_norm = grad_norm\n",
    "        self._grad_clipping = grad_clipping\n",
    "        self._learning_rate_scheduler = learning_rate_scheduler\n",
    "\n",
    "        increase_or_decrease = validation_metric[0]\n",
    "        if increase_or_decrease not in [\"+\", \"-\"]:\n",
    "            raise ConfigurationError(\"Validation metrics must specify whether they should increase \"\n",
    "                                     \"or decrease by pre-pending the metric name with a +/-.\")\n",
    "        self._validation_metric = validation_metric[1:]\n",
    "        self._validation_metric_decreases = increase_or_decrease == \"-\"\n",
    "\n",
    "        if not isinstance(cuda_device, int) and not isinstance(cuda_device, list):\n",
    "            raise ConfigurationError(\"Expected an int or list for cuda_device, got {}\".format(cuda_device))\n",
    "\n",
    "        if isinstance(cuda_device, list):\n",
    "            logger.warning(f\"Multiple GPU support is experimental not recommended for use. \"\n",
    "                           \"In some cases it may lead to incorrect results or undefined behavior.\")\n",
    "            self._multiple_gpu = True\n",
    "            self._cuda_devices = cuda_device\n",
    "        else:\n",
    "            self._multiple_gpu = False\n",
    "            self._cuda_devices = [cuda_device]\n",
    "\n",
    "        if self._cuda_devices[0] != -1:\n",
    "            self._model = self._model.cuda(self._cuda_devices[0])\n",
    "\n",
    "        self._cuda_device = self._cuda_devices[0]\n",
    "\n",
    "        self._log_interval = 10  # seconds\n",
    "        self._summary_interval = summary_interval\n",
    "        self._histogram_interval = histogram_interval\n",
    "        self._log_histograms_this_batch = False\n",
    "        self._should_log_parameter_statistics = should_log_parameter_statistics\n",
    "        self._should_log_learning_rate = should_log_learning_rate\n",
    "\n",
    "        # We keep the total batch number as a class variable because it\n",
    "        # is used inside a closure for the hook which logs activations in\n",
    "        # ``_enable_activation_logging``.\n",
    "        self._batch_num_total = 0\n",
    "\n",
    "        self._last_log = 0.0  # time of last logging\n",
    "\n",
    "        if serialization_dir is not None:\n",
    "            train_log = SummaryWriter(os.path.join(serialization_dir, \"log\", \"train\"))\n",
    "            validation_log = SummaryWriter(os.path.join(serialization_dir, \"log\", \"validation\"))\n",
    "            self._tensorboard = TensorboardWriter(train_log, validation_log)\n",
    "        else:\n",
    "            self._tensorboard = TensorboardWriter()\n",
    "        self._warned_tqdm_ignores_underscores = False\n",
    "\n",
    "    def _enable_gradient_clipping(self) -> None:\n",
    "        if self._grad_clipping is not None:\n",
    "            # Pylint is unable to tell that we're in the case that _grad_clipping is not None...\n",
    "            # pylint: disable=invalid-unary-operand-type\n",
    "            clip_function = lambda grad: grad.clamp(-self._grad_clipping, self._grad_clipping)\n",
    "            for parameter in self._model.parameters():\n",
    "                if parameter.requires_grad:\n",
    "                    parameter.register_hook(clip_function)\n",
    "\n",
    "    def _enable_activation_logging(self) -> None:\n",
    "        \"\"\"\n",
    "        Log activations to tensorboard\n",
    "        \"\"\"\n",
    "        if self._histogram_interval is not None:\n",
    "            # To log activation histograms to the forward pass, we register\n",
    "            # a hook on forward to capture the output tensors.\n",
    "            # This uses a closure on self._log_histograms_this_batch to\n",
    "            # determine whether to send the activations to tensorboard,\n",
    "            # since we don't want them on every call.\n",
    "            for _, module in self._model.named_modules():\n",
    "                if not getattr(module, 'should_log_activations', False):\n",
    "                    # skip it\n",
    "                    continue\n",
    "\n",
    "                def hook(module_, inputs, outputs):\n",
    "                    # pylint: disable=unused-argument,cell-var-from-loop\n",
    "                    log_prefix = 'activation_histogram/{0}'.format(module_.__class__)\n",
    "                    if self._log_histograms_this_batch:\n",
    "                        if isinstance(outputs, torch.Tensor):\n",
    "                            log_name = log_prefix\n",
    "                            self._tensorboard.add_train_histogram(log_name,\n",
    "                                                                  outputs,\n",
    "                                                                  self._batch_num_total)\n",
    "                        elif isinstance(outputs, (list, tuple)):\n",
    "                            for i, output in enumerate(outputs):\n",
    "                                log_name = \"{0}_{1}\".format(log_prefix, i)\n",
    "                                self._tensorboard.add_train_histogram(log_name,\n",
    "                                                                      output,\n",
    "                                                                      self._batch_num_total)\n",
    "                        elif isinstance(outputs, dict):\n",
    "                            for k, tensor in outputs.items():\n",
    "                                log_name = \"{0}_{1}\".format(log_prefix, k)\n",
    "                                self._tensorboard.add_train_histogram(log_name,\n",
    "                                                                      tensor,\n",
    "                                                                      self._batch_num_total)\n",
    "                        else:\n",
    "                            # skip it\n",
    "                            pass\n",
    "\n",
    "                module.register_forward_hook(hook)\n",
    "\n",
    "    def _rescale_gradients(self) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Performs gradient rescaling. Is a no-op if gradient rescaling is not enabled.\n",
    "        \"\"\"\n",
    "        if self._grad_norm:\n",
    "            parameters_to_clip = [p for p in self._model.parameters()\n",
    "                                  if p.grad is not None]\n",
    "            return sparse_clip_norm(parameters_to_clip, self._grad_norm)\n",
    "        return None\n",
    "\n",
    "    def _data_parallel(self, batch):\n",
    "        \"\"\"\n",
    "        Do the forward pass using multiple GPUs.  This is a simplification\n",
    "        of torch.nn.parallel.data_parallel to support the allennlp model\n",
    "        interface.\n",
    "        \"\"\"\n",
    "        inputs, module_kwargs = scatter_kwargs((), batch, self._cuda_devices, 0)\n",
    "        used_device_ids = self._cuda_devices[:len(inputs)]\n",
    "        replicas = replicate(self._model, used_device_ids)\n",
    "        outputs = parallel_apply(replicas, inputs, module_kwargs, used_device_ids)\n",
    "\n",
    "        # Only the 'loss' is needed.\n",
    "        # a (num_gpu, ) tensor with loss on each GPU\n",
    "        losses = gather([output['loss'].unsqueeze(0) for output in outputs], used_device_ids[0], 0)\n",
    "        return {'loss': losses.mean()}\n",
    "\n",
    "    def _batch_loss(self, batch: torch.Tensor,\n",
    "                    for_training: bool,\n",
    "                    batch_aux: torch.Tensor=None,\n",
    "                    batch_aux2: torch.Tensor=None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Does a forward pass on the given batch and auxiliary data batches and returns the ``loss`` value in the result.\n",
    "        If ``for_training`` is `True` also applies regularization penalty.\n",
    "        \"\"\"\n",
    "        if self._multiple_gpu:\n",
    "            output_dict = self._data_parallel(batch)\n",
    "            if batch_aux is not None:\n",
    "                raise ConfigurationError('multi-gpu not supported for multi-task training.')\n",
    "        else:\n",
    "            batch = util.move_to_device(batch, self._cuda_devices[0])\n",
    "            print(batch)\n",
    "            output_dict = self._model(**batch)\n",
    "\n",
    "        try:\n",
    "            loss = output_dict[\"loss\"]\n",
    "            if for_training:\n",
    "                loss += self._model.get_regularization_penalty()\n",
    "        except KeyError:\n",
    "            if for_training:\n",
    "                raise RuntimeError(\"The model you are trying to optimize does not contain a\"\n",
    "                                   \" 'loss' key in the output of model.forward(inputs).\")\n",
    "            loss = None\n",
    "\n",
    "        if batch_aux is not None and batch_aux2 is not None:\n",
    "            batch_aux = util.move_to_device(batch_aux, self._cuda_devices[0])\n",
    "            batch_aux2 = util.move_to_device(batch_aux2, self._cuda_devices[0])\n",
    "            output_dict_aux = self._model(**batch_aux)\n",
    "            output_dict_aux2 = self._model(**batch_aux2)\n",
    "            try:\n",
    "                loss_aux = output_dict_aux[\"loss\"]\n",
    "                loss_aux2 = output_dict_aux2[\"loss\"]\n",
    "                if for_training:\n",
    "                    loss_aux += self._model.get_regularization_penalty()\n",
    "                    loss_aux2 += self._model.get_regularization_penalty()\n",
    "            except KeyError:\n",
    "                raise ConfigurationError(\"The auxiliary model you are trying to optimize does not contain a\"\n",
    "                                         \" 'loss' key in the output of model.forward(inputs).\")\n",
    "\n",
    "            # multi-task loss\n",
    "            loss = loss + self._mixing_ratio * loss_aux + self._mixing_ratio2 * loss_aux2\n",
    "        return loss\n",
    "\n",
    "    def _get_metrics(self, total_loss: float, num_batches: int, reset: bool = False) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Gets the metrics but sets ``\"loss\"`` to\n",
    "        the total loss divided by the ``num_batches`` so that\n",
    "        the ``\"loss\"`` metric is \"average loss per batch\".\n",
    "        \"\"\"\n",
    "        metrics = self._model.get_metrics(reset=reset)\n",
    "        metrics[\"loss\"] = float(total_loss / num_batches) if num_batches > 0 else 0.0\n",
    "        return metrics\n",
    "\n",
    "    def _train_epoch(self, epoch: int) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Trains one epoch and returns metrics.\n",
    "        \"\"\"\n",
    "        logger.info(\"Epoch %d/%d\", epoch, self._num_epochs - 1)\n",
    "        logger.info(f\"Peak CPU memory usage MB: {peak_memory_mb()}\")\n",
    "        for gpu, memory in gpu_memory_mb().items():\n",
    "            logger.info(f\"GPU {gpu} memory usage MB: {memory}\")\n",
    "\n",
    "        train_loss = 0.0\n",
    "        # Set the model to \"train\" mode.\n",
    "        self._model.train()\n",
    "\n",
    "        # Get tqdm for the training batches\n",
    "        train_generator = self._iterator(self._train_data,\n",
    "                                         num_epochs=1,\n",
    "                                         shuffle=self._shuffle)\n",
    "        train_generator_aux = self._iterator_aux(self._train_dataset_aux,\n",
    "                                                 num_epochs=1,\n",
    "                                                 shuffle=self._shuffle)\n",
    "        train_generator_aux2 = self._iterator_aux2(self._train_dataset_aux2,\n",
    "                                                  num_epochs=1,\n",
    "                                                  shuffle=self._shuffle)\n",
    "\n",
    "        multitask_training = False\n",
    "        if epoch > self._cutoff_epoch:\n",
    "            multitask_training = True\n",
    "            logger.info(\"Multitask Training\")\n",
    "        else:\n",
    "            logger.info(\"Training\")\n",
    "\n",
    "        num_training_batches = self._iterator.get_num_batches(self._train_data)\n",
    "        num_training_batches_aux = self._iterator_aux.get_num_batches(self._train_dataset_aux)\n",
    "        num_training_batches_aux2 = self._iterator_aux2.get_num_batches(self._train_dataset_aux2)\n",
    "        self._last_log = time.time()\n",
    "        last_save_time = time.time()\n",
    "\n",
    "        batches_this_epoch = 0\n",
    "        if self._batch_num_total is None:\n",
    "            self._batch_num_total = 0\n",
    "\n",
    "        if self._histogram_interval is not None:\n",
    "            histogram_parameters = set(self._model.get_parameters_for_histogram_tensorboard_logging())\n",
    "\n",
    "        logger.info(\"Training\")\n",
    "        train_generator_tqdm = Tqdm.tqdm(train_generator,\n",
    "                                         total=num_training_batches)\n",
    "        # train_aux_generator_tqdm = Tqdm.tqdm(train_generator_aux,\n",
    "        #                                      total=num_training_batches_aux)\n",
    "        for batch, batch_aux, batch_aux2 in zip(train_generator_tqdm, train_generator_aux, train_generator_aux2):\n",
    "            batches_this_epoch += 1\n",
    "            self._batch_num_total += 1\n",
    "            batch_num_total = self._batch_num_total\n",
    "\n",
    "            self._log_histograms_this_batch = self._histogram_interval is not None and (\n",
    "                    batch_num_total % self._histogram_interval == 0)\n",
    "\n",
    "            self._optimizer.zero_grad()\n",
    "\n",
    "            if multitask_training:\n",
    "                loss = self._batch_loss(batch,\n",
    "                                        for_training=True,\n",
    "                                        batch_aux=batch_aux,\n",
    "                                        batch_aux2=batch_aux2)\n",
    "            else:\n",
    "                loss = self._batch_loss(batch, for_training=True)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            batch_grad_norm = self._rescale_gradients()\n",
    "\n",
    "            # This does nothing if batch_num_total is None or you are using an\n",
    "            # LRScheduler which doesn't update per batch.\n",
    "            if self._learning_rate_scheduler:\n",
    "                self._learning_rate_scheduler.step_batch(batch_num_total)\n",
    "\n",
    "            if self._log_histograms_this_batch:\n",
    "                # get the magnitude of parameter updates for logging\n",
    "                # We need a copy of current parameters to compute magnitude of updates,\n",
    "                # and copy them to CPU so large models won't go OOM on the GPU.\n",
    "                param_updates = {name: param.detach().cpu().clone()\n",
    "                                 for name, param in self._model.named_parameters()}\n",
    "                self._optimizer.step()\n",
    "                for name, param in self._model.named_parameters():\n",
    "                    param_updates[name].sub_(param.detach().cpu())\n",
    "                    update_norm = torch.norm(param_updates[name].view(-1, ))\n",
    "                    param_norm = torch.norm(param.view(-1, )).cpu()\n",
    "                    self._tensorboard.add_train_scalar(\"gradient_update/\" + name,\n",
    "                                                       update_norm / (param_norm + 1e-7),\n",
    "                                                       batch_num_total)\n",
    "            else:\n",
    "                self._optimizer.step()\n",
    "\n",
    "            # Update the description with the latest metrics\n",
    "            metrics = self._get_metrics(train_loss, batches_this_epoch)\n",
    "            description = self._description_from_metrics(metrics)\n",
    "\n",
    "            train_generator_tqdm.set_description(description, refresh=False)\n",
    "\n",
    "            # Log parameter values to Tensorboard\n",
    "            if batch_num_total % self._summary_interval == 0:\n",
    "                if self._should_log_parameter_statistics:\n",
    "                    self._parameter_and_gradient_statistics_to_tensorboard(batch_num_total, batch_grad_norm)\n",
    "                if self._should_log_learning_rate:\n",
    "                    self._learning_rates_to_tensorboard(batch_num_total)\n",
    "                self._tensorboard.add_train_scalar(\"loss/loss_train\", metrics[\"loss\"], batch_num_total)\n",
    "                self._metrics_to_tensorboard(batch_num_total,\n",
    "                                             {\"epoch_metrics/\" + k: v for k, v in metrics.items()})\n",
    "\n",
    "            if self._log_histograms_this_batch:\n",
    "                self._histograms_to_tensorboard(batch_num_total, histogram_parameters)\n",
    "\n",
    "            # Save model if needed.\n",
    "            if self._model_save_interval is not None and (\n",
    "                    time.time() - last_save_time > self._model_save_interval\n",
    "            ):\n",
    "                last_save_time = time.time()\n",
    "                self._save_checkpoint(\n",
    "                        '{0}.{1}'.format(epoch, time_to_str(int(last_save_time))), [], is_best=False\n",
    "                )\n",
    "\n",
    "        return self._get_metrics(train_loss, batches_this_epoch, reset=True)\n",
    "\n",
    "    def _should_stop_early(self, metric_history: List[float]) -> bool:\n",
    "        \"\"\"\n",
    "        uses patience and the validation metric to determine if training should stop early\n",
    "        \"\"\"\n",
    "        if self._patience and self._patience < len(metric_history):\n",
    "            # Pylint can't figure out that in this branch `self._patience` is an int.\n",
    "            # pylint: disable=invalid-unary-operand-type\n",
    "\n",
    "            # Is the best score in the past N epochs worse than or equal the best score overall?\n",
    "            if self._validation_metric_decreases:\n",
    "                return min(metric_history[-self._patience:]) >= min(metric_history[:-self._patience])\n",
    "            else:\n",
    "                return max(metric_history[-self._patience:]) <= max(metric_history[:-self._patience])\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _parameter_and_gradient_statistics_to_tensorboard(self, # pylint: disable=invalid-name\n",
    "                                                          epoch: int,\n",
    "                                                          batch_grad_norm: float) -> None:\n",
    "        \"\"\"\n",
    "        Send the mean and std of all parameters and gradients to tensorboard, as well\n",
    "        as logging the average gradient norm.\n",
    "        \"\"\"\n",
    "        # Log parameter values to Tensorboard\n",
    "        for name, param in self._model.named_parameters():\n",
    "            self._tensorboard.add_train_scalar(\"parameter_mean/\" + name,\n",
    "                                               param.data.mean(),\n",
    "                                               epoch)\n",
    "            self._tensorboard.add_train_scalar(\"parameter_std/\" + name, param.data.std(), epoch)\n",
    "            if param.grad is not None:\n",
    "                if is_sparse(param.grad):\n",
    "                    # pylint: disable=protected-access\n",
    "                    grad_data = param.grad.data._values()\n",
    "                else:\n",
    "                    grad_data = param.grad.data\n",
    "\n",
    "                # skip empty gradients\n",
    "                if torch.prod(torch.tensor(grad_data.shape)).item() > 0: # pylint: disable=not-callable\n",
    "                    self._tensorboard.add_train_scalar(\"gradient_mean/\" + name,\n",
    "                                                       grad_data.mean(),\n",
    "                                                       epoch)\n",
    "                    self._tensorboard.add_train_scalar(\"gradient_std/\" + name,\n",
    "                                                       grad_data.std(),\n",
    "                                                       epoch)\n",
    "                else:\n",
    "                    # no gradient for a parameter with sparse gradients\n",
    "                    logger.info(\"No gradient for %s, skipping tensorboard logging.\", name)\n",
    "        # norm of gradients\n",
    "        if batch_grad_norm is not None:\n",
    "            self._tensorboard.add_train_scalar(\"gradient_norm\",\n",
    "                                               batch_grad_norm,\n",
    "                                               epoch)\n",
    "\n",
    "    def _learning_rates_to_tensorboard(self, batch_num_total: int):\n",
    "        \"\"\"\n",
    "        Send current parameter specific learning rates to tensorboard\n",
    "        \"\"\"\n",
    "        # optimizer stores lr info keyed by parameter tensor\n",
    "        # we want to log with parameter name\n",
    "        names = {param: name for name, param in self._model.named_parameters()}\n",
    "        for group in self._optimizer.param_groups:\n",
    "            if 'lr' not in group:\n",
    "                continue\n",
    "            rate = group['lr']\n",
    "            for param in group['params']:\n",
    "                # check whether params has requires grad or not\n",
    "                effective_rate = rate * float(param.requires_grad)\n",
    "                self._tensorboard.add_train_scalar(\n",
    "                        \"learning_rate/\" + names[param],\n",
    "                        effective_rate,\n",
    "                        batch_num_total\n",
    "                )\n",
    "\n",
    "    def _histograms_to_tensorboard(self, epoch: int, histogram_parameters: Set[str]) -> None:\n",
    "        \"\"\"\n",
    "        Send histograms of parameters to tensorboard.\n",
    "        \"\"\"\n",
    "        for name, param in self._model.named_parameters():\n",
    "            if name in histogram_parameters:\n",
    "                self._tensorboard.add_train_histogram(\"parameter_histogram/\" + name,\n",
    "                                                      param,\n",
    "                                                      epoch)\n",
    "\n",
    "    def _metrics_to_tensorboard(self,\n",
    "                                epoch: int,\n",
    "                                train_metrics: dict,\n",
    "                                val_metrics: dict = None) -> None:\n",
    "        \"\"\"\n",
    "        Sends all of the train metrics (and validation metrics, if provided) to tensorboard.\n",
    "        \"\"\"\n",
    "        metric_names = set(train_metrics.keys())\n",
    "        if val_metrics is not None:\n",
    "            metric_names.update(val_metrics.keys())\n",
    "        val_metrics = val_metrics or {}\n",
    "\n",
    "        for name in metric_names:\n",
    "            train_metric = train_metrics.get(name)\n",
    "            if train_metric is not None:\n",
    "                self._tensorboard.add_train_scalar(name, train_metric, epoch)\n",
    "            val_metric = val_metrics.get(name)\n",
    "            if val_metric is not None:\n",
    "                self._tensorboard.add_validation_scalar(name, val_metric, epoch)\n",
    "\n",
    "    def _metrics_to_console(self,  # pylint: disable=no-self-use\n",
    "                            train_metrics: dict,\n",
    "                            val_metrics: dict = None) -> None:\n",
    "        \"\"\"\n",
    "        Logs all of the train metrics (and validation metrics, if provided) to the console.\n",
    "        \"\"\"\n",
    "        val_metrics = val_metrics or {}\n",
    "        dual_message_template = \"%s |  %8.3f  |  %8.3f\"\n",
    "        no_val_message_template = \"%s |  %8.3f  |  %8s\"\n",
    "        no_train_message_template = \"%s |  %8s  |  %8.3f\"\n",
    "        header_template = \"%s |  %-10s\"\n",
    "\n",
    "        metric_names = set(train_metrics.keys())\n",
    "        if val_metrics:\n",
    "            metric_names.update(val_metrics.keys())\n",
    "\n",
    "        name_length = max([len(x) for x in metric_names])\n",
    "\n",
    "        logger.info(header_template, \"Training\".rjust(name_length + 13), \"Validation\")\n",
    "        for name in metric_names:\n",
    "            train_metric = train_metrics.get(name)\n",
    "            val_metric = val_metrics.get(name)\n",
    "\n",
    "            if val_metric is not None and train_metric is not None:\n",
    "                logger.info(dual_message_template, name.ljust(name_length), train_metric, val_metric)\n",
    "            elif val_metric is not None:\n",
    "                logger.info(no_train_message_template, name.ljust(name_length), \"N/A\", val_metric)\n",
    "            elif train_metric is not None:\n",
    "                logger.info(no_val_message_template, name.ljust(name_length), train_metric, \"N/A\")\n",
    "\n",
    "    def _validation_loss(self) -> Tuple[float, int]:\n",
    "        \"\"\"\n",
    "        Computes the validation loss. Returns it and the number of batches.\n",
    "        \"\"\"\n",
    "        logger.info(\"Validating\")\n",
    "\n",
    "        self._model.eval()\n",
    "\n",
    "        if self._validation_iterator is not None:\n",
    "            val_iterator = self._validation_iterator\n",
    "        else:\n",
    "            val_iterator = self._iterator\n",
    "\n",
    "        val_generator = val_iterator(self._validation_data,\n",
    "                                     num_epochs=1,\n",
    "                                     shuffle=False)\n",
    "        num_validation_batches = val_iterator.get_num_batches(self._validation_data)\n",
    "        val_generator_tqdm = Tqdm.tqdm(val_generator,\n",
    "                                       total=num_validation_batches)\n",
    "        batches_this_epoch = 0\n",
    "        val_loss = 0\n",
    "        for batch in val_generator_tqdm:\n",
    "\n",
    "            loss = self._batch_loss(batch, for_training=False)\n",
    "            if loss is not None:\n",
    "                # You shouldn't necessarily have to compute a loss for validation, so we allow for\n",
    "                # `loss` to be None.  We need to be careful, though - `batches_this_epoch` is\n",
    "                # currently only used as the divisor for the loss function, so we can safely only\n",
    "                # count those batches for which we actually have a loss.  If this variable ever\n",
    "                # gets used for something else, we might need to change things around a bit.\n",
    "                batches_this_epoch += 1\n",
    "                val_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "            # Update the description with the latest metrics\n",
    "            val_metrics = self._get_metrics(val_loss, batches_this_epoch)\n",
    "            description = self._description_from_metrics(val_metrics)\n",
    "            val_generator_tqdm.set_description(description, refresh=False)\n",
    "\n",
    "        return val_loss, batches_this_epoch\n",
    "\n",
    "    def train(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Trains the supplied model with the supplied parameters.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            epoch_counter, validation_metric_per_epoch = self._restore_checkpoint()\n",
    "        except RuntimeError:\n",
    "            traceback.print_exc()\n",
    "            raise ConfigurationError(\"Could not recover training from the checkpoint.  Did you mean to output to \"\n",
    "                                     \"a different serialization directory or delete the existing serialization \"\n",
    "                                     \"directory?\")\n",
    "\n",
    "        self._enable_gradient_clipping()\n",
    "        self._enable_activation_logging()\n",
    "\n",
    "        logger.info(\"Beginning training.\")\n",
    "\n",
    "        train_metrics: Dict[str, float] = {}\n",
    "        val_metrics: Dict[str, float] = {}\n",
    "        metrics: Dict[str, Any] = {}\n",
    "        epochs_trained = 0\n",
    "        training_start_time = time.time()\n",
    "\n",
    "        for epoch in range(epoch_counter, self._num_epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            train_metrics = self._train_epoch(epoch)\n",
    "\n",
    "            if self._validation_data is not None:\n",
    "                with torch.no_grad():\n",
    "                    # We have a validation set, so compute all the metrics on it.\n",
    "                    val_loss, num_batches = self._validation_loss()\n",
    "                    val_metrics = self._get_metrics(val_loss, num_batches, reset=True)\n",
    "\n",
    "                    # Check validation metric for early stopping\n",
    "                    this_epoch_val_metric = val_metrics[self._validation_metric]\n",
    "\n",
    "                    # Check validation metric to see if it's the best so far\n",
    "                    is_best_so_far = self._is_best_so_far(this_epoch_val_metric, validation_metric_per_epoch)\n",
    "                    validation_metric_per_epoch.append(this_epoch_val_metric)\n",
    "                    if self._should_stop_early(validation_metric_per_epoch):\n",
    "                        logger.info(\"Ran out of patience.  Stopping training.\")\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                # No validation set, so just assume it's the best so far.\n",
    "                is_best_so_far = True\n",
    "                val_metrics = {}\n",
    "                this_epoch_val_metric = None\n",
    "\n",
    "            self._metrics_to_tensorboard(epoch, train_metrics, val_metrics=val_metrics)\n",
    "            self._metrics_to_console(train_metrics, val_metrics)\n",
    "\n",
    "            # Create overall metrics dict\n",
    "            training_elapsed_time = time.time() - training_start_time\n",
    "            metrics[\"training_duration\"] = time.strftime(\"%H:%M:%S\", time.gmtime(training_elapsed_time))\n",
    "            metrics[\"training_start_epoch\"] = epoch_counter\n",
    "            metrics[\"training_epochs\"] = epochs_trained\n",
    "            metrics[\"epoch\"] = epoch\n",
    "\n",
    "            for key, value in train_metrics.items():\n",
    "                metrics[\"training_\" + key] = value\n",
    "            for key, value in val_metrics.items():\n",
    "                metrics[\"validation_\" + key] = value\n",
    "\n",
    "            if is_best_so_far:\n",
    "                # Update all the best_ metrics.\n",
    "                # (Otherwise they just stay the same as they were.)\n",
    "                metrics['best_epoch'] = epoch\n",
    "                for key, value in val_metrics.items():\n",
    "                    metrics[\"best_validation_\" + key] = value\n",
    "\n",
    "            if self._serialization_dir:\n",
    "                dump_metrics(os.path.join(self._serialization_dir, f'metrics_epoch_{epoch}.json'), metrics)\n",
    "\n",
    "            if self._learning_rate_scheduler:\n",
    "                # The LRScheduler API is agnostic to whether your schedule requires a validation metric -\n",
    "                # if it doesn't, the validation metric passed here is ignored.\n",
    "                self._learning_rate_scheduler.step(this_epoch_val_metric, epoch)\n",
    "\n",
    "            self._save_checkpoint(epoch, validation_metric_per_epoch, is_best=is_best_so_far)\n",
    "\n",
    "            epoch_elapsed_time = time.time() - epoch_start_time\n",
    "            logger.info(\"Epoch duration: %s\", time.strftime(\"%H:%M:%S\", time.gmtime(epoch_elapsed_time)))\n",
    "\n",
    "            if epoch < self._num_epochs - 1:\n",
    "                training_elapsed_time = time.time() - training_start_time\n",
    "                estimated_time_remaining = training_elapsed_time * \\\n",
    "                    ((self._num_epochs - epoch_counter) / float(epoch - epoch_counter + 1) - 1)\n",
    "                formatted_time = str(datetime.timedelta(seconds=int(estimated_time_remaining)))\n",
    "                logger.info(\"Estimated training time remaining: %s\", formatted_time)\n",
    "\n",
    "            epochs_trained += 1\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def _is_best_so_far(self,\n",
    "                        this_epoch_val_metric: float,\n",
    "                        validation_metric_per_epoch: List[float]):\n",
    "        if not validation_metric_per_epoch:\n",
    "            return True\n",
    "        elif self._validation_metric_decreases:\n",
    "            return this_epoch_val_metric < min(validation_metric_per_epoch)\n",
    "        else:\n",
    "            return this_epoch_val_metric > max(validation_metric_per_epoch)\n",
    "\n",
    "    def _description_from_metrics(self, metrics: Dict[str, float]) -> str:\n",
    "        if (not self._warned_tqdm_ignores_underscores and\n",
    "                    any(metric_name.startswith(\"_\") for metric_name in metrics)):\n",
    "            logger.warning(\"Metrics with names beginning with \\\"_\\\" will \"\n",
    "                           \"not be logged to the tqdm progress bar.\")\n",
    "            self._warned_tqdm_ignores_underscores = True\n",
    "        return ', '.join([\"%s: %.4f\" % (name, value) for name, value in\n",
    "                          metrics.items() if not name.startswith(\"_\")]) + \" ||\"\n",
    "\n",
    "    def _save_checkpoint(self,\n",
    "                         epoch: Union[int, str],\n",
    "                         val_metric_per_epoch: List[float],\n",
    "                         is_best: Optional[bool] = None) -> None:\n",
    "        \"\"\"\n",
    "        Saves a checkpoint of the model to self._serialization_dir.\n",
    "        Is a no-op if self._serialization_dir is None.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epoch : Union[int, str], required.\n",
    "            The epoch of training.  If the checkpoint is saved in the middle\n",
    "            of an epoch, the parameter is a string with the epoch and timestamp.\n",
    "        is_best: bool, optional (default = None)\n",
    "            A flag which causes the model weights at the given epoch to\n",
    "            be copied to a \"best.th\" file. The value of this flag should\n",
    "            be based on some validation metric computed by your model.\n",
    "        \"\"\"\n",
    "        if self._serialization_dir is not None:\n",
    "            model_path = os.path.join(self._serialization_dir, \"model_state_epoch_{}.th\".format(epoch))\n",
    "            model_state = self._model.state_dict()\n",
    "            torch.save(model_state, model_path)\n",
    "\n",
    "            training_state = {'epoch': epoch,\n",
    "                              'val_metric_per_epoch': val_metric_per_epoch,\n",
    "                              'optimizer': self._optimizer.state_dict(),\n",
    "                              'batch_num_total': self._batch_num_total}\n",
    "            if self._learning_rate_scheduler is not None:\n",
    "                training_state[\"learning_rate_scheduler\"] = \\\n",
    "                    self._learning_rate_scheduler.lr_scheduler.state_dict()\n",
    "            training_path = os.path.join(self._serialization_dir,\n",
    "                                         \"training_state_epoch_{}.th\".format(epoch))\n",
    "            torch.save(training_state, training_path)\n",
    "            if is_best:\n",
    "                logger.info(\"Best validation performance so far. \"\n",
    "                            \"Copying weights to '%s/best.th'.\", self._serialization_dir)\n",
    "                shutil.copyfile(model_path, os.path.join(self._serialization_dir, \"best.th\"))\n",
    "\n",
    "            if self._num_serialized_models_to_keep and self._num_serialized_models_to_keep >= 0:\n",
    "                self._serialized_paths.append([time.time(), model_path, training_path])\n",
    "                if len(self._serialized_paths) > self._num_serialized_models_to_keep:\n",
    "                    paths_to_remove = self._serialized_paths.pop(0)\n",
    "                    # Check to see if we should keep this checkpoint, if it has been longer\n",
    "                    # then self._keep_serialized_model_every_num_seconds since the last\n",
    "                    # kept checkpoint.\n",
    "                    remove_path = True\n",
    "                    if self._keep_serialized_model_every_num_seconds is not None:\n",
    "                        save_time = paths_to_remove[0]\n",
    "                        time_since_checkpoint_kept = save_time - self._last_permanent_saved_checkpoint_time\n",
    "                        if time_since_checkpoint_kept > self._keep_serialized_model_every_num_seconds:\n",
    "                            # We want to keep this checkpoint.\n",
    "                            remove_path = False\n",
    "                            self._last_permanent_saved_checkpoint_time = save_time\n",
    "                    if remove_path:\n",
    "                        for fname in paths_to_remove[1:]:\n",
    "                            os.remove(fname)\n",
    "\n",
    "    def find_latest_checkpoint(self) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Return the location of the latest model and training state files.\n",
    "        If there isn't a valid checkpoint then return None.\n",
    "        \"\"\"\n",
    "        have_checkpoint = (self._serialization_dir is not None and\n",
    "                           any(\"model_state_epoch_\" in x for x in os.listdir(self._serialization_dir)))\n",
    "\n",
    "        if not have_checkpoint:\n",
    "            return None\n",
    "\n",
    "        serialization_files = os.listdir(self._serialization_dir)\n",
    "        model_checkpoints = [x for x in serialization_files if \"model_state_epoch\" in x]\n",
    "        # Get the last checkpoint file.  Epochs are specified as either an\n",
    "        # int (for end of epoch files) or with epoch and timestamp for\n",
    "        # within epoch checkpoints, e.g. 5.2018-02-02-15-33-42\n",
    "        found_epochs = [\n",
    "                # pylint: disable=anomalous-backslash-in-string\n",
    "                re.search(\"model_state_epoch_([0-9\\.\\-]+)\\.th\", x).group(1)\n",
    "                for x in model_checkpoints\n",
    "        ]\n",
    "        int_epochs: Any = []\n",
    "        for epoch in found_epochs:\n",
    "            pieces = epoch.split('.')\n",
    "            if len(pieces) == 1:\n",
    "                # Just a single epoch without timestamp\n",
    "                int_epochs.append([int(pieces[0]), 0])\n",
    "            else:\n",
    "                # has a timestamp\n",
    "                int_epochs.append([int(pieces[0]), pieces[1]])\n",
    "        last_epoch = sorted(int_epochs, reverse=True)[0]\n",
    "        if last_epoch[1] == 0:\n",
    "            epoch_to_load = str(last_epoch[0])\n",
    "        else:\n",
    "            epoch_to_load = '{0}.{1}'.format(last_epoch[0], last_epoch[1])\n",
    "\n",
    "        model_path = os.path.join(self._serialization_dir,\n",
    "                                  \"model_state_epoch_{}.th\".format(epoch_to_load))\n",
    "        training_state_path = os.path.join(self._serialization_dir,\n",
    "                                           \"training_state_epoch_{}.th\".format(epoch_to_load))\n",
    "\n",
    "        return (model_path, training_state_path)\n",
    "\n",
    "    def _restore_checkpoint(self) -> Tuple[int, List[float]]:\n",
    "        \"\"\"\n",
    "        Restores a model from a serialization_dir to the last saved checkpoint.\n",
    "        This includes an epoch count and optimizer state, which is serialized separately\n",
    "        from  model parameters. This function should only be used to continue training -\n",
    "        if you wish to load a model for inference/load parts of a model into a new\n",
    "        computation graph, you should use the native Pytorch functions:\n",
    "        `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``\n",
    "\n",
    "        If ``self._serialization_dir`` does not exist or does not contain any checkpointed weights,\n",
    "        this function will do nothing and return 0.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        epoch: int\n",
    "            The epoch at which to resume training, which should be one after the epoch\n",
    "            in the saved training state.\n",
    "        \"\"\"\n",
    "        latest_checkpoint = self.find_latest_checkpoint()\n",
    "\n",
    "        if latest_checkpoint is None:\n",
    "            # No checkpoint to restore, start at 0\n",
    "            return 0, []\n",
    "\n",
    "        model_path, training_state_path = latest_checkpoint\n",
    "\n",
    "        # Load the parameters onto CPU, then transfer to GPU.\n",
    "        # This avoids potential OOM on GPU for large models that\n",
    "        # load parameters onto GPU then make a new GPU copy into the parameter\n",
    "        # buffer. The GPU transfer happens implicitly in load_state_dict.\n",
    "        model_state = torch.load(model_path, map_location=util.device_mapping(-1))\n",
    "        training_state = torch.load(training_state_path, map_location=util.device_mapping(-1))\n",
    "        self._model.load_state_dict(model_state)\n",
    "        self._optimizer.load_state_dict(training_state[\"optimizer\"])\n",
    "        if self._learning_rate_scheduler is not None and \"learning_rate_scheduler\" in training_state:\n",
    "            self._learning_rate_scheduler.lr_scheduler.load_state_dict(\n",
    "                    training_state[\"learning_rate_scheduler\"])\n",
    "        move_optimizer_to_cuda(self._optimizer)\n",
    "\n",
    "        # We didn't used to save `validation_metric_per_epoch`, so we can't assume\n",
    "        # that it's part of the trainer state. If it's not there, an empty list is all\n",
    "        # we can do.\n",
    "        if \"val_metric_per_epoch\" not in training_state:\n",
    "            logger.warning(\"trainer state `val_metric_per_epoch` not found, using empty list\")\n",
    "            val_metric_per_epoch: List[float] = []\n",
    "        else:\n",
    "            val_metric_per_epoch = training_state[\"val_metric_per_epoch\"]\n",
    "\n",
    "        if isinstance(training_state[\"epoch\"], int):\n",
    "            epoch_to_return = training_state[\"epoch\"] + 1\n",
    "        else:\n",
    "            epoch_to_return = int(training_state[\"epoch\"].split('.')[0]) + 1\n",
    "\n",
    "        # For older checkpoints with batch_num_total missing, default to old behavior where\n",
    "        # it is unchanged.\n",
    "        batch_num_total = training_state.get('batch_num_total')\n",
    "        if batch_num_total is not None:\n",
    "            self._batch_num_total = batch_num_total\n",
    "\n",
    "        return epoch_to_return, val_metric_per_epoch\n",
    "\n",
    "    # Requires custom from_params.\n",
    "    @classmethod\n",
    "    def from_params(cls,\n",
    "                    model: Model,\n",
    "                    serialization_dir: str,\n",
    "                    iterator: DataIterator,\n",
    "                    iterator_aux: DataIterator,\n",
    "                    iterator_aux2: DataIterator,\n",
    "                    train_data: Iterable[Instance],\n",
    "                    train_data_aux: Iterable[Instance],\n",
    "                    train_data_aux2: Iterable[Instance],\n",
    "                    mixing_ratio: float,\n",
    "                    mixing_ratio2: float,\n",
    "                    cutoff_epoch: int,\n",
    "                    validation_data: Optional[Iterable[Instance]],\n",
    "                    validation_data_aux: Optional[Iterable[Instance]],\n",
    "                    validation_data_aux2: Optional[Iterable[Instance]],\n",
    "                    params: Params,\n",
    "                    validation_iterator: DataIterator = None) -> 'MultiTaskTrainer2':\n",
    "\n",
    "        patience = params.pop_int(\"patience\", None)\n",
    "        validation_metric = params.pop(\"validation_metric\", \"-loss\")\n",
    "        shuffle = params.pop_bool(\"shuffle\", True)\n",
    "        num_epochs = params.pop_int(\"num_epochs\", 20)\n",
    "        cuda_device = params.pop_int(\"cuda_device\", -1)\n",
    "        grad_norm = params.pop_float(\"grad_norm\", None)\n",
    "        grad_clipping = params.pop_float(\"grad_clipping\", None)\n",
    "        lr_scheduler_params = params.pop(\"learning_rate_scheduler\", None)\n",
    "\n",
    "        if cuda_device >= 0:\n",
    "            model = model.cuda(cuda_device)\n",
    "        parameters = [[n, p] for n, p in model.named_parameters() if p.requires_grad]\n",
    "        optimizer = Optimizer.from_params(parameters, params.pop(\"optimizer\"))\n",
    "\n",
    "        if lr_scheduler_params:\n",
    "            scheduler = LearningRateScheduler.from_params(optimizer, lr_scheduler_params)\n",
    "        else:\n",
    "            scheduler = None\n",
    "\n",
    "        num_serialized_models_to_keep = params.pop_int(\"num_serialized_models_to_keep\", 20)\n",
    "        keep_serialized_model_every_num_seconds = params.pop_int(\n",
    "                \"keep_serialized_model_every_num_seconds\", None)\n",
    "        model_save_interval = params.pop_float(\"model_save_interval\", None)\n",
    "        summary_interval = params.pop_int(\"summary_interval\", 100)\n",
    "        histogram_interval = params.pop_int(\"histogram_interval\", None)\n",
    "        should_log_parameter_statistics = params.pop_bool(\"should_log_parameter_statistics\", True)\n",
    "        should_log_learning_rate = params.pop_bool(\"should_log_learning_rate\", False)\n",
    "\n",
    "        params.assert_empty(cls.__name__)\n",
    "        return MultiTaskTrainer2(model, optimizer, iterator,\n",
    "                                    train_data,\n",
    "                                    train_data_aux,\n",
    "                                    train_data_aux2,\n",
    "                                    mixing_ratio,\n",
    "                                    mixing_ratio2,\n",
    "                                    cutoff_epoch,\n",
    "                                    validation_data,\n",
    "                                    validation_data_aux,\n",
    "                                    validation_data_aux2,\n",
    "                                    patience=patience,\n",
    "                                    validation_metric=validation_metric,\n",
    "                                    validation_iterator=validation_iterator,\n",
    "                                    shuffle=shuffle,\n",
    "                                    num_epochs=num_epochs,\n",
    "                                    serialization_dir=serialization_dir,\n",
    "                                    cuda_device=cuda_device,\n",
    "                                    grad_norm=grad_norm,\n",
    "                                    grad_clipping=grad_clipping,\n",
    "                                    learning_rate_scheduler=scheduler,\n",
    "                                    num_serialized_models_to_keep=num_serialized_models_to_keep,\n",
    "                                    keep_serialized_model_every_num_seconds=keep_serialized_model_every_num_seconds,\n",
    "                                    model_save_interval=model_save_interval,\n",
    "                                    summary_interval=summary_interval,\n",
    "                                    histogram_interval=histogram_interval,\n",
    "                                    should_log_parameter_statistics=should_log_parameter_statistics,\n",
    "                                    should_log_learning_rate=should_log_learning_rate,\n",
    "                                    iterator_aux=iterator_aux,\n",
    "                                    iterator_aux2=iterator_aux2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d971a-b82c-4aca-9a3f-7f8bf3bc2f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "48226276-8712-4d73-a276-f024629d4d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-d60b6b1326e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiment_configs/custom_config.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./runs/test1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-21bee45f3107>\u001b[0m in \u001b[0;36mtrain_model_from_file\u001b[0;34m(parameter_filename, serialization_dir, overrides, file_friendly_logging, recover)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Load the experiment config from a file and pass it to ``train_model``.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_friendly_logging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-21bee45f3107>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(params, serialization_dir, file_friendly_logging, recover)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m# if we have completed an epoch, try to create a model archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-2e3a81dc5c77>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-2e3a81dc5c77>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model_from_file('experiment_configs/custom_config.json', './runs/test1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41a148-5521-4eda-b649-35a0fc1ab9cc",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1258675-d32b-4fb6-9515-9a97ad5c0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params.from_file('experiment_configs/custom_config.json', \"\")\n",
    "serialization_dir = './runs/test'\n",
    "file_friendly_logging = False\n",
    "recover = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb79d800-07d0-4b55-abe3-63a92dab064f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   random_seed = 13370\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   numpy_seed = 1337\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   pytorch_seed = 133\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.checks -   Pytorch version: 1.10.2\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'multilabel': 'false', 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.type = scicite_datasetreader\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = None\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.use_lexicon_features = False\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.use_sparse_lexicon_features = false\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.multilabel = false\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.with_elmo = true\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   dataset_reader.reader_format = flat\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   validation_dataset_reader = None\n",
      "03/30/2024 10:05:32 - INFO - allennlp.common.params -   train_data_path = scicite_data/train.jsonl\n",
      "03/30/2024 10:05:32 - INFO - __main__ -   Reading training data from scicite_data/train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "8243it [00:02, 3499.11it/s]\n",
      "\n",
      "03/30/2024 10:05:34 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_section_title_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:05:34 - INFO - allennlp.common.params -   dataset_reader_aux.type = scicite_section_title_data_reader\n",
      "03/30/2024 10:05:34 - INFO - allennlp.common.params -   dataset_reader_aux.with_elmo = true\n",
      "03/30/2024 10:05:34 - INFO - allennlp.common.params -   train_data_path_aux = scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "03/30/2024 10:05:34 - INFO - __main__ -   Reading auxiliary training data from scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "43796it [00:10, 4379.60it/s]\n",
      "91323it [00:20, 4598.98it/s]\n",
      "91412it [00:20, 4566.76it/s]\n",
      "\n",
      "03/30/2024 10:05:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_cite_worthiness_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:05:54 - INFO - allennlp.common.params -   dataset_reader_aux2.type = scicite_cite_worthiness_data_reader\n",
      "03/30/2024 10:05:54 - INFO - allennlp.common.params -   dataset_reader_aux2.with_elmo = true\n",
      "03/30/2024 10:05:54 - INFO - allennlp.common.params -   train_data_path_aux2 = scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "03/30/2024 10:05:54 - INFO - __main__ -   Reading second auxiliary training data for from scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "59869it [00:10, 5986.67it/s]\n",
      "73484it [00:11, 6175.99it/s]\n",
      "\n",
      "03/30/2024 10:06:06 - INFO - allennlp.common.params -   aux_sample_fraction = 1.0\n",
      "03/30/2024 10:06:06 - INFO - __main__ -   Inflating train data from 8243 to 91412 samples\n",
      "03/30/2024 10:06:06 - INFO - allennlp.common.params -   validation_data_path = scicite_data/dev.jsonl\n",
      "03/30/2024 10:06:06 - INFO - __main__ -   Reading validation data from scicite_data/dev.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "916it [00:00, 3636.51it/s]\n",
      "\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   validation_data_path_aux = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   validation_data_path_aux2 = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   test_data_path = scicite_data/test.jsonl\n",
      "03/30/2024 10:06:07 - INFO - __main__ -   Reading test data from scicite_data/test.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "1861it [00:00, 3672.42it/s]\n",
      "\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   test_data_path_aux = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   test_data_path_aux2 = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   mixing_ratio = 0.05\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   mixing_ratio2 = 0.05\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   cutoff_epoch = -1\n",
      "03/30/2024 10:06:07 - INFO - __main__ -   From dataset instances, train, validation, test will be considered for vocabulary creation.\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.type = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.extend = False\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.directory_path = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.min_count = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.max_vocab_size = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.min_pretrained_embeddings = None\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.only_include_pretrained_words = False\n",
      "03/30/2024 10:06:07 - INFO - allennlp.common.params -   vocabulary.tokens_to_add = None\n",
      "03/30/2024 10:06:07 - INFO - scicite.training.vocabulary_multitask -   Fitting token dictionary from dataset.\n",
      "0it [00:00, ?it/s]\n",
      "94189it [00:04, 21887.33it/s]\n",
      "\n",
      "03/30/2024 10:06:11 - INFO - scicite.training.vocabulary_multitask -   Fitting token dictionary from auxillary dataset.\n",
      "  0%|          | 0/146968 [00:00<?, ?it/s]\n",
      "100%|##########| 146968/146968 [00:04<00:00, 31560.97it/s]\n",
      "\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'citation_text_encoder': {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 100, 'input_size': 1124, 'num_layers': 2, 'type': 'gru'}, 'classifier_feedforward': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 3], 'input_dim': 200, 'num_layers': 2}, 'classifier_feedforward_2': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 5], 'input_dim': 200, 'num_layers': 2}, 'classifier_feedforward_3': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 2], 'input_dim': 200, 'num_layers': 2}, 'data_format': 'scicite_flat_jsonlines', 'elmo_text_field_embedder': {'elmo': {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'}, 'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}}, 'lexicon_embedder': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'vocab_namespace': 'lexicon_ids'}, 'multilabel': 'false', 'report_auxiliary_metrics': 'true', 'text_field_embedder': {'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}}, 'type': 'scaffold_bilstm_attention_classifier', 'use_lexicon_features': 'false', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f4774aecf98>}\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.type = scaffold_bilstm_attention_classifier\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.with_elmo = true\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'elmo': {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'}, 'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f4774aecf98>}\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.type = basic\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.embedder_to_indexer_map = None\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.allow_unmatched_keys = False\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.token_embedders = None\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f4774aecf98>}\n",
      "03/30/2024 10:06:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.type = elmo_token_embedder\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.options_file = https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.weight_file = https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.requires_grad = False\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.do_layer_norm = true\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.dropout = 0.5\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.namespace_to_cache = None\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.projection_dim = None\n",
      "03/30/2024 10:06:19 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.scalar_mix_parameters = None\n",
      "03/30/2024 10:06:19 - INFO - allennlp.modules.elmo -   Initializing ELMo\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f4774aecf98>}\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.type = embedding\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.num_embeddings = None\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.vocab_namespace = tokens\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.embedding_dim = 100\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.projection_dim = None\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.trainable = false\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.padding_index = None\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.max_norm = None\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.norm_type = 2.0\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.scale_grad_by_freq = False\n",
      "03/30/2024 10:06:39 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.sparse = False\n",
      "03/30/2024 10:06:39 - INFO - allennlp.modules.token_embedders.embedding -   Reading pretrained embeddings from file\n",
      "0it [00:00, ?it/s]\n",
      "400000it [00:02, 186878.63it/s]\n",
      "\n",
      "03/30/2024 10:06:42 - INFO - allennlp.modules.token_embedders.embedding -   Initializing pre-trained embedding layer\n",
      "03/30/2024 10:06:42 - INFO - allennlp.modules.token_embedders.embedding -   Pretrained embeddings were found for 38133 out of 142711 tokens\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 100, 'input_size': 1124, 'num_layers': 2, 'type': 'gru'} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.type = gru\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.batch_first = True\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.stateful = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.bidirectional = True\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.dropout = 0.3\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.hidden_size = 100\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.input_size = 1124\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.num_layers = 2\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.citation_text_encoder.batch_first = True\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward.input_dim = 200\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward.num_layers = 2\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward.hidden_dims = [20, 3]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward.activations = ['linear', 'linear']\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward.dropout = [0, 0]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_2.input_dim = 200\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_2.num_layers = 2\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_2.hidden_dims = [20, 5]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_2.activations = ['linear', 'linear']\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_2.dropout = [0, 0]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_3.input_dim = 200\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_3.num_layers = 2\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_3.hidden_dims = [20, 2]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_3.activations = ['linear', 'linear']\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.classifier_feedforward_3.dropout = [0, 0]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.initializer = []\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.regularizer = []\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.use_lexicon_features = false\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.use_sparse_lexicon_features = false\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.data_format = scicite_flat_jsonlines\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.report_auxiliary_metrics = true\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   model.predict_mode = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      attention_seq2seq.attention\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l0\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l0\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l0\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l0\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2\n",
      "03/30/2024 10:06:43 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_tokens.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred mode: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.type = bucket\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.padding_noise = 0.1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.biggest_batch_first = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.batch_size = 16\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.instances_per_epoch = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.max_instances_in_memory = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.cache_instances = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.track_epoch = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator.maximum_samples_per_batch = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.type = bucket\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.padding_noise = 0.1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.biggest_batch_first = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.batch_size = 16\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.instances_per_epoch = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.max_instances_in_memory = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.cache_instances = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.track_epoch = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux.maximum_samples_per_batch = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.type = bucket\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.padding_noise = 0.1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.biggest_batch_first = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.batch_size = 16\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.instances_per_epoch = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.max_instances_in_memory = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.cache_instances = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.track_epoch = False\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   iterator_aux2.maximum_samples_per_batch = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   validation_iterator = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.no_grad = ()\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   Following parameters are Frozen  (without gradient):\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_tokens.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   Following parameters are Tunable (with gradient):\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l0\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l0\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l0\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l0\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l0_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l1\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l1\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l1\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l1\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l1_reverse\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward._linear_layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward._linear_layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward._linear_layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward._linear_layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_2._linear_layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_2._linear_layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_2._linear_layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_2._linear_layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_3._linear_layers.0.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_3._linear_layers.0.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_3._linear_layers.1.weight\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   classifier_feedforward_3._linear_layers.1.bias\n",
      "03/30/2024 10:06:43 - INFO - __main__ -   attention_seq2seq.attention\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.patience = 4\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.validation_metric = +average_F1\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.shuffle = True\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.num_epochs = 10\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.cuda_device = 0\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.grad_norm = None\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.grad_clipping = 5\n",
      "03/30/2024 10:06:43 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler = None\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.optimizer.type = adadelta\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.optimizer.parameter_groups = None\n",
      "03/30/2024 10:06:45 - INFO - allennlp.training.optimizers -   Number of trainable parameters: 929274\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.optimizer.rho = 0.95\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.num_serialized_models_to_keep = 20\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.keep_serialized_model_every_num_seconds = None\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.model_save_interval = None\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.summary_interval = 100\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.histogram_interval = None\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.should_log_parameter_statistics = True\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   trainer.should_log_learning_rate = False\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   evaluate_on_test = true\n",
      "03/30/2024 10:06:45 - INFO - allennlp.common.params -   evaluate_aux_on_test = true\n",
      "03/30/2024 10:06:45 - INFO - __main__ -   Beginning training.\n",
      "03/30/2024 10:06:45 - INFO - __main__ -   Epoch 0/9\n",
      "03/30/2024 10:06:45 - INFO - __main__ -   Peak CPU memory usage MB: 7241.656\n",
      "03/30/2024 10:06:45 - INFO - __main__ -   GPU 0 memory usage MB: 2481\n",
      "03/30/2024 10:06:45 - INFO - __main__ -   Multitask Training\n",
      "03/30/2024 10:06:45 - INFO - __main__ -   Training\n",
      "  0%|          | 0/5714 [00:00<?, ?it/s]\n",
      "background_P: 0.0000, background_R: 0.0000, background_F1: 0.0000, method_P: 0.0000, method_R: 0.0000, method_F1: 0.0000, result_P: 0.0000, result_R: 0.0000, result_F1: 0.0000, average_F1: 0.0000, aux-sec--introduction_P: 0.0000, aux-sec--introduction_R: 0.0000, aux-sec--introduction_F1: 0.0000, aux-sec--conclusion_P: 0.1875, aux-sec--conclusion_R: 1.0000, aux-sec--conclusion_F1: 0.3158, aux-sec--experiments_P: 0.0000, aux-sec--experiments_R: 0.0000, aux-sec--experiments_F1: 0.0000, aux-sec--method_P: 0.0000, aux-sec--method_R: 0.0000, aux-sec--method_F1: 0.0000, aux-sec--related work_P: 0.0000, aux-sec--related work_R: 0.0000, aux-sec--related work_F1: 0.0000, aux-sec--average_F1: 0.0632, aux-worth--False_P: 0.9375, aux-worth--False_R: 1.0000, aux-worth--False_F1: 0.9677, aux-worth--True_P: 0.0000, aux-worth--True_R: 0.0000, aux-worth--True_F1: 0.0000, aux-worth--average_F1: 0.4839, loss: 1.3970 ||:   0%|          | 1/5714 [00:35<56:48:47, 35.80s/it]\n",
      "background_P: 0.6404, background_R: 0.7790, background_F1: 0.7029, method_P: 0.5781, method_R: 0.4353, method_F1: 0.4966, result_P: 0.3651, result_R: 0.2371, result_F1: 0.2875, average_F1: 0.4957, aux-sec--introduction_P: 0.3615, aux-sec--introduction_R: 0.6691, aux-sec--introduction_F1: 0.4694, aux-sec--conclusion_P: 0.1631, aux-sec--conclusion_R: 0.2436, aux-sec--conclusion_F1: 0.1954, aux-sec--experiments_P: 0.3810, aux-sec--experiments_R: 0.0988, aux-sec--experiments_F1: 0.1569, aux-sec--method_P: 0.0000, aux-sec--method_R: 0.0000, aux-sec--method_F1: 0.0000, aux-sec--related work_P: 0.0625, aux-sec--related work_R: 0.0137, aux-sec--related work_F1: 0.0225, aux-sec--average_F1: 0.1688, aux-worth--False_P: 0.8625, aux-worth--False_R: 1.0000, aux-worth--False_F1: 0.9262, aux-worth--True_P: 0.0000, aux-worth--True_R: 0.0000, aux-worth--True_F1: 0.0000, aux-worth--average_F1: 0.4631, loss: 0.9789 ||:   1%|          | 50/5714 [00:45<1:06:38,  1.42it/s]\n",
      "background_P: 0.7061, background_R: 0.8070, background_F1: 0.7532, method_P: 0.6253, method_R: 0.5133, method_F1: 0.5638, result_P: 0.5515, result_R: 0.4233, result_F1: 0.4789, average_F1: 0.5986, aux-sec--introduction_P: 0.3837, aux-sec--introduction_R: 0.7888, aux-sec--introduction_F1: 0.5163, aux-sec--conclusion_P: 0.1947, aux-sec--conclusion_R: 0.1667, aux-sec--conclusion_F1: 0.1796, aux-sec--experiments_P: 0.2921, aux-sec--experiments_R: 0.0929, aux-sec--experiments_F1: 0.1409, aux-sec--method_P: 0.2500, aux-sec--method_R: 0.0076, aux-sec--method_F1: 0.0148, aux-sec--related work_P: 0.1064, aux-sec--related work_R: 0.0309, aux-sec--related work_F1: 0.0478, aux-sec--average_F1: 0.1799, aux-worth--False_P: 0.8648, aux-worth--False_R: 0.9993, aux-worth--False_F1: 0.9272, aux-worth--True_P: 0.0000, aux-worth--True_R: 0.0000, aux-worth--True_F1: 0.0000, aux-worth--average_F1: 0.4636, loss: 0.8593 ||:   2%|1         | 99/5714 [00:56<39:10,  2.39it/s]  \n",
      "03/30/2024 10:07:41 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:07:41 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:07:41 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.7323, background_R: 0.8173, background_F1: 0.7725, method_P: 0.6621, method_R: 0.5660, method_F1: 0.6103, result_P: 0.6154, result_R: 0.5031, result_F1: 0.5536, average_F1: 0.6455, aux-sec--introduction_P: 0.3997, aux-sec--introduction_R: 0.8236, aux-sec--introduction_F1: 0.5382, aux-sec--conclusion_P: 0.2417, aux-sec--conclusion_R: 0.1560, aux-sec--conclusion_F1: 0.1896, aux-sec--experiments_P: 0.2727, aux-sec--experiments_R: 0.0741, aux-sec--experiments_F1: 0.1165, aux-sec--method_P: 0.2857, aux-sec--method_R: 0.0623, aux-sec--method_F1: 0.1023, aux-sec--related work_P: 0.0877, aux-sec--related work_R: 0.0226, aux-sec--related work_F1: 0.0360, aux-sec--average_F1: 0.1965, aux-worth--False_P: 0.8753, aux-worth--False_R: 0.9995, aux-worth--False_F1: 0.9333, aux-worth--True_P: 0.5000, aux-worth--True_R: 0.0034, aux-worth--True_F1: 0.0068, aux-worth--average_F1: 0.4700, loss: 0.7923 ||:   3%|2         | 147/5714 [01:06<30:13,  3.07it/s]\n",
      "background_P: 0.7527, background_R: 0.8304, background_F1: 0.7897, method_P: 0.6680, method_R: 0.5752, method_F1: 0.6181, result_P: 0.6667, result_R: 0.5621, result_F1: 0.6099, average_F1: 0.6726, aux-sec--introduction_P: 0.4069, aux-sec--introduction_R: 0.8362, aux-sec--introduction_F1: 0.5474, aux-sec--conclusion_P: 0.2787, aux-sec--conclusion_R: 0.1661, aux-sec--conclusion_F1: 0.2082, aux-sec--experiments_P: 0.2793, aux-sec--experiments_R: 0.0584, aux-sec--experiments_F1: 0.0966, aux-sec--method_P: 0.3046, aux-sec--method_R: 0.0895, aux-sec--method_F1: 0.1383, aux-sec--related work_P: 0.0845, aux-sec--related work_R: 0.0212, aux-sec--related work_F1: 0.0339, aux-sec--average_F1: 0.2049, aux-worth--False_P: 0.8665, aux-worth--False_R: 0.9967, aux-worth--False_F1: 0.9270, aux-worth--True_P: 0.1818, aux-worth--True_R: 0.0048, aux-worth--True_F1: 0.0093, aux-worth--average_F1: 0.4682, loss: 0.7555 ||:   3%|3         | 195/5714 [01:17<26:16,  3.50it/s]\n",
      "03/30/2024 10:08:03 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:08:03 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:08:03 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.7663, background_R: 0.8359, background_F1: 0.7996, method_P: 0.6780, method_R: 0.5948, method_F1: 0.6337, result_P: 0.6912, result_R: 0.6004, result_F1: 0.6426, average_F1: 0.6919, aux-sec--introduction_P: 0.4082, aux-sec--introduction_R: 0.8396, aux-sec--introduction_F1: 0.5493, aux-sec--conclusion_P: 0.3063, aux-sec--conclusion_R: 0.1804, aux-sec--conclusion_F1: 0.2270, aux-sec--experiments_P: 0.2719, aux-sec--experiments_R: 0.0478, aux-sec--experiments_F1: 0.0813, aux-sec--method_P: 0.3054, aux-sec--method_R: 0.1111, aux-sec--method_F1: 0.1629, aux-sec--related work_P: 0.0811, aux-sec--related work_R: 0.0170, aux-sec--related work_F1: 0.0281, aux-sec--average_F1: 0.2097, aux-worth--False_P: 0.8670, aux-worth--False_R: 0.9964, aux-worth--False_F1: 0.9272, aux-worth--True_P: 0.1429, aux-worth--True_R: 0.0039, aux-worth--True_F1: 0.0076, aux-worth--average_F1: 0.4674, loss: 0.7265 ||:   4%|4         | 242/5714 [01:27<23:53,  3.82it/s]\n",
      "background_P: 0.7802, background_R: 0.8452, background_F1: 0.8114, method_P: 0.6882, method_R: 0.6081, method_F1: 0.6456, result_P: 0.7120, result_R: 0.6258, result_F1: 0.6661, average_F1: 0.7077, aux-sec--introduction_P: 0.4082, aux-sec--introduction_R: 0.8325, aux-sec--introduction_F1: 0.5478, aux-sec--conclusion_P: 0.3256, aux-sec--conclusion_R: 0.1957, aux-sec--conclusion_F1: 0.2445, aux-sec--experiments_P: 0.2759, aux-sec--experiments_R: 0.0422, aux-sec--experiments_F1: 0.0731, aux-sec--method_P: 0.3186, aux-sec--method_R: 0.1376, aux-sec--method_F1: 0.1922, aux-sec--related work_P: 0.0789, aux-sec--related work_R: 0.0147, aux-sec--related work_F1: 0.0247, aux-sec--average_F1: 0.2165, aux-worth--False_P: 0.8683, aux-worth--False_R: 0.9970, aux-worth--False_F1: 0.9282, aux-worth--True_P: 0.2000, aux-worth--True_R: 0.0049, aux-worth--True_F1: 0.0096, aux-worth--average_F1: 0.4689, loss: 0.6944 ||:   5%|5         | 288/5714 [01:38<22:44,  3.98it/s]\n",
      "03/30/2024 10:08:25 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:08:25 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:08:25 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.7915, background_R: 0.8510, background_F1: 0.8202, method_P: 0.7019, method_R: 0.6288, method_F1: 0.6633, result_P: 0.7178, result_R: 0.6351, result_F1: 0.6739, average_F1: 0.7192, aux-sec--introduction_P: 0.4133, aux-sec--introduction_R: 0.8295, aux-sec--introduction_F1: 0.5517, aux-sec--conclusion_P: 0.3418, aux-sec--conclusion_R: 0.2007, aux-sec--conclusion_F1: 0.2529, aux-sec--experiments_P: 0.2578, aux-sec--experiments_R: 0.0374, aux-sec--experiments_F1: 0.0653, aux-sec--method_P: 0.3176, aux-sec--method_R: 0.1549, aux-sec--method_F1: 0.2083, aux-sec--related work_P: 0.0789, aux-sec--related work_R: 0.0128, aux-sec--related work_F1: 0.0221, aux-sec--average_F1: 0.2201, aux-worth--False_P: 0.8677, aux-worth--False_R: 0.9972, aux-worth--False_F1: 0.9279, aux-worth--True_P: 0.2778, aux-worth--True_R: 0.0070, aux-worth--True_F1: 0.0137, aux-worth--average_F1: 0.4708, loss: 0.6723 ||:   6%|5         | 336/5714 [01:48<21:18,  4.21it/s]\n",
      "background_P: 0.7967, background_R: 0.8541, background_F1: 0.8244, method_P: 0.7074, method_R: 0.6389, method_F1: 0.6714, result_P: 0.7264, result_R: 0.6432, result_F1: 0.6823, average_F1: 0.7260, aux-sec--introduction_P: 0.4133, aux-sec--introduction_R: 0.8335, aux-sec--introduction_F1: 0.5526, aux-sec--conclusion_P: 0.3562, aux-sec--conclusion_R: 0.2010, aux-sec--conclusion_F1: 0.2570, aux-sec--experiments_P: 0.2595, aux-sec--experiments_R: 0.0334, aux-sec--experiments_F1: 0.0592, aux-sec--method_P: 0.3321, aux-sec--method_R: 0.1716, aux-sec--method_F1: 0.2263, aux-sec--related work_P: 0.0789, aux-sec--related work_R: 0.0117, aux-sec--related work_F1: 0.0203, aux-sec--average_F1: 0.2231, aux-worth--False_P: 0.8701, aux-worth--False_R: 0.9970, aux-worth--False_F1: 0.9293, aux-worth--True_P: 0.3043, aux-worth--True_R: 0.0087, aux-worth--True_F1: 0.0170, aux-worth--average_F1: 0.4731, loss: 0.6594 ||:   7%|6         | 384/5714 [01:58<20:41,  4.29it/s]\n",
      "03/30/2024 10:08:47 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:08:47 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:08:47 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8017, background_R: 0.8574, background_F1: 0.8286, method_P: 0.7157, method_R: 0.6503, method_F1: 0.6814, result_P: 0.7347, result_R: 0.6511, result_F1: 0.6904, average_F1: 0.7335, aux-sec--introduction_P: 0.4145, aux-sec--introduction_R: 0.8341, aux-sec--introduction_F1: 0.5538, aux-sec--conclusion_P: 0.3776, aux-sec--conclusion_R: 0.2179, aux-sec--conclusion_F1: 0.2763, aux-sec--experiments_P: 0.2740, aux-sec--experiments_R: 0.0348, aux-sec--experiments_F1: 0.0617, aux-sec--method_P: 0.3317, aux-sec--method_R: 0.1740, aux-sec--method_F1: 0.2282, aux-sec--related work_P: 0.0779, aux-sec--related work_R: 0.0107, aux-sec--related work_F1: 0.0188, aux-sec--average_F1: 0.2278, aux-worth--False_P: 0.8633, aux-worth--False_R: 0.9953, aux-worth--False_F1: 0.9246, aux-worth--True_P: 0.5821, aux-worth--True_R: 0.0403, aux-worth--True_F1: 0.0754, aux-worth--average_F1: 0.5000, loss: 0.6484 ||:   8%|7         | 429/5714 [02:09<20:19,  4.33it/s]\n",
      "background_P: 0.8079, background_R: 0.8608, background_F1: 0.8335, method_P: 0.7227, method_R: 0.6605, method_F1: 0.6902, result_P: 0.7447, result_R: 0.6638, result_F1: 0.7019, average_F1: 0.7419, aux-sec--introduction_P: 0.4162, aux-sec--introduction_R: 0.8313, aux-sec--introduction_F1: 0.5547, aux-sec--conclusion_P: 0.3801, aux-sec--conclusion_R: 0.2208, aux-sec--conclusion_F1: 0.2793, aux-sec--experiments_P: 0.2972, aux-sec--experiments_R: 0.0490, aux-sec--experiments_F1: 0.0841, aux-sec--method_P: 0.3208, aux-sec--method_R: 0.1678, aux-sec--method_F1: 0.2204, aux-sec--related work_P: 0.0875, aux-sec--related work_R: 0.0109, aux-sec--related work_F1: 0.0194, aux-sec--average_F1: 0.2316, aux-worth--False_P: 0.8645, aux-worth--False_R: 0.9948, aux-worth--False_F1: 0.9251, aux-worth--True_P: 0.5641, aux-worth--True_R: 0.0410, aux-worth--True_F1: 0.0765, aux-worth--average_F1: 0.5008, loss: 0.6331 ||:   8%|8         | 479/5714 [02:19<19:16,  4.53it/s]\n",
      "03/30/2024 10:09:08 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:09:08 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:09:08 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8127, background_R: 0.8635, background_F1: 0.8373, method_P: 0.7330, method_R: 0.6725, method_F1: 0.7014, result_P: 0.7524, result_R: 0.6772, result_F1: 0.7128, average_F1: 0.7505, aux-sec--introduction_P: 0.4171, aux-sec--introduction_R: 0.8276, aux-sec--introduction_F1: 0.5547, aux-sec--conclusion_P: 0.3793, aux-sec--conclusion_R: 0.2190, aux-sec--conclusion_F1: 0.2777, aux-sec--experiments_P: 0.2987, aux-sec--experiments_R: 0.0492, aux-sec--experiments_F1: 0.0845, aux-sec--method_P: 0.3171, aux-sec--method_R: 0.1668, aux-sec--method_F1: 0.2186, aux-sec--related work_P: 0.1215, aux-sec--related work_R: 0.0181, aux-sec--related work_F1: 0.0315, aux-sec--average_F1: 0.2334, aux-worth--False_P: 0.8678, aux-worth--False_R: 0.9938, aux-worth--False_F1: 0.9265, aux-worth--True_P: 0.5055, aux-worth--True_R: 0.0399, aux-worth--True_F1: 0.0740, aux-worth--average_F1: 0.5003, loss: 0.6211 ||:   9%|9         | 529/5714 [02:29<18:59,  4.55it/s]\n",
      "background_P: 0.8169, background_R: 0.8670, background_F1: 0.8412, method_P: 0.7422, method_R: 0.6829, method_F1: 0.7113, result_P: 0.7546, result_R: 0.6789, result_F1: 0.7148, average_F1: 0.7558, aux-sec--introduction_P: 0.4164, aux-sec--introduction_R: 0.8243, aux-sec--introduction_F1: 0.5533, aux-sec--conclusion_P: 0.3890, aux-sec--conclusion_R: 0.2272, aux-sec--conclusion_F1: 0.2869, aux-sec--experiments_P: 0.3080, aux-sec--experiments_R: 0.0534, aux-sec--experiments_F1: 0.0911, aux-sec--method_P: 0.3171, aux-sec--method_R: 0.1615, aux-sec--method_F1: 0.2140, aux-sec--related work_P: 0.1439, aux-sec--related work_R: 0.0253, aux-sec--related work_F1: 0.0431, aux-sec--average_F1: 0.2377, aux-worth--False_P: 0.8670, aux-worth--False_R: 0.9924, aux-worth--False_F1: 0.9255, aux-worth--True_P: 0.5122, aux-worth--True_R: 0.0495, aux-worth--True_F1: 0.0903, aux-worth--average_F1: 0.5079, loss: 0.6130 ||:  10%|#         | 576/5714 [02:40<19:12,  4.46it/s]\n",
      "03/30/2024 10:09:31 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:09:31 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:09:31 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8207, background_R: 0.8701, background_F1: 0.8447, method_P: 0.7525, method_R: 0.6938, method_F1: 0.7220, result_P: 0.7584, result_R: 0.6855, result_F1: 0.7201, average_F1: 0.7622, aux-sec--introduction_P: 0.4168, aux-sec--introduction_R: 0.8227, aux-sec--introduction_F1: 0.5533, aux-sec--conclusion_P: 0.3968, aux-sec--conclusion_R: 0.2328, aux-sec--conclusion_F1: 0.2934, aux-sec--experiments_P: 0.3105, aux-sec--experiments_R: 0.0575, aux-sec--experiments_F1: 0.0970, aux-sec--method_P: 0.3133, aux-sec--method_R: 0.1601, aux-sec--method_F1: 0.2120, aux-sec--related work_P: 0.1389, aux-sec--related work_R: 0.0236, aux-sec--related work_F1: 0.0404, aux-sec--average_F1: 0.2392, aux-worth--False_P: 0.8692, aux-worth--False_R: 0.9928, aux-worth--False_F1: 0.9269, aux-worth--True_P: 0.5231, aux-worth--True_R: 0.0500, aux-worth--True_F1: 0.0912, aux-worth--average_F1: 0.5091, loss: 0.6032 ||:  11%|#         | 626/5714 [02:51<18:28,  4.59it/s]\n",
      "background_P: 0.8231, background_R: 0.8706, background_F1: 0.8462, method_P: 0.7544, method_R: 0.6964, method_F1: 0.7242, result_P: 0.7549, result_R: 0.6864, result_F1: 0.7190, average_F1: 0.7632, aux-sec--introduction_P: 0.4194, aux-sec--introduction_R: 0.8247, aux-sec--introduction_F1: 0.5560, aux-sec--conclusion_P: 0.4020, aux-sec--conclusion_R: 0.2330, aux-sec--conclusion_F1: 0.2950, aux-sec--experiments_P: 0.3041, aux-sec--experiments_R: 0.0550, aux-sec--experiments_F1: 0.0931, aux-sec--method_P: 0.3136, aux-sec--method_R: 0.1628, aux-sec--method_F1: 0.2143, aux-sec--related work_P: 0.1400, aux-sec--related work_R: 0.0232, aux-sec--related work_F1: 0.0397, aux-sec--average_F1: 0.2396, aux-worth--False_P: 0.8689, aux-worth--False_R: 0.9922, aux-worth--False_F1: 0.9265, aux-worth--True_P: 0.5602, aux-worth--True_R: 0.0625, aux-worth--True_F1: 0.1125, aux-worth--average_F1: 0.5195, loss: 0.5961 ||:  12%|#1        | 675/5714 [03:02<18:27,  4.55it/s]\n",
      "03/30/2024 10:09:52 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:09:52 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:09:52 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8257, background_R: 0.8723, background_F1: 0.8483, method_P: 0.7581, method_R: 0.7015, method_F1: 0.7287, result_P: 0.7599, result_R: 0.6923, result_F1: 0.7246, average_F1: 0.7672, aux-sec--introduction_P: 0.4216, aux-sec--introduction_R: 0.8266, aux-sec--introduction_F1: 0.5584, aux-sec--conclusion_P: 0.4078, aux-sec--conclusion_R: 0.2375, aux-sec--conclusion_F1: 0.3002, aux-sec--experiments_P: 0.3153, aux-sec--experiments_R: 0.0585, aux-sec--experiments_F1: 0.0987, aux-sec--method_P: 0.3114, aux-sec--method_R: 0.1601, aux-sec--method_F1: 0.2115, aux-sec--related work_P: 0.1391, aux-sec--related work_R: 0.0218, aux-sec--related work_F1: 0.0377, aux-sec--average_F1: 0.2413, aux-worth--False_P: 0.8700, aux-worth--False_R: 0.9914, aux-worth--False_F1: 0.9268, aux-worth--True_P: 0.5635, aux-worth--True_R: 0.0698, aux-worth--True_F1: 0.1242, aux-worth--average_F1: 0.5255, loss: 0.5888 ||:  13%|#2        | 724/5714 [03:12<17:59,  4.62it/s]\n",
      "background_P: 0.8273, background_R: 0.8733, background_F1: 0.8497, method_P: 0.7596, method_R: 0.7027, method_F1: 0.7300, result_P: 0.7638, result_R: 0.6978, result_F1: 0.7293, average_F1: 0.7697, aux-sec--introduction_P: 0.4223, aux-sec--introduction_R: 0.8282, aux-sec--introduction_F1: 0.5594, aux-sec--conclusion_P: 0.4124, aux-sec--conclusion_R: 0.2402, aux-sec--conclusion_F1: 0.3036, aux-sec--experiments_P: 0.3158, aux-sec--experiments_R: 0.0645, aux-sec--experiments_F1: 0.1071, aux-sec--method_P: 0.3075, aux-sec--method_R: 0.1535, aux-sec--method_F1: 0.2048, aux-sec--related work_P: 0.1382, aux-sec--related work_R: 0.0209, aux-sec--related work_F1: 0.0362, aux-sec--average_F1: 0.2422, aux-worth--False_P: 0.8702, aux-worth--False_R: 0.9900, aux-worth--False_F1: 0.9263, aux-worth--True_P: 0.6000, aux-worth--True_R: 0.0919, aux-worth--True_F1: 0.1594, aux-worth--average_F1: 0.5428, loss: 0.5824 ||:  14%|#3        | 773/5714 [03:23<17:57,  4.59it/s]\n",
      "03/30/2024 10:10:14 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:10:14 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:10:14 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8303, background_R: 0.8742, background_F1: 0.8517, method_P: 0.7627, method_R: 0.7085, method_F1: 0.7346, result_P: 0.7662, result_R: 0.7034, result_F1: 0.7335, average_F1: 0.7733, aux-sec--introduction_P: 0.4243, aux-sec--introduction_R: 0.8265, aux-sec--introduction_F1: 0.5607, aux-sec--conclusion_P: 0.4123, aux-sec--conclusion_R: 0.2405, aux-sec--conclusion_F1: 0.3038, aux-sec--experiments_P: 0.3041, aux-sec--experiments_R: 0.0623, aux-sec--experiments_F1: 0.1034, aux-sec--method_P: 0.3103, aux-sec--method_R: 0.1607, aux-sec--method_F1: 0.2117, aux-sec--related work_P: 0.1538, aux-sec--related work_R: 0.0244, aux-sec--related work_F1: 0.0421, aux-sec--average_F1: 0.2444, aux-worth--False_P: 0.8704, aux-worth--False_R: 0.9889, aux-worth--False_F1: 0.9259, aux-worth--True_P: 0.6118, aux-worth--True_R: 0.1062, aux-worth--True_F1: 0.1810, aux-worth--average_F1: 0.5534, loss: 0.5770 ||:  14%|#4        | 820/5714 [03:33<17:46,  4.59it/s]\n",
      "background_P: 0.8331, background_R: 0.8766, background_F1: 0.8543, method_P: 0.7654, method_R: 0.7113, method_F1: 0.7374, result_P: 0.7683, result_R: 0.7052, result_F1: 0.7354, average_F1: 0.7757, aux-sec--introduction_P: 0.4257, aux-sec--introduction_R: 0.8283, aux-sec--introduction_F1: 0.5624, aux-sec--conclusion_P: 0.4109, aux-sec--conclusion_R: 0.2376, aux-sec--conclusion_F1: 0.3011, aux-sec--experiments_P: 0.3049, aux-sec--experiments_R: 0.0625, aux-sec--experiments_F1: 0.1037, aux-sec--method_P: 0.3122, aux-sec--method_R: 0.1641, aux-sec--method_F1: 0.2151, aux-sec--related work_P: 0.1618, aux-sec--related work_R: 0.0250, aux-sec--related work_F1: 0.0432, aux-sec--average_F1: 0.2451, aux-worth--False_P: 0.8712, aux-worth--False_R: 0.9886, aux-worth--False_F1: 0.9262, aux-worth--True_P: 0.6190, aux-worth--True_R: 0.1128, aux-worth--True_F1: 0.1908, aux-worth--average_F1: 0.5585, loss: 0.5723 ||:  15%|#5        | 866/5714 [03:44<17:56,  4.50it/s]\n",
      "03/30/2024 10:10:36 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:10:36 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:10:36 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8345, background_R: 0.8768, background_F1: 0.8552, method_P: 0.7671, method_R: 0.7141, method_F1: 0.7397, result_P: 0.7701, result_R: 0.7098, result_F1: 0.7387, average_F1: 0.7779, aux-sec--introduction_P: 0.4260, aux-sec--introduction_R: 0.8250, aux-sec--introduction_F1: 0.5619, aux-sec--conclusion_P: 0.4131, aux-sec--conclusion_R: 0.2398, aux-sec--conclusion_F1: 0.3034, aux-sec--experiments_P: 0.3000, aux-sec--experiments_R: 0.0613, aux-sec--experiments_F1: 0.1018, aux-sec--method_P: 0.3119, aux-sec--method_R: 0.1675, aux-sec--method_F1: 0.2179, aux-sec--related work_P: 0.1774, aux-sec--related work_R: 0.0282, aux-sec--related work_F1: 0.0487, aux-sec--average_F1: 0.2467, aux-worth--False_P: 0.8721, aux-worth--False_R: 0.9883, aux-worth--False_F1: 0.9266, aux-worth--True_P: 0.6294, aux-worth--True_R: 0.1204, aux-worth--True_F1: 0.2021, aux-worth--average_F1: 0.5643, loss: 0.5683 ||:  16%|#5        | 910/5714 [03:54<17:56,  4.46it/s]\n",
      "background_P: 0.8372, background_R: 0.8784, background_F1: 0.8573, method_P: 0.7724, method_R: 0.7207, method_F1: 0.7456, result_P: 0.7742, result_R: 0.7160, result_F1: 0.7440, average_F1: 0.7823, aux-sec--introduction_P: 0.4254, aux-sec--introduction_R: 0.8236, aux-sec--introduction_F1: 0.5611, aux-sec--conclusion_P: 0.4135, aux-sec--conclusion_R: 0.2405, aux-sec--conclusion_F1: 0.3041, aux-sec--experiments_P: 0.3168, aux-sec--experiments_R: 0.0706, aux-sec--experiments_F1: 0.1154, aux-sec--method_P: 0.3122, aux-sec--method_R: 0.1611, aux-sec--method_F1: 0.2125, aux-sec--related work_P: 0.1869, aux-sec--related work_R: 0.0323, aux-sec--related work_F1: 0.0551, aux-sec--average_F1: 0.2496, aux-worth--False_P: 0.8727, aux-worth--False_R: 0.9882, aux-worth--False_F1: 0.9268, aux-worth--True_P: 0.6286, aux-worth--True_R: 0.1220, aux-worth--True_F1: 0.2043, aux-worth--average_F1: 0.5656, loss: 0.5615 ||:  17%|#6        | 959/5714 [04:04<17:18,  4.58it/s]\n",
      "03/30/2024 10:10:59 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:10:59 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:10:59 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8394, background_R: 0.8801, background_F1: 0.8593, method_P: 0.7761, method_R: 0.7237, method_F1: 0.7490, result_P: 0.7772, result_R: 0.7221, result_F1: 0.7486, average_F1: 0.7856, aux-sec--introduction_P: 0.4242, aux-sec--introduction_R: 0.8182, aux-sec--introduction_F1: 0.5587, aux-sec--conclusion_P: 0.4179, aux-sec--conclusion_R: 0.2467, aux-sec--conclusion_F1: 0.3103, aux-sec--experiments_P: 0.3266, aux-sec--experiments_R: 0.0788, aux-sec--experiments_F1: 0.1270, aux-sec--method_P: 0.3120, aux-sec--method_R: 0.1587, aux-sec--method_F1: 0.2104, aux-sec--related work_P: 0.2222, aux-sec--related work_R: 0.0457, aux-sec--related work_F1: 0.0758, aux-sec--average_F1: 0.2564, aux-worth--False_P: 0.8721, aux-worth--False_R: 0.9876, aux-worth--False_F1: 0.9263, aux-worth--True_P: 0.6362, aux-worth--True_R: 0.1299, aux-worth--True_F1: 0.2158, aux-worth--average_F1: 0.5711, loss: 0.5557 ||:  18%|#7        | 1008/5714 [04:15<17:29,  4.48it/s]\n",
      "background_P: 0.8416, background_R: 0.8816, background_F1: 0.8612, method_P: 0.7784, method_R: 0.7273, method_F1: 0.7520, result_P: 0.7799, result_R: 0.7240, result_F1: 0.7509, average_F1: 0.7880, aux-sec--introduction_P: 0.4251, aux-sec--introduction_R: 0.8163, aux-sec--introduction_F1: 0.5591, aux-sec--conclusion_P: 0.4185, aux-sec--conclusion_R: 0.2491, aux-sec--conclusion_F1: 0.3123, aux-sec--experiments_P: 0.3220, aux-sec--experiments_R: 0.0810, aux-sec--experiments_F1: 0.1295, aux-sec--method_P: 0.3103, aux-sec--method_R: 0.1574, aux-sec--method_F1: 0.2089, aux-sec--related work_P: 0.2297, aux-sec--related work_R: 0.0478, aux-sec--related work_F1: 0.0791, aux-sec--average_F1: 0.2578, aux-worth--False_P: 0.8731, aux-worth--False_R: 0.9878, aux-worth--False_F1: 0.9269, aux-worth--True_P: 0.6358, aux-worth--True_R: 0.1293, aux-worth--True_F1: 0.2150, aux-worth--average_F1: 0.5709, loss: 0.5509 ||:  18%|#8        | 1055/5714 [04:25<17:06,  4.54it/s]\n",
      "03/30/2024 10:11:22 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:11:22 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:11:22 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8428, background_R: 0.8823, background_F1: 0.8621, method_P: 0.7798, method_R: 0.7299, method_F1: 0.7540, result_P: 0.7836, result_R: 0.7270, result_F1: 0.7543, average_F1: 0.7901, aux-sec--introduction_P: 0.4247, aux-sec--introduction_R: 0.8160, aux-sec--introduction_F1: 0.5587, aux-sec--conclusion_P: 0.4220, aux-sec--conclusion_R: 0.2516, aux-sec--conclusion_F1: 0.3153, aux-sec--experiments_P: 0.3307, aux-sec--experiments_R: 0.0852, aux-sec--experiments_F1: 0.1355, aux-sec--method_P: 0.3114, aux-sec--method_R: 0.1545, aux-sec--method_F1: 0.2065, aux-sec--related work_P: 0.2218, aux-sec--related work_R: 0.0459, aux-sec--related work_F1: 0.0760, aux-sec--average_F1: 0.2584, aux-worth--False_P: 0.8728, aux-worth--False_R: 0.9872, aux-worth--False_F1: 0.9265, aux-worth--True_P: 0.6446, aux-worth--True_R: 0.1387, aux-worth--True_F1: 0.2282, aux-worth--average_F1: 0.5774, loss: 0.5473 ||:  19%|#9        | 1102/5714 [04:37<17:43,  4.34it/s]\n",
      "background_P: 0.8440, background_R: 0.8826, background_F1: 0.8629, method_P: 0.7809, method_R: 0.7320, method_F1: 0.7557, result_P: 0.7831, result_R: 0.7283, result_F1: 0.7547, average_F1: 0.7911, aux-sec--introduction_P: 0.4252, aux-sec--introduction_R: 0.8163, aux-sec--introduction_F1: 0.5591, aux-sec--conclusion_P: 0.4204, aux-sec--conclusion_R: 0.2506, aux-sec--conclusion_F1: 0.3140, aux-sec--experiments_P: 0.3321, aux-sec--experiments_R: 0.0894, aux-sec--experiments_F1: 0.1409, aux-sec--method_P: 0.3104, aux-sec--method_R: 0.1499, aux-sec--method_F1: 0.2022, aux-sec--related work_P: 0.2236, aux-sec--related work_R: 0.0470, aux-sec--related work_F1: 0.0777, aux-sec--average_F1: 0.2588, aux-worth--False_P: 0.8739, aux-worth--False_R: 0.9871, aux-worth--False_F1: 0.9271, aux-worth--True_P: 0.6577, aux-worth--True_R: 0.1481, aux-worth--True_F1: 0.2418, aux-worth--average_F1: 0.5844, loss: 0.5444 ||:  20%|##        | 1149/5714 [04:47<17:10,  4.43it/s]\n",
      "background_P: 0.8451, background_R: 0.8837, background_F1: 0.8640, method_P: 0.7839, method_R: 0.7349, method_F1: 0.7586, result_P: 0.7847, result_R: 0.7300, result_F1: 0.7563, average_F1: 0.7930, aux-sec--introduction_P: 0.4252, aux-sec--introduction_R: 0.8128, aux-sec--introduction_F1: 0.5583, aux-sec--conclusion_P: 0.4228, aux-sec--conclusion_R: 0.2535, aux-sec--conclusion_F1: 0.3169, aux-sec--experiments_P: 0.3344, aux-sec--experiments_R: 0.0959, aux-sec--experiments_F1: 0.1491, aux-sec--method_P: 0.3152, aux-sec--method_R: 0.1495, aux-sec--method_F1: 0.2028, aux-sec--related work_P: 0.2343, aux-sec--related work_R: 0.0527, aux-sec--related work_F1: 0.0861, aux-sec--average_F1: 0.2626, aux-worth--False_P: 0.8747, aux-worth--False_R: 0.9870, aux-worth--False_F1: 0.9275, aux-worth--True_P: 0.6625, aux-worth--True_R: 0.1532, aux-worth--True_F1: 0.2488, aux-worth--average_F1: 0.5881, loss: 0.5421 ||:  21%|##        | 1198/5714 [04:58<16:34,  4.54it/s]\n",
      "03/30/2024 10:11:43 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:11:43 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:11:43 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8468, background_R: 0.8845, background_F1: 0.8652, method_P: 0.7856, method_R: 0.7376, method_F1: 0.7608, result_P: 0.7863, result_R: 0.7331, result_F1: 0.7588, average_F1: 0.7949, aux-sec--introduction_P: 0.4269, aux-sec--introduction_R: 0.8131, aux-sec--introduction_F1: 0.5599, aux-sec--conclusion_P: 0.4228, aux-sec--conclusion_R: 0.2515, aux-sec--conclusion_F1: 0.3154, aux-sec--experiments_P: 0.3357, aux-sec--experiments_R: 0.0986, aux-sec--experiments_F1: 0.1524, aux-sec--method_P: 0.3190, aux-sec--method_R: 0.1514, aux-sec--method_F1: 0.2053, aux-sec--related work_P: 0.2426, aux-sec--related work_R: 0.0560, aux-sec--related work_F1: 0.0910, aux-sec--average_F1: 0.2648, aux-worth--False_P: 0.8751, aux-worth--False_R: 0.9864, aux-worth--False_F1: 0.9274, aux-worth--True_P: 0.6719, aux-worth--True_R: 0.1650, aux-worth--True_F1: 0.2649, aux-worth--average_F1: 0.5962, loss: 0.5380 ||:  22%|##1       | 1247/5714 [05:08<16:12,  4.60it/s]\n",
      "background_P: 0.8479, background_R: 0.8852, background_F1: 0.8661, method_P: 0.7863, method_R: 0.7386, method_F1: 0.7617, result_P: 0.7890, result_R: 0.7367, result_F1: 0.7620, average_F1: 0.7966, aux-sec--introduction_P: 0.4277, aux-sec--introduction_R: 0.8138, aux-sec--introduction_F1: 0.5607, aux-sec--conclusion_P: 0.4248, aux-sec--conclusion_R: 0.2512, aux-sec--conclusion_F1: 0.3157, aux-sec--experiments_P: 0.3366, aux-sec--experiments_R: 0.0986, aux-sec--experiments_F1: 0.1525, aux-sec--method_P: 0.3162, aux-sec--method_R: 0.1504, aux-sec--method_F1: 0.2038, aux-sec--related work_P: 0.2506, aux-sec--related work_R: 0.0589, aux-sec--related work_F1: 0.0954, aux-sec--average_F1: 0.2656, aux-worth--False_P: 0.8757, aux-worth--False_R: 0.9861, aux-worth--False_F1: 0.9276, aux-worth--True_P: 0.6720, aux-worth--True_R: 0.1694, aux-worth--True_F1: 0.2706, aux-worth--average_F1: 0.5991, loss: 0.5354 ||:  23%|##2       | 1295/5714 [05:18<15:57,  4.61it/s]\n",
      "03/30/2024 10:12:04 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:12:04 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:12:04 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8493, background_R: 0.8863, background_F1: 0.8674, method_P: 0.7865, method_R: 0.7396, method_F1: 0.7623, result_P: 0.7910, result_R: 0.7378, result_F1: 0.7635, average_F1: 0.7977, aux-sec--introduction_P: 0.4281, aux-sec--introduction_R: 0.8117, aux-sec--introduction_F1: 0.5605, aux-sec--conclusion_P: 0.4272, aux-sec--conclusion_R: 0.2543, aux-sec--conclusion_F1: 0.3188, aux-sec--experiments_P: 0.3383, aux-sec--experiments_R: 0.1011, aux-sec--experiments_F1: 0.1557, aux-sec--method_P: 0.3169, aux-sec--method_R: 0.1509, aux-sec--method_F1: 0.2045, aux-sec--related work_P: 0.2494, aux-sec--related work_R: 0.0590, aux-sec--related work_F1: 0.0955, aux-sec--average_F1: 0.2670, aux-worth--False_P: 0.8767, aux-worth--False_R: 0.9861, aux-worth--False_F1: 0.9282, aux-worth--True_P: 0.6808, aux-worth--True_R: 0.1761, aux-worth--True_F1: 0.2798, aux-worth--average_F1: 0.6040, loss: 0.5319 ||:  24%|##3       | 1345/5714 [05:28<15:31,  4.69it/s]\n",
      "background_P: 0.8500, background_R: 0.8869, background_F1: 0.8681, method_P: 0.7873, method_R: 0.7402, method_F1: 0.7630, result_P: 0.7926, result_R: 0.7406, result_F1: 0.7657, average_F1: 0.7989, aux-sec--introduction_P: 0.4282, aux-sec--introduction_R: 0.8102, aux-sec--introduction_F1: 0.5602, aux-sec--conclusion_P: 0.4305, aux-sec--conclusion_R: 0.2584, aux-sec--conclusion_F1: 0.3229, aux-sec--experiments_P: 0.3381, aux-sec--experiments_R: 0.1018, aux-sec--experiments_F1: 0.1565, aux-sec--method_P: 0.3167, aux-sec--method_R: 0.1524, aux-sec--method_F1: 0.2058, aux-sec--related work_P: 0.2453, aux-sec--related work_R: 0.0591, aux-sec--related work_F1: 0.0952, aux-sec--average_F1: 0.2681, aux-worth--False_P: 0.8773, aux-worth--False_R: 0.9860, aux-worth--False_F1: 0.9285, aux-worth--True_P: 0.6884, aux-worth--True_R: 0.1837, aux-worth--True_F1: 0.2900, aux-worth--average_F1: 0.6092, loss: 0.5300 ||:  24%|##4       | 1394/5714 [05:39<15:28,  4.65it/s]\n",
      "03/30/2024 10:12:26 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:12:26 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:12:26 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8516, background_R: 0.8882, background_F1: 0.8695, method_P: 0.7893, method_R: 0.7437, method_F1: 0.7658, result_P: 0.7971, result_R: 0.7434, result_F1: 0.7693, average_F1: 0.8015, aux-sec--introduction_P: 0.4282, aux-sec--introduction_R: 0.8074, aux-sec--introduction_F1: 0.5596, aux-sec--conclusion_P: 0.4314, aux-sec--conclusion_R: 0.2615, aux-sec--conclusion_F1: 0.3256, aux-sec--experiments_P: 0.3362, aux-sec--experiments_R: 0.1017, aux-sec--experiments_F1: 0.1561, aux-sec--method_P: 0.3184, aux-sec--method_R: 0.1529, aux-sec--method_F1: 0.2066, aux-sec--related work_P: 0.2551, aux-sec--related work_R: 0.0675, aux-sec--related work_F1: 0.1067, aux-sec--average_F1: 0.2709, aux-worth--False_P: 0.8779, aux-worth--False_R: 0.9859, aux-worth--False_F1: 0.9288, aux-worth--True_P: 0.6957, aux-worth--True_R: 0.1903, aux-worth--True_F1: 0.2989, aux-worth--average_F1: 0.6138, loss: 0.5250 ||:  25%|##5       | 1447/5714 [05:49<14:43,  4.83it/s]\n",
      "03/30/2024 10:12:45 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:12:45 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:12:45 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8528, background_R: 0.8889, background_F1: 0.8705, method_P: 0.7902, method_R: 0.7453, method_F1: 0.7671, result_P: 0.7987, result_R: 0.7454, result_F1: 0.7711, average_F1: 0.8029, aux-sec--introduction_P: 0.4283, aux-sec--introduction_R: 0.8050, aux-sec--introduction_F1: 0.5591, aux-sec--conclusion_P: 0.4335, aux-sec--conclusion_R: 0.2632, aux-sec--conclusion_F1: 0.3275, aux-sec--experiments_P: 0.3368, aux-sec--experiments_R: 0.1055, aux-sec--experiments_F1: 0.1607, aux-sec--method_P: 0.3183, aux-sec--method_R: 0.1521, aux-sec--method_F1: 0.2059, aux-sec--related work_P: 0.2596, aux-sec--related work_R: 0.0703, aux-sec--related work_F1: 0.1106, aux-sec--average_F1: 0.2728, aux-worth--False_P: 0.8787, aux-worth--False_R: 0.9856, aux-worth--False_F1: 0.9291, aux-worth--True_P: 0.6992, aux-worth--True_R: 0.1977, aux-worth--True_F1: 0.3082, aux-worth--average_F1: 0.6187, loss: 0.5219 ||:  26%|##6       | 1500/5714 [06:00<14:21,  4.89it/s]\n",
      "background_P: 0.8535, background_R: 0.8894, background_F1: 0.8711, method_P: 0.7915, method_R: 0.7462, method_F1: 0.7682, result_P: 0.8008, result_R: 0.7487, result_F1: 0.7739, average_F1: 0.8044, aux-sec--introduction_P: 0.4285, aux-sec--introduction_R: 0.8052, aux-sec--introduction_F1: 0.5593, aux-sec--conclusion_P: 0.4332, aux-sec--conclusion_R: 0.2633, aux-sec--conclusion_F1: 0.3275, aux-sec--experiments_P: 0.3382, aux-sec--experiments_R: 0.1071, aux-sec--experiments_F1: 0.1627, aux-sec--method_P: 0.3172, aux-sec--method_R: 0.1499, aux-sec--method_F1: 0.2036, aux-sec--related work_P: 0.2589, aux-sec--related work_R: 0.0696, aux-sec--related work_F1: 0.1097, aux-sec--average_F1: 0.2726, aux-worth--False_P: 0.8803, aux-worth--False_R: 0.9857, aux-worth--False_F1: 0.9300, aux-worth--True_P: 0.6987, aux-worth--True_R: 0.1984, aux-worth--True_F1: 0.3090, aux-worth--average_F1: 0.6195, loss: 0.5188 ||:  27%|##7       | 1551/5714 [06:11<14:21,  4.83it/s]\n",
      "03/30/2024 10:13:05 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:13:05 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:13:05 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8546, background_R: 0.8906, background_F1: 0.8722, method_P: 0.7942, method_R: 0.7490, method_F1: 0.7709, result_P: 0.8026, result_R: 0.7496, result_F1: 0.7752, average_F1: 0.8061, aux-sec--introduction_P: 0.4288, aux-sec--introduction_R: 0.8053, aux-sec--introduction_F1: 0.5596, aux-sec--conclusion_P: 0.4331, aux-sec--conclusion_R: 0.2609, aux-sec--conclusion_F1: 0.3256, aux-sec--experiments_P: 0.3421, aux-sec--experiments_R: 0.1101, aux-sec--experiments_F1: 0.1666, aux-sec--method_P: 0.3192, aux-sec--method_R: 0.1499, aux-sec--method_F1: 0.2040, aux-sec--related work_P: 0.2698, aux-sec--related work_R: 0.0760, aux-sec--related work_F1: 0.1186, aux-sec--average_F1: 0.2749, aux-worth--False_P: 0.8812, aux-worth--False_R: 0.9858, aux-worth--False_F1: 0.9306, aux-worth--True_P: 0.6989, aux-worth--True_R: 0.1992, aux-worth--True_F1: 0.3101, aux-worth--average_F1: 0.6203, loss: 0.5152 ||:  28%|##8       | 1607/5714 [06:21<13:34,  5.05it/s]\n",
      "background_P: 0.8549, background_R: 0.8908, background_F1: 0.8725, method_P: 0.7946, method_R: 0.7493, method_F1: 0.7713, result_P: 0.8056, result_R: 0.7534, result_F1: 0.7786, average_F1: 0.8075, aux-sec--introduction_P: 0.4290, aux-sec--introduction_R: 0.8045, aux-sec--introduction_F1: 0.5596, aux-sec--conclusion_P: 0.4362, aux-sec--conclusion_R: 0.2627, aux-sec--conclusion_F1: 0.3279, aux-sec--experiments_P: 0.3421, aux-sec--experiments_R: 0.1090, aux-sec--experiments_F1: 0.1653, aux-sec--method_P: 0.3194, aux-sec--method_R: 0.1535, aux-sec--method_F1: 0.2073, aux-sec--related work_P: 0.2771, aux-sec--related work_R: 0.0814, aux-sec--related work_F1: 0.1258, aux-sec--average_F1: 0.2772, aux-worth--False_P: 0.8813, aux-worth--False_R: 0.9854, aux-worth--False_F1: 0.9305, aux-worth--True_P: 0.7077, aux-worth--True_R: 0.2101, aux-worth--True_F1: 0.3240, aux-worth--average_F1: 0.6272, loss: 0.5129 ||:  29%|##9       | 1663/5714 [06:32<13:26,  5.02it/s]\n",
      "03/30/2024 10:13:25 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:13:25 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:13:25 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8557, background_R: 0.8911, background_F1: 0.8730, method_P: 0.7960, method_R: 0.7509, method_F1: 0.7728, result_P: 0.8078, result_R: 0.7577, result_F1: 0.7819, average_F1: 0.8092, aux-sec--introduction_P: 0.4295, aux-sec--introduction_R: 0.8039, aux-sec--introduction_F1: 0.5599, aux-sec--conclusion_P: 0.4381, aux-sec--conclusion_R: 0.2646, aux-sec--conclusion_F1: 0.3299, aux-sec--experiments_P: 0.3436, aux-sec--experiments_R: 0.1131, aux-sec--experiments_F1: 0.1702, aux-sec--method_P: 0.3194, aux-sec--method_R: 0.1510, aux-sec--method_F1: 0.2051, aux-sec--related work_P: 0.2770, aux-sec--related work_R: 0.0827, aux-sec--related work_F1: 0.1274, aux-sec--average_F1: 0.2785, aux-worth--False_P: 0.8817, aux-worth--False_R: 0.9849, aux-worth--False_F1: 0.9304, aux-worth--True_P: 0.7107, aux-worth--True_R: 0.2186, aux-worth--True_F1: 0.3344, aux-worth--average_F1: 0.6324, loss: 0.5102 ||:  30%|##9       | 1713/5714 [06:43<13:31,  4.93it/s]\n",
      "background_P: 0.8569, background_R: 0.8922, background_F1: 0.8742, method_P: 0.7974, method_R: 0.7519, method_F1: 0.7740, result_P: 0.8096, result_R: 0.7604, result_F1: 0.7842, average_F1: 0.8108, aux-sec--introduction_P: 0.4297, aux-sec--introduction_R: 0.8031, aux-sec--introduction_F1: 0.5599, aux-sec--conclusion_P: 0.4387, aux-sec--conclusion_R: 0.2668, aux-sec--conclusion_F1: 0.3318, aux-sec--experiments_P: 0.3439, aux-sec--experiments_R: 0.1137, aux-sec--experiments_F1: 0.1709, aux-sec--method_P: 0.3191, aux-sec--method_R: 0.1501, aux-sec--method_F1: 0.2042, aux-sec--related work_P: 0.2770, aux-sec--related work_R: 0.0840, aux-sec--related work_F1: 0.1289, aux-sec--average_F1: 0.2791, aux-worth--False_P: 0.8822, aux-worth--False_R: 0.9850, aux-worth--False_F1: 0.9308, aux-worth--True_P: 0.7146, aux-worth--True_R: 0.2218, aux-worth--True_F1: 0.3386, aux-worth--average_F1: 0.6347, loss: 0.5072 ||:  31%|###       | 1762/5714 [06:53<13:25,  4.90it/s]\n",
      "03/30/2024 10:13:46 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:13:46 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:13:46 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8572, background_R: 0.8922, background_F1: 0.8744, method_P: 0.7981, method_R: 0.7529, method_F1: 0.7748, result_P: 0.8113, result_R: 0.7626, result_F1: 0.7862, average_F1: 0.8118, aux-sec--introduction_P: 0.4292, aux-sec--introduction_R: 0.8006, aux-sec--introduction_F1: 0.5589, aux-sec--conclusion_P: 0.4398, aux-sec--conclusion_R: 0.2704, aux-sec--conclusion_F1: 0.3349, aux-sec--experiments_P: 0.3470, aux-sec--experiments_R: 0.1166, aux-sec--experiments_F1: 0.1746, aux-sec--method_P: 0.3191, aux-sec--method_R: 0.1494, aux-sec--method_F1: 0.2036, aux-sec--related work_P: 0.2780, aux-sec--related work_R: 0.0843, aux-sec--related work_F1: 0.1294, aux-sec--average_F1: 0.2803, aux-worth--False_P: 0.8829, aux-worth--False_R: 0.9848, aux-worth--False_F1: 0.9311, aux-worth--True_P: 0.7143, aux-worth--True_R: 0.2259, aux-worth--True_F1: 0.3433, aux-worth--average_F1: 0.6372, loss: 0.5057 ||:  32%|###1      | 1811/5714 [07:03<13:22,  4.86it/s]\n",
      "background_P: 0.8579, background_R: 0.8931, background_F1: 0.8751, method_P: 0.7988, method_R: 0.7529, method_F1: 0.7752, result_P: 0.8124, result_R: 0.7643, result_F1: 0.7876, average_F1: 0.8127, aux-sec--introduction_P: 0.4301, aux-sec--introduction_R: 0.8006, aux-sec--introduction_F1: 0.5596, aux-sec--conclusion_P: 0.4398, aux-sec--conclusion_R: 0.2704, aux-sec--conclusion_F1: 0.3349, aux-sec--experiments_P: 0.3459, aux-sec--experiments_R: 0.1171, aux-sec--experiments_F1: 0.1750, aux-sec--method_P: 0.3208, aux-sec--method_R: 0.1493, aux-sec--method_F1: 0.2038, aux-sec--related work_P: 0.2789, aux-sec--related work_R: 0.0885, aux-sec--related work_F1: 0.1344, aux-sec--average_F1: 0.2815, aux-worth--False_P: 0.8830, aux-worth--False_R: 0.9842, aux-worth--False_F1: 0.9309, aux-worth--True_P: 0.7133, aux-worth--True_R: 0.2315, aux-worth--True_F1: 0.3496, aux-worth--average_F1: 0.6402, loss: 0.5043 ||:  33%|###2      | 1861/5714 [07:13<13:08,  4.89it/s]\n",
      "03/30/2024 10:14:06 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:14:06 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:14:06 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8592, background_R: 0.8939, background_F1: 0.8762, method_P: 0.8004, method_R: 0.7550, method_F1: 0.7771, result_P: 0.8138, result_R: 0.7662, result_F1: 0.7893, average_F1: 0.8142, aux-sec--introduction_P: 0.4303, aux-sec--introduction_R: 0.7992, aux-sec--introduction_F1: 0.5594, aux-sec--conclusion_P: 0.4390, aux-sec--conclusion_R: 0.2706, aux-sec--conclusion_F1: 0.3348, aux-sec--experiments_P: 0.3464, aux-sec--experiments_R: 0.1203, aux-sec--experiments_F1: 0.1786, aux-sec--method_P: 0.3178, aux-sec--method_R: 0.1470, aux-sec--method_F1: 0.2010, aux-sec--related work_P: 0.2875, aux-sec--related work_R: 0.0950, aux-sec--related work_F1: 0.1428, aux-sec--average_F1: 0.2833, aux-worth--False_P: 0.8834, aux-worth--False_R: 0.9844, aux-worth--False_F1: 0.9312, aux-worth--True_P: 0.7147, aux-worth--True_R: 0.2313, aux-worth--True_F1: 0.3495, aux-worth--average_F1: 0.6403, loss: 0.5016 ||:  33%|###3      | 1911/5714 [07:24<13:04,  4.85it/s]\n",
      "background_P: 0.8601, background_R: 0.8945, background_F1: 0.8769, method_P: 0.8010, method_R: 0.7560, method_F1: 0.7779, result_P: 0.8153, result_R: 0.7684, result_F1: 0.7912, average_F1: 0.8153, aux-sec--introduction_P: 0.4306, aux-sec--introduction_R: 0.7996, aux-sec--introduction_F1: 0.5598, aux-sec--conclusion_P: 0.4391, aux-sec--conclusion_R: 0.2698, aux-sec--conclusion_F1: 0.3342, aux-sec--experiments_P: 0.3431, aux-sec--experiments_R: 0.1218, aux-sec--experiments_F1: 0.1798, aux-sec--method_P: 0.3186, aux-sec--method_R: 0.1447, aux-sec--method_F1: 0.1990, aux-sec--related work_P: 0.2864, aux-sec--related work_R: 0.0955, aux-sec--related work_F1: 0.1432, aux-sec--average_F1: 0.2832, aux-worth--False_P: 0.8837, aux-worth--False_R: 0.9845, aux-worth--False_F1: 0.9314, aux-worth--True_P: 0.7169, aux-worth--True_R: 0.2330, aux-worth--True_F1: 0.3516, aux-worth--average_F1: 0.6415, loss: 0.4994 ||:  34%|###4      | 1961/5714 [07:34<12:52,  4.86it/s]\n",
      "03/30/2024 10:14:27 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:14:27 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:14:27 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8612, background_R: 0.8953, background_F1: 0.8779, method_P: 0.8029, method_R: 0.7578, method_F1: 0.7797, result_P: 0.8153, result_R: 0.7699, result_F1: 0.7920, average_F1: 0.8165, aux-sec--introduction_P: 0.4302, aux-sec--introduction_R: 0.7976, aux-sec--introduction_F1: 0.5589, aux-sec--conclusion_P: 0.4384, aux-sec--conclusion_R: 0.2724, aux-sec--conclusion_F1: 0.3360, aux-sec--experiments_P: 0.3436, aux-sec--experiments_R: 0.1230, aux-sec--experiments_F1: 0.1811, aux-sec--method_P: 0.3181, aux-sec--method_R: 0.1424, aux-sec--method_F1: 0.1968, aux-sec--related work_P: 0.2882, aux-sec--related work_R: 0.0963, aux-sec--related work_F1: 0.1443, aux-sec--average_F1: 0.2834, aux-worth--False_P: 0.8836, aux-worth--False_R: 0.9842, aux-worth--False_F1: 0.9312, aux-worth--True_P: 0.7203, aux-worth--True_R: 0.2383, aux-worth--True_F1: 0.3581, aux-worth--average_F1: 0.6447, loss: 0.4970 ||:  35%|###5      | 2010/5714 [07:44<12:44,  4.84it/s]\n",
      "background_P: 0.8623, background_R: 0.8957, background_F1: 0.8787, method_P: 0.8045, method_R: 0.7596, method_F1: 0.7814, result_P: 0.8161, result_R: 0.7725, result_F1: 0.7937, average_F1: 0.8179, aux-sec--introduction_P: 0.4294, aux-sec--introduction_R: 0.7945, aux-sec--introduction_F1: 0.5575, aux-sec--conclusion_P: 0.4379, aux-sec--conclusion_R: 0.2754, aux-sec--conclusion_F1: 0.3381, aux-sec--experiments_P: 0.3438, aux-sec--experiments_R: 0.1220, aux-sec--experiments_F1: 0.1801, aux-sec--method_P: 0.3190, aux-sec--method_R: 0.1442, aux-sec--method_F1: 0.1986, aux-sec--related work_P: 0.2934, aux-sec--related work_R: 0.1012, aux-sec--related work_F1: 0.1505, aux-sec--average_F1: 0.2850, aux-worth--False_P: 0.8839, aux-worth--False_R: 0.9840, aux-worth--False_F1: 0.9313, aux-worth--True_P: 0.7240, aux-worth--True_R: 0.2448, aux-worth--True_F1: 0.3658, aux-worth--average_F1: 0.6486, loss: 0.4943 ||:  36%|###6      | 2059/5714 [07:56<13:07,  4.64it/s]\n",
      "03/30/2024 10:14:50 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:14:50 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:14:50 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8627, background_R: 0.8963, background_F1: 0.8792, method_P: 0.8053, method_R: 0.7607, method_F1: 0.7824, result_P: 0.8183, result_R: 0.7741, result_F1: 0.7956, average_F1: 0.8190, aux-sec--introduction_P: 0.4292, aux-sec--introduction_R: 0.7938, aux-sec--introduction_F1: 0.5572, aux-sec--conclusion_P: 0.4359, aux-sec--conclusion_R: 0.2738, aux-sec--conclusion_F1: 0.3364, aux-sec--experiments_P: 0.3462, aux-sec--experiments_R: 0.1250, aux-sec--experiments_F1: 0.1837, aux-sec--method_P: 0.3194, aux-sec--method_R: 0.1424, aux-sec--method_F1: 0.1970, aux-sec--related work_P: 0.2970, aux-sec--related work_R: 0.1041, aux-sec--related work_F1: 0.1541, aux-sec--average_F1: 0.2857, aux-worth--False_P: 0.8845, aux-worth--False_R: 0.9840, aux-worth--False_F1: 0.9316, aux-worth--True_P: 0.7224, aux-worth--True_R: 0.2445, aux-worth--True_F1: 0.3653, aux-worth--average_F1: 0.6485, loss: 0.4920 ||:  37%|###6      | 2105/5714 [08:06<13:03,  4.61it/s]\n",
      "background_P: 0.8633, background_R: 0.8965, background_F1: 0.8796, method_P: 0.8070, method_R: 0.7628, method_F1: 0.7843, result_P: 0.8192, result_R: 0.7757, result_F1: 0.7969, average_F1: 0.8203, aux-sec--introduction_P: 0.4294, aux-sec--introduction_R: 0.7935, aux-sec--introduction_F1: 0.5572, aux-sec--conclusion_P: 0.4376, aux-sec--conclusion_R: 0.2754, aux-sec--conclusion_F1: 0.3381, aux-sec--experiments_P: 0.3485, aux-sec--experiments_R: 0.1271, aux-sec--experiments_F1: 0.1863, aux-sec--method_P: 0.3184, aux-sec--method_R: 0.1411, aux-sec--method_F1: 0.1955, aux-sec--related work_P: 0.2955, aux-sec--related work_R: 0.1038, aux-sec--related work_F1: 0.1536, aux-sec--average_F1: 0.2861, aux-worth--False_P: 0.8845, aux-worth--False_R: 0.9837, aux-worth--False_F1: 0.9315, aux-worth--True_P: 0.7243, aux-worth--True_R: 0.2505, aux-worth--True_F1: 0.3723, aux-worth--average_F1: 0.6519, loss: 0.4904 ||:  38%|###7      | 2151/5714 [08:16<13:01,  4.56it/s]\n",
      "background_P: 0.8643, background_R: 0.8973, background_F1: 0.8804, method_P: 0.8081, method_R: 0.7644, method_F1: 0.7856, result_P: 0.8200, result_R: 0.7759, result_F1: 0.7973, average_F1: 0.8211, aux-sec--introduction_P: 0.4291, aux-sec--introduction_R: 0.7911, aux-sec--introduction_F1: 0.5564, aux-sec--conclusion_P: 0.4357, aux-sec--conclusion_R: 0.2768, aux-sec--conclusion_F1: 0.3386, aux-sec--experiments_P: 0.3501, aux-sec--experiments_R: 0.1299, aux-sec--experiments_F1: 0.1895, aux-sec--method_P: 0.3166, aux-sec--method_R: 0.1398, aux-sec--method_F1: 0.1940, aux-sec--related work_P: 0.2958, aux-sec--related work_R: 0.1049, aux-sec--related work_F1: 0.1549, aux-sec--average_F1: 0.2867, aux-worth--False_P: 0.8847, aux-worth--False_R: 0.9835, aux-worth--False_F1: 0.9315, aux-worth--True_P: 0.7262, aux-worth--True_R: 0.2542, aux-worth--True_F1: 0.3766, aux-worth--average_F1: 0.6541, loss: 0.4886 ||:  38%|###8      | 2196/5714 [08:27<13:05,  4.48it/s]\n",
      "03/30/2024 10:15:13 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:15:13 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:15:13 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8656, background_R: 0.8980, background_F1: 0.8815, method_P: 0.8096, method_R: 0.7664, method_F1: 0.7875, result_P: 0.8211, result_R: 0.7782, result_F1: 0.7991, average_F1: 0.8227, aux-sec--introduction_P: 0.4301, aux-sec--introduction_R: 0.7912, aux-sec--introduction_F1: 0.5572, aux-sec--conclusion_P: 0.4367, aux-sec--conclusion_R: 0.2773, aux-sec--conclusion_F1: 0.3392, aux-sec--experiments_P: 0.3526, aux-sec--experiments_R: 0.1309, aux-sec--experiments_F1: 0.1909, aux-sec--method_P: 0.3169, aux-sec--method_R: 0.1396, aux-sec--method_F1: 0.1938, aux-sec--related work_P: 0.3032, aux-sec--related work_R: 0.1110, aux-sec--related work_F1: 0.1625, aux-sec--average_F1: 0.2887, aux-worth--False_P: 0.8851, aux-worth--False_R: 0.9835, aux-worth--False_F1: 0.9317, aux-worth--True_P: 0.7266, aux-worth--True_R: 0.2558, aux-worth--True_F1: 0.3784, aux-worth--average_F1: 0.6550, loss: 0.4861 ||:  39%|###9      | 2244/5714 [08:37<12:40,  4.56it/s]\n",
      "background_P: 0.8663, background_R: 0.8986, background_F1: 0.8821, method_P: 0.8100, method_R: 0.7665, method_F1: 0.7877, result_P: 0.8225, result_R: 0.7805, result_F1: 0.8009, average_F1: 0.8236, aux-sec--introduction_P: 0.4314, aux-sec--introduction_R: 0.7917, aux-sec--introduction_F1: 0.5585, aux-sec--conclusion_P: 0.4379, aux-sec--conclusion_R: 0.2774, aux-sec--conclusion_F1: 0.3397, aux-sec--experiments_P: 0.3521, aux-sec--experiments_R: 0.1318, aux-sec--experiments_F1: 0.1918, aux-sec--method_P: 0.3154, aux-sec--method_R: 0.1403, aux-sec--method_F1: 0.1942, aux-sec--related work_P: 0.3052, aux-sec--related work_R: 0.1124, aux-sec--related work_F1: 0.1643, aux-sec--average_F1: 0.2897, aux-worth--False_P: 0.8857, aux-worth--False_R: 0.9837, aux-worth--False_F1: 0.9321, aux-worth--True_P: 0.7298, aux-worth--True_R: 0.2569, aux-worth--True_F1: 0.3800, aux-worth--average_F1: 0.6561, loss: 0.4836 ||:  40%|####      | 2292/5714 [08:47<12:20,  4.62it/s]\n",
      "03/30/2024 10:15:34 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:15:34 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:15:34 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8671, background_R: 0.8991, background_F1: 0.8828, method_P: 0.8108, method_R: 0.7681, method_F1: 0.7889, result_P: 0.8232, result_R: 0.7804, result_F1: 0.8013, average_F1: 0.8243, aux-sec--introduction_P: 0.4318, aux-sec--introduction_R: 0.7900, aux-sec--introduction_F1: 0.5584, aux-sec--conclusion_P: 0.4396, aux-sec--conclusion_R: 0.2796, aux-sec--conclusion_F1: 0.3418, aux-sec--experiments_P: 0.3571, aux-sec--experiments_R: 0.1365, aux-sec--experiments_F1: 0.1975, aux-sec--method_P: 0.3157, aux-sec--method_R: 0.1399, aux-sec--method_F1: 0.1939, aux-sec--related work_P: 0.3065, aux-sec--related work_R: 0.1164, aux-sec--related work_F1: 0.1687, aux-sec--average_F1: 0.2921, aux-worth--False_P: 0.8864, aux-worth--False_R: 0.9837, aux-worth--False_F1: 0.9325, aux-worth--True_P: 0.7325, aux-worth--True_R: 0.2610, aux-worth--True_F1: 0.3849, aux-worth--average_F1: 0.6587, loss: 0.4818 ||:  41%|####      | 2340/5714 [08:57<12:03,  4.67it/s]\n",
      "background_P: 0.8682, background_R: 0.8999, background_F1: 0.8838, method_P: 0.8121, method_R: 0.7700, method_F1: 0.7905, result_P: 0.8235, result_R: 0.7809, result_F1: 0.8016, average_F1: 0.8253, aux-sec--introduction_P: 0.4323, aux-sec--introduction_R: 0.7899, aux-sec--introduction_F1: 0.5588, aux-sec--conclusion_P: 0.4400, aux-sec--conclusion_R: 0.2798, aux-sec--conclusion_F1: 0.3421, aux-sec--experiments_P: 0.3586, aux-sec--experiments_R: 0.1389, aux-sec--experiments_F1: 0.2002, aux-sec--method_P: 0.3154, aux-sec--method_R: 0.1380, aux-sec--method_F1: 0.1920, aux-sec--related work_P: 0.3079, aux-sec--related work_R: 0.1169, aux-sec--related work_F1: 0.1695, aux-sec--average_F1: 0.2925, aux-worth--False_P: 0.8868, aux-worth--False_R: 0.9836, aux-worth--False_F1: 0.9327, aux-worth--True_P: 0.7311, aux-worth--True_R: 0.2620, aux-worth--True_F1: 0.3858, aux-worth--average_F1: 0.6592, loss: 0.4795 ||:  42%|####1     | 2390/5714 [09:07<11:38,  4.76it/s]\n",
      "03/30/2024 10:15:54 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_P is illegal; using epoch_metrics/aux-sec--related_work_P instead.\n",
      "03/30/2024 10:15:54 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_F1 is illegal; using epoch_metrics/aux-sec--related_work_F1 instead.\n",
      "03/30/2024 10:15:54 - INFO - root -   Summary name epoch_metrics/aux-sec--related work_R is illegal; using epoch_metrics/aux-sec--related_work_R instead.\n",
      "background_P: 0.8684, background_R: 0.8998, background_F1: 0.8838, method_P: 0.8124, method_R: 0.7706, method_F1: 0.7909, result_P: 0.8239, result_R: 0.7818, result_F1: 0.8023, average_F1: 0.8257, aux-sec--introduction_P: 0.4320, aux-sec--introduction_R: 0.7893, aux-sec--introduction_F1: 0.5584, aux-sec--conclusion_P: 0.4395, aux-sec--conclusion_R: 0.2797, aux-sec--conclusion_F1: 0.3419, aux-sec--experiments_P: 0.3580, aux-sec--experiments_R: 0.1398, aux-sec--experiments_F1: 0.2011, aux-sec--method_P: 0.3156, aux-sec--method_R: 0.1373, aux-sec--method_F1: 0.1914, aux-sec--related work_P: 0.3095, aux-sec--related work_R: 0.1172, aux-sec--related work_F1: 0.1700, aux-sec--average_F1: 0.2925, aux-worth--False_P: 0.8872, aux-worth--False_R: 0.9837, aux-worth--False_F1: 0.9330, aux-worth--True_P: 0.7328, aux-worth--True_R: 0.2639, aux-worth--True_F1: 0.3881, aux-worth--average_F1: 0.6605, loss: 0.4789 ||:  42%|####2     | 2416/5714 [09:12<12:34,  4.37it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e2267bd2615c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# if we have completed an epoch, try to create a model archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-723f5a54d455>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-723f5a54d455>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                         \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                         \u001b[0mbatch_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_aux\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                                         batch_aux2=batch_aux2)\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-723f5a54d455>\u001b[0m in \u001b[0;36m_batch_loss\u001b[0;34m(self, batch, for_training, batch_aux, batch_aux2)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kanhon/NUS Computing/CS4248/github_dir/cs4248/scaffold/Project/sci-cite/scicite/scicite/models/scaffold_bilstm_attention_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, citation_text, labels, lexicon_features, year_diff, citing_paper_id, cited_paper_id, citation_excerpt_index, citation_id, section_label, is_citation)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# pylint: disable=arguments-differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mcitation_text_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_field_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcitation_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# print(\"citation_text\", citation_text) # {'elmo': tensor, 'tokens': tensor}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# print(\"citation_text_embedding\", citation_text_embedding) # tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_field_input, num_wrapping_dims)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_wrapping_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0membedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mtoken_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0membedded_representations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_representations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/allennlp/modules/token_embedders/elmo_token_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0melmo_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0melmo_representations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melmo_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elmo_representations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_projection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 representation_without_bos_eos, mask_without_bos_eos = remove_sentence_boundaries(\n\u001b[0;32m--> 181\u001b[0;31m                         representation_with_bos_eos, mask_with_bos_eos)\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mprocessed_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepresentation_without_bos_eos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mprocessed_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_without_bos_eos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4248_scicite_torch/lib/python3.6/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mremove_sentence_boundaries\u001b[0;34m(tensor, mask)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \"\"\"\n\u001b[1;32m   1190\u001b[0m     \u001b[0;31m# TODO: matthewp, profile this transfer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m     \u001b[0msequence_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0mtensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 10:16:07 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'multilabel': 'false', 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.type = scicite_datasetreader\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = None\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.use_lexicon_features = False\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.use_sparse_lexicon_features = false\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.multilabel = false\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.with_elmo = true\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   dataset_reader.reader_format = flat\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   validation_dataset_reader = None\n",
      "03/30/2024 10:16:07 - INFO - allennlp.common.params -   train_data_path = scicite_data/train.jsonl\n",
      "03/30/2024 10:16:07 - INFO - __main__ -   Reading training data from scicite_data/train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "8243it [00:02, 3950.19it/s]\n",
      "\n",
      "03/30/2024 10:16:09 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_section_title_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:16:09 - INFO - allennlp.common.params -   dataset_reader_aux.type = scicite_section_title_data_reader\n",
      "03/30/2024 10:16:09 - INFO - allennlp.common.params -   dataset_reader_aux.with_elmo = true\n",
      "03/30/2024 10:16:09 - INFO - allennlp.common.params -   train_data_path_aux = scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "03/30/2024 10:16:09 - INFO - __main__ -   Reading auxiliary training data from scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "23698it [00:04, 5443.46it/s]\n",
      "\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'multilabel': 'false', 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.type = scicite_datasetreader\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = None\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.use_lexicon_features = False\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.use_sparse_lexicon_features = false\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.multilabel = false\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.with_elmo = true\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   dataset_reader.reader_format = flat\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   validation_dataset_reader = None\n",
      "03/30/2024 10:16:15 - INFO - allennlp.common.params -   train_data_path = scicite_data/train.jsonl\n",
      "03/30/2024 10:16:15 - INFO - __main__ -   Reading training data from scicite_data/train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "8243it [00:02, 4042.85it/s]\n",
      "\n",
      "03/30/2024 10:16:17 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_section_title_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:16:17 - INFO - allennlp.common.params -   dataset_reader_aux.type = scicite_section_title_data_reader\n",
      "03/30/2024 10:16:17 - INFO - allennlp.common.params -   dataset_reader_aux.with_elmo = true\n",
      "03/30/2024 10:16:17 - INFO - allennlp.common.params -   train_data_path_aux = scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "03/30/2024 10:16:17 - INFO - __main__ -   Reading auxiliary training data from scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "39016it [00:10, 3901.53it/s]\n",
      "91412it [00:19, 4633.60it/s]\n",
      "\n",
      "03/30/2024 10:16:37 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_cite_worthiness_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:16:37 - INFO - allennlp.common.params -   dataset_reader_aux2.type = scicite_cite_worthiness_data_reader\n",
      "03/30/2024 10:16:37 - INFO - allennlp.common.params -   dataset_reader_aux2.with_elmo = true\n",
      "03/30/2024 10:16:37 - INFO - allennlp.common.params -   train_data_path_aux2 = scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "03/30/2024 10:16:37 - INFO - __main__ -   Reading second auxiliary training data for from scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "51781it [00:10, 5178.08it/s]\n",
      "73484it [00:12, 5715.89it/s]\n",
      "\n",
      "03/30/2024 10:16:50 - INFO - allennlp.common.params -   aux_sample_fraction = 1.0\n",
      "03/30/2024 10:16:50 - INFO - __main__ -   Inflating train data from 8243 to 91412 samples\n",
      "03/30/2024 10:16:50 - INFO - allennlp.common.params -   validation_data_path = scicite_data/dev.jsonl\n",
      "03/30/2024 10:16:50 - INFO - __main__ -   Reading validation data from scicite_data/dev.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "916it [00:00, 3845.91it/s]\n",
      "\n",
      "03/30/2024 10:16:50 - INFO - allennlp.common.params -   validation_data_path_aux = None\n",
      "03/30/2024 10:16:50 - INFO - allennlp.common.params -   validation_data_path_aux2 = None\n",
      "03/30/2024 10:16:50 - INFO - allennlp.common.params -   test_data_path = scicite_data/test.jsonl\n",
      "03/30/2024 10:16:50 - INFO - __main__ -   Reading test data from scicite_data/test.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "1861it [00:00, 3962.19it/s]\n",
      "\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   test_data_path_aux = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   test_data_path_aux2 = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.type = bucket\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.padding_noise = 0.1\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.biggest_batch_first = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.batch_size = 16\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.instances_per_epoch = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.max_instances_in_memory = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.cache_instances = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.track_epoch = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator.maximum_samples_per_batch = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.type = bucket\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.padding_noise = 0.1\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.biggest_batch_first = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.batch_size = 16\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.instances_per_epoch = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.max_instances_in_memory = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.cache_instances = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.track_epoch = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux.maximum_samples_per_batch = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.type = bucket\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.padding_noise = 0.1\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.biggest_batch_first = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.batch_size = 16\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.instances_per_epoch = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.max_instances_in_memory = None\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.cache_instances = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.track_epoch = False\n",
      "03/30/2024 10:16:51 - INFO - allennlp.common.params -   iterator_aux2.maximum_samples_per_batch = None\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 112,  99,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 101,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  69, 260,  ..., 261, 261, 261],\n",
      "         [259, 112, 120,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259,  54,  50,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         [259,  59, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[11413,     5,  6484,  ...,     0,     0,     0],\n",
      "        [   65,  1029,    16,  ...,     0,     0,     0],\n",
      "        [   26, 13992,    52,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   35,   602,  5407,  ...,     0,     0,     0],\n",
      "        [    8,  1559,     7,  ...,     0,     0,     0],\n",
      "        [   35,    22,    48,  ...,     0,     0,     0]])}, 'labels': tensor([0, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]]), 'citing_paper_id': ['8f146171c9d6ce082589bf45759204a33fa6494b', '57d1b3a25e00a2212dad89aa1712234d96f797c8', 'd6d46dcb41cc6a0883566f223c7689a5d479f785', 'b3231e925e9c851d01c0c5e08edb711f82617903', '17dd4ed72780aeba00d47dafd8cb60f78bbf3891', 'd9d512655e9ef7bf1d2898150c1ad7e2964717db', '1ed8042c32b484573035db874ee8db00b77ba326', '012566f39e626ade3effd06c583ebd1644da2e77', '2ac8f2ecc50fbbc86cdac39a747da4e294bef9f2', '0c2df06e08abaa4128481a07752aa00e7d4d2ba8', '0ebc4128400125a8c07a09d3c89fc730a4a21338', 'e630311c0ca0d19549bd0959fedd924d929fba85', 'c1a85696bc2faf53a535afd601ae746287183666', '0194f973fb5ed6367f1d76b238b3d3399faa68cb', '1c6b446bc13a454686b6c3872a78fa9c0760677b', 'be6fd38a37df063e38c9672269cd5e6b38d81b18'], 'cited_paper_id': ['6f04e7388117ce4263ab24706c3f7f8e0f4f1955', 'fc07799f1fb1db2a00f7d05d42d93e387a3a7346', 'None', 'ed10f059dd82bba94b4485223720255b9dd8dc70', '20deb8d3344b569308e0579d59723f75a8eb1cca', 'c5a23b594780b11d0671e98624b52c3c97ff3fb6', 'f08f08fab4db474ed6d556b908622d95afa2704f', '770b8815246048d3fbedc1cc1b7f1c770a3a9249', '8ec5dbce8df62233e9ad3fc70cd5c39c754373b7', '3ee799d6ef37787ae053bf961863b8fd0b3d6397', '30ee4210a90728acec437b9c0f6f66b57f34d903', '2cb9f88cf6425013c7c976fbb8b65bcbbff0d7e9', '2640c22781cc90ee4adfc3274d91bee624a13977', '646b48fe86f98e439e617c739a2c3c59c84b8eae', '815bd94807ff43a3f3a4f361e5b21e3f7a63556d', 'aa067ac2b98c72a393f99316513074f0e3d770ff'], 'citation_excerpt_index': [1, 0, 0, 0, 0, 5, 11, 0, 1, 0, 0, 4, 4, 1, 0, 0], 'citation_id': ['8f146171c9d6ce082589bf45759204a33fa6494b>6f04e7388117ce4263ab24706c3f7f8e0f4f1955', '57d1b3a25e00a2212dad89aa1712234d96f797c8>fc07799f1fb1db2a00f7d05d42d93e387a3a7346', 'd6d46dcb41cc6a0883566f223c7689a5d479f785>None', 'b3231e925e9c851d01c0c5e08edb711f82617903>ed10f059dd82bba94b4485223720255b9dd8dc70', '17dd4ed72780aeba00d47dafd8cb60f78bbf3891>20deb8d3344b569308e0579d59723f75a8eb1cca', 'd9d512655e9ef7bf1d2898150c1ad7e2964717db>c5a23b594780b11d0671e98624b52c3c97ff3fb6', '1ed8042c32b484573035db874ee8db00b77ba326>f08f08fab4db474ed6d556b908622d95afa2704f', '012566f39e626ade3effd06c583ebd1644da2e77>770b8815246048d3fbedc1cc1b7f1c770a3a9249', '2ac8f2ecc50fbbc86cdac39a747da4e294bef9f2>8ec5dbce8df62233e9ad3fc70cd5c39c754373b7', '0c2df06e08abaa4128481a07752aa00e7d4d2ba8>3ee799d6ef37787ae053bf961863b8fd0b3d6397', '0ebc4128400125a8c07a09d3c89fc730a4a21338>30ee4210a90728acec437b9c0f6f66b57f34d903', 'e630311c0ca0d19549bd0959fedd924d929fba85>2cb9f88cf6425013c7c976fbb8b65bcbbff0d7e9', 'c1a85696bc2faf53a535afd601ae746287183666>2640c22781cc90ee4adfc3274d91bee624a13977', '0194f973fb5ed6367f1d76b238b3d3399faa68cb>646b48fe86f98e439e617c739a2c3c59c84b8eae', '1c6b446bc13a454686b6c3872a78fa9c0760677b>815bd94807ff43a3f3a4f361e5b21e3f7a63556d', 'be6fd38a37df063e38c9672269cd5e6b38d81b18>aa067ac2b98c72a393f99316513074f0e3d770ff']} {'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         [259, 118, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         [259, 100, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 103,  98,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113,  98,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 102, 104,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  66, 110,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         [259, 117, 122,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 106,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[    65,    135,    745,      4,   1851,   3267,    141,      9,      9,\n",
      "             51,     15,    426,     17,     50,     16,    292,    107,    136,\n",
      "             15,    686,    118,      6,   6189,     44,      4,   2274,      6,\n",
      "              4,    208,      3,      0,      0,      0,      0,      0],\n",
      "        [    93,     30,   1362,     10,   5521,   1275,    294,      8,  38595,\n",
      "              7,     22,   1372,    553,    115,     18,   8325,  36871,     59,\n",
      "            381,      2,     22,     63,     24,    211,     10,   4849,     97,\n",
      "             19,     15,    195,    648,    413,      2,      3,      0],\n",
      "        [    26,    562,     17,     43,    336,    261,   3143,      6,    479,\n",
      "           8229,    765,     17,   1248,    856,     10,   1668,     39,    319,\n",
      "            268,     27,   7902,      8,     56,      2,     72,      2,    171,\n",
      "              2,    143,      2,    241,      7,      3,      0,      0],\n",
      "        [    41,      2,  94827,      5,  11102,     76,   3118,    731,     10,\n",
      "           1235,      4,   9897,     58,    145,      5,   1274,      9,  45581,\n",
      "            346,     49,   1169,     51,     22,  10950,      5,   7508,    893,\n",
      "             51,     22,  10302,      3,      0,      0,      0,      0],\n",
      "        [    26,    141,     59,      6,      4,  27995,     18,  55708,   1211,\n",
      "              2,      8,  92440,    196,  55708,      2,  92441,    196,  92442,\n",
      "              2,     29,  92443,    196,  38875,      7,      2,     16,     54,\n",
      "             25,      4,  92444,     59,      3,      0,      0,      0],\n",
      "        [ 38651,      8,      7,     16,     15,    598,     54,     25,   9162,\n",
      "           7351,   2324,      8,      7,     32,  69720,   2452,    222,     23,\n",
      "           5433,      4,   4356,    117,     58,     15,   1620,      6,   2480,\n",
      "            645,      5,      4,    576,    496,      3,      0,      0],\n",
      "        [    56,      8,    108,    760,   4491,     16,    671,     19,      4,\n",
      "            985,      6,      4,   4401,    625,      9,      5,      4,    134,\n",
      "          95539,    133,    502,      7,      2,   4270,  39215,      2,      5,\n",
      "          12025,      4,    821,    648,      3,      0,      0,      0],\n",
      "        [    26,  57070,     11,   3200,    510,   1225,     36,   1503,     28,\n",
      "              2,  57070,   2506,     28,      2,  15501,   2506,     22,     97,\n",
      "             22,    185,  11819,    994,  15501,   3056,     28,      2,      5,\n",
      "           9199,   2506,      9,   1916,      0,      0,      0,      0],\n",
      "        [    41,    132,      2,    700,     12,     13,      3,    782,     15,\n",
      "           3413,    103,     18,      4,    362,  23679,      6,  18733,   1884,\n",
      "              8,  91791,      7,      2,     32,   2492,  70798,    526,   3593,\n",
      "             10,  70799,    226,      3,      0,      0,      0,      0],\n",
      "        [ 12520,   5039,     11,  52520,   1058,     40,     46,     27,   4670,\n",
      "              6,    509,  57148,      2,    610,      6,     15,    480,     29,\n",
      "           3289,    353,      2,      9,     15,   2446,   1459,     10,     22,\n",
      "             15,  62599,     59,      3,      0,      0,      0,      0],\n",
      "        [102316,      5, 102317,      8,     62,      7,   2173,     15,     59,\n",
      "              6,      4,    380,    677,      6,   7762,    162,     54,     25,\n",
      "             15,   1071,    581,    223,    470,      6,     82,   4037,  36561,\n",
      "              5,     15,    103,     18,    582,   1561,   4580,      3],\n",
      "        [   539,      2,  11734,      2,      5,  56803,      8,    318,      7,\n",
      "            141,     15,     82,     11,   1008,    917,     59,     17,  73202,\n",
      "              4,    139,      5,  18839,    518,      6,      4,   2026,   2769,\n",
      "              6,     15,    849,     11,   3280,   2152,      3,      0],\n",
      "        [     8,  18767,   7022,      2,  16824,  48198,      2,   6675,      2,\n",
      "          24038,   4475,   4890,      2,   1185,   3865,   4890,      2,     29,\n",
      "           6688,   4475,   4890,      7,     21,     56,      2,    128,      2,\n",
      "          11202,     20,      3,      0,      0,      0,      0,      0],\n",
      "        [    65,    503,     16,    231,     19,  36518,      6,  22264,     22,\n",
      "            299,    727,     25,     15,    293,    153,      6,  43848,      9,\n",
      "          11264,     91,      8,  10045,      7,   4178,      6,   1089,     29,\n",
      "              9,     34,    649,    540,      6,  15086,    197,      3],\n",
      "        [  1856,     84,    325,      6,   3663,      2,   7658,     24,    211,\n",
      "             10,    322,    258,   7463,     52,    232,     10,      4,    562,\n",
      "             17,    111,   2166,    133,  14057,    559,    133,     10,   9283,\n",
      "             53,     28,    287,   2028,      6,     85,      3,      0],\n",
      "        [    65,    135,     16,    139,     10,      2,     19,      4,   3836,\n",
      "              6,     49,   1475,   1458,   1654,     18,    105,   1228,      5,\n",
      "             15,    195,    118,      6,   2344,    304,     19,   1458,   2986,\n",
      "           1434,   2861,     18,    209,      3,      0,      0,      0]])}, 'section_label': tensor([3, 0, 1, 4, 3, 0, 2, 3, 1, 2, 3, 4, 1, 1, 3, 4]), 'citing_paper_id': ['82beed03eee73c77c6d5edfd7952a5c4837d7ea1', '23738361c0111b525ee611512d5ab6acece3bbca', 'dbcda98b7fed00e82563d7c340393046540fd741', '6522e947390e2ce80bf6280ecc4fc95bda5ee7e0', 'de1610a8f90cad153730c45f39bcfcdb54d597cc', '6f900e683ea1fc85825a403d1ba2df7875f35bb9', '0e0dd5b51ed698d58bf3975106ef025a347a523e', '94c4acaa7bf75955fddcaf30021defddd7502590', '7b60832d550c93de7f61b0040f50ac64dc748a87', '7a80658821ba5dd63684699abe24de3d1ae43d48', '72900e0eadbe8ce187f36dbe8bcbab100cf67c06', 'df7ef1abf27970e3952f68f9130d8dccfcbd6841', '0af55ceac092602f5af93f76d940e346f213a11c', 'db868dfd56cfc45711bdd7d55e52425f235bf22f', '47ec091ba9d916e391c2f4e8ec36edcb59d104d6', 'a58f385cd5118ce70ae31c0800042b851c44ab6e'], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]} {'citation_text': {'elmo': tensor([[[259,  71, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 112, 118,  ..., 261, 261, 261],\n",
      "         [259, 109,  98,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 101,  ..., 261, 261, 261],\n",
      "         [259, 111, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259,  74,  83,  ..., 261, 261, 261],\n",
      "         [259, 115,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  99, 102,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 100, 118,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  69,  68,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[   546,      2,    140,     24,     82,   1101,   1210,    706,      2,\n",
      "           3481,     23,  27301,      5,  23387,      2,    173,      4,     82,\n",
      "           1342,      6,  11754,   1202,     81,   1957,     81,  18800,   1665,\n",
      "              5,    563,      4,    647,    483,      3],\n",
      "        [   114,    159,      2,   5921,  84637,   4122,     10,     76,    273,\n",
      "          14285,   4115,     10,   1811,     10,      4,    169,  18724,      2,\n",
      "             32,    270,     42,   2918,   2444,     19,      4,  12295,  18724,\n",
      "           2322,      3,      0,      0,      0,      0],\n",
      "        [   146,    548,   1089,   3447,    112,      4,   1150,      6,   1394,\n",
      "            616,    291,   1385,      2,  85847,   1385,      2,    498,     11,\n",
      "            844,    255,    855,      2,    910,     59,   7986,      2,      5,\n",
      "            291,    918,    855,      3,      0,      0],\n",
      "        [   146,     47,     46,    511,     17,    423,      6,   4286,    634,\n",
      "         124608,      7,    275,     27,    312,      9,      4,    447,      6,\n",
      "          13410,     70,     42,    120,   2046, 124609,   5513,  39345,  59534,\n",
      "              3,      0,      0,      0,      0,      0],\n",
      "        [   624,   5582,     57,   1320,   1060,   1655,   1342,      9,      4,\n",
      "            295,     11,   1412,     53,     68,      4,   3957,    364,     53,\n",
      "              2,     70,     15,    446,   1320,   1060,   1655,   1342,     24,\n",
      "            663,      9,      4,   1580,      3,      0],\n",
      "        [ 47206,      2,    500,      5,    475,  47206,    172,    900,     15,\n",
      "            683,    219,      9,   4687,    549,    283,     23,  11619,      4,\n",
      "            475,      5,   1377,   1395,    500,     18,     15,   1415,    819,\n",
      "              3,      0,      0,      0,      0,      0],\n",
      "        [    65,  44719,     85,      9,   8695,    276,    361,  13484,   2512,\n",
      "             10,    105,   4535,   2090,     22,     97,     22,      4,     85,\n",
      "             10,   9252,   2090,  11212,    733,   3524,     23,    105,   4535,\n",
      "           2090,      3,      0,      0,      0,      0],\n",
      "        [    41,    449,     10,      4,   4016,    200,    147,     15,  26234,\n",
      "            726,   2577,     16,   2564,      2,    805,      4,   2979,     16,\n",
      "             17,    168,     57,     68,     82,   7538,     24,   3928,     10,\n",
      "            105,  11081,      3,      0,      0,      0],\n",
      "        [    26,    380,     38,    168,   1513,      6,    120,     29,     10,\n",
      "            619,   1349,  50222,    172,   6244,      2,      5,      4,    551,\n",
      "            493,     40,     27,   1910,     10,    972,    316,     10,     76,\n",
      "              5,    881,     10,    177,      3,      0],\n",
      "        [   640,      2,     50,     40,   2417,     15,    573,      6,    836,\n",
      "              6,   2882,      2,    129,    407,      5,   1549,   2882,      2,\n",
      "             98,      6,     32,     40,     30,  11145,  26343,    175,     25,\n",
      "              4,    947,   1402,     29,   4294,      3],\n",
      "        [    65,     42,    107,   1244,   4667,    130,   3441,      2,     70,\n",
      "             46,    638,     17,    542,  11833,     24,  55084,     18, 131173,\n",
      "             17,    430,     10,     27,  39330,     44,   2407,     25,    194,\n",
      "             53,      3,      0,      0,      0,      0],\n",
      "        [    41,    110,    279,      2,      4,     53,     24,    427,     22,\n",
      "             15,   9301,     29,    837,     44,      4,  38501,      2,      5,\n",
      "              4,    144,    628,      6,   6060,      4,   3189,    332,    100,\n",
      "            507,     16,   6962,      3,      0,      0],\n",
      "        [    26,   1416,     16,      4,  84413,     32,     15,    194,   1618,\n",
      "             16,     10,     27,   1140,      5,      4,    756,     16,      4,\n",
      "          84413,     32,      4,  15026,   2785,     81,  17213,    628,     31,\n",
      "            471,      3,      0,      0,      0,      0],\n",
      "        [   204,   2958,   1692,     16,   7296,    161,     15,    453,      2,\n",
      "            176,   9843,     24,   9612,   2347,      4,   1626,   5180,      9,\n",
      "              4,   1572,     10,   6124,  31615,     51,     22,   7453,      2,\n",
      "          22981,      2,      5,  10048,      3,      0],\n",
      "        [    87,   1902,   1924,   1476,      5,     15,    249,  59789,      6,\n",
      "          19209,     38,     33,    292,     10,   2414,   1902,  19494,      5,\n",
      "           4396,    609,     18,   3171,      6,   1902,   2979,      9,  34578,\n",
      "           5602,      3,      0,      0,      0,      0],\n",
      "        [    35,   7608,    427,     23,      2,  25504,    221,      2,      5,\n",
      "          34214,    221,     25,    273,    187,    307,   3093,      2,    129,\n",
      "              4,   5781,      2,   6093,      5,  21462,      2,      5,  22176,\n",
      "             53,    811,      3,      0,      0,      0]])}, 'is_citation': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), 'citing_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'c1f05b723e53ac4eb1133249b445c0011d42ca79'], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  67,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 109, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  80, 118,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259,  81, 112,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 105, 106,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[ 1238,    25,    63,   250,     2,     4, 13876,   570,    58, 24351,\n",
      "             5, 10983,   680,    24,    44,   534,     9,   377,   232,    10,\n",
      "             4,   565,     6,   680,    11,  8208, 24351,     8,    29, 21659,\n",
      "             7, 42346, 18978,     8, 11895,    12,    13,     3,     2,    74,\n",
      "            14, 25496,     5,  9968,     2,    88,     7,     3],\n",
      "        [ 6497,   164,     6, 35067,    24,    92,     9,  2603,   160,  9459,\n",
      "           834,    15,   312,  1814,     6,     4,  3876,  2683,    10,   354,\n",
      "            11,   163,   492,  2820,    21,   323,    20,     2,    70,     4,\n",
      "           533,     6,  1030,    25,  3876,   358,     9,     4,   160,   364,\n",
      "            38,    42,    33,   448,     3,     0,     0,     0],\n",
      "        [  305,   176,  1814,    16,    10,  4617,   619,    38,   263,  1130,\n",
      "            33, 21684,    11,    54,  3895,    25,   316,   998,  8977,   848,\n",
      "            40,    29,    40,    42, 19011,  8392,  3243,     5,   524,    10,\n",
      "          8127,     6,  3381,   454,     8,  4946,     2,    67,    14, 10103,\n",
      "             5, 14503,     2,    74,     7,     3,     0,     0],\n",
      "        [  869,    47,    30,    99,    17,     4,  1693,  2630,     6, 20861,\n",
      "            24,  4419,    23,  6606,    11,    87, 20862, 20863,     8, 20864,\n",
      "             9,  1509,    11,  6219,  3758,     7,     9,    98, 12066,     5,\n",
      "          6599,  5263,   631,     8,  1987,    12,    13,     3,     2,    80,\n",
      "             2,  2693,     7,     3,     0,     0,     0,     0],\n",
      "        [   87,   234,   755,     6,    39,  6531,    31,  5662,    11, 42879,\n",
      "            18,   548,  2294,    11,   604,  6643,     8,    15, 24763,    83,\n",
      "          9404,  9796,  9300, 40495,  5447,    11,    18,    11,   604,  1321,\n",
      "           144,   625,     9,    69,     2,   174, 12384,    12,    13,     3,\n",
      "          2799,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [  114,   159,     2,  2924, 43000,     5, 43001,    36,    98,  2252,\n",
      "            10,    77, 33599,     2,   149, 43002,     2,    22,   111,  1480,\n",
      "             4,   169,  9100,   347,     5,  2867,  1283,     6,     4, 24846,\n",
      "           353,  3691, 15940,     8,  6017,    12,    13,     3,     2,    64,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 9661,   354,     2,    55,    47,    17,   467,  3476,  1092,    19,\n",
      "         28303,    29, 44782,    30,    79,   139, 44783,     7,    41,   449,\n",
      "             2,   354,    31,    42,    79,    10,    27,   151,    19,   847,\n",
      "             9,   489,    61,    17,   467,  3476,  1092,    19, 28303,     2,\n",
      "             5,    75,    52,    24,   231,    19,  9412,     3],\n",
      "        [ 3286,   179,   114,  4218,     6,  1474,   179,     9,  5148,   496,\n",
      "             2,    94,    81,  1182,    36, 30587,     9, 37575,     8, 10105,\n",
      "             7,     2,     5,   718,    31,  1503,     5,  2122,    31,   576,\n",
      "             5,  4328,    22,   122,   100,     8,  5029,     7,    49,    15,\n",
      "         12633, 42540, 28725,   662,     8,  5859,     7,     3],\n",
      "        [  155,     2,  1051,    24,   579,    10,  3614,  5096,   719,    28,\n",
      "         26679,   719,    23,    60,    97,    11,   238,  5196,   103,     8,\n",
      "         34722,     5, 22429,  1630,    14, 30156,    12,    13,     3,  1405,\n",
      "            14, 34723,     5, 22430,  1001,    14, 24294,     5, 10069,   439,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [   26,  3410,  1054,    23, 13089,     9,     4,   181,     5,  3418,\n",
      "         12597,     6,   498,    66,    27,  3164,     9,   110, 38158,    20,\n",
      "           624,     6,    75,    96,  6207,  7324,     2,     5,   489,   461,\n",
      "         26002,    10,   127,     9, 38159, 10281,  3230,  1062,  1993,  3020,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    8,  3156,     7,    21,   367,    20,     2, 45238, 11607, 35686,\n",
      "             8, 45239,     7,    21,   334,    20,     2,  4348,  3216,     8,\n",
      "         19262,     7,    21,   282,    20,     2, 14980, 15355,  5094,  9902,\n",
      "             8, 45240,     7,    21,   384,    20,     2,     5,  9487, 31147,\n",
      "             8, 45241,     7,    21,   541,    20,     3,     0],\n",
      "        [ 1328,     2,   436,     4,  4415,   370,     6,  9759,   550,     9,\n",
      "          3283,  1019,  3357,   484,    84,  3934,   325,     8,  9906,     7,\n",
      "             5,  1556,     8,   473,     2,   564,     7,     2,    50,    16,\n",
      "           748,   946,    10,     4,  3957,   558,   370,     2,  1904,   945,\n",
      "            15, 24839,   188,    44,  2071,     3,     0,     0],\n",
      "        [25357, 32167,     8, 14769,     7,    31,   286,    18,  1335,  1024,\n",
      "             6, 39547,    11, 39548,     8,     4,  1547,  1453,   673,     6,\n",
      "         39549,     7,     5, 39550,     8,     4,  1547,  1453,   673,     6,\n",
      "         16287,     7,    22,   100,   122,     8,   218,     2,   384,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   26,  1531,     6,   433,  4906,    40,    27,   760,    58,    11,\n",
      "           361,   518,     6,    15,   433,   228,     8, 25651,    12,    13,\n",
      "             3,     2,   393,     2,   142,    14, 25652,    12,    13,     3,\n",
      "             2,   257,    14, 40085,    12,    13,     3,     2,    64,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    8, 29284,     7,  4663,    15,   113,   153,     6,   639,  1596,\n",
      "            14, 11165,     5, 19921,  2519,     2,     4,  5302,     6,  8120,\n",
      "          2772,     5,  3354,  1225,    36,   372,   223,     4,   104,  6788,\n",
      "          1224,     6,     4,   113,  4341,    11,   176,   729,  1596,   198,\n",
      "             8,  6237,    12,    13,     3,    67,     7,     3],\n",
      "        [   26,   113,   863,     6,  4747,     9,     4,  5228,  3507,   154,\n",
      "          5951,     5,    55,   375,    17,   524,    10,  1499,     5,  6440,\n",
      "             6, 22840,  2426,     5,  9489,     6,   465,  1765,    21,   331,\n",
      "             2,   367,     2,   674,     2,  1893,     2,   720,     2,  4375,\n",
      "             2, 10684,    20,     3,     0,     0,     0,     0]])}, 'labels': tensor([0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0]), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]]), 'citing_paper_id': ['09e0d57688dff5fafb510c85b5c78035f298d58f', '32551266b5f5240c082e4dc45c8673ba0155da31', '2594d5a4fe56fd16b141fc870ffa202daee78435', '067e6e179759e6ae14ab7f615d3102758972f47d', '1b69830499fe27ffa7e1752f76bf7a1b412f509d', '5ddd341c20f323d736e9b3899ad20561c9bdbeea', 'b97240634418a7c2a7dfc8165c056964d29c48c9', 'd0af90fe7c47cc41ed2dfd0e18a79be75abae6aa', 'b89b2a7c55bf2d0a8edec86586935d0782124361', '0239f5e83b2394c8728eb0a9987ca5a3d85bde5c', '1aa696d4bb83066c3c97e5e0ad572dffe589e101', '318ff0c00e6899a66ee4a4d969e0d72500e16a3e', '3779984763892cc04f1b401be15619c19dde6dbd', '8e8ebc082592e5f8a730aa8be1fc277304a4904d', '291ca965a80c0b484e70533599b2898f3c9b7cf7', 'cf3d0d63e8ed6cb6bac03c00d21d8b87c83a39d5'], 'cited_paper_id': ['3610fb9b112315fd8f771bfec66d2d18a13fa76f', 'ba28d89a6944ec0b816e76cc18fa181975ec4f6a', '14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '21ff60da9f24acf1a426761e35c897cc73e0401f', '3dac6d4eb221945f009c543a65537513d186c5ed', '8f2cfced117e54b3e1ba97b0e43f34e0ec747952', 'd5e65197f8fe03eb75980112e823c91b9ea4b5d7', 'b58be1db1b62f58924c59abcbc183fafc6ba38c5', '134c2c721923e6b7daea799dd0a1e568e6fc8cc9', '5726e2bf1e9164b67a20cd932bdbc8fb19d31cde', '1442780fa1dfc4df886bb2dc201f69ddaa23ac29', '41129a35ce2f54686e6a9c697a4ab9d6b0312150', 'db089612ae724c9f1f3f273a4b8762055e49701e', '306162a897125aff076a682d474579337c6b14a7', '63daf1741972395162371e6e9bf12348828cfe44', '3d8487b14c2aae003bcdf41f857e0b51c91f285f'], 'citation_excerpt_index': [15, 0, 1, 6, 1, 1, 0, 0, 0, 0, 3, 0, 10, 0, 14, 0], 'citation_id': ['09e0d57688dff5fafb510c85b5c78035f298d58f>3610fb9b112315fd8f771bfec66d2d18a13fa76f', '32551266b5f5240c082e4dc45c8673ba0155da31>ba28d89a6944ec0b816e76cc18fa181975ec4f6a', '2594d5a4fe56fd16b141fc870ffa202daee78435>14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '067e6e179759e6ae14ab7f615d3102758972f47d>21ff60da9f24acf1a426761e35c897cc73e0401f', '1b69830499fe27ffa7e1752f76bf7a1b412f509d>3dac6d4eb221945f009c543a65537513d186c5ed', '5ddd341c20f323d736e9b3899ad20561c9bdbeea>8f2cfced117e54b3e1ba97b0e43f34e0ec747952', 'b97240634418a7c2a7dfc8165c056964d29c48c9>d5e65197f8fe03eb75980112e823c91b9ea4b5d7', 'd0af90fe7c47cc41ed2dfd0e18a79be75abae6aa>b58be1db1b62f58924c59abcbc183fafc6ba38c5', 'b89b2a7c55bf2d0a8edec86586935d0782124361>134c2c721923e6b7daea799dd0a1e568e6fc8cc9', '0239f5e83b2394c8728eb0a9987ca5a3d85bde5c>5726e2bf1e9164b67a20cd932bdbc8fb19d31cde', '1aa696d4bb83066c3c97e5e0ad572dffe589e101>1442780fa1dfc4df886bb2dc201f69ddaa23ac29', '318ff0c00e6899a66ee4a4d969e0d72500e16a3e>41129a35ce2f54686e6a9c697a4ab9d6b0312150', '3779984763892cc04f1b401be15619c19dde6dbd>db089612ae724c9f1f3f273a4b8762055e49701e', '8e8ebc082592e5f8a730aa8be1fc277304a4904d>306162a897125aff076a682d474579337c6b14a7', '291ca965a80c0b484e70533599b2898f3c9b7cf7>63daf1741972395162371e6e9bf12348828cfe44', 'cf3d0d63e8ed6cb6bac03c00d21d8b87c83a39d5>3d8487b14c2aae003bcdf41f857e0b51c91f285f']} {'citation_text': {'elmo': tensor([[[259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 113,  98,  ..., 261, 261, 261],\n",
      "         [259,  98, 100,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  79, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 115, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 104, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69,  81,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  66,  68,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[  852,     4,  1766,  3018,  5514,  1489,     2,    16,    44,   201,\n",
      "            19,  1768,    10,    39,  3361, 15021,  6777,     8,   468,     3,\n",
      "             0,     0,     0],\n",
      "        [16276,   708,    10, 34135,  1518,    46,  1986,    15,  2208,  7439,\n",
      "             6,    98,  5389,     5,  6663,   804,  1171,    10,    60,  8366,\n",
      "          2764,   358,     3],\n",
      "        [ 1697,    17,     4,    59,  1634,  2897, 20659,   196, 36541,     2,\n",
      "           216,    43,  9929, 14108,    10, 49437,   922, 10066,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [38759,    28, 17801,    48,  1693,  1507,     9, 10646,    11,  5343,\n",
      "             2, 23372,  1507,     9,  6324,    11,  9793,     5, 10291,     9,\n",
      "          9215,     3,     0],\n",
      "        [   92,     4,   188,     6, 19440,    23,  1929,  8400, 71138,     9,\n",
      "          4301,   274, 45782,    31,   234,  1400,  1062, 55575,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [73335,    11,   891,   497,   966,    36,   873,    23,  1159,     4,\n",
      "          1324,    10,     4,   264,   651,    19,     4,   239,   179,    48,\n",
      "             0,     0,     0],\n",
      "        [ 8217,   248,  7887,     2,   147,     4,   685,   248,     6,     4,\n",
      "          4136,    31,  1065,    23,  2309,   843,   368,     2,    31,   702,\n",
      "             9,     3,     0],\n",
      "        [ 3980,    10,   492,  7573,     5,  7612,  1421,     2,  3906,  1421,\n",
      "            16,    57, 12375,     9,  1070,     5,  1372,    18,  1211,    47,\n",
      "             3,     0,     0],\n",
      "        [ 1596,     6,    75,   109,     2,    43,  2417,     4,  2483,   419,\n",
      "         72111,     2, 13206,     2,   791,     7,    49,    34,  6030,  2320,\n",
      "         62427,     3,     0],\n",
      "        [ 1148,   326,   450,  1228,   297, 19463,    21, 11352,    20,     2,\n",
      "            70,    46,  2501,   450,   297,  1543,     2,    76,    51,    15,\n",
      "          4936,   617,     3],\n",
      "        [  869,   127,     9,   740,   485,  1540,    38,   727,    25,  3237,\n",
      "         11826,   203,  9382,  2498,    25, 11832,    11,    54,  1540,     3,\n",
      "             0,     0,     0],\n",
      "        [  114,   667,     2,   745,    15,   917,   170,    15,   347,     6,\n",
      "           517,  2044,    19,    15,  4870,   483,    25,  1085,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [  781,  4194, 23002,   194,  4678,   272,   955,   127,     2,     4,\n",
      "          1819,     6,  1085,   410,  1318,     4,  2457,    24,     6,   683,\n",
      "           820,     3,     0],\n",
      "        [55262,  1034,  3680,     2,    39,  8770,   462,     6,  3680,     2,\n",
      "            24,  1100,   914,    10,  7639,  2260,     9, 45849,    60,  2073,\n",
      "             3,     0,     0],\n",
      "        [   41,   274,     2,   139,    52,    24,   262,   120,  2357,   201,\n",
      "           222,    18,   357,   328,    11,    79,    29, 12295, 12274,     3,\n",
      "             0,     0,     0],\n",
      "        [12693,     2, 20670,     2,     5, 64043,    24,     4,   104,   826,\n",
      "            45,  1036,    11,     4,    11,  7458,  7116,  3618,     3,     0,\n",
      "             0,     0,     0]])}, 'section_label': tensor([0, 2, 3, 1, 4, 2, 2, 3, 3, 4, 4, 4, 2, 0, 0, 4]), 'citing_paper_id': ['133e1fdb349ad7aa2f534b4eb315774adc98f057', 'b1cb8d136522ac19c4dc77e0149db628d3f8b724', '071b16f25117fb6133480c6259227d54fc2a5ea0', 'a135e466c95d0e878e39187d41bf01016bc80dd6', 'a45d033f7fc4de28b084e26d1aa6a7488dd473f6', 'a7eb55e571dba20935af8006428f762811e9a49f', '58cdb0bc1b57f675fbba2902c6d60b9f6c07b8e8', '6d7fbbadc27094d4ae67862d6566f66939562629', '800e1b2e4981fe652f8010b1971d80b72a852cf1', '720bdf8e06917c227fdd13fd5b10bf04dbd08454', 'd4553ed06b6bfdd6091eab25c3fc50b616f73900', '0891ed6ed64fb461bc03557b28c686f87d880c9a', '7a25690e3771286c2e5874b98ba20312d4f87be8', '473ce6e221f9ea8785ff8f3f2eeeebd9cff0b687', '2d2ad1026a0dfb56471e6977868b88196ff88b5e', '0c769c19d894e0dbd6eb314781dc1db3c626df57'], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]} {'citation_text': {'elmo': tensor([[[259,  66, 103,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 100,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 103, 106,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 102, 117,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         [259, 103, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  86, 116,  ..., 261, 261, 261],\n",
      "         [259,  66,  78,  ..., 261, 261, 261],\n",
      "         [259,  50,  57,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 120, 112,  ..., 261, 261, 261],\n",
      "         [259, 115,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259,  98, 101,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]]), 'tokens': tensor([[  1309,      4,   3565,      6,    602,     16,   2642,      2,     43,\n",
      "           1927,     23,   1159,     10,   1744,     95,  36123,   1278,    249,\n",
      "             16,    269,     68,      4,   1175,  26558,    152,  85285,  85286,\n",
      "              3,      0,      0],\n",
      "        [   146,    250,     36,   5316,      9,     15,  24711,     61,      9,\n",
      "           5669,   1342,  12754,     18,   1940,      2,      5,      9,    258,\n",
      "            195,   3940,   1325,     47,      9,      4,   1835,      8,  52098,\n",
      "             12,     13,      3],\n",
      "        [   189,     15,  68394,   2650,   1530,     15,    554,   5181,      2,\n",
      "          20134,      2,    470,      2,      5,     15,    615,  21675,    615,\n",
      "              6,    455,    193,     24,   1035,     23,      4,    554,      3,\n",
      "              0,      0,      0],\n",
      "        [ 21319,     11,    333,     53,    811,  16582,     30,    743,   3641,\n",
      "            222,      2,    178,      4,   2778,     29,   4957,     31,   1035,\n",
      "             18,     95,      4,    329,   1662,     25,      4,  43768,      3,\n",
      "              0,      0,      0],\n",
      "        [  5129,     94,      5,   4740,   1206,   2731,   1616,     28,    424,\n",
      "           1206,      2,    431,     94,      2,      5,   4740,   1206,      8,\n",
      "              4,   1687,    483,     16,   1101,   1210,      7,      3,      0,\n",
      "              0,      0,      0],\n",
      "        [ 38748,     39,    660,     38,    168,    188,      2,    402,     15,\n",
      "           6662,      6,   4052,   1406,      9,      4,   7726,    734,  11502,\n",
      "          11299,    232,     10,     76,      6,   1354,   8544,   3928,     10,\n",
      "            936,   1526,      3],\n",
      "        [  2672,      2,      4,  61269,   3331,      6,    948,      5,   3658,\n",
      "              5,      4,    493,     19,    386,    255,   3590,   1270,     18,\n",
      "           1432,    175,     17,    184,     42,     27,   6874,     19,    102,\n",
      "            243,      3,      0],\n",
      "        [    26,    755,      6,    670,   2870,     28,   2730,     25,     15,\n",
      "           8137,    816,     44,      4,  54216,     16,    182,    801,   4385,\n",
      "              6,   1531,    220,     68,      4,    755,    365,    311,  35116,\n",
      "          44586,   8243,      3],\n",
      "        [    26,   3171,    134,  14446,    133,   3732,   2424,     10,   1348,\n",
      "              5,    399,     17,     79,      4,    125,      2,      5,     40,\n",
      "             27,     45,     23,   2643,   4859,     18,    337,   1935,      3,\n",
      "              0,      0,      0],\n",
      "        [   622,      4,  16222,     38,     33,   1723,   4308,     22,     15,\n",
      "           1372,  13215,    404,      2,    140,     16,    168,    298,     10,\n",
      "            722,     39,    342,     19,    759,    301,    487,     51,     22,\n",
      "              4,  36382,      3],\n",
      "        [  1426,   2044,     24,  15096,    112,     15,    253,    659,     17,\n",
      "             16,     45,     22,    424,     10,     15,   5898,   2018,      2,\n",
      "             32,   5801,     15,    809,  19388,     18,     15,    517,  16616,\n",
      "              3,      0,      0],\n",
      "        [   624,    442,    205,     19,     39,    135,     16,     17,     50,\n",
      "           5231,   2620,    634,    255,     18,    470,    193,     24,     42,\n",
      "           6457,    336,     23,      4,    103,    311,   2960,      3,      0,\n",
      "              0,      0,      0],\n",
      "        [116895,      8,     67,      7,  15996,     15,    320,      6,    312,\n",
      "           1569,    550,     10, 116896,   6390,      2,   3395,   1340,     44,\n",
      "          11619,   2285,      5,   9161,     28, 116897,      5, 116898,    115,\n",
      "              3,      0,      0],\n",
      "        [  1430,  49749,  80849,      2,  11242,    368,    119,     31,    581,\n",
      "             10,   3377,      4,   1266,      6,    105,   2337,      2,    203,\n",
      "            903,   1717,    731,     31,     45,     10,    256,   2471,      3,\n",
      "              0,      0,      0],\n",
      "        [    93,    275,    491,   2394,    646,    800,   2567,      5,     76,\n",
      "              4,    474,   1037,      2,    357,    433,  36557,     29,  29922,\n",
      "            602,   1037,    500,      2,     10,   2638,   4371,    105,    179,\n",
      "              3,      0,      0],\n",
      "        [    26,     61,  11065, 121914,    338,    342,     28,    186,     10,\n",
      "             56,   2226,    796,   3112,      2,   3112,      2,   2859,   3112,\n",
      "              2,    168,   4844,      2,   2859,   9448,      2,   9448,      2,\n",
      "            796,   9448,      3]])}, 'is_citation': tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]), 'citing_paper_id': [None, '162e5c05567ba508a8f9ec4729930505696c4198', None, None, None, None, None, None, None, None, None, None, '27c46337525dcccb7ba02f05f3ad2c3d2a1e5971', None, None, None], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]}\n",
      "{'citation_text': {'elmo': tensor([[[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259,  81,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 110,  ..., 261, 261, 261],\n",
      "         [259, 120, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  78,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  70,  98,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  84, 106,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[  114,     4,  5310,  3818,  4071,   425,    21,    90,    20,     2,\n",
      "            43,   843,     4,  1243,     2,  2655,     2,     5, 13082,     6,\n",
      "           105,  1228,    22,     4,  4330,     3,     0,     0,     0],\n",
      "        [18450,   203,  5545,    16,     4,   975,   630,     6, 24448,  5560,\n",
      "          4201,     5,  1325,     2,    22,    97,    22,  2067,  1969,    21,\n",
      "            56,    11,   171,    20,     3,     0,     0,     0,     0],\n",
      "        [  155,     2,   139,    10,    75,    52,     2,   102,    47,    30,\n",
      "           229,    17, 33077,  3117,    94,   245,   210, 17764,   358,    21,\n",
      "          2404,    11,  2437,    20,     3,     0,     0,     0,     0],\n",
      "        [ 6965,     6, 20385,  8572,   392,  3049,  9656,    11,   310,  3001,\n",
      "             8,   300,  5753,     7,    22,    31,    46,    99,   122,     8,\n",
      "         10126,    12,    13,     3,     2,    78,     7,     3,     0],\n",
      "        [   21,   171,    20,    76,    15,   732,    11,  3386,  6003,  2047,\n",
      "          2112,    10,   499,  6277,    15, 29338,   883,    28,   261,   304,\n",
      "             6,     4,   450,     3,     0,     0,     0,     0,     0],\n",
      "        [  546,     2,    44,   148,  4730,     4,  5244, 13922,     6,     4,\n",
      "          5239,    94,    16,  3379,   551,     9,  5239,   121,  4711,     8,\n",
      "         11289,    14,  9983,     2,   303,     7,     3,     0,     0],\n",
      "        [  158,    31,    46,   198,    17,  2873,   235,   210, 35373,     5,\n",
      "          8790,   164,     8, 32940,    12,    13,     3,     2,   257,    14,\n",
      "          5424,    12,    13,     3,     2,    80,     7,     3,     0],\n",
      "        [25777,     7,   146,    52,    24,   231,    19,     4,    79,   355,\n",
      "             9,  6192,   264,    58,  7200,     5, 16061, 25778,     2,  1704,\n",
      "         25779,   740,  7200,   319,     3,     0,     0,     0,     0],\n",
      "        [ 1172,     8,    80,     7,   908,    84,   822,   568,     6,  2880,\n",
      "           382,    58, 22589,     5, 28625,  1680,  9510,     2,    32,    24,\n",
      "           107, 12159,  4427,  5654,     9,  5679,  7676,     3,     0],\n",
      "        [   26,  1454, 30490,   668,     6, 42477,    32,    31,    92,    10,\n",
      "            30,   537,   707,     5,  2167,    31,    45,     9,    39,    61,\n",
      "            21,   473,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [13584,   804,    46,  1812, 17333, 32479,     5,   253,  1008,   326,\n",
      "            11,  1509,   688,     2,  1999,  8177,  3832,     2,     5,  2059,\n",
      "          8991,     7,  3592,     8,    90,     7,     3,     0,     0],\n",
      "        [  146,   308,  2417,    10,   552,   340,   812,  1145,     5,  2273,\n",
      "           235,    15,  7771,     2,   278,    18,     4, 18868,    96,    21,\n",
      "           290,     2,   282,    20,     3,     0,     0,     0,     0],\n",
      "        [    2,    78,     7,     2, 26803,     8, 25521,    18,   653,     7,\n",
      "           425,     8, 26804,     5, 26805,     2,   106,     7,     5,  4522,\n",
      "           425,     8, 11137,     5,  4338,     2,    62,     7,     3],\n",
      "        [  155,     2, 11328,   791,    12,    13,    92,    17,     4,  7644,\n",
      "           847,   248,     6, 31215,    96,    31,   392,   293,    68,    17,\n",
      "             6, 31216,    96,    21,  1047,    20,     3,     0,     0],\n",
      "        [ 1667,  2229,    31,    46,  3095,    23,     4,  4733,     6,    15,\n",
      "          3469,  7129,     2,    32,  2691,     4,   952,  2110,     6,     4,\n",
      "           872,     8, 27196,    12,    13,     3,   106,     7,     3],\n",
      "        [ 1059,    52,    30,    33,   100,    23,    75,   228,     9,   160,\n",
      "          3757,    21,   783,    20,     2,     5,    23,    55,   607,     9,\n",
      "          5148,  2697,    21,  2565,    20,     3,     0,     0,     0]])}, 'labels': tensor([1, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 2]), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]]), 'citing_paper_id': ['33e6eeec4cd55d49a355d41f585e736e616105ed', 'ee9b607fc7ea5e6e77530145ab032e6662404845', '415f1da66d3e8911bbc9dbe9f7b6d1bbc7998e0b', 'fc2fa61db68563e26daafe962633ab2b7e8e8b3d', 'bd36544bfecd5b9ea58d0eab186968b3c9d181aa', 'fd954be600a25a685dece1dd7118035e270ffc7a', '952660f4a305ebc8bc46ea23dd1ea41464d6681f', '032cda3876f80eaff146d59a15c3ac86050a4d24', '812e50bdbc19a822b0619ea835bed77415782d4b', 'a51bcd70a00c2f9f1b7f04fd44539a085490071e', '0ab03e9a01130305934265780f883a2edc0ca792', '68746a4e82e33029804f135bd35a2bc42c68df26', '55c6181ad66a1086badffb379502d7b062037bbb', 'e818279fda22c67a74f6c64d8bfe38698345c2dc', '6d6c4329489dc22731a61f08698b4083c71cf548', '4dbd1183f0ab39a05c396a9c19f83028efdc90d9'], 'cited_paper_id': ['09e15bb266da86d0a9525d2a94ac0b38f0b53b88', 'ffd39ac1ee59cb94766a425cc0934ada913d94bb', '6f05059c16e8ef3f49dee2afd11402631c824e54', '18dba91edf38fe354fd3a1123737185c841be419', '9a01ad5d531d9662795f4d65fdf4c06116dc871c', '13d455598df90628864bca0122480b04a8879ac6', '6b1223f442606ef04c8c04b36f1cdc0efb14c560', 'ea0372b4c4f44085dec5f7f637a1c0900c7b20a9', '5f19115ea3ee17d6d2a9288412fc6165932cea91', 'e7d820c9c1ad6c08c83782fec15fd45b76b147df', 'f10b9fa71de2ce784c6f6f13d6e10d4b65f8d23d', '4fb0ebdfe25b15c4bc42d81b1338cfdb9f2469be', '3824a648507000b7f319b9bf2ec0b7d07bcdfee4', '025c3136dd748f1f8aa4e3eabd0f524a8dc772ba', '3b27d285108fb0ee146cb9e0018f4603b59f8c62', 'ff9d4f21af8bafd3a0a0c014000942d40a7c03bd'], 'citation_excerpt_index': [6, 0, 0, 0, 2, 1, 0, 0, 6, 0, 1, 0, 3, 0, 8, 0], 'citation_id': ['33e6eeec4cd55d49a355d41f585e736e616105ed>09e15bb266da86d0a9525d2a94ac0b38f0b53b88', 'ee9b607fc7ea5e6e77530145ab032e6662404845>ffd39ac1ee59cb94766a425cc0934ada913d94bb', '415f1da66d3e8911bbc9dbe9f7b6d1bbc7998e0b>6f05059c16e8ef3f49dee2afd11402631c824e54', 'fc2fa61db68563e26daafe962633ab2b7e8e8b3d>18dba91edf38fe354fd3a1123737185c841be419', 'bd36544bfecd5b9ea58d0eab186968b3c9d181aa>9a01ad5d531d9662795f4d65fdf4c06116dc871c', 'fd954be600a25a685dece1dd7118035e270ffc7a>13d455598df90628864bca0122480b04a8879ac6', '952660f4a305ebc8bc46ea23dd1ea41464d6681f>6b1223f442606ef04c8c04b36f1cdc0efb14c560', '032cda3876f80eaff146d59a15c3ac86050a4d24>ea0372b4c4f44085dec5f7f637a1c0900c7b20a9', '812e50bdbc19a822b0619ea835bed77415782d4b>5f19115ea3ee17d6d2a9288412fc6165932cea91', 'a51bcd70a00c2f9f1b7f04fd44539a085490071e>e7d820c9c1ad6c08c83782fec15fd45b76b147df', '0ab03e9a01130305934265780f883a2edc0ca792>f10b9fa71de2ce784c6f6f13d6e10d4b65f8d23d', '68746a4e82e33029804f135bd35a2bc42c68df26>4fb0ebdfe25b15c4bc42d81b1338cfdb9f2469be', '55c6181ad66a1086badffb379502d7b062037bbb>3824a648507000b7f319b9bf2ec0b7d07bcdfee4', 'e818279fda22c67a74f6c64d8bfe38698345c2dc>025c3136dd748f1f8aa4e3eabd0f524a8dc772ba', '6d6c4329489dc22731a61f08698b4083c71cf548>3b27d285108fb0ee146cb9e0018f4603b59f8c62', '4dbd1183f0ab39a05c396a9c19f83028efdc90d9>ff9d4f21af8bafd3a0a0c014000942d40a7c03bd']} {'citation_text': {'elmo': tensor([[[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 116, 106,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 117,  98,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  83, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113,  98,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 102,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[    93,     30,    107,  23162,     25,     39,   1134,     19,     75,\n",
      "            298,      9,    255,      6,   8406,      9,   2250,     11,  53792,\n",
      "            319,      2,     32,     16,  12404,      6,     34,   8954,      2,\n",
      "            491,     68,     15,   3236,      2,   1564,     18,   3460,   2250,\n",
      "          29932,      3,      0,      0,      0],\n",
      "        [   675,      2,      4,    906,      6,  57714,     38,   1462,     10,\n",
      "              4,    993,     17,   5320,   1914,     24,    764,      5,     17,\n",
      "            110,   5320,    277,      9,   5693,    723,     66,     27,   1412,\n",
      "             23,  29364,   4424,      4,  10832,      6,      8,  75052,     10,\n",
      "             15,    194,    618,      3,      0],\n",
      "        [    26,  26252,    553,      6,  77811,      5,   6546,     31,   4140,\n",
      "              9,  77767,      5,   1796,     25,     15,  47064,     86,   3054,\n",
      "           1241, 102025,     11,  65905,    911,     19,     15,  65905,  10710,\n",
      "          65906,    662,   6130,      5,      4,   6665,      6,   2531,     12,\n",
      "             13,      3,      0,      0,      0],\n",
      "        [  1288,      2,      9,    686,    346,      6,   8066,   3526,      2,\n",
      "             51,     22,   2766,    187,   1888,      2,    691,     16,   1734,\n",
      "             28,     15,   1620,      6,      4,   1791,   4571,   2237,    756,\n",
      "              2,    263,      4,    542,     16,  64356,   2027,    818,      7,\n",
      "             49,      4,  14662,      3,      0],\n",
      "        [    92,     17,   3026,   2931,   1880,  25236,      6,      4,  12686,\n",
      "            314,    368,    501,      5,    160,  12686,    314,    368,    501,\n",
      "             72,   3019,      2,    543,   3026,   4774,   1082,      4,   2995,\n",
      "              6,      4,   3019,     11,   1825,    612,      3,      0,      0,\n",
      "              0,      0,      0,      0,      0],\n",
      "        [   158,     16,     54,     25,      4,   2014,   2022,      5,     38,\n",
      "           2798,     15,  11428,      6,     55,    109,     51,     22,  79066,\n",
      "           7736,      8,  13516,      7,      2,    789,     11,    912,     11,\n",
      "          13541,     11,   2014,      8,  79067,      7,      2,  11361,  31782,\n",
      "          59024,      0,      0,      0,      0],\n",
      "        [  8338,   1646,  11253,    137,    135,     38,  17115,     10,    552,\n",
      "           3579,      4,    258,     84,   2511,      6,    619,   3421,     16,\n",
      "             15,  11253,    103,      2,     22,    663,     28,     15,    320,\n",
      "              6,  18197,  13186,      8,  31888,     12,     13,      3,      2,\n",
      "            202,      2,    142,      7,      3],\n",
      "        [110708,     31,    144,    238,     23, 110709,      5,  43317,     18,\n",
      "              4,  39441,      5,   1593,    205,      5,     63,    422,    932,\n",
      "           2967,    154,   1455,      6,      4,   2090,   2700,    205,     19,\n",
      "             15,    274,    212,     54,     25,      4,    169,   1725,      3,\n",
      "              0,      0,      0,      0,      0],\n",
      "        [  1671,    140,     24,    243,     32,     24,     42,   7487,     44,\n",
      "              4,   1888,      6,   1797,    499,      2,     70,    322,     15,\n",
      "            796,   5408,     18,    337,    360,     23,   2687,   1797,      2,\n",
      "           3461,   5257,      2,  20804,    306,    758,     29,  10055,    520,\n",
      "          20597,      3,      0,      0,      0],\n",
      "        [  9625,      2,     34,   6307,     19,     57,     68,     77,   1687,\n",
      "            706,     16,    528,     15,    418,   6307,      5,    105,    548,\n",
      "           1687,    483,    857,     34,    548,   2152,      6,   6644,    655,\n",
      "              8,   2017,      7,      5,  27904,    602,      8,   2017,      7,\n",
      "              3,      0,      0,      0,      0],\n",
      "        [    41,   7313,      6,     63,  41885,   1840,     19,    113,     11,\n",
      "            529,  55745,      5,  78149,   5441,  23193,    554,      2,      4,\n",
      "           2739,  66064,   2349,    107,  13698,     73,      6,      4,   1966,\n",
      "              2,      5,  66065,    898,   1786,     10,     15,   4671,      3,\n",
      "              0,      0,      0,      0,      0],\n",
      "        [  8925,    875,     24,     42,    377,      6,      4,    498,   7187,\n",
      "             14,    411,      2,    168,  41218,  26313,     18,     51,    875,\n",
      "             16,    913,      8,  29660,     37,   6873,      2,     80,      2,\n",
      "             74,     14,   6873,     37,  29660,      2,     89,      7,      3,\n",
      "              0,      0,      0,      0,      0],\n",
      "        [    65,     16,    231,     19,      4,    250,     28,     55,     47,\n",
      "              8,    143,      2,    282,      7,     32,     79,     17,    865,\n",
      "              6,   2641,    182,    850,   3128,   2980,     10,    180,   3128,\n",
      "              6,    850,   1093,      9,    947,      5,   3901,    273,    369,\n",
      "           2077,      3,      0,      0,      0],\n",
      "        [  1120,      2,    625,     15,    194,    505,   1321,     54,     25,\n",
      "            517,  20744,     17,   3651,      4,   8139,    332,      6,      4,\n",
      "            517,    659,    413,     23,   2214,     42,      4,   5785,    724,\n",
      "             58,    517,   1393,      2,     70,    491,     60,    273,   1555,\n",
      "              6,    684,      3,      0,      0],\n",
      "        [    26,   6456,     16,     15,   4936,   1478,     11,     54,   6456,\n",
      "             49,      4,   7561,     11,  16634,   1478,    103,      6,  14682,\n",
      "              8,     89,      2,     64,      7,     19,      4,    306,   1006,\n",
      "            379,     23,    904,      5,  14682,      8,     83,      7,      3,\n",
      "              0,      0,      0,      0,      0],\n",
      "        [    26,    145,      5,   1072,      6,     63,    243,   2392,    532,\n",
      "             25,      4,    557,      6,      4,   1603,   3885,   1365,     59,\n",
      "              2,     32,     46,     38,     10,     27,   2583,   2967,     49,\n",
      "           2608,   1079,     18,   1962,   7814,    177,      3,      0,      0,\n",
      "              0,      0,      0,      0,      0]])}, 'section_label': tensor([1, 1, 2, 2, 1, 0, 0, 3, 4, 0, 0, 1, 1, 0, 2, 0]), 'citing_paper_id': ['174d2928b6cee50f3f28ec462b3a2840255814e2', '31bd506005323b1ce09230dd05e0a7e0225964ca', '0ababc103b081a48b2e403cc2b8b84446721136c', '34fe87515826dce400f0b3090c4cdd638bc3277b', 'c281da4b1c70cf5e2ca9051e71745c8368dbef71', 'bd000fe7e222b8095c6591291cd7bef18f970ab7', '5ce33b4e2114e86859a71cf0082e9f6490d0edf3', '0ababc103b081a48b2e403cc2b8b84446721136c', '87bee0e68dfc86b714f0107860d600fffdaf7996', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '23ebda99aa7020e703be88b82ad255376c6d8878', 'b9f8fc42e5dee71545267ecda7c43100fa2c72df', 'db554e20fe4039e43eedb68b764dcefce8b82a11', '0825788b9b5a18e3dfea5b0af123b5e939a4f564', '22697256ec19ecc3e14fcfc63624a44cf9c22df4', '163a35665374fcd5283da47a7ee611af7df2d876'], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]} {'citation_text': {'elmo': tensor([[[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259,  99, 112,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  74, 103,  ..., 261, 261, 261],\n",
      "         [259, 116, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  51,  47,  ..., 261, 261, 261],\n",
      "         [259,  83, 102,  ..., 261, 261, 261],\n",
      "         [259,  84, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 120, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  50,  49,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[   593,     26,   2289,     48,      4,    504,      6,     39,    802,\n",
      "            503,    857,     15,   1258,    731,      6,      4,    205,     44,\n",
      "            479,      5,     15,   2884,    505,      6,      4,   2604,    125,\n",
      "              5,  13246,   4226,    574,  53224,      3,      0,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [    26,   3403,    215,   8807,      4,    553,    413,      6,    312,\n",
      "            227,    414,    526,     18,      4,    951,  12011,      8,    300,\n",
      "            128,      7,      2,     49,     63,  15266,     10,    742,    105,\n",
      "          19443,    347,      8,   6299,    171,      7,      3,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [   321,     98,   3090,   4932,      8,  47388,      7,      5,   3332,\n",
      "           4932,      8,  44711,      7,   1714,     15,    324,   1468,      2,\n",
      "           1658,      2,     15,    253,   1447,   2942,      9,   2078,      2,\n",
      "            107,  44711,    857,      4,    809,      6,     15,    181,   1233,\n",
      "              3,      0,      0,      0],\n",
      "        [  2105,      6,      4,    214,     11,    744,   1380,     48,  18787,\n",
      "             11,   6044,   8741,     93,   2394,     17,      2,      9,   1009,\n",
      "              2,    762,     11,   6044,   8741,     24,   7384,   3502,      2,\n",
      "            280,     44,    258,    180,   3975,      3,      0,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [   158,     16,    771,     17,    713,     10,   3090,      2,    921,\n",
      "              2,     29,  67264,    861,     23,    638,     55,     68,  30027,\n",
      "              8,    124,      2,     55,   1472,   3864,      2,     29,   2495,\n",
      "           2109,      6,      4,   1141,      7,    275,     27,    881,      3,\n",
      "              0,      0,      0,      0],\n",
      "        [ 10370,   1682,      6,   3174,    455,  25898,  66032,     29,  69415,\n",
      "             11, 141662,   3638,      6, 141663,      2,    975,     10,     15,\n",
      "            113,   1045,      6,   1614,     11,    519,   1243,      5,   2655,\n",
      "            302,     22,     97,     22,   8819,    302,      3,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [    26,   1387,    243,     10,   1940,     40,     27,   2002,    112,\n",
      "             82,   1964,   1150,     48,   3595,      6,      4,   3991,   8004,\n",
      "              8,   7259,     29,  20715,   1259,      7,     29,      4,   3612,\n",
      "              6,     15,   3991,  12020,      8,    344,     56,      7,      3,\n",
      "              0,      0,      0,      0],\n",
      "        [140526,      7,      2,     98,      4,  50268,      5,      4,  47212,\n",
      "           1749,      6,      4,  22288,      9,      4,  34573,    408,     44,\n",
      "          14404,      8,  14404,   2542,  85577,     14,    715,    152,     56,\n",
      "              2,     72,      7,    748,  15210,     19,   2398,     11,  14246,\n",
      "           1749,     22,     97,      3],\n",
      "        [ 38954,     48,    901,     11,  20004,      8,  80552,     37,   3696,\n",
      "              2,     64,      7,   2927,      6,   1687,    483,   3682,      6,\n",
      "             15,     82,     11,    483,  17516,    681,     25,      4,  36784,\n",
      "            425,     49,    126,     73,      6,   1836,      3,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [   657,      4,   1246,     16,   8973,     17,     50,     40,   3800,\n",
      "             57,   1623,     10,    108,    545,   2242,      8,      5,     38,\n",
      "            104,  13799,    514,     18,      7,     19,  25190,    152,   4052,\n",
      "              2,    215,     50,   1089,    107,    182,  15755,  18188,      3,\n",
      "              0,      0,      0,      0],\n",
      "        [    41,      4,    144,   1184,      6,      4,   1737,  41819,     36,\n",
      "            843,   2309,     28,      4,    365,   2380,  41819,     44,      4,\n",
      "             85,      2,    815,     23,   3194,   2284,     10,    552,   7322,\n",
      "              4,    450,   1150,     36,     42,   1506,  17268,      3,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [    41,    102,    127,      2,      2,     43,   2287,     60,    190,\n",
      "             10,      4,    200,    147,      4,   3519,   1388,     16, 119146,\n",
      "          23678,  14980,  39339,     29,   1617, 119147,     18,      4,    859,\n",
      "              8,    459,      7,    320,     56,   1323,   5386,   4479,     72,\n",
      "              3,      0,      0,      0],\n",
      "        [    87,   2041,   4012,     25,     34,    713,    177,  84798,    785,\n",
      "           1398,     15,    437,     11,  54249,   1121,   1278,    846,      6,\n",
      "           7586,     24,     42,   8714,      9,    785,      2,   4012,    152,\n",
      "           5615, 125737,   2664,   3983, 125738,      3,      0,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [   657,    263,      2,     50,     16,    610,     18,     15,   6426,\n",
      "             19,     15,  54393,    249,     17,     16,    682,    271,      9,\n",
      "           1531,    178,     39,  41321,   6426,  31568,    357,   1467,      4,\n",
      "           2694,      6,      4,  50276,   7541,  12435,     29,   1775,  22087,\n",
      "              3,      0,      0,      0],\n",
      "        [  6670,  34053,  34575,  34576,     26,   1233,      6,  34575,  34576,\n",
      "             16,     10,   3489,     28,      4,   2011,    117,    996,    686,\n",
      "           1652,      6,     34,   2488,      2,     32,     66,     27,     15,\n",
      "           1018,     29,    110,    217,      6,   1417,      3,      0,      0,\n",
      "              0,      0,      0,      0],\n",
      "        [   675,      2,     19,      4,    453,    247,    621,    152,    549,\n",
      "              2,      4,   1463,   1510,     18,      4,    648,     10,   6299,\n",
      "           5695,     18,      4,    118,      6,    312,  24182,     21,    916,\n",
      "             20,      2,      5,    411,      6,     21,  13516,     20,      2,\n",
      "             16,    143,      3,      0]])}, 'is_citation': tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]), 'citing_paper_id': [None, None, None, None, None, None, None, None, '1762baa638866a13dcc6d146fd5a49b36cbd9c30', None, None, '047452775a1557951a06f4dd12cfdf42d634eb0f', None, None, None, None], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 10:33:02 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'multilabel': 'false', 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.type = scicite_datasetreader\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = None\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.use_lexicon_features = False\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.use_sparse_lexicon_features = false\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.multilabel = false\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.with_elmo = true\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   dataset_reader.reader_format = flat\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   validation_dataset_reader = None\n",
      "03/30/2024 10:33:02 - INFO - allennlp.common.params -   train_data_path = scicite_data/train.jsonl\n",
      "03/30/2024 10:33:02 - INFO - __main__ -   Reading training data from scicite_data/train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "8243it [00:02, 4090.91it/s]\n",
      "\n",
      "03/30/2024 10:33:04 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_section_title_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:33:04 - INFO - allennlp.common.params -   dataset_reader_aux.type = scicite_section_title_data_reader\n",
      "03/30/2024 10:33:04 - INFO - allennlp.common.params -   dataset_reader_aux.with_elmo = true\n",
      "03/30/2024 10:33:04 - INFO - allennlp.common.params -   train_data_path_aux = scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "03/30/2024 10:33:04 - INFO - __main__ -   Reading auxiliary training data from scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "33447it [00:10, 3270.37it/s]\n",
      "89592it [00:20, 4636.43it/s]\n",
      "91412it [00:20, 4447.44it/s]\n",
      "\n",
      "03/30/2024 10:33:25 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_cite_worthiness_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 10:33:25 - INFO - allennlp.common.params -   dataset_reader_aux2.type = scicite_cite_worthiness_data_reader\n",
      "03/30/2024 10:33:25 - INFO - allennlp.common.params -   dataset_reader_aux2.with_elmo = true\n",
      "03/30/2024 10:33:25 - INFO - allennlp.common.params -   train_data_path_aux2 = scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "03/30/2024 10:33:25 - INFO - __main__ -   Reading second auxiliary training data for from scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "73484it [00:09, 7960.14it/s]\n",
      "\n",
      "03/30/2024 10:33:34 - INFO - allennlp.common.params -   aux_sample_fraction = 1.0\n",
      "03/30/2024 10:33:34 - INFO - __main__ -   Inflating train data from 8243 to 91412 samples\n",
      "03/30/2024 10:33:34 - INFO - allennlp.common.params -   validation_data_path = scicite_data/dev.jsonl\n",
      "03/30/2024 10:33:34 - INFO - __main__ -   Reading validation data from scicite_data/dev.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "916it [00:00, 3853.97it/s]\n",
      "\n",
      "03/30/2024 10:33:34 - INFO - allennlp.common.params -   validation_data_path_aux = None\n",
      "03/30/2024 10:33:34 - INFO - allennlp.common.params -   validation_data_path_aux2 = None\n",
      "03/30/2024 10:33:34 - INFO - allennlp.common.params -   test_data_path = scicite_data/test.jsonl\n",
      "03/30/2024 10:33:34 - INFO - __main__ -   Reading test data from scicite_data/test.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "1861it [00:05, 339.32it/s]\n",
      "\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   test_data_path_aux = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   test_data_path_aux2 = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.type = bucket\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.padding_noise = 0.1\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.biggest_batch_first = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.batch_size = 16\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.instances_per_epoch = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.max_instances_in_memory = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.cache_instances = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.track_epoch = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator.maximum_samples_per_batch = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.type = bucket\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.padding_noise = 0.1\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.biggest_batch_first = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.batch_size = 16\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.instances_per_epoch = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.max_instances_in_memory = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.cache_instances = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.track_epoch = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux.maximum_samples_per_batch = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.type = bucket\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.padding_noise = 0.1\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.biggest_batch_first = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.batch_size = 16\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.instances_per_epoch = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.max_instances_in_memory = None\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.cache_instances = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.track_epoch = False\n",
      "03/30/2024 10:33:40 - INFO - allennlp.common.params -   iterator_aux2.maximum_samples_per_batch = None\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  78, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  88, 106,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 102, 119,  ..., 261, 261, 261],\n",
      "         [259, 106, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]]), 'tokens': tensor([[   26,   197,     6,  2608,   109,    18,  1414,     6,   585,  4444,\n",
      "             6,   561,     9, 11023,   162,     2,    22,    97,    22,    60,\n",
      "          5919,   112,     4,   291,   208,     2,    30,     4,   370,    10,\n",
      "          6244,     4,  1635,    10,  9477,     6,   763,   509,   799,     9,\n",
      "          7449,  1182,    14,   174,    21,    56,    20,    18,    15,   605,\n",
      "             6,   731,   243,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  546,     2,  1704,    17,     4, 19697,  3675,    90,  5720,  7716,\n",
      "           263,  7275,     9,  2728,    95,  7427,    11,  2738,   530,     9,\n",
      "             4,  2213,   103,     2,    50,    16,  3301,    17,    39,  1468,\n",
      "          7716,   258, 12874,     9,     4,  4835,     2,     5,   278,   215,\n",
      "            50,    16,    42,   596,  1505,   488,   932,     9,   197,     8,\n",
      "          5716,    12,    13,     3,     2,    64,     7,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [  640,     2,   436,  8162,   400,    36,    99,    10,    27,     4,\n",
      "           104,   921,   884,   989,    10,     4,  7400,   456,     6,  3274,\n",
      "             2,    19,  7432,   175,     9,     4,  7219,   989,     8,  5004,\n",
      "            12,    13,     3,    62,     7,     2,     4,  2547,   175,    30,\n",
      "            46,    33,   229,     9,    15,  4188,  1163,  2412,  2034,     8,\n",
      "          5461,    12,    13,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   35, 37070,  5364,  4256, 37071,  5364,  1949,    15,  7852,     2,\n",
      "           967,  1280,     3,   265,  1238,    25,   192,    11,  6893,  1490,\n",
      "           825,     3,   785,  1238,    25,  1116,   196,  7307,  1490,   825,\n",
      "             3, 12327,  1490,    85,    16,    57,  1741,    68,  9412,     2,\n",
      "           178,  1107,   329,   111,    45,    24,    42,  6112,     9,    15,\n",
      "         26656,  2515,     9,  8538,     8,  9189,    12,    13,     3,   131,\n",
      "             7,     3],\n",
      "        [  640,     2,     4,  2272,   511,    17,     4,   135,  1244,    50,\n",
      "           312,    10,  8311,    15,   149,  1480,  4784,    58,   717,     5,\n",
      "         15603,     8,  4088,    12,    13,     3,     2,   132,     2,  1250,\n",
      "         10690,     7,     2,     5,   736,     2, 10082,  2891,    85,    16,\n",
      "           280,  1100, 10256,     8,  8293,    12,    13,     3,     2,    64,\n",
      "            14,  4017,    12,    13,     3,     2,   123,    14,  4088,    35,\n",
      "             0,     0],\n",
      "        [   72,    41,   251,    10,    63,  9471,    11,   822,     5,  5508,\n",
      "            11,  3198,  1365,     2,   127,     9, 25686,    16,    46,  1035,\n",
      "            23, 22652,  5275,  2087,     2,    32,  8404,     5,  9195,     8,\n",
      "            67,     7,  1574,    22,     4,   118,     6, 10676,  7317,   586,\n",
      "             5,     4,   574,   118,     6,  2141,  1093,    44,   138,   586,\n",
      "             2,   590,     6,    35,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [28776,     8,   126,  3139,     7,     6,     4,   121,  4866,    36,\n",
      "          1157,    28,     4,  2439,    44,   273,   825,   173,  5229,     2,\n",
      "          1064,     9,   128,    73, 13335,     9,  6202,    11, 11673,  6448,\n",
      "             8,  5355,     7,     8,  5273,    12,    13,     3,     2,    62,\n",
      "             7,    18,   143,  1033,     2,     5,   215,  5368,    10, 20369,\n",
      "           339,  1429,    11, 12183,     3,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  695,    24,  3097,     9,  2172,    51,    22,  3950,   938,    18,\n",
      "          1994,  3949,     8,  5713,    12,    13,     3,     2,   515,    14,\n",
      "          3154,    12,    13,     3,     2,  5836,    14,  5001,    12,    13,\n",
      "             3,     2,   515,     7,     2,     5, 10980,     4,   428,   632,\n",
      "            23,  2030,   938,    10,    15,   313,   187,     8,   983,     7,\n",
      "             8,  9839,    12,    13,     3,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   35,    57,  1081, 15206,     6,  4563,   250,  1984,     4,  1128,\n",
      "           228,   993,     8,  9434,   654,    14, 15207,    12,    13,     3,\n",
      "           439,    14, 19001,    12,    13,     3,   101,    14,  5823,    12,\n",
      "            13,     3,    74,     7,     2,     5, 14498,   110,     6,     4,\n",
      "           629,  4523,   182,   619,  4654,     4,  1128,   228,    18,  8038,\n",
      "           987,     8,  2114,    37,  4655,   142,     7,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [  155,     2,   120,   944,     4,   188,     6,   791,    11, 30758,\n",
      "          1281,    11,  5837,    15,    84,   135,    31,    45,   402,    39,\n",
      "          2330,    38,    15,  1682,    11,   498,     6,   269,    68,   323,\n",
      "           757,     8,  6575,     2, 23585,     2, 25751,     2,  6926,    37,\n",
      "          4824,     2,   303,    14,  6926,     2, 30759,    37,  3048,     2,\n",
      "           266,     7,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   26,   884,  1230,  1958,   121,   383, 19746,    31,  2714,     5,\n",
      "          2216,    22,   122,   100,     8,  5293,    12,    13,     3,    62,\n",
      "             7,     2,    49,   549,  3922,     6,   256,  2810,     2,   143,\n",
      "          3922,     6,   177,  2810,     8, 19747,     2, 11199,     7,     2,\n",
      "             5,     4, 19748,   171,  4220,  8232,     8,  5859,  4627, 19141,\n",
      "             2, 28798,     2,  4167,     7,     3,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   35,    23,    32, 39913, 39914,     4, 12601,  1401,     9,   240,\n",
      "            10,  1922,    16,   341,    10,  2013,   277,     9,   185,  7150,\n",
      "             8, 39915,    12,    13,     3,     2,   101,    14, 37445,    12,\n",
      "            13,     3,     2,    88,     2,    62,     7,    17,   184,    27,\n",
      "         13622,    23,   786,    19,    55,   375,  1510,     9,   946,  4268,\n",
      "             8, 39916,    12,    13,     3,     2,    74,    14,    35,     0,\n",
      "             0,     0],\n",
      "        [   93,  1212,    17,     4,   545,  4987,     6,  4903, 12064,     8,\n",
      "         19738,     7,     5,  4505,  8086,     8, 19739,     7,    36,  2333,\n",
      "          1060,    22,   122,    79,     5,  1173,    10,   190,    28,   210,\n",
      "          4505,   608,  2881,  5737,    19,   210,  4903,  5242,     8,  8019,\n",
      "            12,    13,     3,     2,    78,    14,  7924,    12,    13,     3,\n",
      "             2,    80,     7,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [ 1050,     4,  1863,     6,  2948,    10,     4,   348,     6,     4,\n",
      "           356,   770,     6,     4,   992,     6,  7795,     9, 20298,     2,\n",
      "            15,   553,    31,   581,     9,     4,  6059,    81,  3959,  4759,\n",
      "            49,     4,   347,     6, 26824,  2664, 26825,  8974,     2,    15,\n",
      "          9323,     6,     4, 20299,  3883,     8,  4977,    12,    13,     3,\n",
      "            88,    14,  9332,    12,    13,     3,    83,     7,     3,     0,\n",
      "             0,     0],\n",
      "        [   35,   278,   216,     4,   220,   858,    16,    57,  2884,     2,\n",
      "             4,   405,     6,     4,  6603,  2000,  8950,    16,    23,   168,\n",
      "           638,  3819,    14,   108,   320,    16,   258,   497,     2,   108,\n",
      "           966,    24,  7779,     5,  6056,     2,     5,     4,  5313,    28,\n",
      "           337,  2066,   385,     5,   160,  2965,  2906, 19529,     8,  4158,\n",
      "            12,    13,     3,   106,     7,     3,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   35,    52,     9,     4,   670,     6,     4,   326,  3895,  2552,\n",
      "             4,  6788,  1131,  1585,    18,     4,   113,   153,     6,  3914,\n",
      "             5,   108,  5351,   371,   484,     4,    84, 17858,   530,     9,\n",
      "            39, 20960,     8,  5683,    12,    13,     3,    78,    14,  9303,\n",
      "            37, 16826,    83,    14,  9414,    83,    14,   791, 15504,    12,\n",
      "            13,     3,    83,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0,     0]])}, 'labels': tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0]), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]]), 'citing_paper_id': ['e766dafdbb3c34b757e25411cdea417cc5c1f0b3', '602d56f55b8c21475c9bf67e73c5d8e999ee9696', '07895f7b08a16c607fc6e8621a1256784c7461c4', '63ce508d942d89bcf695e782b5d4ee85ade5c4e1', 'd79a9cc876798786762088cdacd3978d9beb24d9', '32d61d5e28d2769c6dfcc296473eb10484520bec', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9', '48bff8eae05fb5369b0026742eaa79178e107fbb', '48793a345eacc733e0e3dd51cb0cafd56baf101f', 'c60ea9c93e88dc67bdb4231a5dc6e59501e831ed', '2417526934446d81023af49f27bb7f52044bcb78', '4503199b204743bb9095a699bbd86b3d88fb1e26', '45701ff05d3ed583a658f18aa998944c1d4eee7a', '1299de4f6f7b52a81ab2612c75fd09982c21a2e7', '1e07b16fb589780721887f60271a8b1c2868fb8b', '2b80f65e936e58979de232164026543edb2a79e8'], 'cited_paper_id': ['4a3e37d3e6349fd4d6fe9662d3d45bf4152d89ce', 'd9bb6f5360b6e9413e5f675d4164e29a6040a7c0', '488e1b26dcc9274c9bf4f8ee7dd5d96109565214', 'fc7bd558af7699381c4f41f2eb7d5326368d386a', '12a23d19543e73b5808b35f1ff2d00faba633bb6', '76e63fddfa3b6f2d08ceb5b38ff9c4583103cbe9', '6d6bb93872a190de290f259e63587db4f17d539c', 'bc6ad001c395e92920839e45dfd7e05ce69405d2', '990f0494d4f46e43bdb76415e8524ce591902792', '1ca488faf0209c7d89ed794622d8cd924f064116', '73f36294b5992a53e4f075e384fe30a13c629bb4', '7e8787215a4d872b9619cacb6029b998afb00dc1', 'f89d87e5f4d58e9bb7d576ec6ae34a84240b9c5e', '34e5513017c555463409013e0f16af946348f7bf', '40c5741dc18ca03e625306b5bbf6622d097176a3', '8f01119d68d6a980ec1608e905be6e4f58cb328a'], 'citation_excerpt_index': [0, 2, 7, 7, 11, 2, 3, 1, 1, 0, 13, 0, 3, 3, 1, 1], 'citation_id': ['e766dafdbb3c34b757e25411cdea417cc5c1f0b3>4a3e37d3e6349fd4d6fe9662d3d45bf4152d89ce', '602d56f55b8c21475c9bf67e73c5d8e999ee9696>d9bb6f5360b6e9413e5f675d4164e29a6040a7c0', '07895f7b08a16c607fc6e8621a1256784c7461c4>488e1b26dcc9274c9bf4f8ee7dd5d96109565214', '63ce508d942d89bcf695e782b5d4ee85ade5c4e1>fc7bd558af7699381c4f41f2eb7d5326368d386a', 'd79a9cc876798786762088cdacd3978d9beb24d9>12a23d19543e73b5808b35f1ff2d00faba633bb6', '32d61d5e28d2769c6dfcc296473eb10484520bec>76e63fddfa3b6f2d08ceb5b38ff9c4583103cbe9', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9>6d6bb93872a190de290f259e63587db4f17d539c', '48bff8eae05fb5369b0026742eaa79178e107fbb>bc6ad001c395e92920839e45dfd7e05ce69405d2', '48793a345eacc733e0e3dd51cb0cafd56baf101f>990f0494d4f46e43bdb76415e8524ce591902792', 'c60ea9c93e88dc67bdb4231a5dc6e59501e831ed>1ca488faf0209c7d89ed794622d8cd924f064116', '2417526934446d81023af49f27bb7f52044bcb78>73f36294b5992a53e4f075e384fe30a13c629bb4', '4503199b204743bb9095a699bbd86b3d88fb1e26>7e8787215a4d872b9619cacb6029b998afb00dc1', '45701ff05d3ed583a658f18aa998944c1d4eee7a>f89d87e5f4d58e9bb7d576ec6ae34a84240b9c5e', '1299de4f6f7b52a81ab2612c75fd09982c21a2e7>34e5513017c555463409013e0f16af946348f7bf', '1e07b16fb589780721887f60271a8b1c2868fb8b>40c5741dc18ca03e625306b5bbf6622d097176a3', '2b80f65e936e58979de232164026543edb2a79e8>8f01119d68d6a980ec1608e905be6e4f58cb328a']} {'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 122,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 102, 117,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 103,  98,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  98, 119,  ..., 261, 261, 261],\n",
      "         [259, 227, 129,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 101,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  99,  98,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259, 117, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  78, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]]), 'tokens': tensor([[    26,    103,     31,    888,     49,  18196,      5,  49057,      8,\n",
      "          78246,     12,     13,      3],\n",
      "        [    41,    562,      2,   1869,    891,   3142,     16,  63518,     10,\n",
      "           7831,   3042,   5124,      0],\n",
      "        [ 51880,      2,      5,      4,   8169,      6,      4,  10595,      6,\n",
      "             34,   7717,      3,      0],\n",
      "        [  3057,   5462,    319,     16,    288,     10,    620,     53,    578,\n",
      "             18,  13654,      3,      0],\n",
      "        [  2971,    487,     17,   1533,     19,     63,    855,      2,      5,\n",
      "           3214,     51,     22,  54707],\n",
      "        [  1604,     49,      4,   4725,    125,   2369,    614,    392,   3265,\n",
      "          36755,    136,  11790,      3],\n",
      "        [   245,     17,    258,    195,      5,    418,   1202,    221,    681,\n",
      "             23,    395,  76107,      0],\n",
      "        [   305,   1202,   3196,     11,   3403,    267,    157,    778,     16,\n",
      "            139,     10,      3,      0],\n",
      "        [   114,    159,      2,   2024,   4224,      4,  19387,      6,   3805,\n",
      "            220,     68,   1577,      3],\n",
      "        [    65,    547,  11175,   1634,     15,   1737,   7922,    488,    560,\n",
      "              5,    137,      3,      0],\n",
      "        [    26,   4909,      5, 110943,    617,   3365,     18,     84, 110944,\n",
      "             24,    514,      9,      3],\n",
      "        [    26,   4009,   1675,      6,  27926,     38,   1353,    214,    183,\n",
      "           2332,   1336,      3,      0],\n",
      "        [  2263,    157,    296,     30,     33,    292,     10,   6013,    297,\n",
      "            162,      2,      2,      3],\n",
      "        [    41,    251,      2,    111,     24,    579,     10,  54891,  38627,\n",
      "           4782,   1299,      3,      0],\n",
      "        [    26,   1258,    235,     40,     27,     92,      9,  33896,      8,\n",
      "             71,      7,      5,      3],\n",
      "        [   640,      2,     43,    722,     75,    294,     19,    214,    759,\n",
      "           3645,    119,    294,      3]])}, 'section_label': tensor([2, 3, 0, 3, 0, 1, 4, 2, 0, 0, 3, 0, 4, 0, 3, 0]), 'citing_paper_id': ['1713643a7865b763d7e2dcf142f762a1acbf118d', '2c8f24f859bbbc4193d4d83645ef467bcf25adc2', 'f26c8f6754627b8d599e56480f49ab39e9b64dd7', '3dffacda086689c1bcb01a8dad4557a4e92b8205', '452e3393e3ecc34f913e8c49d8faf19b9f89b75d', '2308c99ea98ed50683e87bb887574b8f35c6f916', '14ce7635ff18318e7094417d0f92acbec6669f1c', '749bf572cfbb3821a5d93d7d71827bb115b2f5c7', 'ac077b01d61032f40e103f5c249d651995108b23', 'c75d7db768c1d2f9d64d3a45a81a0a9dfbc59bf3', '21356fca524e8b8dca999fbab767ef8572955645', '3f98b5337ba2d289db9477662eaa894c963e7192', 'c0bcffddd322236c8800680f5ebd59ed5923ea6c', '1e7f8066b1f0c930aab2a2ae2ae88d455e8e2965', 'f26c8f6754627b8d599e56480f49ab39e9b64dd7', '03086d1ea707933399c530299e6216237c415ef1'], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]} {'citation_text': {'elmo': tensor([[[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84,  74,  ..., 261, 261, 261],\n",
      "         [259,  70,  89,  ..., 261, 261, 261],\n",
      "         [259,  70, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 122,  ..., 261, 261, 261],\n",
      "         [259, 104, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259, 100, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 113,  98,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]]), 'tokens': tensor([[   155,      2,  80976,   1379,    115,      5,   9762,     16,    168,\n",
      "           1934,    295,      2,    178,     10,    414,      4,   2096,    918,\n",
      "             16,  41235,      2,   1967,      5,    532,     85,     11,   4443,\n",
      "              3,      0,      0],\n",
      "        [ 44666,  54198,  11907,     26,    556,   1863,      6,     15,    569,\n",
      "           1056,   1211,    119,    427,      9,     39,    692,     16,     10,\n",
      "            322,      4,   4260,      6,     84,  12618,   1465,      9,     15,\n",
      "           2884,   1464,      3],\n",
      "        [    26,   4379,     59,    215,     31,   2876,      2,    984,      5,\n",
      "            873,      9,    459,     85,     49, 130786,     11,   3080,     91,\n",
      "           4643,     11,   4069, 130787,      8,   3080,     11,  46314,      7,\n",
      "              3,      0,      0],\n",
      "        [   781,  20930,     16,   4548,      2,      4,    157,   2395,    172,\n",
      "             76,      4,   5172,   5024,  86048,     10,    177,      4,    529,\n",
      "             11,   1141,     91,     53,    248,      5,    987,    463,      3,\n",
      "              0,      0,      0],\n",
      "        [   155,      2,    183,    119,      6,     39,   2703,      9,   9729,\n",
      "            765,     34,    878,   1810,      2,      9,     32,  80792,   1032,\n",
      "           2333,   1780,      4,    179,      6, 134475,   1883,      3,      0,\n",
      "              0,      0,      0],\n",
      "        [ 14166,     10,      4,    551,   1385,     30,     33,  17628,    448,\n",
      "            192, 119764,      2,    975,     10,     15,   1109,    462,      6,\n",
      "            297,    294,   2509,  55702,  23875,     54, 119765,   7760,      8,\n",
      "         119766,      7,      3],\n",
      "        [ 49567,   6488,      4,    755,      6,   9612,   4583,     10,      4,\n",
      "            755,      6,  12153,   4583,      5,     10,  58837,   3622,   2075,\n",
      "             46,  63427,  68926,     19,      4,   6350,    440,      3,      0,\n",
      "              0,      0,      0],\n",
      "        [  2005,   2093,     17,   2826,   2134,    410,     16,  48491,    386,\n",
      "            178,      6,      4,   5908,   1054,     23,    261,   1770,      2,\n",
      "           2049,      2,    910,  43949,      2,  14068,      5,   7721,      3,\n",
      "              0,      0,      0],\n",
      "        [ 14635,  28157,     24,  40909,     10,      4,   1463,    164,      8,\n",
      "           5094,     72,      5,   5094,     90,      7,    120,    111,     40,\n",
      "             42,     27,   5983,      9,      4,    102,    153,      3,      0,\n",
      "              0,      0,      0],\n",
      "        [   767,      2,     50,     16,    827,     18,   7353,  13772,     10,\n",
      "             76,     98,      6,     63,    296,      9,   3763,      9,    246,\n",
      "             10,   1720,      4,   2291,      6,      4,   2148,    117,      3,\n",
      "              0,      0,      0],\n",
      "        [ 65986,     25,     39,    591,     19,   3178,    113,     11,    201,\n",
      "             96,      2,     51,     22,    138,    193,     24,      9,   9159,\n",
      "              2,    397,   1163,    330,     44,    482,    201,    216,      4,\n",
      "            591,   6119,      3],\n",
      "        [    26,    137,    527,     15,    376,    632,      6,      4,    688,\n",
      "            223,   3347,      2,  26500,      2,   6543,      5,   7581,     18,\n",
      "           1984,      4,   1232,    566,      6,   3347,      3,      0,      0,\n",
      "              0,      0,      0],\n",
      "        [    26,    833,     10,  60817,   2837,    170,      4,    927,    446,\n",
      "           2555,     38,     33,   5608,      9,  18210,   1877,     18,     15,\n",
      "            482,    573,      6,   1741,    848,     19,    653,    524,     11,\n",
      "             85,      3,      0],\n",
      "        [    41,   1283,   7052,    554,      2,   7999,     16,   8840,     19,\n",
      "             15,  60310,     59,      2,    263,     95,      4,  13787,    861,\n",
      "              2,   2572,      6,    724,      2,     24,      9,    560,      3,\n",
      "              0,      0,      0],\n",
      "        [    65,   1877,   2195,   1651,   5334,    994,    316,   1433,   2285,\n",
      "           5665,      4,   6249,     91,    673,     10,     27,      9,    637,\n",
      "             19,    139,    848,    365,     28,     55,   8078,      3,      0,\n",
      "              0,      0,      0],\n",
      "        [    41,    327,      4,   1532,     38,     33,     99,     44,    258,\n",
      "            113,    164,      9,      4,   2635,   4329,      5,   3222,    108,\n",
      "            219,      9,      4,   7156,      6,   2277,  21045,     38,     33,\n",
      "          31635,    448,      3]])}, 'is_citation': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'citing_paper_id': [None, None, None, None, None, 'ccbd02b5346ef37c6b6440f880c97bd654ec201b', None, None, None, None, None, None, None, None, None, None], 'cited_paper_id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.type = None\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.extend = False\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.directory_path = None\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.min_count = None\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.max_vocab_size = None\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.min_pretrained_embeddings = None\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.only_include_pretrained_words = False\n",
      "03/30/2024 11:19:04 - INFO - allennlp.common.params -   vocabulary.tokens_to_add = None\n",
      "03/30/2024 11:19:04 - INFO - scicite.training.vocabulary_multitask -   Fitting token dictionary from dataset.\n",
      "0it [00:00, ?it/s]\n",
      "94189it [00:03, 24541.93it/s]\n",
      "\n",
      "03/30/2024 11:19:08 - INFO - scicite.training.vocabulary_multitask -   Fitting token dictionary from auxillary dataset.\n",
      "  0%|          | 0/146968 [00:00<?, ?it/s]\n",
      "100%|##########| 146968/146968 [00:04<00:00, 33046.42it/s]\n",
      "\n",
      "03/30/2024 11:28:29 - INFO - allennlp.common.params -   random_seed = 21016\n",
      "03/30/2024 11:28:29 - INFO - allennlp.common.params -   numpy_seed = 5000\n",
      "03/30/2024 11:28:29 - INFO - allennlp.common.params -   pytorch_seed = 8000\n",
      "03/30/2024 11:28:29 - INFO - allennlp.common.checks -   Pytorch version: 1.10.2\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   random_seed = 21016\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   numpy_seed = 5000\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   pytorch_seed = 8000\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.checks -   Pytorch version: 1.10.2\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'multilabel': 'false', 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.type = scicite_datasetreader\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {} and extras {}\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = None\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.use_lexicon_features = False\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.use_sparse_lexicon_features = false\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.multilabel = false\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.with_elmo = true\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   dataset_reader.reader_format = flat\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   validation_dataset_reader = None\n",
      "03/30/2024 11:28:33 - INFO - allennlp.common.params -   train_data_path = scicite_data/train.jsonl\n",
      "03/30/2024 11:28:33 - INFO - __main__ -   Reading training data from scicite_data/train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "8243it [00:02, 3892.72it/s]\n",
      "\n",
      "03/30/2024 11:28:35 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_section_title_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 11:28:35 - INFO - allennlp.common.params -   dataset_reader_aux.type = scicite_section_title_data_reader\n",
      "03/30/2024 11:28:35 - INFO - allennlp.common.params -   dataset_reader_aux.with_elmo = true\n",
      "03/30/2024 11:28:35 - INFO - allennlp.common.params -   train_data_path_aux = scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "03/30/2024 11:28:35 - INFO - __main__ -   Reading auxiliary training data from scicite_data/scaffolds/sections-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "56910it [00:10, 5690.99it/s]\n",
      "91412it [00:15, 5720.77it/s]\n",
      "\n",
      "03/30/2024 11:28:51 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'scicite_cite_worthiness_data_reader', 'with_elmo': 'true'} and extras {}\n",
      "03/30/2024 11:28:51 - INFO - allennlp.common.params -   dataset_reader_aux2.type = scicite_cite_worthiness_data_reader\n",
      "03/30/2024 11:28:51 - INFO - allennlp.common.params -   dataset_reader_aux2.with_elmo = true\n",
      "03/30/2024 11:28:51 - INFO - allennlp.common.params -   train_data_path_aux2 = scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "03/30/2024 11:28:51 - INFO - __main__ -   Reading second auxiliary training data for from scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "42147it [00:10, 4214.60it/s]\n",
      "73484it [00:13, 5337.41it/s]\n",
      "\n",
      "03/30/2024 11:29:05 - INFO - allennlp.common.params -   aux_sample_fraction = 1.0\n",
      "03/30/2024 11:29:05 - INFO - __main__ -   Inflating train data from 8243 to 91412 samples\n",
      "03/30/2024 11:29:05 - INFO - allennlp.common.params -   validation_data_path = scicite_data/dev.jsonl\n",
      "03/30/2024 11:29:05 - INFO - __main__ -   Reading validation data from scicite_data/dev.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "916it [00:00, 3941.41it/s]\n",
      "\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   validation_data_path_aux = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   validation_data_path_aux2 = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   test_data_path = scicite_data/test.jsonl\n",
      "03/30/2024 11:29:06 - INFO - __main__ -   Reading test data from scicite_data/test.jsonl\n",
      "0it [00:00, ?it/s]\n",
      "1861it [00:00, 4030.36it/s]\n",
      "\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   test_data_path_aux = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   test_data_path_aux2 = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   mixing_ratio = 0.05\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   mixing_ratio2 = 0.05\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   cutoff_epoch = -1\n",
      "03/30/2024 11:29:06 - INFO - __main__ -   From dataset instances, train, validation, test will be considered for vocabulary creation.\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.type = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.extend = False\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.directory_path = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.min_count = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.max_vocab_size = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.min_pretrained_embeddings = None\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.only_include_pretrained_words = False\n",
      "03/30/2024 11:29:06 - INFO - allennlp.common.params -   vocabulary.tokens_to_add = None\n",
      "03/30/2024 11:29:06 - INFO - scicite.training.vocabulary_multitask -   Fitting token dictionary from dataset.\n",
      "0it [00:00, ?it/s]\n",
      "94189it [00:03, 24387.14it/s]\n",
      "\n",
      "03/30/2024 11:29:10 - INFO - scicite.training.vocabulary_multitask -   Fitting token dictionary from auxillary dataset.\n",
      "  0%|          | 0/146968 [00:00<?, ?it/s]\n",
      "100%|##########| 146968/146968 [00:04<00:00, 33569.32it/s]\n",
      "\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'citation_text_encoder': {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 100, 'input_size': 1124, 'num_layers': 2, 'type': 'gru'}, 'classifier_feedforward': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 3], 'input_dim': 200, 'num_layers': 2}, 'classifier_feedforward_2': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 5], 'input_dim': 200, 'num_layers': 2}, 'classifier_feedforward_3': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 2], 'input_dim': 200, 'num_layers': 2}, 'data_format': 'scicite_flat_jsonlines', 'elmo_text_field_embedder': {'elmo': {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'}, 'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}}, 'lexicon_embedder': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'vocab_namespace': 'lexicon_ids'}, 'multilabel': 'false', 'report_auxiliary_metrics': 'true', 'text_field_embedder': {'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}}, 'type': 'scaffold_bilstm_attention_classifier', 'use_lexicon_features': 'false', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43e85a6d30>}\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.type = scaffold_bilstm_attention_classifier\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.with_elmo = true\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'elmo': {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'}, 'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43e85a6d30>}\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.type = basic\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.embedder_to_indexer_map = None\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.allow_unmatched_keys = False\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.token_embedders = None\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43e85a6d30>}\n",
      "03/30/2024 11:29:14 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.type = elmo_token_embedder\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.options_file = https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.weight_file = https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.requires_grad = False\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.do_layer_norm = true\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.dropout = 0.5\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.namespace_to_cache = None\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.projection_dim = None\n",
      "03/30/2024 11:29:16 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.scalar_mix_parameters = None\n",
      "03/30/2024 11:29:16 - INFO - allennlp.modules.elmo -   Initializing ELMo\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43e85a6d30>}\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.type = embedding\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.num_embeddings = None\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.vocab_namespace = tokens\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.embedding_dim = 100\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.projection_dim = None\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.trainable = false\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.padding_index = None\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.max_norm = None\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.norm_type = 2.0\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.scale_grad_by_freq = False\n",
      "03/30/2024 11:29:38 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.sparse = False\n",
      "03/30/2024 11:29:38 - INFO - allennlp.modules.token_embedders.embedding -   Reading pretrained embeddings from file\n",
      "0it [00:00, ?it/s]\n",
      "400000it [00:02, 187638.29it/s]\n",
      "\n",
      "03/30/2024 11:29:41 - INFO - allennlp.modules.token_embedders.embedding -   Initializing pre-trained embedding layer\n",
      "03/30/2024 11:29:41 - INFO - allennlp.modules.token_embedders.embedding -   Pretrained embeddings were found for 38122 out of 142790 tokens\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 100, 'input_size': 1124, 'num_layers': 2, 'type': 'gru'} and extras {}\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.type = gru\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.batch_first = True\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.stateful = False\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.bidirectional = True\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.dropout = 0.3\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.hidden_size = 100\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.input_size = 1124\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.num_layers = 2\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.citation_text_encoder.batch_first = True\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward.input_dim = 200\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward.num_layers = 2\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward.hidden_dims = [20, 3]\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward.activations = ['linear', 'linear']\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward.dropout = [0, 0]\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_2.input_dim = 200\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_2.num_layers = 2\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_2.hidden_dims = [20, 5]\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_2.activations = ['linear', 'linear']\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_2.dropout = [0, 0]\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_3.input_dim = 200\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_3.num_layers = 2\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_3.hidden_dims = [20, 2]\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_3.activations = ['linear', 'linear']\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.classifier_feedforward_3.dropout = [0, 0]\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.initializer = []\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.regularizer = []\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.use_lexicon_features = false\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.use_sparse_lexicon_features = false\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.data_format = scicite_flat_jsonlines\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.report_auxiliary_metrics = true\n",
      "03/30/2024 11:29:41 - INFO - allennlp.common.params -   model.predict_mode = False\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      attention_seq2seq.attention\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l0\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l0_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l1\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_hh_l1_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l0\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l0_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l1\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.bias_ih_l1_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l0\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l0_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l1\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_hh_l1_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l0\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l0_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l1\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      citation_text_encoder._module.weight_ih_l1_reverse\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.0.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.0.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.1.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward._linear_layers.1.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.0.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.0.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.1.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_2._linear_layers.1.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.0.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.0.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.1.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      classifier_feedforward_3._linear_layers.1.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2\n",
      "03/30/2024 11:29:41 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_tokens.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred mode: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 11:29:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.type = bucket\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.padding_noise = 0.1\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.biggest_batch_first = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.batch_size = 16\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.instances_per_epoch = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.max_instances_in_memory = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.cache_instances = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.track_epoch = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator.maximum_samples_per_batch = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.type = bucket\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.padding_noise = 0.1\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.biggest_batch_first = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.batch_size = 16\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.instances_per_epoch = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.max_instances_in_memory = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.cache_instances = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.track_epoch = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux.maximum_samples_per_batch = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.type = bucket\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']]} and extras {}\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.sorting_keys = [['citation_text', 'num_tokens']]\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.padding_noise = 0.1\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.biggest_batch_first = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.batch_size = 16\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.instances_per_epoch = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.max_instances_in_memory = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.cache_instances = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.track_epoch = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   iterator_aux2.maximum_samples_per_batch = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   validation_iterator = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.no_grad = ()\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Following parameters are Frozen  (without gradient):\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_tokens.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Following parameters are Tunable (with gradient):\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l0\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l0\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l0\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l0\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l0_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l0_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l0_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l0_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l1\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l1\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l1\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l1\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_ih_l1_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.weight_hh_l1_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_ih_l1_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   citation_text_encoder._module.bias_hh_l1_reverse\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward._linear_layers.0.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward._linear_layers.0.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward._linear_layers.1.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward._linear_layers.1.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_2._linear_layers.0.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_2._linear_layers.0.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_2._linear_layers.1.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_2._linear_layers.1.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_3._linear_layers.0.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_3._linear_layers.0.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_3._linear_layers.1.weight\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   classifier_feedforward_3._linear_layers.1.bias\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   attention_seq2seq.attention\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.patience = 4\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.validation_metric = +average_F1\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.shuffle = True\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.num_epochs = 10\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.cuda_device = 0\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.grad_norm = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.grad_clipping = 5\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.optimizer.type = adadelta\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.optimizer.parameter_groups = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.training.optimizers -   Number of trainable parameters: 929274\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.optimizer.rho = 0.95\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.num_serialized_models_to_keep = 20\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.keep_serialized_model_every_num_seconds = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.model_save_interval = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.summary_interval = 100\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.histogram_interval = None\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.should_log_parameter_statistics = True\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   trainer.should_log_learning_rate = False\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   evaluate_on_test = true\n",
      "03/30/2024 11:29:42 - INFO - allennlp.common.params -   evaluate_aux_on_test = true\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Beginning training.\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Epoch 0/9\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Peak CPU memory usage MB: 22383.344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2024 11:29:42 - INFO - __main__ -   GPU 0 memory usage MB: 7773\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Multitask Training\n",
      "03/30/2024 11:29:42 - INFO - __main__ -   Training\n",
      "  0%|          | 0/5714 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  87, 106,  ..., 261, 261, 261],\n",
      "         [259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259,  72, 118,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  72, 106,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 108, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         [259, 113,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  72,  71,  ..., 261, 261, 261],\n",
      "         [259, 103, 109,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[22229,    88,  3834,     9, 23939,   369,  1717,     4,  1425,     5,\n",
      "         31596,   283,     8,   129,     7,     2, 26269,  4447,     8,   128,\n",
      "             7,     2, 21872,     8,   169,     2,   191,     7,     2,     6,\n",
      "          6433,    12,    10,    12,  1434,  1029,     5,  2059,     8,  2069,\n",
      "             3,     0,     0,     0,     0,     0],\n",
      "        [ 1524, 29006,     6, 29007,     8,   118,     7,     2,    15,  2006,\n",
      "            12,  2083,   351,  2954,   794,    31,    45,    10,  1182,   475,\n",
      "          3799,  2006,    12,  4127,    25,     4, 20456,  1028,  2633,     2,\n",
      "            22,   882,     9,     4,  1277, 29008,   174,     8, 29009,   316,\n",
      "             7,     3,     0,     0,     0,     0],\n",
      "        [ 1243,     4,   213, 20214,     9,  1272,   352,     5, 10668,     9,\n",
      "           369,    19,  2799,     8, 12535,    11,    14,     3,   274,    13,\n",
      "           541,    11,    14,     3,    89,    13,  9560,    11,    14,     3,\n",
      "            61,    13, 11528,    11,    14,     3,    70,     7,     2,    77,\n",
      "            66,  6344,    17,     4, 30384,     0],\n",
      "        [    8,   662,     7,   259,    17,  7205,   465,    19,   937,   359,\n",
      "         22865,    31,   139,    10,    17,   465,    19, 38690,   310,   493,\n",
      "           287,     9, 23465,    12,  7393,   412,     2,    32,   765,    17,\n",
      "             4, 20683,   727,    16,   270,   310,    50,   287,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  153,    16,   713,  3700,    17, 16713,   917,    15,  1865,   219,\n",
      "             9,     4,  2282,     5,  5170,   879,     2,    50,    22,     4,\n",
      "          3134,   586,  1432,     9,   340,  3064,  2644,     6, 14925,     5,\n",
      "         40130,     9,  1201,    91,     8,   240,     2,   224,     7,     3,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [    8,   316,     7,   238,    17,  4795, 13180,  1239,   527,    19,\n",
      "            15,  3049,   325,  2256,     2, 13181,    12, 13182,    21, 13183,\n",
      "             8, 13184,    12, 12909,     7,     2,    38,   975,    18,  2449,\n",
      "             6,  1063,  1901,     6,  4400,     9,   412,     8,  3271,    11,\n",
      "            14,     3,     2,   316,     7,     3],\n",
      "        [   93,  1851,    71,  2037,    28,    15,   184,    62,    17,    82,\n",
      "           387,   381,  1809,     5,  3917,     5,  4906,   789,     9,  1065,\n",
      "          1156,   121,  1638,   119,    31,   228,    19,   612,   348,    67,\n",
      "           121,    51,    31,  3153,     8, 17065,     2,    61,     7,     3,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [   93,   338,    92,    17,  1100,     8,  7204,    11,    14,     3,\n",
      "             2,   113,     7,    22,   103,    22,   161,     8,  7204,    11,\n",
      "            14,     3,    85,     7,  3016,    24,  1546,     9,  6647,  1372,\n",
      "             6,   180,     2,  1977,    15,   628,   219,    18,     4,  6647,\n",
      "           472,     9,  2451,  6249,     3,     0],\n",
      "        [   41, 22882,   928,     2,  2516,     8,  3101,     7, 20530,   551,\n",
      "         22883,    24,  4954,    28,     4,  3104,     2,     6,   917,    34,\n",
      "          1122,   219,     9,  9384, 15738,  3455,  3101,     9,     4, 15362,\n",
      "             8, 12569,    11,    14,     3,    97,    13, 10360,    11,    14,\n",
      "             3,    97,     7,     3,     0,     0],\n",
      "        [  144,    52,    37,  8701,    19, 15584,    11,    14,     3,     2,\n",
      "             8,    83,     7,   199,   192,  6080,  1541,     5, 12807,   434,\n",
      "            31,   214,   231,    10,   737,   434,     6,    82,   176,   241,\n",
      "           186,     5,  1149,    25,  6080,  1541,     9, 10243,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  770,     5,    65,   356,   922,   377,     9,  1112,  6055,     6,\n",
      "          3341,  8509,     2,    50,    22,  4218,   752,    12, 27146,     8,\n",
      "         12109,     7,     2, 12593, 12594,  1633,     8, 32964,     7,     6,\n",
      "         14936,    12,  6010,  8578,    21,  1026,     2,  1898,     2,  1455,\n",
      "            20,     3,     0,     0,     0,     0],\n",
      "        [ 1484,     2,   184,   126,    23, 23790,     2, 19207,     6, 16138,\n",
      "            21,    72,    20,   520,    34,  1470,  1468,    25,  1722,    12,\n",
      "          1036,     5, 23791,  1962,    57,     7,    18,   127,  1744,    12,\n",
      "          2542,   310,     4,  3171,     2,     9,    15,   700, 15737,  2559,\n",
      "             2,   525,    34, 11251,   215,     3],\n",
      "        [   26,   561, 12851,  3174,     9,     4, 32876,    38,   275,    33,\n",
      "           292,    10,    27,     4, 15263,    21,   129,    20,     2,     6,\n",
      "             4,   195, 21902,  8081,     6,  3691,    24,  1228,    10,    27,\n",
      "             4,   561,  4499,     5,  2486,     9,     4, 35181,    21,    57,\n",
      "             2,    72,    20,     3,     0,     0],\n",
      "        [   26,    52,     5,  5971,    11,    14,     3,     8,    76,     7,\n",
      "            46,   362,    17,   145,    16,    15,   250,   114,   675,    58,\n",
      "             4,  1429,  2920,     6,     4,  2524,  1129,     5,     4,  1472,\n",
      "             6,  1103,   751,    18,    96,     4,  5326,     5,     4,  5522,\n",
      "          9105,     3,     0,     0,     0,     0],\n",
      "        [  205,    15,   377,     5,  1841,  1168,   505,    18,     4,    62,\n",
      "          2770,  3367,  3330,   817,    48,     4, 30583,    21,   169,    20,\n",
      "             6,  4881,  1180,    48,     4,  2625, 12151,    10,  1589,  1858,\n",
      "         20275,  6334,   166, 15617, 30584, 18365,     8, 18366,     7,    21,\n",
      "           191,    20,     3,     0,     0,     0],\n",
      "        [ 2663,  3123,     5, 24845,    91,  2680,  2663,    12, 24846,     6,\n",
      "             4,  3044,  2622, 24847,    12, 12018,     7,     2,  3170,   989,\n",
      "          1259,    57,    12,   143,     2,     6,  2663,    12, 24848,    12,\n",
      "         12018,     7,     2,  3170,   989,  1259,    57,    12,   726,     3,\n",
      "             0,     0,     0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['9ce909dc3a55c00bde287c27f0128d8ee7648b83', '6f1d728fe93065c50f032df07a6997272714a02f', 'd70c2ec4118ba21ec83b96cb5780a89358349b61', '302106972f47762ff950c4c8bc7dcfae6edff655', '3f7f1b6c5e859de1c7e318ba6b6c9786513487b0', 'c0958dd33b8fe8b63400345d4ae70b316acfe654', '10eb32511984198b5f42d1dc18e6f88a4ebb0ce3', '6bd3d6b81899b05097be5fca2d8cd2766569b836', '482a6e8cdf2658f1e0d0d446c65013a724ec3ebe', 'a2d6e60cd95a4f0ee7c81c226e829d6c9ab01edb', 'c24645826ecf07e7a064bb606157168f9ef792e2', '4a695f55ff3ba9490a947f934164cd959231aa3a', 'bd3a8973d19752de1eadef935a08a7085c9b7e5a', 'ba43f7a0b2850788b818f2096ae492ea4ba0fc90', '5aafdd98ce3e4be63baa04a230e5635e8dd69bcf', 'a957bb986d6d80321c4de34334b68d080da651f3'], 'cited_paper_id': ['6df615b3c555ee61dee9fa6079f905466ed2fb8f', '34858dcd73746930218eaf514304008e201da687', '38cfba9172c94b091950a5a8975144a06a288b32', '129cb5a91a0ac0119fd08fc4fd91b604f3b4875c', '9d149e0e3fb670b6a765b3a19c1717f615cf63ae', 'f22ae74ea1dd405108e55c996175e77ff0e575e4', 'af07306f99ecbbf9689f03f089824f67a7b9a570', 'cd5fd50d44267650aa5a113f044ee333a58c7abb', 'd1ee4ae4d3493211a79a5f253b409bef8456f4f5', 'dd0509337c9d8c4ac5a24b2a0fc6e01fc8b5a335', 'ba480ce512aba288b1f259d2e4b1340915f4e541', '12707ed35c44575b9d1a9c920eb956e0477cee39', 'cf3af80ea7b58742973ac5e1fc17d23b5497b0ef', 'd1a14535c8d5eb2a6f09e5e3d2c1b025c182d7ea', '30e771155ed96439a8d682584751d0e0c53d5501', 'de7f14901918ff72f5f27b00f60996e6fd513cf6'], 'citation_excerpt_index': [0, 0, 4, 0, 0, 0, 1, 2, 0, 0, 2, 1, 0, 2, 4, 1], 'citation_id': ['9ce909dc3a55c00bde287c27f0128d8ee7648b83>6df615b3c555ee61dee9fa6079f905466ed2fb8f', '6f1d728fe93065c50f032df07a6997272714a02f>34858dcd73746930218eaf514304008e201da687', 'd70c2ec4118ba21ec83b96cb5780a89358349b61>38cfba9172c94b091950a5a8975144a06a288b32', '302106972f47762ff950c4c8bc7dcfae6edff655>129cb5a91a0ac0119fd08fc4fd91b604f3b4875c', '3f7f1b6c5e859de1c7e318ba6b6c9786513487b0>9d149e0e3fb670b6a765b3a19c1717f615cf63ae', 'c0958dd33b8fe8b63400345d4ae70b316acfe654>f22ae74ea1dd405108e55c996175e77ff0e575e4', '10eb32511984198b5f42d1dc18e6f88a4ebb0ce3>af07306f99ecbbf9689f03f089824f67a7b9a570', '6bd3d6b81899b05097be5fca2d8cd2766569b836>cd5fd50d44267650aa5a113f044ee333a58c7abb', '482a6e8cdf2658f1e0d0d446c65013a724ec3ebe>d1ee4ae4d3493211a79a5f253b409bef8456f4f5', 'a2d6e60cd95a4f0ee7c81c226e829d6c9ab01edb>dd0509337c9d8c4ac5a24b2a0fc6e01fc8b5a335', 'c24645826ecf07e7a064bb606157168f9ef792e2>ba480ce512aba288b1f259d2e4b1340915f4e541', '4a695f55ff3ba9490a947f934164cd959231aa3a>12707ed35c44575b9d1a9c920eb956e0477cee39', 'bd3a8973d19752de1eadef935a08a7085c9b7e5a>cf3af80ea7b58742973ac5e1fc17d23b5497b0ef', 'ba43f7a0b2850788b818f2096ae492ea4ba0fc90>d1a14535c8d5eb2a6f09e5e3d2c1b025c182d7ea', '5aafdd98ce3e4be63baa04a230e5635e8dd69bcf>30e771155ed96439a8d682584751d0e0c53d5501', 'a957bb986d6d80321c4de34334b68d080da651f3>de7f14901918ff72f5f27b00f60996e6fd513cf6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "background_P: 0.6875, background_R: 1.0000, background_F1: 0.8148, method_P: 0.0000, method_R: 0.0000, method_F1: 0.0000, result_P: 0.0000, result_R: 0.0000, result_F1: 0.0000, average_F1: 0.2716, aux-sec--introduction_P: 0.0000, aux-sec--introduction_R: 0.0000, aux-sec--introduction_F1: 0.0000, aux-sec--conclusion_P: 0.0000, aux-sec--conclusion_R: 0.0000, aux-sec--conclusion_F1: 0.0000, aux-sec--experiments_P: 0.0000, aux-sec--experiments_R: 0.0000, aux-sec--experiments_F1: 0.0000, aux-sec--method_P: 0.0000, aux-sec--method_R: 0.0000, aux-sec--method_F1: 0.0000, aux-sec--related work_P: 0.0000, aux-sec--related work_R: 0.0000, aux-sec--related work_F1: 0.0000, aux-sec--average_F1: 0.0000, aux-worth--False_P: 0.8750, aux-worth--False_R: 1.0000, aux-worth--False_F1: 0.9333, aux-worth--True_P: 0.0000, aux-worth--True_R: 0.0000, aux-worth--True_F1: 0.0000, aux-worth--average_F1: 0.4667, loss: 1.1318 ||:   0%|          | 1/5714 [00:57<91:20:53, 57.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  50, 260,  ..., 261, 261, 261],\n",
      "         [259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259, 100, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 105,  ..., 261, 261, 261],\n",
      "         [259, 117,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 113, 112,  ..., 261, 261, 261],\n",
      "         [259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259,  71, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   14,    46,   897,    17,   446,   199,    37,   277,   286,    29,\n",
      "          1444,    44,  7675,    37,    56,   335,    10,  2335,   498,   262,\n",
      "            19,    60, 22657,     6,    37,    46,    56,   335,    10,   624,\n",
      "           276,   183,    15,   124,     5,  8066,    67,    60,  3280,  5210,\n",
      "             8,   630,     7,     3,     0],\n",
      "        [   57,     8, 22677,    12, 22678,     7,     9,  8418, 11130,     2,\n",
      "           846,   122,     9,    39,  8418,    48, 15245,    21,   236,    20,\n",
      "             2,    31,  2324,   846,     9,    71, 21868,   553,     6,   713,\n",
      "           105,    10,  1079,    15,   474,  6925,   871,  2196,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [   88,  6007,   291,    31,    45,     8, 42304,    36,  6441,     2,\n",
      "            70,     7,     9,    32,   483,   233,    10,   126,   276,    32,\n",
      "           459,    31,     4,   437,     9,    15,  1674,   154,  2373,     5,\n",
      "            81,  1826,     6,    81, 13295,     8,   301,    57,     7,     3,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [ 1422,    10,  6110,  1113,  4251,  4285,     6,   188,     9,    15,\n",
      "           374,    29,  4753,     5,   871,  5373,     8,  5544,    11,    14,\n",
      "             3,     2,    85,    13,  6816,    11,    14,     3,     2,    87,\n",
      "            13,  5731,     6,  5731,     2,    68,    13,  5499,    11,    14,\n",
      "             3,     2,    79,     7,     3],\n",
      "        [   41,    65,   226,     2,   279,    18, 27289,  3452,     2, 10721,\n",
      "          3901,    16,  1675,   168,   273,    67,   526,  3835,     2,     6,\n",
      "            16,   250,   516,   168,   684,  3835,     8, 22036,    12, 12629,\n",
      "            11,    14,     3,    61,    13,  8390,    11,    14,     3,   104,\n",
      "             7,     3,     0,     0,     0],\n",
      "        [  152,     2,     4,   790,    12, 20617,     5,     4, 13788,   364,\n",
      "            42,  4797,     4,  2718,     5,     4,   158,  4716,    43,    46,\n",
      "          1468,     4,   117,     5, 11827,   754,    23, 20618,  1997,   790,\n",
      "             7,  1997,    57,    21,   297,     2,   718,    20,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [11679,     2, 14508,     2,   130,   265,  1149,  6200,     7,     6,\n",
      "          1058,    12,   501,  1149,  2737,     8, 47552,     7,     2,    22,\n",
      "           103,    22,   226,     9,    32,     4,    81,  3605,     5,  1149,\n",
      "          2737,  1793,    21, 47553,    12,   726,    20,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [   41,    99,  3209,     8,  2449,    12,   218,     7,     6, 12015,\n",
      "         26026,     2,  8006,  3187,    38,    33,    82,     9,    99,   317,\n",
      "           486,     6, 31168,     2,   883,    34,   340,  1757,     5,  8006,\n",
      "          6818,     9,     4, 31169,  2756,    21, 21256,    20,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [   64,    31,   539,    22,    15,  2252,     5,     4,   426,   226,\n",
      "             2,    54,    25,   108,   226,   735,  2439,  2299,    23,   107,\n",
      "           735,   450,     5,  1794,   227,  5222,     2,    48,     4,   124,\n",
      "           239,    23, 29065,     6, 13742,     8,    78,     7,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [ 8621,    24,  1113,   491,     5,     4,   120,   811,  4425,     6,\n",
      "             4,  3658,  4410,  2384,   120,   811,  1593,     8,  5295,     6,\n",
      "          5296,     2,    89,    13, 13201,     6, 13202,     2,    79,    13,\n",
      "          5925,     6,  1139,     2,    75,    13,  5295,     6,  5296,     2,\n",
      "            75,     7,     3,     0,     0],\n",
      "        [  224,   976,  7889,    21,   295,     2,   388,     2,   571,     2,\n",
      "           313,     2,   873,    20,     6,   526,   976,  7889,    21,   726,\n",
      "             2,   662,     2,  1012,    20,    13,     9,   109,   289,     4,\n",
      "          3509,   262,    31,    42,  2190,    21,   630,     2,   718,    20,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [  112,   160,     2,    77, 11161,  2196,    52,     9, 33876,     2,\n",
      "            46,   551, 33877,     8, 14383,     6, 14383,    87,     7,     3,\n",
      "             4,  7507,    12,   150, 19316, 33878, 33879,    16,  1514,   189,\n",
      "          9557,    90,     5,     4, 33880,  2273,     5, 19316,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [ 2828,  2408,     9,  2740, 39974,    16,   588,  6084,     9,   688,\n",
      "           270,    12, 20252,   226, 15224,   819,  3657,    18,    32,  6963,\n",
      "           196,    16,   114,     8, 21001,   661,    13, 16825,   428,    13,\n",
      "          9448,    12,  7029,    11,    14,     3,  5161,    13,  2655,     6,\n",
      "          4488,   132,     7,     3,     0],\n",
      "        [   26,   249,     5,   416,     9,   842,  9976,    31,  1000,    19,\n",
      "           757,   123,   784,    23,   904,    12,   260,     8,  8835,   635,\n",
      "             5,  3720, 40795, 31470,  3765,  6185,     2, 47816,  6185, 47817,\n",
      "             2,  2590,     2,  1789,     7,    21,   221,     2,   341,    20,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [   26,   188,    16,   228,    19,     4,  4806,    23, 38429,    11,\n",
      "            14,     3,     8,   198,    13,    85,     7,    17,     4,  1853,\n",
      "             5,     4, 38430,   885,    10, 38431,    16,  1087,    10,    17,\n",
      "             5,     4,     8, 38432,     7,  1277, 38433,   225,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [19857,     8,   301,    90,     7,     2,   228,    19,     4,   102,\n",
      "           188,     5,  2060,    11,    14,     3,     8,   113,     7,     3,\n",
      "          6157,     5,   114,   163,     5,  4468, 45322,     8,   976,     7,\n",
      "             6, 40644,     8, 38201,     7,    46,  3013,   120,  1367,     8,\n",
      "           301,    90,     7,     3,     0]], device='cuda:0')}, 'labels': tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 2], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['b8ad040357eaae50c8efbe3cc8ae9d93b800db2d', '4fa6bc9e73e52f4e7a4f165b2f4799eb05c31aa2', 'b83206f7faa26b6067151f721c4f39e81402c88a', '4e76d6b98473d7af7d7c946cd9b4e2d110de5606', 'd8f915342dee431558368107381583a6db146135', '796ce7f3bd4c08ffc98d94d6986ed8901bfe565a', '0210744712745069cf428272f413db0483ec764d', '571987bcb1353f81dd30606209c84e8899e5c368', '8727d14b6345f467809ffade94d78f6b4c3dec5c', '0ec5bf54921fb55a66383970dbf9040724e281e4', 'fb77c4e7eabf78a74edbb58a8f8c8093c7f43c30', '5a310d2892ef475127d54004ec1b7d79ff3352fa', 'da2a80ac34255bd566db0fcb01f9a4d0877cc43d', 'd8c864a4aa8110247168039b488bc42de92bb7f7', '15741804409acbe248ed63533c7bb88bd184dac9', '898a524f2ea0579ef33e7264a6e938ab968e1d1e'], 'cited_paper_id': ['e18666bf07e60f7414838aed88c0d35510bce67c', 'fc6f38bd4724635723ffe8518f2be1a8f3085ea5', '05ad0bce83740b1ab8f57c3be7831a4b6b976ae1', '9d57eaed154045f05a5d6543d72db7db873ab390', 'da1bfc89bdd64622df21b78a99235ec0d2512ba7', 'c8276cd15b179bf3d678aac6f9a0e48231e895b2', '485a7c05469a177cc929b616bb246c242ea61f4b', '198679eee53032443122b876740e707d56a3a645', '15667617fa119d773eced96ddcbc925db6640fa5', 'c824fde7bf52707c957aeb5c297268efb9d9a669', '25f7210be4449d4fec53f0bf97aef9764242306a', '3b6f481c9c76bc8b38f7b056d16b801aad9ab96f', '1fd9bb3fda0dae1ee2d5495072456b6c64f3fdc2', 'b2d0f0d999f1eeb8f5d7d29f5e154891534e58b9', 'None', 'e6790bb859751e91d443696e0e78354d260955fd'], 'citation_excerpt_index': [3, 11, 13, 7, 1, 1, 1, 6, 0, 4, 5, 0, 3, 0, 0, 0], 'citation_id': ['b8ad040357eaae50c8efbe3cc8ae9d93b800db2d>e18666bf07e60f7414838aed88c0d35510bce67c', '4fa6bc9e73e52f4e7a4f165b2f4799eb05c31aa2>fc6f38bd4724635723ffe8518f2be1a8f3085ea5', 'b83206f7faa26b6067151f721c4f39e81402c88a>05ad0bce83740b1ab8f57c3be7831a4b6b976ae1', '4e76d6b98473d7af7d7c946cd9b4e2d110de5606>9d57eaed154045f05a5d6543d72db7db873ab390', 'd8f915342dee431558368107381583a6db146135>da1bfc89bdd64622df21b78a99235ec0d2512ba7', '796ce7f3bd4c08ffc98d94d6986ed8901bfe565a>c8276cd15b179bf3d678aac6f9a0e48231e895b2', '0210744712745069cf428272f413db0483ec764d>485a7c05469a177cc929b616bb246c242ea61f4b', '571987bcb1353f81dd30606209c84e8899e5c368>198679eee53032443122b876740e707d56a3a645', '8727d14b6345f467809ffade94d78f6b4c3dec5c>15667617fa119d773eced96ddcbc925db6640fa5', '0ec5bf54921fb55a66383970dbf9040724e281e4>c824fde7bf52707c957aeb5c297268efb9d9a669', 'fb77c4e7eabf78a74edbb58a8f8c8093c7f43c30>25f7210be4449d4fec53f0bf97aef9764242306a', '5a310d2892ef475127d54004ec1b7d79ff3352fa>3b6f481c9c76bc8b38f7b056d16b801aad9ab96f', 'da2a80ac34255bd566db0fcb01f9a4d0877cc43d>1fd9bb3fda0dae1ee2d5495072456b6c64f3fdc2', 'd8c864a4aa8110247168039b488bc42de92bb7f7>b2d0f0d999f1eeb8f5d7d29f5e154891534e58b9', '15741804409acbe248ed63533c7bb88bd184dac9>None', '898a524f2ea0579ef33e7264a6e938ab968e1d1e>e6790bb859751e91d443696e0e78354d260955fd']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  84, 106,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259,  78,  81,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 260,  ..., 261, 261, 261],\n",
      "         [259, 115,  98,  ..., 261, 261, 261],\n",
      "         [259, 116,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  84, 106,  ..., 261, 261, 261],\n",
      "         [259,  66, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  68, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 117, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259, 118, 111,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 111,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]], device='cuda:0'), 'tokens': tensor([[ 9797,  2014, 13459,   475,   178,   323,  2372,  1021,   980,   520,\n",
      "            15,  3353,    10,   638,   420,   294,     2,    51,   364,    42,\n",
      "           857,    18,     4,  1142,   282,   872,     9,    71,   102,    49,\n",
      "             8,  5417,     6,  3970,    85,     7,     3,     0,     0,     0],\n",
      "        [  831,  6316, 25916,  4390,     7,  1238,  2644,     8,  3686,    11,\n",
      "            14,     3,     2,   198,    13, 11920,    11,    14,     3,     2,\n",
      "           198,    13,  2592,    11,    14,     3,     2,    97,    13,  3667,\n",
      "             6,   724,     2,    68,     7,     3,     0,     0,     0,     0],\n",
      "        [   26, 12397, 14296,   133,    38,    33,  1756,    10,    27,   250,\n",
      "           466,   121,   284,    10,   203,  3080,   808,     2,    18,    32,\n",
      "          1033,    54,   303,    66,  3837,    10,   749,   528,   990,     2,\n",
      "         23584,     8,   448,     7,    13,  8336,    11,    14,     3,     0],\n",
      "        [ 2114,     2,   145,    16,   176,   114,    12,   332,   296,    18,\n",
      "             4,  1222,     5, 26739,   720,    18,     4,   235,     5, 37138,\n",
      "            20,     7,  9652,    12,  2432,  3378,  3823,     8,  7441,     7,\n",
      "            16,   868,    45,    10,  2803,  8966,     9,  1504,     3,     0],\n",
      "        [  544,     2, 19655,  3506,   120,   613,  8184, 14870,    30,    33,\n",
      "           100,     9,    99,  7649,     6, 14193,     8,  4992,     2,   404,\n",
      "             2,   209,    13,  8774,    12,  8775,    11,    14,     3,     2,\n",
      "           151,    13, 11509,    11,    14,     3,     2,    89,     7,     3],\n",
      "        [  144,   177,     5,  6871,    25,     4,  1168,   165,     5, 40035,\n",
      "          9582,  1568,   109,   102,    52,     8, 40036,    11,    14,     3,\n",
      "             2,   118,     7,    69,   110,  1134,    10,  7760,    19,    55,\n",
      "           914,     8,  5918,    11,    14,     3,     2,   132,     7,     3],\n",
      "        [ 1353,     2,    22,   740,    18, 36153,    44, 33838,    21, 36154,\n",
      "            20,     2, 15415,   589,   553,     5,  3785,     6,   370,    53,\n",
      "           259,    17,  1515, 15799,   784,    34,  2773,   379,     6, 13233,\n",
      "         15799,   784,    15,   469,    12,  3165,   379,     3,     0,     0],\n",
      "        [   41,     4,  1126,    49,     2, 11565,    11,    14,     3,     8,\n",
      "          3984,     7,     6, 10122,    11,    14,     3,     8,    76,     7,\n",
      "          1133,     4, 20463,     5, 14603,  9815,     5, 17372,  2858,     3,\n",
      "           986, 21897,     6, 31056, 21896,     2,   463,     3,     0,     0],\n",
      "        [29349,  6164,     3,   749,     4, 31437, 18996, 35922,   658,     8,\n",
      "         35923,    11,    14,     3,   209,    13, 35924,    11,    14,     3,\n",
      "           142,     7,     6,     4,   173, 35925,    12,   501, 35926,   472,\n",
      "         35927,     2,    99,   423,     9,  2516,  1968,     3,     0,     0],\n",
      "        [   41,   894,   115,     5,  5581,    12,   256,  1753,     2,   492,\n",
      "          2236,   609,   597,  1173,   103,   534,   252,  2775,    29, 34909,\n",
      "          3952,  2636,     8, 11157,    11,    14,     3,     2,  4290,     2,\n",
      "           256,    13, 42384,     2,    76,     7,     3,     0,     0,     0],\n",
      "        [  112,   160,     2,     4,  1160, 33898,     6, 38612,  3347,    37,\n",
      "           105,    10,  2576,     4,  2138,   186,     5, 10796,  7810, 26341,\n",
      "             6,  4598,    25, 22259,  2485,     2,   463,    21,   346,     2,\n",
      "          1304,    20,     2,     9, 22260,    91,     3,     0,     0,     0],\n",
      "        [  646,    42,     2,    15,  1416,     9,     4,  2236,   352,     5,\n",
      "          8094,   441,  1218,    16,   250,   335,     2,    32,    16,  1819,\n",
      "            10,   536,    10,     4,   192,  2172,     9,  7922,    12,    95,\n",
      "             8,  8078,    11,    14,     3,     2,    63,     7,     3,     0],\n",
      "        [ 4990,     6, 12361,    26,  1605,     5, 42643, 25803,     9,     4,\n",
      "           420,    31,   139,    10,     4,  1315,    52,   530,    15,  1290,\n",
      "          1605,     5, 42644,    31, 25803,     9,     4,   420,     8,   345,\n",
      "            57,     2,  5579,    11,    14,     3, 37722,     7,     3,     0],\n",
      "        [ 4736,     5,  6120,   262,     9, 13733,     6,     4,  7005,  9348,\n",
      "             2,     4, 27311,     2,   396,     2,   997,   176,  1935,  1802,\n",
      "            58,     4,    81,   392,     5, 27312,     9,    15,   102,    62,\n",
      "             8,  4488,  2189,     7,     2,   776,    39,  2139,  4329,     3],\n",
      "        [   93,   231,    65,   462,  1817,    10,   138,     5,    95,    19,\n",
      "           945,   283,    17,   233,  1301,     9,    12,  1024,  1281,    12,\n",
      "           260,  2001,  6409,     9,    15,  2511,    62,  2620,  1268,  1343,\n",
      "             8,  5851,     7,    21,   277,    20,     3,     0,     0,     0],\n",
      "        [22573,   393,    16,  1006,    10,   306,    15,  1987,  1511,    10,\n",
      "             4, 12518,    23,  4084,     4,   328,     5,  4452, 12519,     8,\n",
      "          1708,     6, 15547,     2,   428,    13, 42338,     6,  1409,     2,\n",
      "            85,    13,  4223,    11,    14,     3,     2,  2121,     7,     3]],\n",
      "       device='cuda:0')}, 'labels': tensor([0, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['77f4a2365ba1b6ffc8d13e049654b1359c29671a', '0012d808e76e1cd0e5ddeea10824a0811942a7e5', '3afa3ca2b90928ac23ed113311762193e5ba5d14', 'ebf18b99b02fb3d1db0496847c4a501822c13c5e', '85157a05c0eba82e6d6e424fca5ad60946339006', '9188d4db89d7031f7ca876c1677c7e61be9e5237', '9b0f8366932a559cf29283bf8299ecfe77997c20', '19d3a5f60b9e670448af8e03a532fcf0d5ba7c86', '37716f4614fdd18b9d7c3f820419cce893e3c146', 'c27f36488ff6459850015a434bf46c878cf20b6c', 'dc18241f7235cc320af8980253f3a19c89ca1026', '062ab02c421a101c2f4ce8b57e03efbcad9e65cf', '874344959b17ac83a71c60ca9daaf662ac7e86b4', '6c0d40cfabb567805bef3f50b7af4549e66019fd', 'be9a51c999f8cb2514e16ee00b7fc5d47f53fea7', 'cf82d977a64226a15cca9fc0eea7de1e0078ce29'], 'cited_paper_id': ['841aba543847838da1e2310ed5339a546c5a2b2d', '53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', 'a765aed737ecc4b8961e8be7b046964220208ee9', '8cd504093b651fd4e1ee5cc5695bc607289314b3', '2865b07f8b8189049cf726bff1ccdaeef3fbe62b', '2b187f3b3326c4537740c5d8a08387cfc450e7df', '42dc50c30fc3cdee9b7dc9405ad70c239c03ae1c', '795dea03985914118aff6306635fc53c3792b758', 'fb231eafa3e40e4e9171bd005d57f85c2622ef52', '3c8212a69aaf6f9a80da72d119eaf29668b9a0af', 'a48ca1f01ecc9ba8e76587a782f0b578975459d2', '31d31b65fa7b01ce90080264e7d1472af469355d', 'd722e3aef1de49301010e5f74a3449ffb44a7e52', '98cc989e358d6ff824272048e1030fda47e6e544', '45ff42e8ed2d8e7bb29919d87bf647b20cfea6fc', 'efe167e81022b9fb2b41ea7de996515c26f94838'], 'citation_excerpt_index': [13, 4, 1, 0, 11, 15, 4, 4, 0, 1, 3, 4, 2, 4, 3, 3], 'citation_id': ['77f4a2365ba1b6ffc8d13e049654b1359c29671a>841aba543847838da1e2310ed5339a546c5a2b2d', '0012d808e76e1cd0e5ddeea10824a0811942a7e5>53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', '3afa3ca2b90928ac23ed113311762193e5ba5d14>a765aed737ecc4b8961e8be7b046964220208ee9', 'ebf18b99b02fb3d1db0496847c4a501822c13c5e>8cd504093b651fd4e1ee5cc5695bc607289314b3', '85157a05c0eba82e6d6e424fca5ad60946339006>2865b07f8b8189049cf726bff1ccdaeef3fbe62b', '9188d4db89d7031f7ca876c1677c7e61be9e5237>2b187f3b3326c4537740c5d8a08387cfc450e7df', '9b0f8366932a559cf29283bf8299ecfe77997c20>42dc50c30fc3cdee9b7dc9405ad70c239c03ae1c', '19d3a5f60b9e670448af8e03a532fcf0d5ba7c86>795dea03985914118aff6306635fc53c3792b758', '37716f4614fdd18b9d7c3f820419cce893e3c146>fb231eafa3e40e4e9171bd005d57f85c2622ef52', 'c27f36488ff6459850015a434bf46c878cf20b6c>3c8212a69aaf6f9a80da72d119eaf29668b9a0af', 'dc18241f7235cc320af8980253f3a19c89ca1026>a48ca1f01ecc9ba8e76587a782f0b578975459d2', '062ab02c421a101c2f4ce8b57e03efbcad9e65cf>31d31b65fa7b01ce90080264e7d1472af469355d', '874344959b17ac83a71c60ca9daaf662ac7e86b4>d722e3aef1de49301010e5f74a3449ffb44a7e52', '6c0d40cfabb567805bef3f50b7af4549e66019fd>98cc989e358d6ff824272048e1030fda47e6e544', 'be9a51c999f8cb2514e16ee00b7fc5d47f53fea7>45ff42e8ed2d8e7bb29919d87bf647b20cfea6fc', 'cf82d977a64226a15cca9fc0eea7de1e0078ce29>efe167e81022b9fb2b41ea7de996515c26f94838']}\n",
      "{'citation_text': {'elmo': tensor([[[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259,  70, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  78,  98,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259, 109, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 116, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259, 120, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73,  98,  ..., 261, 261, 261],\n",
      "         [259,  39, 260,  ..., 261, 261, 261],\n",
      "         [259,  76,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   35,    88,  6273,  ...,     0,     0,     0],\n",
      "        [ 5804,  2833,   163,  ...,     0,     0,     0],\n",
      "        [   35,   116,  1861,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   64,  5099,  1502,  ...,     3,     0,     0],\n",
      "        [   35,   228,    19,  ...,     0,     0,     0],\n",
      "        [27575,    36,  8400,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 1, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['fcbfb0dc4ea5f34129d8bd5bdac9f3071e53731c', 'f88ff6818995fec1af997dea738fbc5391b6c676', '25a58b728ebeee5bc33d753bccb89617af1cd6d6', '8234e3304b21fd300d37575b2a0c7eb5645a4ae7', 'efaa33b745b1420d6bf13873a4df09680c7984e0', '1e07b16fb589780721887f60271a8b1c2868fb8b', '55e8e01dcb4d886fc46bf8d1b909355c080307ed', 'c91f1257ec590f9b94e0bf6a5f228c2df2c6edfd', '8fb05e797a37388e390c7b6c3f66e368393991d0', '8c4901f35b5d170ee08ac0210faef1a091b5faee', 'ed087351a270da4eb990e096ea4346a02de17176', '7ac67ff0f59585ad3b31d22424c2cef72e20a27d', '899def4b8ab14421cbbe76f9d39a6b4f6be4c230', 'd5e9bb418f5183ebcaf371efce583b2e710315ef', '80160aee8cdcbc26e6b65dd28fd07246c349140c', 'dfa93f8940770740c6a270c47349fd54d4a713b3'], 'cited_paper_id': ['4b557a30c883f974cf871d87b2646e1dc9cdff4a', '352b4767205024ed0e2d30c41ba9e70b8d80d08c', '5b97f710fe7b89887740e292d1c5e2b9f1d65b1f', '54f0eb70e18caac1551e26e815e41af41f5d2ed5', 'eb08d5a6852228a7b45deb22f1bf4dde945020c6', '40c5741dc18ca03e625306b5bbf6622d097176a3', 'ae277fdf3c34f05b869119974846fa11243326c4', 'a724a8246ee26d83496261cfb4406d9de61b4de9', '5a734f41ce7e10bba7edf0f2161acf3a1f1d8ef4', 'None', '22f62024be2ad2679676353f7d053ecb9b9c83b5', '8d588720ea1b676f8b3906b696e06cf64f5b766b', 'c8d0886c41b726b264ebfa042e86bcc59cf2ada3', '6aa6183f41837ccaed16951fe32e9e3e861a0356', '9b191008e5ce88ef5fb79694fa7fb8d7ab10170b', '2a75b1663009d46e28127c1b5c92098dbf9ae219'], 'citation_excerpt_index': [7, 0, 14, 0, 7, 5, 0, 15, 0, 0, 0, 3, 0, 6, 1, 1], 'citation_id': ['fcbfb0dc4ea5f34129d8bd5bdac9f3071e53731c>4b557a30c883f974cf871d87b2646e1dc9cdff4a', 'f88ff6818995fec1af997dea738fbc5391b6c676>352b4767205024ed0e2d30c41ba9e70b8d80d08c', '25a58b728ebeee5bc33d753bccb89617af1cd6d6>5b97f710fe7b89887740e292d1c5e2b9f1d65b1f', '8234e3304b21fd300d37575b2a0c7eb5645a4ae7>54f0eb70e18caac1551e26e815e41af41f5d2ed5', 'efaa33b745b1420d6bf13873a4df09680c7984e0>eb08d5a6852228a7b45deb22f1bf4dde945020c6', '1e07b16fb589780721887f60271a8b1c2868fb8b>40c5741dc18ca03e625306b5bbf6622d097176a3', '55e8e01dcb4d886fc46bf8d1b909355c080307ed>ae277fdf3c34f05b869119974846fa11243326c4', 'c91f1257ec590f9b94e0bf6a5f228c2df2c6edfd>a724a8246ee26d83496261cfb4406d9de61b4de9', '8fb05e797a37388e390c7b6c3f66e368393991d0>5a734f41ce7e10bba7edf0f2161acf3a1f1d8ef4', '8c4901f35b5d170ee08ac0210faef1a091b5faee>None', 'ed087351a270da4eb990e096ea4346a02de17176>22f62024be2ad2679676353f7d053ecb9b9c83b5', '7ac67ff0f59585ad3b31d22424c2cef72e20a27d>8d588720ea1b676f8b3906b696e06cf64f5b766b', '899def4b8ab14421cbbe76f9d39a6b4f6be4c230>c8d0886c41b726b264ebfa042e86bcc59cf2ada3', 'd5e9bb418f5183ebcaf371efce583b2e710315ef>6aa6183f41837ccaed16951fe32e9e3e861a0356', '80160aee8cdcbc26e6b65dd28fd07246c349140c>9b191008e5ce88ef5fb79694fa7fb8d7ab10170b', 'dfa93f8940770740c6a270c47349fd54d4a713b3>2a75b1663009d46e28127c1b5c92098dbf9ae219']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  67,  67,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84,  78,  ..., 261, 261, 261],\n",
      "         [259,  48, 260,  ..., 261, 261, 261],\n",
      "         [259,  75, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  78, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  53,  55,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 101,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 106,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 103, 115,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[ 8137,  1137,    10,  1775,    22,    34, 11713,    17,  8915, 30721,\n",
      "          2734,     5, 13615,  1148,  4425,    19,  5870,     6,   407, 13984,\n",
      "             4,  9138,  2652,     5,  5870,     6,   107,   150,  9138,   356,\n",
      "           435,    18,     4,  1457,     5,  4495, 22704,    28,     4,  9541,\n",
      "             8,   221,     7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 3847,    80,  2102,     6, 10907,    80,  2102,  1339,     9,    60,\n",
      "          4192,   229,    10,    15,   114,    12,  1428,  1647,     2,    19,\n",
      "          3847,    80,  2102,   288,    56,  5256,    67, 10907,    80,  2102,\n",
      "            18,   147,  2281,     2,  1617,    12,   164,     2,     6,  1296,\n",
      "          2124,   156,  1229,    21,  7600,    20,     3,     0,     0,     0],\n",
      "        [  651,     2,   145,    16,  2215,   360,    17, 38060,    16,    34,\n",
      "           838,  4832,   611,     5,  7199,     8,  2418,     2,  3169,     7,\n",
      "             2,    15,   447,  8401,    17,    38,    34,   171,  2908,   219,\n",
      "           179,     5,   107, 10981,  1559,    25, 19162,    12,  7824,  3373,\n",
      "             6, 42815,  3373,  1042,     9, 18287,     8,  1523,     7,     3],\n",
      "        [   41,   444,    10,   610,   410, 35597,   227,     4, 35598,    21,\n",
      "           297,    20,    29, 35599,    21,   383,    20,     2,    71,   123,\n",
      "           765,    17,    51,    66,    27,    34,  1016,   232,     8,  1526,\n",
      "             4,   456, 35600,     7,     9,     4, 35601,     5, 35602,     2,\n",
      "             9,   685,    19,   541,    11,    14,    21,   295,    20,     3],\n",
      "        [ 5216,   244,    30,    33,  3876,     2,   130, 12964,  2813,   116,\n",
      "            21,  3189,     2,  6587,    20,     2,  2722,   507,    59,    12,\n",
      "            54,   116,    21,  7026,    20,     2,   314,    12,    54,   116,\n",
      "            21,   191,    20,     6,  2722,  2226,    59,    12,    54,   116,\n",
      "            21, 22221,    20,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  770,  1891,   464,    24,  4822,     9,  1112,   178,     6,  6577,\n",
      "          1513,     5,  5076,     9,     4,  4565,   380,     8, 11314,    11,\n",
      "            14,     3,     2,  2986,    13,  8419,    11,    14,     3,     2,\n",
      "         29489,    76,    13, 43140,    11,    14,     3,     2,    68,    13,\n",
      "          4337,    11,    14,     3,     2,    63,     7,     3,     0,     0],\n",
      "        [   41,  2502,  7253, 17049,  1238,     2,     4,   178,   156,     5,\n",
      "          6712,    16,   213,    10,    27,   273,    67,    77,    12,  1147,\n",
      "             5,   138,     5,  9024,     2,  9025,     2,     6, 10861,     8,\n",
      "          5884,    11,    14,     3,     2,    79,    13, 17050,    11,    14,\n",
      "             3,     2,   104,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [22194,    52,    37,    92,     9,    49,    25, 31498,     8, 29406,\n",
      "         13293,     2,   125, 16141,    11,    14,     3,  5313,     2,   256,\n",
      "            13, 29407,    11,    14,     3,  4290,    13, 31499,    11,    14,\n",
      "             3,    79,    13, 31500,    11,    14,     3,    61,    13, 31501,\n",
      "            11,    14,     3,    63,     7,     3,     0,     0,     0,     0],\n",
      "        [16850,    11,    14,     3,     8,   118,     7,   325,  3244,  1178,\n",
      "             9,     4, 29050,   246,  1453, 42839,  6982,  3175,  2734,     6,\n",
      "             4, 45273,   246,  1453,  6832,   424,  6982,     9, 14347,     2,\n",
      "            32,    24,   329,   423,     9,  3477,  3995,     2,  4548,     2,\n",
      "             6,  1892,  2372,  3858,     3,     0,     0,     0,     0,     0],\n",
      "        [ 2839,    55,  2621,   774,  1466,    12,   353,   409,   177,    25,\n",
      "          4618,   549,     8,   125,     2,  3052, 27718,    13, 12879,    36,\n",
      "          4791,     2,   113,     2,    87,     7,     2, 43141,  1137,    10,\n",
      "            27,    15,   639,    12,   353,   186,    17, 10633,  1116, 36108,\n",
      "         10759,     8, 45473,    36, 20650,     2,    85,     7,     3,     0],\n",
      "        [19772,   507,    12,  1714,  1239,    57,     6,    72,     8, 17417,\n",
      "             7,     2,     4,   781,    12,  6366,   989,    12,  1587,  1239,\n",
      "             8,  9413, 30897,     7,     2, 14301,  1239,     2,     6, 30898,\n",
      "            24,     4,   468,   838, 28881,  1374,    23,  1161,  1218,    21,\n",
      "            57,    20,     3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [10352,    11,    14,     3,     8,    70,     7,    82,    17, 30259,\n",
      "             9,  2502, 16739,    16, 30260,    12,   324,     2,  4900,     6,\n",
      "          4528,   539,     9,     4,  5607,  1428,   359,     5,     4,  1099,\n",
      "         24386,     6,     9,     4,  5607,  4729,     5, 15174,   521,     2,\n",
      "             6,   107,   178,  1480,    10,  7297,   120,  1311,     3,     0],\n",
      "        [   41,   444,     2,    71,   123,     5,     4,   436,   602,     5,\n",
      "           873, 15176,   997,    17,   147, 34905,   335,  2094,    22,  6706,\n",
      "             9,   340,  5886,   202,     2,  3805,    10,   623,    38,    33,\n",
      "           192,     9,  2857,     8, 10664,    11,    14,     3,    70,    13,\n",
      "         10665,    11,    14,     3,    63,     7,     3,     0,     0,     0],\n",
      "        [   41,   253,     2,     4,  2724,   469,     5,     4,   535,   608,\n",
      "            45,    18,    15,  2100,  5551,  2173,     8, 38436,    11,    14,\n",
      "             2,   118,     7,     6,     4,   186,     5,     4,   117,     5,\n",
      "          3430,  8930,     8, 21993,    11,    14,     2,    61,     7,   835,\n",
      "           317,    37,   805,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1484,     2,    43,    30,   338,    92,    17,  8206,     5,  2546,\n",
      "          3250,  9109,     8, 11695,     7,    19,  2546,  3250, 20243,     8,\n",
      "          6404,     7,    52,     9,   598,     5, 10087,  2889,  4148,     2,\n",
      "            32,  1424,   357,     5,  7659,   712,     6,  1518,     5,     4,\n",
      "          6404,  1364,    15,  4595,  1658,     8,   341,     7,     3,     0],\n",
      "        [ 6975,    28,     4,   234,   958,     2,  3930,    21,   129,    20,\n",
      "             2, 17088,    21,   169,    20,     2, 17087,    21, 11599,    20,\n",
      "             2,  9790,    21,   128,    20,     2,  8976,    21,    90,    20,\n",
      "             2, 13940,    21,   240,    20,     2,     6,  3391,  8679,    21,\n",
      "           224,    20,     3,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['158d278c6ea8bed1b0ecb102474104883857dedf', '0388ab26736d8c5cbb4ae7a309699bb1c5ca780a', '38c0e9d5dfb9e05ea81b311e2b44e1762f18d122', '193a77e90f974047803a464170692e9ad80fe394', '683c12293b08763e025116a43656b7c7a45517f8', '80160aee8cdcbc26e6b65dd28fd07246c349140c', '405e2a5d3bb5c430c4d0cbd020d8bebe8c1364ba', '7f421b51cc6b9eb34d483d1490551022265b88c9', '745ed8b94bf76fb4c915306512ecb5abc76900dd', '87d654250036db47c8e28310f4da8f9e1ea80870', '87dd9024cfc0f47841436e27789400f2e99c6c8f', 'c8847eac969aa25c150cebffe64901b6ce95d913', '7cda88815f9e7424090048076e27807c9dc013bb', 'f9c7faa2ee912434236928bc5c925e1e751fc99a', '937444dc1ba977382b4c92eb9eab8518401fe154', '247529f16eeda88cc76d19c49d38c633c8f17288'], 'cited_paper_id': ['a978585942c78dcd00f1ece19b7ed244b4a76978', '72671f894477b6f275504d3e8187845ca363fe4d', '1e1f26aee409b2a156936534cc875861dc5ddcfe', '1e87d2c0dd149ad01efecf2d43f41ab4b6c47762', '609c724521bd2791df36cc133b8bddab1381a3e6', '9b191008e5ce88ef5fb79694fa7fb8d7ab10170b', '855f0edac470b58ab2dc7ecb8e873c970f273a23', '7a2cde124990f039d6e95cf543e2977ba9090343', '43afb2f226d2f5d4bf72c5975a58234ec96074c3', '08fb9a962f64c7e978f201464640e3eb5c161bae', '35dd0c622b42a60b73d62acc69057165b7804d67', '97dd64362e69cbf1842ad144bd2c3a3b24ac2de7', '3f93c7d5e18c1ebf108f3daac65e0701811667d7', 'dd86c88e7e03a067d7055a965f5888c40baa7d32', '156fb7b12ac3780dc3135685202f9ca520b99d21', '41088dd73ae7ad8baac9323c5dcbf6cb12be2a9d'], 'citation_excerpt_index': [2, 6, 1, 3, 0, 13, 5, 0, 5, 0, 9, 2, 3, 0, 0, 3], 'citation_id': ['158d278c6ea8bed1b0ecb102474104883857dedf>a978585942c78dcd00f1ece19b7ed244b4a76978', '0388ab26736d8c5cbb4ae7a309699bb1c5ca780a>72671f894477b6f275504d3e8187845ca363fe4d', '38c0e9d5dfb9e05ea81b311e2b44e1762f18d122>1e1f26aee409b2a156936534cc875861dc5ddcfe', '193a77e90f974047803a464170692e9ad80fe394>1e87d2c0dd149ad01efecf2d43f41ab4b6c47762', '683c12293b08763e025116a43656b7c7a45517f8>609c724521bd2791df36cc133b8bddab1381a3e6', '80160aee8cdcbc26e6b65dd28fd07246c349140c>9b191008e5ce88ef5fb79694fa7fb8d7ab10170b', '405e2a5d3bb5c430c4d0cbd020d8bebe8c1364ba>855f0edac470b58ab2dc7ecb8e873c970f273a23', '7f421b51cc6b9eb34d483d1490551022265b88c9>7a2cde124990f039d6e95cf543e2977ba9090343', '745ed8b94bf76fb4c915306512ecb5abc76900dd>43afb2f226d2f5d4bf72c5975a58234ec96074c3', '87d654250036db47c8e28310f4da8f9e1ea80870>08fb9a962f64c7e978f201464640e3eb5c161bae', '87dd9024cfc0f47841436e27789400f2e99c6c8f>35dd0c622b42a60b73d62acc69057165b7804d67', 'c8847eac969aa25c150cebffe64901b6ce95d913>97dd64362e69cbf1842ad144bd2c3a3b24ac2de7', '7cda88815f9e7424090048076e27807c9dc013bb>3f93c7d5e18c1ebf108f3daac65e0701811667d7', 'f9c7faa2ee912434236928bc5c925e1e751fc99a>dd86c88e7e03a067d7055a965f5888c40baa7d32', '937444dc1ba977382b4c92eb9eab8518401fe154>156fb7b12ac3780dc3135685202f9ca520b99d21', '247529f16eeda88cc76d19c49d38c633c8f17288>41088dd73ae7ad8baac9323c5dcbf6cb12be2a9d']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 101,  ..., 261, 261, 261],\n",
      "         [259, 118, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 117,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  55,  57,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  88, 105,  ..., 261, 261, 261],\n",
      "         [259, 104, 115,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  52,  54,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  83,  67,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  72, 109,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 105, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  50,  53,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[35063,   638,     6,  4596,   648,    53,    16,   657,    10,    30,\n",
      "          1170,   900,   975,     8,  6170,     2,  3428,     7,     3,     0,\n",
      "             0],\n",
      "        [  153,    16,    15,   321,  1741,    18,  4273,  1701,  3803,    28,\n",
      "           981,  1359,   491,     6,  8956,    21,  1144,     2,  4674,    20,\n",
      "             3],\n",
      "        [  743,  1413,     9,    15, 22237,    12,  3141,  1094,     2,  1432,\n",
      "           249,     6,   328,   249,    37,   387,   492,    21,   718,    20,\n",
      "             3],\n",
      "        [ 2114,     2,  8729,  4989,    28,  6612, 25104,  1804,  2737,     5,\n",
      "          7039,    12,   371,     7,   436,  4380,    10,     4, 24864,   386,\n",
      "             3],\n",
      "        [16493,    12,   398, 10427,   941,   139,   836,     5,    65,  9736,\n",
      "            69,    16,   615,     5, 16494,     8,   169,     7,     3,     0,\n",
      "             0],\n",
      "        [   21,   297,    20,   411,    15,   117,     5,  1680,    17,   403,\n",
      "           857,    18,     4, 15411,    58,    65,    81,    49,     3,     0,\n",
      "             0],\n",
      "        [ 6781,  2322,   362, 38210,   115,     5,   147,  1530, 19003, 33487,\n",
      "             2, 14580,     6, 19696,     8, 11886,     7,     3,     0,     0,\n",
      "             0],\n",
      "        [37171,  1296,   836,    37,   663,    48,    15,  1399,  5543,   197,\n",
      "          1558,    80,  1558,  1840,    21,   128,    20,     3,     0,     0,\n",
      "             0],\n",
      "        [   26,   458,     5, 19912,  1356,   283,    31,   805,   385,    10,\n",
      "             4,   327,  1663,    21,   236,     2,   300,     2,   254,    20,\n",
      "             3],\n",
      "        [  152,     2,     4,  1832,  1098,     5,   265,  4528,  5781, 10867,\n",
      "         21903,    21,  3915,     6,  1532,     2,    97,    20,  4997,   642,\n",
      "             0],\n",
      "        [ 5576,     5,  5384,   598,     6,   328,  3289,    37,   281,    23,\n",
      "           391,   116,    22,   122,   100,     8,   143,     2,   718,     7,\n",
      "             3],\n",
      "        [  276,   876,     9,  4892,   613,     5, 37527,    21,    72,    20,\n",
      "             2,   715,    19,     4,   114,  1077,     5,  1989,     0,     0,\n",
      "             0],\n",
      "        [   26,   478,  1050,     5,     4,    95,    31,   930,    23,    48,\n",
      "             4, 12002,   656,     5,     4, 42735,    21,   300,    20,     3,\n",
      "             0],\n",
      "        [16004,  1278,    77,    29,   157,  1499,   719,    12,   436,  4417,\n",
      "            17,  1068,  1793,    19,   719,    21, 31641,    20,     3,     0,\n",
      "             0],\n",
      "        [24615,     5,   161, 16048,    16,    34,   556,   171,  4125,    18,\n",
      "          4231,   165,     8,   722,    11,    14,     3,     2,    85,     7,\n",
      "             3],\n",
      "        [   21,   254,    20,  1127, 19123,  2233,     9,   245,    10,  1772,\n",
      "          2450,   119,    28,  8994,   159,   181,   591,     3,     0,     0,\n",
      "             0]], device='cuda:0')}, 'labels': tensor([0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['34d919880d3958aa73039d78d9aba6c74e5e5558', 'd4b7f8a099242e9dacb82217fab44b20e3fd25e1', '3876999a3a978c0ac2258622cfe61c4c683a3c35', 'ae24b1e782ed19ac1bd75f08a24e8fa1006e3611', 'c72decaa562b4d0f3ba3ebbe8e8aa68b52664706', '27ea0aa5f8d3e1dc7c449aceef59524dd32307b5', '0021ea82506c8ad38b459cf2fbd42fc42b062fd7', '991fbde8cbf415150a08b5acfe8d04ba0e1198fa', 'd0d4ed450c35138f692970635b1fbc3c21dcf22e', '599de37e6628fd9e2f42eff08de73e85fc9e3e10', '0cb2300be5b25870c2c7e44a395676a2d9b227aa', 'e27b08948c2ddb6c8050e1a572fc649188f29161', '276d5784f1ae36f8183b0ff086559bc325c5b983', '613ee7e328f2a3b8330d4ba32513f4de26bcdb61', '87711ffc684b0f1d1ad6c22518b78105d68fc5f3', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5'], 'cited_paper_id': ['2f356b52714f0f6a8824aea8996d13cc2140a1dc', '14020f728d2f0dbc23a59138d7d6d6b1d893bf70', '8e691d94b2658984b00cc041b66017c42a4ce703', '710d6808750b71906eb6abc0fe42921313697d7e', '464aeede29bcafb2ef221755a921c319b8259a1e', '21cc7a2a24c33fe78ab21acf5ea2d548fa11b0d3', '11a5f833bef73720e1c85253578a92a99cbdf35e', '4a25bf73afc311870a5b2271da6024c5e8f5bb6c', '78547401a39f1fc034a4e87debd44bfeb318306a', 'd55c95cedf9904a2776b682518c24b4d4d96bec7', '44ab4d2c768fde6c283d6006b7799130f44e10f4', '1d11d4044541b739356c65aaa87caa457c37a2b5', '92148ca64ddcbe22383b78cb39002071f12f3fc7', 'dfbcc4fa1c97f2e92cb677be36647b675d8c5005', 'a3a859fa3fbb1fae7a1d7ac563a7efe37273a2f8', '4448616a83a88c54e1ffddf0390716630f9a4b70'], 'citation_excerpt_index': [0, 0, 1, 4, 0, 7, 7, 1, 0, 13, 1, 2, 4, 1, 1, 7], 'citation_id': ['34d919880d3958aa73039d78d9aba6c74e5e5558>2f356b52714f0f6a8824aea8996d13cc2140a1dc', 'd4b7f8a099242e9dacb82217fab44b20e3fd25e1>14020f728d2f0dbc23a59138d7d6d6b1d893bf70', '3876999a3a978c0ac2258622cfe61c4c683a3c35>8e691d94b2658984b00cc041b66017c42a4ce703', 'ae24b1e782ed19ac1bd75f08a24e8fa1006e3611>710d6808750b71906eb6abc0fe42921313697d7e', 'c72decaa562b4d0f3ba3ebbe8e8aa68b52664706>464aeede29bcafb2ef221755a921c319b8259a1e', '27ea0aa5f8d3e1dc7c449aceef59524dd32307b5>21cc7a2a24c33fe78ab21acf5ea2d548fa11b0d3', '0021ea82506c8ad38b459cf2fbd42fc42b062fd7>11a5f833bef73720e1c85253578a92a99cbdf35e', '991fbde8cbf415150a08b5acfe8d04ba0e1198fa>4a25bf73afc311870a5b2271da6024c5e8f5bb6c', 'd0d4ed450c35138f692970635b1fbc3c21dcf22e>78547401a39f1fc034a4e87debd44bfeb318306a', '599de37e6628fd9e2f42eff08de73e85fc9e3e10>d55c95cedf9904a2776b682518c24b4d4d96bec7', '0cb2300be5b25870c2c7e44a395676a2d9b227aa>44ab4d2c768fde6c283d6006b7799130f44e10f4', 'e27b08948c2ddb6c8050e1a572fc649188f29161>1d11d4044541b739356c65aaa87caa457c37a2b5', '276d5784f1ae36f8183b0ff086559bc325c5b983>92148ca64ddcbe22383b78cb39002071f12f3fc7', '613ee7e328f2a3b8330d4ba32513f4de26bcdb61>dfbcc4fa1c97f2e92cb677be36647b675d8c5005', '87711ffc684b0f1d1ad6c22518b78105d68fc5f3>a3a859fa3fbb1fae7a1d7ac563a7efe37273a2f8', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5>4448616a83a88c54e1ffddf0390716630f9a4b70']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 104, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 104, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  83, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259, 119, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   88, 23882,    29, 15716,  2392,  1217,    48,     4,   608,  7650,\n",
      "            23,     4,  1503,  3168,     5,  8715,     6, 11957,  3195,     6,\n",
      "          6012,     6,  1217,     6,  4306,  3195,  3655,     8, 16016,    12,\n",
      "         16017,     7,     2,     6,     4,  4046,     6,  3765,  3001,     5,\n",
      "          3005,  3195,     8,  3433,    12,  1951,     7,    21,    90,     2,\n",
      "           221,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [   35,     4,   328,     5,    42,   106, 19586,     2,    69,    46,\n",
      "             5,   959,  3526,    10,     4, 25545,     6, 15565, 12312,     2,\n",
      "           201,  4084, 26861,   959,     8,   556, 15566,     7,     8,  5648,\n",
      "            11,    14,     3,     2,    78,     7,     2,    32,    16,   228,\n",
      "            19,     4,   411,    52,    25,     4,  2321,  2687, 13593,     6,\n",
      "         19587,  4782,     3,     0,     0,     0,     0,     0],\n",
      "        [  144,    52,     2,   139,    10,   138,   267,    23, 18989,    11,\n",
      "            14,    21,   297,    20,     9,   120,  1367,     6,    23, 18990,\n",
      "            21,   277,    20,     9, 32885, 18991,    88, 14903,   178,   515,\n",
      "             2,  1338,   243,    10,     4,   458,     5,    15,   420,   186,\n",
      "             9, 13116,  9584,     2,    99,     9,     4, 18992,     6, 18993,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  144,   856,    24,     9,  8428,    19,     4,   188,     5, 35938,\n",
      "             6,  7750,    17,     4,   365,    12,  5252,   357,   414,     5,\n",
      "           161,   781,    12, 10378,     2,   425,  5254,   565,     2,    16,\n",
      "          2738, 11617,     5,     4,  1530,    15,    12, 22181,    29,   256,\n",
      "            12,  5517,   334,  1307,     5, 16159,   356,     8,  3394,    11,\n",
      "            14,     3,    85,     7,     3,     0,     0,     0],\n",
      "        [   26,  1470,   450,  2339,     5,     4,   607,   862,  2692,    10,\n",
      "           923,  7408, 20257,    31, 11943,  3370,     6, 16000,  3370,     9,\n",
      "             4,  2168, 21891,     6,     4, 21892,  6241,     8,    15,  1632,\n",
      "           164,   226,     7,     2,   463,     8, 17368,    11,    14,     3,\n",
      "             2,   404,    13, 35159,    11,    14,     3,     2,   255,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   35,   965,   557,     9,   451,     9,  1322,  2011,   166,  5509,\n",
      "            42,   288,   584,    10,   204,    60,  4949,   196,  1811,     8,\n",
      "            50,    22,  2059,    29,  6082,  4094,   708,     8,  7743,     7,\n",
      "          2319,     7,     6,    27,   537,  2207,    23,     4,   101,  2785,\n",
      "          1811,     8,    50,    22,  1322,  5503,     7,     9,    60,   489,\n",
      "             8,  6869,    11,    14,     3,    85,     7,     3],\n",
      "        [ 5690,   479,    17,   403,  2246,     4,  2210,     5, 43006,    37,\n",
      "             4,  5929,  3005,  3009,  5576,     8,  4873,     7,    21,   222,\n",
      "            20,     2, 17329,  3185,  4897,     8, 12536,     7,    21,   295,\n",
      "            20,     2,  2247,  1780, 13559,     5, 10481, 12505,     8, 10439,\n",
      "             7,     6,    15,   258,   875,    25,   266,   366,  1569,    37,\n",
      "          2244,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  595,     5,     4,   848,    24,  1307,  1654, 14978,  3290,     8,\n",
      "           170,    21, 11229,     6, 42743,     2,   274,    13, 42744,     2,\n",
      "           113,    20,     7,  1851,    10,    15,   478,  1671,  7376,     2,\n",
      "           201,   320,  2686,    28,     4,   248,     5,   478,   874,  3202,\n",
      "             2,    50,    22,   304, 42745,    21, 13727,    11,    14,     3,\n",
      "             2,   142,    20,     2,  3923,    80, 25918,    35],\n",
      "        [16356,     6,  1211,   360,   115,    30,    33,  7650,    18,  3783,\n",
      "           638,   162,     8, 12533,     6,  7128,     2,   209,     7,     2,\n",
      "          2403,   563,     8, 19751,     2,    11,    14,     3,     2,   113,\n",
      "             7,     2,  4351, 13125,   162,     8, 21092,     2, 19729,     2,\n",
      "             6, 20327,     2,    79,     7,     2,     6,  3715,   162,     8,\n",
      "          5230,     6,  2812,     2,    87,     7,     3,     0],\n",
      "        [   41,    39,  1771,     2, 12359,    16,   797,   213,    10,  2664,\n",
      "             9,     4,  1901,     5, 11396,    29,  9578,  2235,  7754,     8,\n",
      "          9012,    11,    14,     3,    78,    13,  8134,    11,    14,     3,\n",
      "            78,    13,  8803,    11,    14,     3,    78,    13,  9013,    11,\n",
      "            14,     3,    78,     7,     2,    32,    16,    46,    15,   213,\n",
      "          9239,   174,     8,  9014,    11,    14,     3,     0],\n",
      "        [ 2114,     2,    50,  4407,    58,     4,   163,   465,     9,     4,\n",
      "           577,   618,     6,  6034,     6, 22689,    30,    33,   100,   534,\n",
      "            44,    99,     4,  1372,     6,     4,   180, 28718,     2,  1026,\n",
      "             2,  1455,    12,  1575,     7,     2,  1261,    17,     4,   247,\n",
      "            19,    71,   625,    12,   246,  1973,   497,    66,  2499,    27,\n",
      "           799,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [   41,  3064,     2,  7895,  5157,  3149,   601,   658,  1553,   658,\n",
      "          9834,   831,   867,   658,   614,   506,    19,     6,  1845,  5443,\n",
      "            44,     4,  9978,   562,     2,     6,    39,   318,  2014,  5443,\n",
      "          1753,    25,     4,  1876,   905,     5,    91,     9,     4,  8839,\n",
      "          4156,     8,  6816,    11,    14,     3,     2,    87,    13, 12438,\n",
      "            11,    14,     3,     2,    87,     7,     3,     0],\n",
      "        [   26,   903, 25860,  1733, 25861,     5,   161, 25862, 17905,    44,\n",
      "             4,   365,    12,  1587,   431,     5,     4,   180,     8, 11037,\n",
      "            47, 25863,     7,     6,    40,    27, 13437,    10,    34,  1052,\n",
      "          1733, 25864,     2,    32,  5426,    10,     4,   456,   660, 13945,\n",
      "           436,  1733,     8, 17410,     2,   146,   424,  2334,    10,    15,\n",
      "          1542,  4164,  4125,     7,     8,   237,     7,     3],\n",
      "        [ 1158,     2,     4, 17869,   431,     9, 13947, 13689,  1068,  1618,\n",
      "            23,  9113,   226,     6,    15,   207,   414,    55,    67, 27357,\n",
      "             9, 13091,    12, 17009,  1618,    23,  3293,    37,    82,    22,\n",
      "           207, 26002,     8,  2824,    11,    14,     3,     2,    83,    13,\n",
      "          5262,    11,    14,     3,     2,   118,    13, 26003,    11,    14,\n",
      "             3,     2,   118,     7,     3,     0,     0,     0],\n",
      "        [   64, 24555, 20298,    17,   203,    12,  1244,  2009,   192,   234,\n",
      "           773,    10,  1610,  9006,  2347,  2246,   999,    12,   437,   177,\n",
      "             8, 37537,    11,    14,     3,     2,    76,     7,    29,    17,\n",
      "             9,  1082, 21865,   408,     5,  9006,    24,  5558,    80,  4961,\n",
      "             9,   947,     8, 27011,    11,    14,     3,     2,    61,    13,\n",
      "          1089,    11,    14,     3,     2,  3186,     7,     3],\n",
      "        [   26,  2117, 35178,     5,  5488,   412,    24,    45,    22,   993,\n",
      "          1482,     5,   397,     8, 16429,    11,    14,     3,     2,    85,\n",
      "             7,    29,   283,   225,     8, 20330,    11,    14,     3,     2,\n",
      "            68,    13, 20331,    11,    14,     3,     2,    63,    13,  2900,\n",
      "            11,    14,     3,     2,    78,    13, 13981,    11,    14,     3,\n",
      "             2,  3336,     7,     3,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['f308573f2763a4fccddef893ec91c88892bf2708', 'e62943d2604289b023d3eacc849a891deca5ea07', 'f48888eb870eba77917d34efc79bbcedd4bbb411', '44c34a13dbd1223a9404f0f7ac5c76a1201845d0', '9be0e24285648aad163bbe1dfcb53c4dd1ec0f53', '52d3a25781a4ce2ff4f7ccd85a3bee74ce8ebc95', 'c367b29adb7d41c562294e3c92faaab4f9f7b7ce', '1d427e5c9b21bcdb2d00e078acf3ae83663fb2cf', '731f4b9498ec9276c76f8bf1e3c32a50eb9394ab', 'f36300a29107655359ffb8ed2db04c93dada24aa', 'a18e8f6d3eba1ec6e7a8984e8a06a75ea29f4e38', '4e76d6b98473d7af7d7c946cd9b4e2d110de5606', '23ab707d609c1b26ae64bbd3f5921073d1561f8d', 'c0bd57273408d61d0802b8d5ec231c6fa59736e2', 'a175a89a08d6c5d085609827e8eacc569a4b68fe', '2fdcd0a26a7749af1d135ac11851cbdb8b29e283'], 'cited_paper_id': ['e8150991705098368d2f201399bc737a80939792', '5dc70077e004e2e004db261138123b4aad3acccf', '6990deef767a4ae50034232f0901d59d9e79770f', 'd06d52afb3dad8c98d36413dd4f8a50a9bdae8f8', 'b7d923a0fc554db58339f3e255e50eb2d8f83136', 'ef9fe70c411e47e908a55d34b8a223d8cca1179e', '282240d6f18d1e4654209ed25e307789c5655483', 'c1bb81ae5300595c2727b78628caa734911c6a6a', 'a4cf4bb41fb0b6fa978fd1456e86308218c8e882', 'aac9fb0178847fc4e17a1acdd5d9662ff53b9c94', 'fbfd4bb0564aac755ef30ae7e42d50d463568076', '9d57eaed154045f05a5d6543d72db7db873ab390', 'bf67c223bad17925756a915a501ab598848c39af', 'd6277359d5f4a7fdca105c27d0e5896eaa6de5f8', 'caface509d1745abcd0d545e39303cf3e8feef02', 'bce1ad08961b82b080dbebec9a7d39e5dac26277'], 'citation_excerpt_index': [5, 0, 0, 0, 1, 2, 0, 1, 2, 8, 0, 8, 0, 1, 1, 0], 'citation_id': ['f308573f2763a4fccddef893ec91c88892bf2708>e8150991705098368d2f201399bc737a80939792', 'e62943d2604289b023d3eacc849a891deca5ea07>5dc70077e004e2e004db261138123b4aad3acccf', 'f48888eb870eba77917d34efc79bbcedd4bbb411>6990deef767a4ae50034232f0901d59d9e79770f', '44c34a13dbd1223a9404f0f7ac5c76a1201845d0>d06d52afb3dad8c98d36413dd4f8a50a9bdae8f8', '9be0e24285648aad163bbe1dfcb53c4dd1ec0f53>b7d923a0fc554db58339f3e255e50eb2d8f83136', '52d3a25781a4ce2ff4f7ccd85a3bee74ce8ebc95>ef9fe70c411e47e908a55d34b8a223d8cca1179e', 'c367b29adb7d41c562294e3c92faaab4f9f7b7ce>282240d6f18d1e4654209ed25e307789c5655483', '1d427e5c9b21bcdb2d00e078acf3ae83663fb2cf>c1bb81ae5300595c2727b78628caa734911c6a6a', '731f4b9498ec9276c76f8bf1e3c32a50eb9394ab>a4cf4bb41fb0b6fa978fd1456e86308218c8e882', 'f36300a29107655359ffb8ed2db04c93dada24aa>aac9fb0178847fc4e17a1acdd5d9662ff53b9c94', 'a18e8f6d3eba1ec6e7a8984e8a06a75ea29f4e38>fbfd4bb0564aac755ef30ae7e42d50d463568076', '4e76d6b98473d7af7d7c946cd9b4e2d110de5606>9d57eaed154045f05a5d6543d72db7db873ab390', '23ab707d609c1b26ae64bbd3f5921073d1561f8d>bf67c223bad17925756a915a501ab598848c39af', 'c0bd57273408d61d0802b8d5ec231c6fa59736e2>d6277359d5f4a7fdca105c27d0e5896eaa6de5f8', 'a175a89a08d6c5d085609827e8eacc569a4b68fe>caface509d1745abcd0d545e39303cf3e8feef02', '2fdcd0a26a7749af1d135ac11851cbdb8b29e283>bce1ad08961b82b080dbebec9a7d39e5dac26277']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69, 118,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         [259, 106, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  67, 118,  ..., 261, 261, 261],\n",
      "         [259, 116, 120,  ..., 261, 261, 261],\n",
      "         [259, 103, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         [259, 112, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 116, 118,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   64,  1151,    38,   250,  1189,    33,   449,     9,     4,   402,\n",
      "             5,  2908,   822,     8, 12325,    11,    14,     3,    63,     7,\n",
      "             3,     0],\n",
      "        [ 2989,    10,   107, 16386,   318,     2, 15227,    21,   297,    20,\n",
      "             6,   107,  2196, 21817,    74,  2841,  2959,     9,    60,   293,\n",
      "             3,     0],\n",
      "        [17495, 12610,    28, 29165, 31194,    37,   967,    48, 31195,   358,\n",
      "         17495, 31196,     8,  3312, 26046, 15010,  2100,     7,     3,     0,\n",
      "             0,     0],\n",
      "        [12376,  2671,    44,     4,    84,     5,     4,  8620,  1090,    31,\n",
      "           741,    48,    15,  1399,   730,   450,  1656,    21,   240,    20,\n",
      "             3,     0],\n",
      "        [25049,     2,  3027,     9,   102,    49,     8, 25050,     2, 25051,\n",
      "         25052,     6, 25053,     7,     8,   388,     2,   341,     7,     3,\n",
      "             0,     0],\n",
      "        [ 1391,  1065,     6, 16186,   451,  1902,    74,  2317,   591,    10,\n",
      "           972,   919,   119,     6,  6314,    21,    57,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [   26, 10537,  2137,    38,    33,    45,     9,   157,  3958, 20949,\n",
      "           303,    21,   399,    12, 37590,    12,  1172,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [ 2493,     2,    81,    49,    21,    90,     2,  1834,    20,    82,\n",
      "          2016,   608,    18,  2388,   111,     4,  1166,   398,     3,     0,\n",
      "             0,     0],\n",
      "        [   41,   245,    10,  2931,    71,   137,   875,     2,    43,   923,\n",
      "             4,   293,  1830,   137,   133,    22,   100,    23,    21,   236,\n",
      "            20,     3],\n",
      "        [18312,   126,    38,    33,   806,    25,  2332,     4,   251,     5,\n",
      "          8800,   507,     9,     4,  2613,  3938,    21,  8604,    20,     3,\n",
      "             0,     0],\n",
      "        [ 1212,    15,  4875, 15562,    34,   206, 23386,  5732,    10,  2675,\n",
      "           920,     9,     4, 11910,  4657,     8,    90,     2,   129,     7,\n",
      "             3,     0],\n",
      "        [   64,  2984,   229,    10,   424,  3358,    38,    33,   192,     9,\n",
      "           157,   400,     8, 16740,     6,   320,    97,    13, 11500,    70,\n",
      "             7,     3],\n",
      "        [  205,    15,   188,     2,    15,  3155,   656,     5,     4,  1940,\n",
      "            12, 28699,  2356,    38,   122,    33,   503,    21,   143,    20,\n",
      "             3,     0],\n",
      "        [    4,  6561,   245,    28,     4, 21113,   245,     5,     4, 14287,\n",
      "          7035,    10,     4, 14000,  1922,    21, 16837,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [ 3615,  4929,    37,  2324, 30854,    25,    81,  1369,  3517,   159,\n",
      "         30855, 30856,    22,   122,   100,    21,   221,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [  378,    17,   145,    31,  1189,   296,     5,     4,  1853,     5,\n",
      "          2283,    10,  6075,     5,  8339,    21,   143,    20,     3,     0,\n",
      "             0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['25ca9559936e465774c15aec38a69a4319395da0', '427bb5862e0959be8928e90589e13fec56c74d71', '052ba5c156a5dc85b8959dc72bd3c70bd71d4d6e', 'a205a088e89034e9d213830de6abfceaf05b84b1', '2c437cb33335a8e6be80be83fe01a6a3ba64543d', '550079470c3509c24d4d41516b8225d1ea3366a1', '3cba0c4066b04692c6d497abe7e00d20729a9ab7', '649da5dc00caf98ed897ade21a16e625ec328d6c', 'b3f8bff925079758e96717a6aa82a5028dbd2dbf', 'c5c49f3d189e63ff31305cff7973fc1cb113a065', '01ed92ffedcf6beb1a83e731ac3360da9ac33a85', '2ab057d0cdf27726b44454e4a35184a46bb1215a', '5bffcb5b344ea2dcfd901cf8949d4ceec1535a90', 'aa04588c952331955dbc6b3719624666717e4e4f', '8b03b8d6774c6c45a4d5ca87ceabbc73e03e4acd', '4d9170a8daa2f40530580a24e8490f569eaf15d7'], 'cited_paper_id': ['1eb080cc5edcfe7f0e0dff1977768ca52e9050ff', '3e2e7f25cea8ff585c4a64a0ddbfaba480de939e', '0ba3ade60e2f63abedbe37d3b5a86bd78d56338b', '2190afa622a3e0a8d398e6fabbd80a0333e8854c', '8c65d72e1785ecce3271e0c703a32b380be81933', 'dc029e23eed2ea6220d8e1f75dac4f9a741a50e0', '2c74b84a46e6937604dce33da228be23b8896c34', '13addfbdfeb738a413365e3df0904a39416aa7ba', 'dec3d3c7bc9b14fbd95061a7e7aee927772f668b', 'c60bd24a1c685c8211e339314ed7b3e7579bbec9', '4ed0c16faebec92455e87fcc2c11ed7bddbc7e95', '95d818f089f256ffdfabbcb1157a3701ab1bd15e', 'bc615cb89f626012e6fa6a14b8bbb26270020502', 'ce6bcdb1076b32ce7663a74675c9eb2417848210', '55fb4d2a1453344786c07481d0d309137a362ab6', 'd6eaf36357406cc26c09d36fc88d8974ba49807d'], 'citation_excerpt_index': [2, 2, 0, 0, 4, 1, 3, 9, 0, 3, 2, 4, 0, 1, 0, 5], 'citation_id': ['25ca9559936e465774c15aec38a69a4319395da0>1eb080cc5edcfe7f0e0dff1977768ca52e9050ff', '427bb5862e0959be8928e90589e13fec56c74d71>3e2e7f25cea8ff585c4a64a0ddbfaba480de939e', '052ba5c156a5dc85b8959dc72bd3c70bd71d4d6e>0ba3ade60e2f63abedbe37d3b5a86bd78d56338b', 'a205a088e89034e9d213830de6abfceaf05b84b1>2190afa622a3e0a8d398e6fabbd80a0333e8854c', '2c437cb33335a8e6be80be83fe01a6a3ba64543d>8c65d72e1785ecce3271e0c703a32b380be81933', '550079470c3509c24d4d41516b8225d1ea3366a1>dc029e23eed2ea6220d8e1f75dac4f9a741a50e0', '3cba0c4066b04692c6d497abe7e00d20729a9ab7>2c74b84a46e6937604dce33da228be23b8896c34', '649da5dc00caf98ed897ade21a16e625ec328d6c>13addfbdfeb738a413365e3df0904a39416aa7ba', 'b3f8bff925079758e96717a6aa82a5028dbd2dbf>dec3d3c7bc9b14fbd95061a7e7aee927772f668b', 'c5c49f3d189e63ff31305cff7973fc1cb113a065>c60bd24a1c685c8211e339314ed7b3e7579bbec9', '01ed92ffedcf6beb1a83e731ac3360da9ac33a85>4ed0c16faebec92455e87fcc2c11ed7bddbc7e95', '2ab057d0cdf27726b44454e4a35184a46bb1215a>95d818f089f256ffdfabbcb1157a3701ab1bd15e', '5bffcb5b344ea2dcfd901cf8949d4ceec1535a90>bc615cb89f626012e6fa6a14b8bbb26270020502', 'aa04588c952331955dbc6b3719624666717e4e4f>ce6bcdb1076b32ce7663a74675c9eb2417848210', '8b03b8d6774c6c45a4d5ca87ceabbc73e03e4acd>55fb4d2a1453344786c07481d0d309137a362ab6', '4d9170a8daa2f40530580a24e8490f569eaf15d7>d6eaf36357406cc26c09d36fc88d8974ba49807d']}\n",
      "{'citation_text': {'elmo': tensor([[[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 103,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         [259, 109, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  78, 102,  ..., 261, 261, 261],\n",
      "         [259, 116, 122,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  78,  70,  ..., 261, 261, 261],\n",
      "         [259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 120, 106,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   35,    77,  6302,  ...,     0,     0,     0],\n",
      "        [22912,   233,   285,  ...,     0,     0,     0],\n",
      "        [ 2062,     2,     4,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [13985,  1076,    31,  ...,     0,     0,     0],\n",
      "        [16857,    88,   426,  ...,     0,     0,     0],\n",
      "        [   35,   189,     6,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 2, 2, 1, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['f36300a29107655359ffb8ed2db04c93dada24aa', '3450c7e9a6d8688ac76fb5f31ceed0270c88d868', 'ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b', 'ad362e39973fa81d94c9a5c425d8755dbdbbc26d', 'e06c8966e57806d20fc9329f16636b2fac2469b8', 'c23d94bd9455491f1928cf74ddb27ace74661d3e', '94cd3445ba69b80253de533a76c4de8ed7bc19c3', '7ef9fe09f54e94ad0fb021f98c587d5f4204da6d', '2523459f40dfd5742e1cc09fa636871625effab0', '27717c955391418fdfd741398938409a32848c93', 'd08acfbe2c697707ac5b07a87218886e34f13428', '44c34a13dbd1223a9404f0f7ac5c76a1201845d0', '8f02c1345e439fc7f6afc787d780053543b016b1', 'f2bc9d4fc0cdbc8cbe17176eb94beda4d945149c', 'aa0cd097835bebe8f8e4012d477ca6562c8ce5bf', '5b209ece1926825e98b03a18f3d75346c0d04c8a'], 'cited_paper_id': ['aac9fb0178847fc4e17a1acdd5d9662ff53b9c94', '3e7af4307ffa0dc06a4dc1f07d95c9f8c29ec472', 'b6642e19efb8db5623b3cc4eef1c5822a6151107', '29ca14af54ab6f6fa8d9a34cb733a811ec6c339e', 'e4675af68d613dc95ae1c192ed154307a0d3d7be', 'f25a3f10162ca191500a2bf7e2d5cce257b4f7c1', 'be6342fa3a4a7ffedf2cbab1b7ea4f75ed80f8f0', 'None', '43cb535e7727e2e07741c81b2c7afe80605b8142', 'f2d1e364a067e08a35265de3c56c9dd5e8595d18', 'f88ebd60707729a608ad985c1050cc1f2d851087', 'd06d52afb3dad8c98d36413dd4f8a50a9bdae8f8', '80d06391c1e0cec51257b89d31b656ad268cc2e5', 'e68dbb485a87733e9b4cfab82309f17558158614', '93a65104595647fecdfe2f92555005614629a415', 'a775da481dbe6a255e8c280d963fa3c51cc1997e'], 'citation_excerpt_index': [10, 0, 3, 0, 6, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'citation_id': ['f36300a29107655359ffb8ed2db04c93dada24aa>aac9fb0178847fc4e17a1acdd5d9662ff53b9c94', '3450c7e9a6d8688ac76fb5f31ceed0270c88d868>3e7af4307ffa0dc06a4dc1f07d95c9f8c29ec472', 'ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642e19efb8db5623b3cc4eef1c5822a6151107', 'ad362e39973fa81d94c9a5c425d8755dbdbbc26d>29ca14af54ab6f6fa8d9a34cb733a811ec6c339e', 'e06c8966e57806d20fc9329f16636b2fac2469b8>e4675af68d613dc95ae1c192ed154307a0d3d7be', 'c23d94bd9455491f1928cf74ddb27ace74661d3e>f25a3f10162ca191500a2bf7e2d5cce257b4f7c1', '94cd3445ba69b80253de533a76c4de8ed7bc19c3>be6342fa3a4a7ffedf2cbab1b7ea4f75ed80f8f0', '7ef9fe09f54e94ad0fb021f98c587d5f4204da6d>None', '2523459f40dfd5742e1cc09fa636871625effab0>43cb535e7727e2e07741c81b2c7afe80605b8142', '27717c955391418fdfd741398938409a32848c93>f2d1e364a067e08a35265de3c56c9dd5e8595d18', 'd08acfbe2c697707ac5b07a87218886e34f13428>f88ebd60707729a608ad985c1050cc1f2d851087', '44c34a13dbd1223a9404f0f7ac5c76a1201845d0>d06d52afb3dad8c98d36413dd4f8a50a9bdae8f8', '8f02c1345e439fc7f6afc787d780053543b016b1>80d06391c1e0cec51257b89d31b656ad268cc2e5', 'f2bc9d4fc0cdbc8cbe17176eb94beda4d945149c>e68dbb485a87733e9b4cfab82309f17558158614', 'aa0cd097835bebe8f8e4012d477ca6562c8ce5bf>93a65104595647fecdfe2f92555005614629a415', '5b209ece1926825e98b03a18f3d75346c0d04c8a>a775da481dbe6a255e8c280d963fa3c51cc1997e']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 115,  98,  ..., 261, 261, 261],\n",
      "         [259, 102,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 102,  98,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  52, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259, 101, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  53,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]], device='cuda:0'), 'tokens': tensor([[   93, 10305,   108,  1539,   635,    18, 16323,  1231,     5,  1814,\n",
      "          1033,  9605,  4263,     2,    48,  6999,     8,  7184,    36, 10302,\n",
      "             2,   190,     7,    10,  4942,     4,   127,   461,    44,   108,\n",
      "           652,     3],\n",
      "        [    2,    68,     7,     2,     6, 42305,   386,     8, 42306,    11,\n",
      "            14,     3,     2,    87,     7,    37,  4026,   111,     4,  1217,\n",
      "           671, 42307,    10,   336,     4,  5483,    12,  2498,     3,     0,\n",
      "             0,     0],\n",
      "        [   41,    21,    90,     2,   129,     2,   128,    20,     2,     4,\n",
      "           419,   141,  8445,    81,    12,   156,   409, 11815,     2,    32,\n",
      "          2951,     4,   999,    12,  5316,   409,  3150,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [  690,     4,    55,   480,     2,   145,    37,   410,   774,    17,\n",
      "         14843,   249,     6,  3192,   318,   389,    42,  1339,    58,   451,\n",
      "            19,   114,     6,   493,  2426,    21,  1966,     2,  2420,    20,\n",
      "             3,     0],\n",
      "        [ 1395,    10, 33457,    11,    14,     3,     8,   104,     7,     2,\n",
      "             4, 31275, 26091,  1278, 23808,     2,     6,    60,  1610,  1812,\n",
      "            16,   386,     6,  4063,   282,     9, 33458,  5150,     3,     0,\n",
      "             0,     0],\n",
      "        [37464,    24,   588,   703,    18,   948,  2454,   183,   158,  1927,\n",
      "             2,     6,   110,    30,  4006,    10,    27,   284,    56,   653,\n",
      "             9,   956,   366,    21,   494,    20,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [ 1238,  2644,     8,  3686,    11,    14,     3,     2,   198,    13,\n",
      "         11920,    11,    14,     3,     2,   198,    13,  2592,    11,    14,\n",
      "             3,     2,    97,    13,  3667,     6,   724,     2,    68,     7,\n",
      "             3,     0],\n",
      "        [  626,  1447,    59,    17, 10684, 18343,    16, 21832,    20,     2,\n",
      "            32,   520,    15,   270,   154,     5,  5091,   414,  1651,    50,\n",
      "            22,  4114,     2,  6305,     2,    29,  4677,  1703,     3,     0,\n",
      "             0,     0],\n",
      "        [26112,    11,    14,    21,  1898,    20,  3355,     4,   149,   235,\n",
      "             5,  2727,  1671,    17,  5113,     4, 15377,    12,   156,     6,\n",
      "          3952,  2464,     5,   409,     9, 27517,    80, 31311,     3,     0,\n",
      "             0,     0],\n",
      "        [   64,  1011,   116,    18,  1386,  6590,    58,   973,  3879,    21,\n",
      "           371,     2,  1172,     2,   659,    20,     2,   280,    48,  2260,\n",
      "             6,  1152,  1046,    28,   759,  1148,   415,     6,   395,  3470,\n",
      "             3,     0],\n",
      "        [ 8922,     6, 35229,    21,   277,    20,   259,    17, 35230,    24,\n",
      "            56,  2437,    10, 35231,   231,    19,     4,   320,  1100,   959,\n",
      "             8, 12160,  7676,     2, 22737,     2, 35232,     6, 30756,     7,\n",
      "             3,     0],\n",
      "        [  311,   124,   364,    42,   306,  2674,   836,    69,   106,   580,\n",
      "           163,    22,   868,    45,     9,    55, 37763,   244,     8, 37764,\n",
      "            11,    14,     3,    75,    13, 15180,    11,    14,     3,    83,\n",
      "             7,     3],\n",
      "        [12656,    49,    37,   930,    48,   608,    54,    25,     4,  1806,\n",
      "          3868,  3719,  4899,  1663,     2,    32,   512,   296,    12,    54,\n",
      "          2482,    25,     4,   817,     5, 17445,  1038,     8,   277,     7,\n",
      "             3,     0],\n",
      "        [  144,    52,    24,     9,   685,    19,    15,   102,   439,  2457,\n",
      "             4,  2138,   186,     5,  9658,    25, 34789,  3257,     9, 34790,\n",
      "             6, 15907,    91,    21,  1575,    20,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  112,   400,    17,  1978,  1670,  3569,     2,    43,  1349,  1033,\n",
      "         12375,   106,    10,  1684,     5, 37580,  2216,     8, 19002,    23,\n",
      "           711,  3439,    90,     7,    10,  6336,   210,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [   26,  1060,  1248,   798,     9,    39,    62,    31,    54,    25,\n",
      "           102,   126,     9,    32,     4,   716,     5,  1060,   435,    10,\n",
      "           970,    15,   241,   507,    31,   663,    21,   371,     2,   346,\n",
      "            20,     3]], device='cuda:0')}, 'labels': tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['419c4685d6109c63789a269f5996946ea04623e5', '0435f121f1278cfd4ef6f8a6db9f44fb56ec2a27', '1101d5e8b3bac5243ccd4251c3f60b59e35ade37', '342eef5853d8b590cffdedaba1e8bb3e93f19fe9', 'cf0222c3c38f5e51db26f01960dcc722e3d9cf70', 'ba9e7e93cd5746895ff9e954ada06b95a8aadec7', '0012d808e76e1cd0e5ddeea10824a0811942a7e5', '210e3d0418b1cc4f6ecf8fcfcf0f754cb65c1305', '65cf6a69def40e663be79b7c489afc04eea20cfa', '61c87ab40835f7439b7f775efa19798b4f124e1d', '8c71b7582c3c72a4c72549e63e8628505c5991bd', 'f3d6dd3105bfcd5670a4d234733c23a32b14dcb9', '130899900efc0bd179fe26209bafc9a21c6eee3b', '160917cab1571403e9ee370771d132bcf5616086', '28c2b083a6c294a05ff5edffa0ccf2b927049108', '298168bc61b6c07aaa8a1b49f9740bd8d17f9e2f'], 'cited_paper_id': ['272216c1f097706721096669d85b2843c23fa77d', '59e6206c40706cb4cb7ef654ec4051904e96a225', 'a0372f7f85607ad16681f4e506c195645c5863ee', '19128eb417bd9f7140dc56476227c9f911100f05', '76c5e21606688d04a69c5af0423cadd2086a3dd0', 'a7acb7ecec638b5fcf1e90bb6b43656b8973512f', '53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', '4721ad0db596f3f78ddb31b4305ddbde35f8f181', '40f7030000e3c31501030cbb1ddd9bd1657bd64f', 'b34ed4e673a44d41168bb7168c314b0cf027e8e9', '361f87657edf646471ea5f1cdcd32a23fa5cecce', '77a79a78aebc70de03efe555f01fe77cbbab575a', 'fc83da674f258c89f7ea7a4c543a7386f61ee3bd', 'e447841fdca3f12401b970d3e43b7b8dd99b9ee3', '4a861d29f36d2e4f03477c5df2730c579d8394d3', '04a729067b4776573460cb47f2e5553b2d9e5cad'], 'citation_excerpt_index': [1, 0, 3, 10, 0, 1, 5, 0, 1, 0, 1, 2, 0, 1, 7, 0], 'citation_id': ['419c4685d6109c63789a269f5996946ea04623e5>272216c1f097706721096669d85b2843c23fa77d', '0435f121f1278cfd4ef6f8a6db9f44fb56ec2a27>59e6206c40706cb4cb7ef654ec4051904e96a225', '1101d5e8b3bac5243ccd4251c3f60b59e35ade37>a0372f7f85607ad16681f4e506c195645c5863ee', '342eef5853d8b590cffdedaba1e8bb3e93f19fe9>19128eb417bd9f7140dc56476227c9f911100f05', 'cf0222c3c38f5e51db26f01960dcc722e3d9cf70>76c5e21606688d04a69c5af0423cadd2086a3dd0', 'ba9e7e93cd5746895ff9e954ada06b95a8aadec7>a7acb7ecec638b5fcf1e90bb6b43656b8973512f', '0012d808e76e1cd0e5ddeea10824a0811942a7e5>53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', '210e3d0418b1cc4f6ecf8fcfcf0f754cb65c1305>4721ad0db596f3f78ddb31b4305ddbde35f8f181', '65cf6a69def40e663be79b7c489afc04eea20cfa>40f7030000e3c31501030cbb1ddd9bd1657bd64f', '61c87ab40835f7439b7f775efa19798b4f124e1d>b34ed4e673a44d41168bb7168c314b0cf027e8e9', '8c71b7582c3c72a4c72549e63e8628505c5991bd>361f87657edf646471ea5f1cdcd32a23fa5cecce', 'f3d6dd3105bfcd5670a4d234733c23a32b14dcb9>77a79a78aebc70de03efe555f01fe77cbbab575a', '130899900efc0bd179fe26209bafc9a21c6eee3b>fc83da674f258c89f7ea7a4c543a7386f61ee3bd', '160917cab1571403e9ee370771d132bcf5616086>e447841fdca3f12401b970d3e43b7b8dd99b9ee3', '28c2b083a6c294a05ff5edffa0ccf2b927049108>4a861d29f36d2e4f03477c5df2730c579d8394d3', '298168bc61b6c07aaa8a1b49f9740bd8d17f9e2f>04a729067b4776573460cb47f2e5553b2d9e5cad']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 103, 112,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 105,  ..., 261, 261, 261],\n",
      "         [259,  74,  77,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 100, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  52,  52,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  70, 116,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 112, 119,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  83,  79,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  50,  52,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 260,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261]]], device='cuda:0'), 'tokens': tensor([[   85,     7,     6, 18421,     8, 17381,    11,    14,     3,     2,\n",
      "            68,     7,    37,  1119,    10, 27100, 10710,    10,  1099,   836,\n",
      "             5,   221,     6,   526,  2537,     2,   463,    18,     0,     0],\n",
      "        [  743,  4406,    16,  4114,   136,    15,   114,    12,  1248,  1762,\n",
      "             2,  7169,  2652,    16, 15267,     2,     6,    39,    66,  2792,\n",
      "          1126,   202,     5,  1682,     8,  2013,     7,     3,     0,     0],\n",
      "        [ 1401,     2,   327,   348,    25, 16054,     6,  2687,  1510,     5,\n",
      "             4, 25787,    40,    27,    92,     9,  1662,   683,    21,   240,\n",
      "             2,   143,     2,   277,     2,   726,     2,   662,    20,     3],\n",
      "        [  651,     2,    51,    38,    33,   378,    17,  7247,  3346,    10,\n",
      "            34, 14359,  5077,   727,   401,    51,  1410, 33425,    19,     4,\n",
      "          5077,  2474,    21,   222,    20,     3,     0,     0,     0,     0],\n",
      "        [  205,    82,     9,    15,   102,    62,     8,   277,     7,     2,\n",
      "         17276,    12,   324,  3630,  1753,     5, 35659,     6, 17997,   356,\n",
      "          1398,    15,   312,  1540,     5, 16750,  1432,     3,     0,     0],\n",
      "        [  217,  1075, 10795,  1318,    58,    81, 11304,     5,     4, 28379,\n",
      "           706,     2, 17694, 30211,  2125,    21,   494,    20,    31,    45,\n",
      "           166, 44904,  5920,     5,    60,   594, 28379, 44905,     3,     0],\n",
      "        [30988,  1221,    15, 15650,   229,     9, 16091,     2,  2884,     2,\n",
      "             6,  1740,   772,     2,    19,    34,   594,   242,     6,  1126,\n",
      "           689,     9,    65,   634,     8,   533,     7,     3,     0,     0],\n",
      "        [31063,     7,   144,    52,    24,   228,    19,     4,    82,   349,\n",
      "             9,  6249,   263,    58,  7536,     6, 16497, 31064,     2,  1761,\n",
      "         31065,   758,  7536,   318,     3,     0,     0,     0,     0,     0],\n",
      "        [   21,   300,    20,    30,  1127,    15,   195,    53,   154,     5,\n",
      "          7528,   302,     2,  7405,  1069,    15,   319,     5,   332,  3333,\n",
      "            67,    17,    45,    23,   327,  2395,  7528,   360,   162,     3],\n",
      "        [  112,   108,  6330,     2,  7131,    31,    84,    12,  2146,    23,\n",
      "          4273,   143,  9303, 18857,  7131,   914,    48,     4, 21712,  8478,\n",
      "         30253,    21,   630,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [33409,   347,    38,    33,   105,    10,    27,  4510,     9,  1082,\n",
      "            23,   180,  1239,    88,     8, 11801,     7,     2,    32,  1918,\n",
      "           107,   436,    10,  9534,     8,   662,     7,     3,     0,     0],\n",
      "        [   26,  2584,   596,   192,    58,  2426,     6, 15203,    67,    58,\n",
      "          2426,     6, 13916,    16,   228,    19,   157,   102,  1906,     8,\n",
      "           191,     2,   341,     2,   767,     7,     3,     0,     0,     0],\n",
      "        [ 1074, 27722,   115,     2,    15,  1422,   117,     5,   559,     9,\n",
      "          1072,   229,  1273,    24,  1122,    18,  2994,   969,     5,  1780,\n",
      "           372,    21,   297,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [10805,     5,   735,  1289,   988,     8,   580,   196,     7,    31,\n",
      "          1044,   276,    48,     4,   840,   668,  9310,    59,   385,    10,\n",
      "         37288,     6,  9679,    21,   224,    20,     3,     0,     0,     0],\n",
      "        [  719,  1619,    24,  1944,   921,     6,  1433,  7244,    23, 25526,\n",
      "             8, 25527,     7,    29,  6542,    23,  2001,   358,   136,     4,\n",
      "          2117,   204,     8,  5255,    11,    14,     3,    70,     7,     3],\n",
      "        [   21,   300,    20,    22,     4,   523,  3895,  7010,   564,   686,\n",
      "            58,    96,   540,    44,    84,   904,     2,    16,   777,   465,\n",
      "            19,     4,   391,  2836,     5, 40150,     2,   904,     7,    22]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 2, 1, 1, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['e41d5d32f0ead268ee2855bfe946378479de5ee7', '998b2e755456700a4fc07c6dd1f32d243899d09f', '3c123df5aa9263271fbaf80df545510f6cf53840', '03026676cf30464b9c5f8e24e5d6d4348d46a994', '48e79e8f23479612755a96293b7081ea56a53302', 'ab37f4f828b5a24c39a89b115c03aaf0747a41d4', '771ef8a1c5bfb2d855f0998445020617c6183bb7', '032cda3876f80eaff146d59a15c3ac86050a4d24', '3ea1f4960d78101aeae7fc604862ba478e3d11b9', '47e2773f8a41702265670651494f22673d8db916', 'f92ee4af334b6218ccc8dcc45bcc96af59c190a6', '8a1dcd51cabbd95bf7212a42a8fc5bae5d6b65e1', 'd9d24925878ff7cdd70ad2fcd8de5241b486f19d', 'fc96bfb0e3dc0395d0b17eee7a533eba887d5619', '941df9dcd2d4ba6e6f641527e667a4bca4a9d23e', 'ca4d2aef7421153f0f2c93db54a3e06a4942d329'], 'cited_paper_id': ['cfa24b743a2660054b8f52eb2b4c452da756a4cb', 'c5162ef5c68848eba50818b64f7a783f1cde4c73', 'c6780aa6016c36e219213cdfbff55b1a25407d69', '903aae8adc61e5b2cbdd349b6527f693b5cd5d99', 'f27cba44904ab9d2611cb57d76f95b8f3541f850', '7e7343a5608fff1c68c5259db0c77b9193f1546d', '41432c23f85cf50ad87761e5be965788eeb579a2', 'ea0372b4c4f44085dec5f7f637a1c0900c7b20a9', '85c158797e0819f8f33c9832e3c1e392c2071415', '453480b67a15cac4ec47b52c3a2eea241c18db64', 'aa3d7a72f3ad9fd00cb9b8e683968489cff824cd', '668c6321b924dc59c2fccf8328f4dde13906ebe1', '2bdc4f0a4956b2aed861682d2be180f0601e52ef', '2098391def9f8db6d400497b9ba397d526d227c3', '7449ebce258d5d0ac3e875a2fc20b7407d862f63', 'a0ecd52bfe814e4941617cb23ba53b88a15397c7'], 'citation_excerpt_index': [2, 13, 1, 4, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0], 'citation_id': ['e41d5d32f0ead268ee2855bfe946378479de5ee7>cfa24b743a2660054b8f52eb2b4c452da756a4cb', '998b2e755456700a4fc07c6dd1f32d243899d09f>c5162ef5c68848eba50818b64f7a783f1cde4c73', '3c123df5aa9263271fbaf80df545510f6cf53840>c6780aa6016c36e219213cdfbff55b1a25407d69', '03026676cf30464b9c5f8e24e5d6d4348d46a994>903aae8adc61e5b2cbdd349b6527f693b5cd5d99', '48e79e8f23479612755a96293b7081ea56a53302>f27cba44904ab9d2611cb57d76f95b8f3541f850', 'ab37f4f828b5a24c39a89b115c03aaf0747a41d4>7e7343a5608fff1c68c5259db0c77b9193f1546d', '771ef8a1c5bfb2d855f0998445020617c6183bb7>41432c23f85cf50ad87761e5be965788eeb579a2', '032cda3876f80eaff146d59a15c3ac86050a4d24>ea0372b4c4f44085dec5f7f637a1c0900c7b20a9', '3ea1f4960d78101aeae7fc604862ba478e3d11b9>85c158797e0819f8f33c9832e3c1e392c2071415', '47e2773f8a41702265670651494f22673d8db916>453480b67a15cac4ec47b52c3a2eea241c18db64', 'f92ee4af334b6218ccc8dcc45bcc96af59c190a6>aa3d7a72f3ad9fd00cb9b8e683968489cff824cd', '8a1dcd51cabbd95bf7212a42a8fc5bae5d6b65e1>668c6321b924dc59c2fccf8328f4dde13906ebe1', 'd9d24925878ff7cdd70ad2fcd8de5241b486f19d>2bdc4f0a4956b2aed861682d2be180f0601e52ef', 'fc96bfb0e3dc0395d0b17eee7a533eba887d5619>2098391def9f8db6d400497b9ba397d526d227c3', '941df9dcd2d4ba6e6f641527e667a4bca4a9d23e>7449ebce258d5d0ac3e875a2fc20b7407d862f63', 'ca4d2aef7421153f0f2c93db54a3e06a4942d329>a0ecd52bfe814e4941617cb23ba53b88a15397c7']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  71, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 112, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 105,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116,  98,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  544,     2,    71,  ...,     0,     0,     0],\n",
      "        [   35, 32464,  1550,  ...,     0,     0,     0],\n",
      "        [14618,     9,     4,  ...,     7,     3,     0],\n",
      "        ...,\n",
      "        [   35,     5,   203,  ...,     0,     0,     0],\n",
      "        [  743,     4,  6242,  ...,     7,     3,     0],\n",
      "        [   26,   167,   188,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['fc1675c2bc19201d392ced5b8f6bc08609788127', '63ce508d942d89bcf695e782b5d4ee85ade5c4e1', '7b0ca6f15e76f285cc19efd2305cb1ec9e16a5b5', '67fd3bb71d0f1a06e61fa0ba6615b0397867fbc3', '96d59f09d602d930beddbc2785972d443efa4d93', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9', 'be4898031f576267bbd1acbf1cf3c8544cfc4ebb', 'afd7858d7e7054b1bfde5d06700a01fb29bbf5a4', '909a77c8e11159e14baacdf51aae17a3f9a07a81', '1653bfbacad13034901d6d634955ca940e2e8fe6', '684872304caa8ff076c9b6a01e3baf2bedb9d3fe', 'c719e655d241e3b629bce0c54278e7a4f39bfa59', '114de63c96176358b8cd3c99aa744c86f0eeced7', 'faed1a633204b8a669a44574338d395a767b16bf', 'd7e5a6661d9642c1835a7901f75c3c4ea072a14a', '2a94aee454f2a8bb6f550c2ce3e2ffd5a5dfbc9e'], 'cited_paper_id': ['586ce8fd008f721acbff72985feee4d52e9f2e1a', 'fc7bd558af7699381c4f41f2eb7d5326368d386a', 'df90f3e882609d15c298251608a5b48b69efb3b8', '85b04d25eac459fab2870ae995d01b09a6d65e1e', '723a4b4f3019cd5a5f8546925d8cf4478a0d03b7', '6d6bb93872a190de290f259e63587db4f17d539c', '1329bcac5ebd0b08ce33ae1af384bd3e7a0deaca', '9b17573ecb732d5b6f42b113ae7241af2a296d50', '261cc9d7335b9d13c4f910ec459296b24311be89', '72c9d0887ad90ec21a7f395811a8079c0bbaf08b', '92cc6d034017530cfcd5934b2e3f1b72d542e61b', '45476edd84e29e94bb19169c733c0e9280db39a1', '7ffdab1930ccf68c10be4cf9a9ffdb933c9dd516', '20aaeabedd9dc0a949850860e904d128405234f8', 'ecf8309cafc950bdad7ea6bc15b1404038547000', '540ed559042c385d8242cc695e0256017169372e'], 'citation_excerpt_index': [0, 6, 6, 2, 2, 2, 0, 1, 1, 2, 1, 2, 3, 1, 1, 0], 'citation_id': ['fc1675c2bc19201d392ced5b8f6bc08609788127>586ce8fd008f721acbff72985feee4d52e9f2e1a', '63ce508d942d89bcf695e782b5d4ee85ade5c4e1>fc7bd558af7699381c4f41f2eb7d5326368d386a', '7b0ca6f15e76f285cc19efd2305cb1ec9e16a5b5>df90f3e882609d15c298251608a5b48b69efb3b8', '67fd3bb71d0f1a06e61fa0ba6615b0397867fbc3>85b04d25eac459fab2870ae995d01b09a6d65e1e', '96d59f09d602d930beddbc2785972d443efa4d93>723a4b4f3019cd5a5f8546925d8cf4478a0d03b7', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9>6d6bb93872a190de290f259e63587db4f17d539c', 'be4898031f576267bbd1acbf1cf3c8544cfc4ebb>1329bcac5ebd0b08ce33ae1af384bd3e7a0deaca', 'afd7858d7e7054b1bfde5d06700a01fb29bbf5a4>9b17573ecb732d5b6f42b113ae7241af2a296d50', '909a77c8e11159e14baacdf51aae17a3f9a07a81>261cc9d7335b9d13c4f910ec459296b24311be89', '1653bfbacad13034901d6d634955ca940e2e8fe6>72c9d0887ad90ec21a7f395811a8079c0bbaf08b', '684872304caa8ff076c9b6a01e3baf2bedb9d3fe>92cc6d034017530cfcd5934b2e3f1b72d542e61b', 'c719e655d241e3b629bce0c54278e7a4f39bfa59>45476edd84e29e94bb19169c733c0e9280db39a1', '114de63c96176358b8cd3c99aa744c86f0eeced7>7ffdab1930ccf68c10be4cf9a9ffdb933c9dd516', 'faed1a633204b8a669a44574338d395a767b16bf>20aaeabedd9dc0a949850860e904d128405234f8', 'd7e5a6661d9642c1835a7901f75c3c4ea072a14a>ecf8309cafc950bdad7ea6bc15b1404038547000', '2a94aee454f2a8bb6f550c2ce3e2ffd5a5dfbc9e>540ed559042c385d8242cc695e0256017169372e']}\n",
      "{'citation_text': {'elmo': tensor([[[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  98, 104,  ..., 261, 261, 261],\n",
      "         [259, 103, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 119, 106,  ..., 261, 261, 261],\n",
      "         [259,  87,  81,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  81,  68,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  80, 118,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 100, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  70, 115,  ..., 261, 261, 261],\n",
      "         [259,  69, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   35,  3230,    28,  ...,     0,     0,     0],\n",
      "        [    8,    68,     7,  ...,     0,     0,     0],\n",
      "        [   26,  2397, 29615,  ...,   858,  2348,     3],\n",
      "        ...,\n",
      "        [  311,    52,  1764,  ...,     0,     0,     0],\n",
      "        [   26,  4419,  7961,  ...,     0,     0,     0],\n",
      "        [    8,    68,     7,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['76bfc9cfbb407b0becb778ddd462a3d5db552664', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab', 'c518ce547cdcdb57f06d67ade815243272408cb5', 'b676c63e9243d92a617f148f96c7b7c4048b8e28', '01f0261418e97b071c33201e37834bd5172bae74', '1ed8042c32b484573035db874ee8db00b77ba326', 'ab6665d32ada3143ffe4985e4d918ec7abfa8a52', 'c518ce547cdcdb57f06d67ade815243272408cb5', 'a88406dcf4f6b9f3fc35978467181d8714f830ef', 'c46611a37f40dccbd5b7f96400be5d5f7e0d6e08', '3cac4eec3bc8b8164edbfa5566b777de4d2f0b0c', '77cc5c7417526334a60494acd658dcbf377cae1d', 'a97e549fc058efda4e870c53ab6ca98d695ea323', '1edc7af9eaa7fe9da79f0605652cfd4443a0cad4', 'f20cf27f1c49917aff7ea08f7715f28e37e067b0', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab'], 'cited_paper_id': ['855bda9eabd7af1f0ca0784e0566ab4435e837e7', 'c14be2a7007e022da13889d804a540d0c0c34264', '9ad6f8b75198186955f4263660549995905d265b', '56d3a0bf0463ad0b750f47166454a2132ecdb7ed', '795ee332ff1a3fd0c6b79b78eac459f929b067be', 'f08f08fab4db474ed6d556b908622d95afa2704f', '3081f5cf281cc86470f0ac36c73de029cbc4ea35', '9ad6f8b75198186955f4263660549995905d265b', 'ee9120c7beace20b23a14e334ee1e76c1cdef7d0', '28dcad7d012c227066072ffe91e2628bfa0f41d8', '408686bd6eeb47494610e876257f9d7f5578355e', 'ced7e3c1f9c912dca5751664c86a7587b58b0854', '881a93939ebb854b95f1e75cd83b4ce80c2e4034', '34be3ccc2ba9343126638a5df3f7dea6e42fe9a4', '91695bee521ee44b2c08a87d9693953afc26583f', 'c14be2a7007e022da13889d804a540d0c0c34264'], 'citation_excerpt_index': [0, 12, 0, 0, 1, 8, 4, 0, 0, 1, 0, 7, 0, 0, 1, 12], 'citation_id': ['76bfc9cfbb407b0becb778ddd462a3d5db552664>855bda9eabd7af1f0ca0784e0566ab4435e837e7', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab>c14be2a7007e022da13889d804a540d0c0c34264', 'c518ce547cdcdb57f06d67ade815243272408cb5>9ad6f8b75198186955f4263660549995905d265b', 'b676c63e9243d92a617f148f96c7b7c4048b8e28>56d3a0bf0463ad0b750f47166454a2132ecdb7ed', '01f0261418e97b071c33201e37834bd5172bae74>795ee332ff1a3fd0c6b79b78eac459f929b067be', '1ed8042c32b484573035db874ee8db00b77ba326>f08f08fab4db474ed6d556b908622d95afa2704f', 'ab6665d32ada3143ffe4985e4d918ec7abfa8a52>3081f5cf281cc86470f0ac36c73de029cbc4ea35', 'c518ce547cdcdb57f06d67ade815243272408cb5>9ad6f8b75198186955f4263660549995905d265b', 'a88406dcf4f6b9f3fc35978467181d8714f830ef>ee9120c7beace20b23a14e334ee1e76c1cdef7d0', 'c46611a37f40dccbd5b7f96400be5d5f7e0d6e08>28dcad7d012c227066072ffe91e2628bfa0f41d8', '3cac4eec3bc8b8164edbfa5566b777de4d2f0b0c>408686bd6eeb47494610e876257f9d7f5578355e', '77cc5c7417526334a60494acd658dcbf377cae1d>ced7e3c1f9c912dca5751664c86a7587b58b0854', 'a97e549fc058efda4e870c53ab6ca98d695ea323>881a93939ebb854b95f1e75cd83b4ce80c2e4034', '1edc7af9eaa7fe9da79f0605652cfd4443a0cad4>34be3ccc2ba9343126638a5df3f7dea6e42fe9a4', 'f20cf27f1c49917aff7ea08f7715f28e37e067b0>91695bee521ee44b2c08a87d9693953afc26583f', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab>c14be2a7007e022da13889d804a540d0c0c34264']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101,  98,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 113,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 105, 122,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  53,  49,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 106, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 110,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 102, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 110,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  144,    53,    24,     9,   685,    19,   410,     5,   298, 30333,\n",
      "             9,  4655,  7241,    32,    30,   106,    33,    82,    28, 30334,\n",
      "             2, 28455,     2,     6, 24425,    12,  5450,   885,     6,    42,\n",
      "            28,  6337,     2, 26851,     2,  2353, 30335,     2, 20195,     2,\n",
      "            29,  2602, 21761,     3,     0,     0,     0],\n",
      "        [ 2423,     2,  3044,     5,    15,   727,     5,     4,   386,   423,\n",
      "             9, 45378,  2283,  1135,     9,     4,   996,     5,     4, 45379,\n",
      "            21,   371,     2,  1026,     2,  8304,    20,     6, 16178,   564,\n",
      "            80, 45380,    21,   371,     2,  1026,     2,  8304,    20,   246,\n",
      "          1845,     2,   463,     3,     0,     0,     0],\n",
      "        [ 1184,  7179,     2,  7494,    23,  1416,     5,     4, 16519,  4167,\n",
      "            98,     8,     6,  9256,   762,     9,  3975,     7,   324,    23,\n",
      "          7179,    21,   494,    20,    29,    23,   628,  2960,     5,     4,\n",
      "         13193,  8644,    23,     4,  6135,  1147,    29,  3685,  5970,    21,\n",
      "            90,     2,   300,     2,   659,    20,     3],\n",
      "        [   21,   873,    20,    88,   612,  5662,     5,  4984, 22663,  4020,\n",
      "         24538,    31,  2392,   121,   145,    31,    15,  1041,     5,    15,\n",
      "         19680,  5662,     5,   441, 20277,    29,   441,   374,   150,    19,\n",
      "          1402,   670,     6,   121,    39,  1145,    31,  1133,    23,   919,\n",
      "          2811,   603,     6,  1102,  3039,     3,     0],\n",
      "        [  544,     2,     4,  2612,  1088,     6,   837,   333,     8, 17893,\n",
      "             7,     8, 16114,     6, 12210,     2,   428,     7,     6,     4,\n",
      "         16516,  1508,   333,    18,   332,     5,   517,     8,  7963,     7,\n",
      "             8, 23736,     7,     8, 22079,    11,    14,     3,     2,    85,\n",
      "             7,    37,    45,     3,     0,     0,     0],\n",
      "        [   41,    21,   236,    20,     2,    43,   192,    17,   201,     4,\n",
      "            71,  1961,    12,    54,   704,   360,   162,  3018,   103,     9,\n",
      "          7187,   704,     2,     4,    98,    38,  1612,  9367,  4127,     8,\n",
      "          2133,  7230,  4234,     7,     9,     4,   458,     5,   949,     6,\n",
      "           280,  1970,  1078,   360,  2454,     3,     0],\n",
      "        [13709,     8,  1453, 19788,     7,    38,   213,  1620,     9,  3380,\n",
      "          5780,   424,     6,  5111,   424,   506,   120,  1518,     8, 13710,\n",
      "            11,    14,     3,     2,    75,    13,  8492,    11,    14,     3,\n",
      "             2,    75,    13,  4855,    11,    14,     3,     2,    75,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0],\n",
      "        [  323,    15,  1331,    12,   931,    28,  9659,    10,  7966,    31,\n",
      "            42,  2735,   470,     9,     4,    59,     2,    51,    31,   872,\n",
      "            17,    50,    15,   931,   185,  1300,    10,     4,   275,    12,\n",
      "          4727, 12308,  3605,     8,  4957,     6,  4338,     2,  2189,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 3454,   243,    18, 33344,    94,   693,  3122,    28, 15695,     6,\n",
      "          6369,    49,     5,  9734,   352,     5,  9879,  1415,  2504,     8,\n",
      "          3692,    11,    14,     3,     2,   113,    13, 12620,    11,    14,\n",
      "             3,     2,   113,    13,  9494,     2,    85,    13,  9494,    11,\n",
      "            14,     3,     2,    85,     7,     3,     0],\n",
      "        [40284, 42720, 13440,  1812,    16,   876,   663,    23,     4, 10015,\n",
      "            58,  2361,  3184,     2,  2363,     6,  7109,   640, 14032,     2,\n",
      "             6,   226,  2512,    21,  1389,  2075, 22024,    11,    14,     3,\n",
      "             2,    97,    13,  3218,     2,    70,    13, 16940,    11,    14,\n",
      "             3,     2,    68,    20,     3,     0,     0],\n",
      "        [    8,   316,     7,   238,    17,  4795, 13180,  1239,   527,    19,\n",
      "            15,  3049,   325,  2256,     2, 13181,    12, 13182,    21, 13183,\n",
      "             8, 13184,    12, 12909,     7,     2,    38,   975,    18,  2449,\n",
      "             6,  1063,  1901,     6,  4400,     9,   412,     8,  3271,    11,\n",
      "            14,     3,     2,   316,     7,     3,     0],\n",
      "        [   26,  1105,     5,   322,    12,   175,    31,  5694,    23,  7024,\n",
      "           483,    44,   840,    10,    77,     5,    81,  4833,   287,     8,\n",
      "           139,    10, 19838,    11,    14,     3,     2,   113,    13, 12010,\n",
      "            36, 10294,     2,    85,    13, 12010,    36, 24797,     2,    87,\n",
      "             7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26,  3784,   124,    48, 12407,  8118,    10,  8402,    12,  1294,\n",
      "            12,  4737,     6,     4,   299,    45,    10, 13698,    91,    10,\n",
      "         12344,  4587,   397,    19,     4,    74,     5,    15,  1086,    12,\n",
      "          3216,  4587,  5640,     6,   597,  2329,    30,    33,   100,  2150,\n",
      "             8,   222,     7,     3,     0,     0,     0],\n",
      "        [ 4106,     2,    51,    31,    82,    17, 18335,  2009,   655,     4,\n",
      "          1084,     5,   269,  3314,  5202,     2,     6,     4,   374,     5,\n",
      "            99, 18335,     6, 32690,    52,     9,     4,  5659,     5,  1934,\n",
      "          8609,    19,  1159,    12,  1950,  1753,     9,  2218, 21005,    21,\n",
      "          1335,     2,  1188,    20,     3,     0,     0],\n",
      "        [ 1862,   157,  2021,  8883,  1619,   213,    10,  2865, 29108,     2,\n",
      "             4,   519,  1002,    24,   614,    12, 29109,     8, 11497,     2,\n",
      "         18280,     7,     6, 18281,     8, 11498,     7,     2,    32,    24,\n",
      "           213,    10,  2786,  1560,  1029,  1943,     4,   380,     8, 13067,\n",
      "            11,    14,     3,     2,   118,     7,     3],\n",
      "        [ 4307,     2, 27710, 31572,    16,   150,    19,    34, 19724,   114,\n",
      "          1289,  1564,    58,   313,    73,     6,   526,    73,     8, 38485,\n",
      "            11,    14,     3,     2,    87,    13, 16792,    11,    14,     3,\n",
      "             2,    76,    13, 38486,    11,    14,     3,     2,    61,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['b114747c7e84e8b93080a352eec0835547ee75b1', '3a61d4416631f5cc6131386bfbf9eddce533840e', '543e668b29f98103913e2b9a64e884e84716b0aa', '748a11b2b3da91cae2bb26d58f70da846f56732c', 'ea79b4b35d650c0d1ef6444fb5a6b7a34602ad97', 'd9f525209f06a5909b0d69cfe7754bf956e5c0cf', '7ea35436e261fc4d48fdcada0a8eb9c1f8c1a93b', '24fe18db8ad1c3b1d77a73b1fea0f9a471434bf7', '2b81352a78236b3e447bb826bcb910d076d85a0a', 'df2c2410833b4a3542665c1e02a6b8c8177983fa', 'c0958dd33b8fe8b63400345d4ae70b316acfe654', '99111b0a8909838c144941ec856fcf618151ad90', 'c79f96fd63c55dcf18d735fed1fb3c88a3b41c2b', '79cef5a7f7458d5fbeaff4a78d2e5496fa03c913', '356aacdebcff251ae7600c2254c46b832e432c4e', '4cbde39dfc35a87f53d8e809cdece917b95a8b91'], 'cited_paper_id': ['aa6cb49e972a4646479bb375bc1b6ecbca332b6c', 'f2b6dc44b32f28ae8da517f92673303f057696ca', '94589a569d7a8a7c23a43dd7771290faa93fa8e1', '07d79e107d1c6899839d98e333b11d56f2713497', '5d09452414c03fcdf784a938f605e744705e8c2b', '2d57462aca8d06674df2b058e23b5c0e3129a472', '25aa4a143d373d371cc8fa3a2d550a0649d8c94c', '57220e5e1106b295bab12105c79f6307ab220e0f', 'f4de1186ffb4aeb811ce95d614d27b6991d26ac0', '3baedb337055da24603a0f2ff0ec4bdc2ad381cf', 'f22ae74ea1dd405108e55c996175e77ff0e575e4', '1c4151ed303b40a27ed6b99b151fadf7437cd041', 'db425871ab8ac182d5f3609e7115b445ef1c9336', '1faf1e62af3c1fe5fd843575ed4daba419177075', '0cf20d19e776395d67fb801cd325cbe4731dc144', 'ac6711823efec1eb57326e6f5767aab70c7066cd'], 'citation_excerpt_index': [0, 0, 1, 9, 2, 1, 6, 1, 0, 0, 0, 0, 0, 0, 0, 2], 'citation_id': ['b114747c7e84e8b93080a352eec0835547ee75b1>aa6cb49e972a4646479bb375bc1b6ecbca332b6c', '3a61d4416631f5cc6131386bfbf9eddce533840e>f2b6dc44b32f28ae8da517f92673303f057696ca', '543e668b29f98103913e2b9a64e884e84716b0aa>94589a569d7a8a7c23a43dd7771290faa93fa8e1', '748a11b2b3da91cae2bb26d58f70da846f56732c>07d79e107d1c6899839d98e333b11d56f2713497', 'ea79b4b35d650c0d1ef6444fb5a6b7a34602ad97>5d09452414c03fcdf784a938f605e744705e8c2b', 'd9f525209f06a5909b0d69cfe7754bf956e5c0cf>2d57462aca8d06674df2b058e23b5c0e3129a472', '7ea35436e261fc4d48fdcada0a8eb9c1f8c1a93b>25aa4a143d373d371cc8fa3a2d550a0649d8c94c', '24fe18db8ad1c3b1d77a73b1fea0f9a471434bf7>57220e5e1106b295bab12105c79f6307ab220e0f', '2b81352a78236b3e447bb826bcb910d076d85a0a>f4de1186ffb4aeb811ce95d614d27b6991d26ac0', 'df2c2410833b4a3542665c1e02a6b8c8177983fa>3baedb337055da24603a0f2ff0ec4bdc2ad381cf', 'c0958dd33b8fe8b63400345d4ae70b316acfe654>f22ae74ea1dd405108e55c996175e77ff0e575e4', '99111b0a8909838c144941ec856fcf618151ad90>1c4151ed303b40a27ed6b99b151fadf7437cd041', 'c79f96fd63c55dcf18d735fed1fb3c88a3b41c2b>db425871ab8ac182d5f3609e7115b445ef1c9336', '79cef5a7f7458d5fbeaff4a78d2e5496fa03c913>1faf1e62af3c1fe5fd843575ed4daba419177075', '356aacdebcff251ae7600c2254c46b832e432c4e>0cf20d19e776395d67fb801cd325cbe4731dc144', '4cbde39dfc35a87f53d8e809cdece917b95a8b91>ac6711823efec1eb57326e6f5767aab70c7066cd']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  69, 106,  ..., 261, 261, 261],\n",
      "         [259,  99, 102,  ..., 261, 261, 261],\n",
      "         [259, 100, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  55, 260,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 104, 102,  ..., 261, 261, 261],\n",
      "         [259, 102, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 102, 119,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[ 8307,    58,   992,     8,  3674,     7,     6, 10717,  3549,   185,\n",
      "            27,  2670,   171,     2,    22,   992,  3549,    16,    56,  1632,\n",
      "          1051,    19,   437,  3174,   951,     9,  2949,    21,   129,    20,\n",
      "            13,    16,  4900,  2207,    23, 22017,   720,   231,    19, 10717,\n",
      "          3549,    21,   128,    20,    13,     6,    66,    27,    15,  1735,\n",
      "          2581,     5,  2868,   879,    67, 10717,  3549,    21,   169,    20,\n",
      "             3],\n",
      "        [   26,  8042,     5,  4914,  5112,    31,  1133,    23,   948,     4,\n",
      "          1323,     5,   361, 22729,    29, 22730,    10,  1475,     4, 22731,\n",
      "           562,  6086,   324,    23, 21921,     8,  1144,  2537,     7,    29,\n",
      "            23,     4,  1538,  4914,  4221, 22732,    12, 22733,     8,    90,\n",
      "          2537,     7,     8,  4816,    11,    14,     3,     2,    63,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [   26,  6340,    59,    16,   103,  1136,   179,   139,  6340,   223,\n",
      "            24,  4301,     9,   455,  3501,    53,   529,    48,   744,    29,\n",
      "           787,   629,   727,   123,     8,  4660,     7,     8, 14953,    11,\n",
      "            14,     3,     2,    75,     7,     2,   266,   481,    59,     8,\n",
      "          8835,     7,     2,  2268,    12,    54,     8, 13428,    12, 16950,\n",
      "            11,    14,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [30425,  2526,    37,  1851,    28,     4, 12805,  5302, 15523,     8,\n",
      "         30426,     7,    21,    57,    20,     2,   201,  1658,  9973,     6,\n",
      "           298,  1663,    37,   967,    28,     4,  2603, 12805, 10092,  7252,\n",
      "             8, 30427,     7,    21,    72,    20,     2,     4,  5618, 12805,\n",
      "         11702,  2828,    21,    90,    20,    29,     4,  1443,  4812,     5,\n",
      "          6493,    21,   129,    20,     3,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 4878,     9,     4,   248,   765,    17,    15,   203,    12,  6647,\n",
      "           472,  1863,    25,  4356,  4781,     9,     4,  2617,     8, 12121,\n",
      "             6, 10662,     2,    79,    13, 32540,     6, 18895,     2,    87,\n",
      "             7,     2,    69,    39,  1352,  4182,     8,  6875,    11,    14,\n",
      "             3,     2,    61,    13, 13325,    11,    14,     3,     2,    70,\n",
      "            13,  7462,     6,  9957,     2,    70,     7,     3,     0,     0,\n",
      "             0],\n",
      "        [   35,    29,  3983,     8,  5579,    11,    14,     3,     2,    89,\n",
      "             7,     2,   425,  1444,  1156,    24,    56,   335,    10,  2755,\n",
      "             9,     4,  2988,   218,     5,   421,   165,     8,  1219,   988,\n",
      "           155, 18412,    13, 12134,    11,    14,     3,     2,    70,     7,\n",
      "             2,     6,     8,   256,     7,     4,  7457,  1621,   273,  1101,\n",
      "           121,  1973, 21096,   421,   165,    50,    22,   266,  4915,    35,\n",
      "             0],\n",
      "        [ 3432,   769,  1906,     6,   184,  1372,  5772,    49,    30,   238,\n",
      "            17,    65,  1326,   559,   680,    44,     4,  1729,   156,     9,\n",
      "          2072,     8, 23419,    12,  6704,    11,    14,     3,    61,    13,\n",
      "          1139,    11,    14,     3,    61,    13, 23420,    11,    14,     3,\n",
      "            79,     7,     6,  3485,   226,     2,    50,    22,  3293,     8,\n",
      "         23421,    12, 23422,    11,    14,     3,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  217,  1075,   529,  9717,   262,  6860,    46,  1061,   480,  1148,\n",
      "           175,     2,     4,   795, 22746,  2374,     5,     4,  6891,  1816,\n",
      "             9,     4,  2684,     5,     4,   126,   475,     2,    15,  1492,\n",
      "             6,   921,   926,     5,   480,  1148,    31,    46,   679,     8,\n",
      "         25776,    11,    14,     3,   274,    13, 37663,     6, 35251,   274,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 1277, 45237,   821,    15,    84,  7359,  1886,   123,     2,    48,\n",
      "           208,   850,  1448,   522,    28,  4770,    11,    14,     3,     8,\n",
      "            75,     7,     9,     4,   563, 20143, 13556,     8, 12298,     6,\n",
      "         20144,    68,     7,    47,     8,    57,     7,     4,  1550,    58,\n",
      "         11487, 20145,     6, 11487, 13293,    31,  2717,    19,    34,  3171,\n",
      "           612,    19, 45238,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [   26,  5047,   555,     5,   195,   232,   262,    25,  2642,     2,\n",
      "           588,   136,  3761,   287,     2,  1450,    52,    28,   492,  7318,\n",
      "          1154,    28, 16452,  2512,     8, 10508,     6,  5703,   142,    13,\n",
      "          5703,     6, 18444,  2892,     7,     2,    22,    92,     9,   157,\n",
      "            55, 20372,   998,     8,  1389, 20373,     6,  1389, 20374,   367,\n",
      "            13,  9614,   142,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [   35,   532,     5, 11402, 19260,  2787,    19,     4,   178,   163,\n",
      "            92,    18,     4, 20675,  3219,     9, 16587,  4386,     8,  5909,\n",
      "            11,    14,     3,   390,     7,     2,     9,   685,    19,     4,\n",
      "          1174,     5, 36214,    19,     4,   180, 17564,    28,     4, 20675,\n",
      "          2286,   342,     6,    60,  9224,   422,     8,  8700,    12,  7316,\n",
      "            11,    14,     3,    85,     7,     3,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  205,   897,    23, 14069,     8,   113,     7,     2,     4,   101,\n",
      "          1080, 17535,   680,     9,     4, 11611, 15747,     2,     6,     9,\n",
      "           109,  1264,     5,     4,   992,  4860,   146,   795,   349,     9,\n",
      "             4,  5790,   523,    40,    27,   183, 31445,  3695,  2839,  3626,\n",
      "             2,     4,   545,     5,  3907,    30,   109,  5869,   282,     9,\n",
      "           109,    91,   715,     4, 23878,    35,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [33023,     4,  2364,     6,   744,   119,    19,     4,    84,   727,\n",
      "           520,  1546,   119,    10,  1225,     4,   417,  1384,   715,     4,\n",
      "            84,    21, 33024,    11,    14,     3,     2,   104,    20,     6,\n",
      "            40,   306,   515,   856,     2,    32,    24,    42,    92,     9,\n",
      "           258,    84,   856,     2,    50,    22,  3662,     6, 30879,    21,\n",
      "         33025,    35,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [   26,   246,  1453,     4,  3587,   180,     5, 10964,    16,    34,\n",
      "           171,   246,  1498,    18,  2397,  2388,     6,   583,    38,    33,\n",
      "          1873,   449,     8,  2592,    11,    14,     3,     2,    63,    13,\n",
      "         40627,    11,    14,     2,   104,    13,   724,    11,    14,     2,\n",
      "           104,    13,   541,    11,    14,     2,   132,    13,   724,     2,\n",
      "           190,    13,  1139,    11,    14,     2,   190,     7,     3,     0,\n",
      "             0],\n",
      "        [   35,     4,   611,     6,   437,   888,    17,  1327,     4,   437,\n",
      "          1427,  3306,    10,   204,    47,   743,   451,    24,   797,  2685,\n",
      "             5,    15, 24687,    22,    15, 22773,     2,   110,    40,   204,\n",
      "            15,   437,  1427,    17,  3264,    39, 13160,    56,  2301,     8,\n",
      "         23619,    36, 12857,     2,    61,    13,  4719,     2,    83,    13,\n",
      "         13699,     2,    87,    13,  9435,    36,  4880,     2,    63,     7,\n",
      "             3],\n",
      "        [   26,   505,     5,     4,   555,     9,     4,   538,     5,     4,\n",
      "           850,    94,   229,    38,    33,   281,    18,   108,  1136,   450,\n",
      "            23,  1517,     4,    52,    19,    71,   839,    59,  7297,     9,\n",
      "          7298,    32, 17253,     4,   850,    94,   800,     6,    16,   797,\n",
      "            45,     9,    21,    90,    20,     2,    21,   129,    20,     2,\n",
      "            21,   128,    20,     6,    21,   169,    20,     3,     0,     0,\n",
      "             0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['30e507c0ba9bdbed320d311bebe5b875c24ef38e', '9d1c38923868aad077de91a389a27f72d592d329', '3194027f46b0c5fac75b843a68361a28c859d9b8', 'cf47eb041429aedec9ab4a06f5263471b431278b', '9067b0284ae1debf2488a7ad1db111b8182e9b26', 'b3231e925e9c851d01c0c5e08edb711f82617903', '81a915b83506b31b1c0b7f4fa35db2c57e83fd07', 'c87e7b027d3e92505f5fc419b97b3b6144fc850a', '6779b348a0a191209db3364c35b385b2cb689ccb', '34d3411b4cae75f253e72cdfc5b63038f9b34a08', '4678c626fa62e46b5d85da06af10ab139a802771', 'e50b5f95083385dc03ff9e30ad2571db39aa8a4e', '1b5291e439d1c04e9382ea9ee867c361e15c9568', '0c756adaec2279fc7270610fcd44d0850de1240a', '97f039b4a9748884cf0892b542b9a3f0fa43b438', 'd793b0e2afcdfe65d4a25ca1acc861fae228ef11'], 'cited_paper_id': ['d7303e7fc223a95be34287f53dca238c43548fac', 'badee7f8b87dbf9d38775bebaad489d664fe0ef3', 'ff3671cfc841b26dd44240ec270e6c3db6c12656', 'e42836feedca130dc3db75a2d6f8843af6161683', 'b13b1cbd30124f18adf4d8c5099313ef218c140c', 'ed10f059dd82bba94b4485223720255b9dd8dc70', '219f5b5f41264e84d8bc7c93a540e256e1f810c9', '1627b598c3195083d93c8659b9571870f382e26c', '566559c6efaca4701bf8c1099b6ecd9ba41b0ee6', '17aaebfb7135313cc1c01c6364542938f842da7a', 'fd920e1229b99b9b441ca93219bd84b6acb3abbb', 'd33169400b4a332cf52252e861b0520f37f137ab', '478a1e8d54f0c50fc137cdc5d0d07c599771aa29', 'd23572e680528d1cda929ec50d444afedbb3df82', '83e7c7909ed8e1c4b9ceefc55004a863c0d80052', 'cdf826f56975a67b3f1ef3778cc866768d22fdc1'], 'citation_excerpt_index': [0, 11, 0, 0, 0, 4, 4, 0, 0, 0, 6, 8, 0, 0, 2, 2], 'citation_id': ['30e507c0ba9bdbed320d311bebe5b875c24ef38e>d7303e7fc223a95be34287f53dca238c43548fac', '9d1c38923868aad077de91a389a27f72d592d329>badee7f8b87dbf9d38775bebaad489d664fe0ef3', '3194027f46b0c5fac75b843a68361a28c859d9b8>ff3671cfc841b26dd44240ec270e6c3db6c12656', 'cf47eb041429aedec9ab4a06f5263471b431278b>e42836feedca130dc3db75a2d6f8843af6161683', '9067b0284ae1debf2488a7ad1db111b8182e9b26>b13b1cbd30124f18adf4d8c5099313ef218c140c', 'b3231e925e9c851d01c0c5e08edb711f82617903>ed10f059dd82bba94b4485223720255b9dd8dc70', '81a915b83506b31b1c0b7f4fa35db2c57e83fd07>219f5b5f41264e84d8bc7c93a540e256e1f810c9', 'c87e7b027d3e92505f5fc419b97b3b6144fc850a>1627b598c3195083d93c8659b9571870f382e26c', '6779b348a0a191209db3364c35b385b2cb689ccb>566559c6efaca4701bf8c1099b6ecd9ba41b0ee6', '34d3411b4cae75f253e72cdfc5b63038f9b34a08>17aaebfb7135313cc1c01c6364542938f842da7a', '4678c626fa62e46b5d85da06af10ab139a802771>fd920e1229b99b9b441ca93219bd84b6acb3abbb', 'e50b5f95083385dc03ff9e30ad2571db39aa8a4e>d33169400b4a332cf52252e861b0520f37f137ab', '1b5291e439d1c04e9382ea9ee867c361e15c9568>478a1e8d54f0c50fc137cdc5d0d07c599771aa29', '0c756adaec2279fc7270610fcd44d0850de1240a>d23572e680528d1cda929ec50d444afedbb3df82', '97f039b4a9748884cf0892b542b9a3f0fa43b438>83e7c7909ed8e1c4b9ceefc55004a863c0d80052', 'd793b0e2afcdfe65d4a25ca1acc861fae228ef11>cdf826f56975a67b3f1ef3778cc866768d22fdc1']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 102, 116,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 122,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 117,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  152,     2,     4,   550,     5,    39,   186,    24,  4182,     8,\n",
      "            57,     2,    72,     2,  1523,     2,  2418,     2,  2147,     7,\n",
      "             3,     0,     0,     0],\n",
      "        [  785,     2,     4,  4868,  6617,    16,     5,  1365,   820,     9,\n",
      "             4,  5998,  2066,    12,  7126,   162,    21,   295,     2,   383,\n",
      "            20,     3,     0,     0],\n",
      "        [   64,  2766,    16,   876,  5437,    10,    15,   762,     9,     4,\n",
      "          1209,     5,  5468,   120,  1797,    21,    90,    12,   143,    20,\n",
      "             3,     0,     0,     0],\n",
      "        [    5,   246,   863,   111, 37681,   928,    16,    10,    74,     4,\n",
      "         15670, 16891,  1767,   636,     8, 16927,     6, 14292,   390,     7,\n",
      "             3,     0,     0,     0],\n",
      "        [   21,  2147,    20, 11515,  4857,  4295,  1435,     8,    29,  1551,\n",
      "          2696,     7,    22,  8234,    17, 17096,    99,  4295,     6,  4857,\n",
      "          1435,     3,     0,     0],\n",
      "        [12044,  2521,   681,    31,    46,  3306,    10,  1358,    28,     4,\n",
      "          3396,  5427,     2,    32,    16,   588,   171,     9, 31682,   400,\n",
      "             8,   383,     7,     3],\n",
      "        [40857,  5306,    31,    45,    10,  1075,     4,   782,     5, 31550,\n",
      "         38442, 10912,   357,     8, 40858,    11,    14,     3,   151,     7,\n",
      "             8,   170,   460,     3],\n",
      "        [ 5453,   287,    37,     4,   167,    22,   100,  2150,     8,   746,\n",
      "            11,    14,     3,     2,   131,    13,   746,     6,   955,     2,\n",
      "           113,     7,     3,     0],\n",
      "        [   41,    21, 30708,    20,   878,  1447,    16,   798,    10,   731,\n",
      "            34,   759,   514,  2914,   898,   168,    15,  2579,  9695,   261,\n",
      "            17,     4,   117,     0],\n",
      "        [35818,    11, 19781,     7,    82,    15,   675,    58,  6298, 35819,\n",
      "             6,  5872,  5693,  3214,   249,     2,    32,  1920,   166,   169,\n",
      "             3,     0,     0,     0],\n",
      "        [ 3872,     2, 16801,     6, 28501,    24,   103,   213,   303,     6,\n",
      "          2605,  4828,    40,  1798,    10,    21,  6596,    20,     6,    21,\n",
      "          9970,    20,     3,     0],\n",
      "        [ 2930,  1103,     2,     4, 26999,   814,    38,    33,   105,    10,\n",
      "           306,  1101,     6,  1804,   119,    25,  1091,  3188,    21,  5836,\n",
      "            20,     3,     0,     0],\n",
      "        [ 8783,  4962,   165,    31,  4658,    48,     4,    77,    12,  1706,\n",
      "          1069,   124,     8,  5703,     2,  1734,    13,  2155,    36, 20948,\n",
      "             2,   428,     7,     3],\n",
      "        [   26,   637,     5, 17292,   174,    23,    39,  2588,    66,    27,\n",
      "          1735,    10,    17,    54,    25,  9129,  4138,     9,   369,     8,\n",
      "           221,     7,     3,     0],\n",
      "        [20300,     2,  2780,     2,     6,   507,  2131,    37,   281,    22,\n",
      "           122,   100,   385,    10,     4, 10228,   755,     8,   371,     2,\n",
      "           662,     7,     3,     0],\n",
      "        [ 1203,     4,  2346,     2,    43,  2061,   109,   299,     9, 23823,\n",
      "            98,    21,    90,     2,   129,    20,    18,  1590,    15,  3696,\n",
      "          1375,     3,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['ef1535a64b39c591db87e3d82fb7128a8f39480b', 'f21feb68e99003d0034c99d301f49babe4f578cd', 'd44b27741213d925d27b462e62a6790ddf0b1c93', '7b424c17ab760c0b0480af4531322d7ff46eddb4', '24f45474d52f1880b6d9ebc6cdc3a8b41d2abc3a', 'e8b28ea410efa058d78aa219498e4b417228cf71', '0e4d80518045295d9ac80f4c03dd560cfe827077', '740aaa319103712a66e1c826ef10947b4958b2d9', '71197e96cc66d18123cffa099c043cf41b67445b', '33cb20c89f0246ec9db4f0c038ba29e6dc1c76c2', '3681cf18350d348acb4b27db3af37e7428670df9', 'e0b658f2d490fef05eeb5e6b9f71c4468427cb74', '3f589edfaba00ce64a419b6ba6b02a1736aa068a', '11d3014aacdecd64e60b32285d4991e6b84ac00f', '456c0582adbf9623150f5c0a052d982a6d5b3bac', '541da7b48aa9c42f9c7791ba52154b6efb282a66'], 'cited_paper_id': ['c923028caac7d0f58db911a22a89a003e10453bb', '22c5d8c5619727c57c86f7c61056fc790e5331bf', 'c29d19107ab8d0de686ae7c24c03b47b642cf3a1', '8424d658b31b9c3b308b14297d03f9f850226570', '03a02c636aef2616afe010f2c81a1adf33808d16', 'e4ba0683cccd1a5c2c8200b48cf76a5fb96af984', '198c4c3d49a7696d476d7e4504ed61f71d2fce4c', 'd2aaa1b7c0f2ba2687dfa658128871bfb7f91f49', '620a12113f0ae1f687dfcf6da5abbe6d3491fa85', '7caf30852a3191f350d7acdc2f996d1db81b1b72', 'b62430598576f433ed7b4c5c3d44000c236feab0', '1eb2a6e97822567a49c6dd0c08b76eae45d0eafa', '2bfe15413f41bb2b73308239940d6c7f73ed70a9', '51d3458450b170a6db92f2476343274737ccc117', 'bbca4bfa9c1c7e4a7ca87b294ef88976c5400c80', '76dcb72da0536c0393afbdf5fa761a80a622eabf'], 'citation_excerpt_index': [3, 0, 0, 0, 9, 8, 0, 0, 1, 0, 10, 0, 0, 0, 3, 0], 'citation_id': ['ef1535a64b39c591db87e3d82fb7128a8f39480b>c923028caac7d0f58db911a22a89a003e10453bb', 'f21feb68e99003d0034c99d301f49babe4f578cd>22c5d8c5619727c57c86f7c61056fc790e5331bf', 'd44b27741213d925d27b462e62a6790ddf0b1c93>c29d19107ab8d0de686ae7c24c03b47b642cf3a1', '7b424c17ab760c0b0480af4531322d7ff46eddb4>8424d658b31b9c3b308b14297d03f9f850226570', '24f45474d52f1880b6d9ebc6cdc3a8b41d2abc3a>03a02c636aef2616afe010f2c81a1adf33808d16', 'e8b28ea410efa058d78aa219498e4b417228cf71>e4ba0683cccd1a5c2c8200b48cf76a5fb96af984', '0e4d80518045295d9ac80f4c03dd560cfe827077>198c4c3d49a7696d476d7e4504ed61f71d2fce4c', '740aaa319103712a66e1c826ef10947b4958b2d9>d2aaa1b7c0f2ba2687dfa658128871bfb7f91f49', '71197e96cc66d18123cffa099c043cf41b67445b>620a12113f0ae1f687dfcf6da5abbe6d3491fa85', '33cb20c89f0246ec9db4f0c038ba29e6dc1c76c2>7caf30852a3191f350d7acdc2f996d1db81b1b72', '3681cf18350d348acb4b27db3af37e7428670df9>b62430598576f433ed7b4c5c3d44000c236feab0', 'e0b658f2d490fef05eeb5e6b9f71c4468427cb74>1eb2a6e97822567a49c6dd0c08b76eae45d0eafa', '3f589edfaba00ce64a419b6ba6b02a1736aa068a>2bfe15413f41bb2b73308239940d6c7f73ed70a9', '11d3014aacdecd64e60b32285d4991e6b84ac00f>51d3458450b170a6db92f2476343274737ccc117', '456c0582adbf9623150f5c0a052d982a6d5b3bac>bbca4bfa9c1c7e4a7ca87b294ef88976c5400c80', '541da7b48aa9c42f9c7791ba52154b6efb282a66>76dcb72da0536c0393afbdf5fa761a80a622eabf']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259,  85,  74,  ..., 261, 261, 261],\n",
      "         [259, 103, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 109, 122,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 102, 103,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 111,  ..., 261, 261, 261],\n",
      "         [259,  84,  87,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 116,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73,  68,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  205, 16414,   408,    42,   106,    22,    15, 25696,  1622,     2,\n",
      "            69,    46,  9344,  4987,     6,   328,   363, 25697,   531,     2,\n",
      "            51,    66,  1581,  1682,     6, 17354,    21,   388,     2,   221,\n",
      "            20,     3,     0,     0,     0,     0,     0],\n",
      "        [12898,     7,     2,    32,    30,    33,  2327,   325,    22,  1619,\n",
      "          1374,    23,   328,   363,    12,  1237,     5, 30978,     2,    24,\n",
      "           467,  3764,     9,     4,  1956,   507,  5272,  1404,     8,    57,\n",
      "            12,   169,     7,     3,     0,     0,     0],\n",
      "        [   26,   186,     5,  4937,    25,  6071,  1029,    16,   569,  4182,\n",
      "             2,    19,   296,    18,    99,   631,     8, 19592,    11,    14,\n",
      "             3,     2,    61,     7,     6,  1904,     8,   955,    11,    14,\n",
      "             3,     2,    63,     7,     3,     0,     0],\n",
      "        [ 6280,     2,    43,  1256,    15,  1375,  1942,   215,    19,    81,\n",
      "          1231,     2,  2813,    23,     4, 23959,    94,  1808,     8,   170,\n",
      "          6179,     5,    57,     8, 33843,     6, 33844,    83,     7,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0],\n",
      "        [   41,    99,  4022,     2,     4,   101,   241, 30601,    16,  1116,\n",
      "          2933,   496,     4,  2445,     6,  2787,    19,     4,   523,   450,\n",
      "             5,    96,  5815,   496,     4,  2127,    21,   873,    20,     2,\n",
      "            19,     4,   675, 30602,     3,     0,     0],\n",
      "        [   26,  1741,    16,  1321,  2207,    23,     4, 12896,  3737,   133,\n",
      "             2,    32,    38,    33,    45,  1279,     9,   102,    49,     8,\n",
      "          1409,     2,    76,    13,  7937,    36, 15319,     2,    89,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0],\n",
      "        [  144,    52,    24,     9,   685,    19,    15,    62,    23, 38407,\n",
      "            11,    14,     3,     8,    68,     7,     9,    32,   374,     5,\n",
      "         22738,   178,    31,    46,   192,    10,   680,    44,    15,   943,\n",
      "           339,     9,   254, 11203,    95,     3,     0],\n",
      "        [ 1252,     4,  1981,   398,     5, 42491,     2,     4,   158,  4349,\n",
      "           111,    15,  1375,   398,     5,  1675,  6713, 15983,     6,   562,\n",
      "           253,    16,  1931,    10,    34,  9978,   747,     8,  8801,     6,\n",
      "          7028,     2,    85,     7,     3,     0,     0],\n",
      "        [   26,    52,     5,     4,    81,   757,  2240,     2,    32,   852,\n",
      "          2929,  2802,    22,  3447,     5,  3425,     8,   875,   128,     7,\n",
      "             2,    37,  2807,  3153,    19,   137,   411,     9,     4,  2629,\n",
      "             8,  3053,     6, 28581,   131,     7,     3],\n",
      "        [  632,   109,    49,   238,    17,  6829,   907,  1827,    15,   304,\n",
      "           422,    19,  7983,     8,   143,     2,   236,     7,   477,    82,\n",
      "            17,  6829,   907,   364,    42,    30,    34,   555,    25,  7983,\n",
      "             8,   254,     7,     3,     0,     0,     0],\n",
      "        [24710,  5727,  1255,    47,  5216,  2154,    30,  1293,     4,   819,\n",
      "          5727,  1255,  2237,     8, 35379,     7,     5,  6355,   382,   231,\n",
      "            19, 35380,  1257,    21,  1787,     2,  3121,     2,  2415,     2,\n",
      "          1387,     2,  4909,    20,     3,     0,     0],\n",
      "        [   68,     7,    29,    15,   265,  2314,  1816,   375, 18323,     8,\n",
      "           130,    15,  8908,  2870, 10991,     7,     8,   864,    11,    14,\n",
      "             3,    61,    13,  3667,    11,    14,     3,    70,    13,  8702,\n",
      "            11,    14,     3,    68,     7,     3,     0],\n",
      "        [   26,   969,   830,    10,  1003,     4,   438,   262,  3191,    18,\n",
      "            39,  1343,    37,   663,    28,   553,   281,    25,     4, 12660,\n",
      "           240,    95,     5,    39, 29356,     7,  1857,    39,   505,     2,\n",
      "             4,   192,  8826,   186,   262,     8,  1860],\n",
      "        [  702, 13114,    16,  2185,    10,    15,  5156,  9341,     6,    15,\n",
      "          5156, 17026,    17,    40,    27,  2524,    10,   175,     4,  1536,\n",
      "             6,  2313,   469,    44,   107,  4781,     9,    15, 10434,  1485,\n",
      "            21,   224,    20,     3,     0,     0,     0],\n",
      "        [  112,    65,   486,     2,    43,   284,    15,  5035,  3594,   133,\n",
      "             6,    45,     4,   543,  2348,    47, 23781,  1253,     8, 23782,\n",
      "             6, 23783,    97,     7,     6, 23784,  1253,     8, 23785,    11,\n",
      "            14,     3,   390,     7,     3,     0,     0],\n",
      "        [35539,     2,    15,   322,    12,  2244,  1656,     2,    31,   239,\n",
      "            23, 31100,   979,     6,  1093, 21229,     9,    61,    23,  5449,\n",
      "             4, 35540,   111,    15,   222,  1780,  9123,    21,   341,    20,\n",
      "             3,     0,     0,     0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 0, 1, 0, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['43e8553881f0f6d27480f0bab2c43465b7927836', '3236304ccc08771361e7459e431da419b0392c8e', '01b514ecf50afd022e9cbfd948e0b9352ab8cd72', 'f424e78e62c0907263d4b35ec5aa09e28237fea4', '4043bc0792c398a9dc5dbf1e6bc87552f0613f3e', 'd7b62277cba9cdcc7c33d562064fca6f8b7fd2e6', '9f17b5e3dd2e49e9725f6c34b6e2cb466ebb6144', 'cf43ab7995bb90d374fddcf917685ae5c757c13f', '972ed633b66aa93fa76043fde547bec654759b44', 'a09c20b269bcae23a839bab9f6719f47df50f2e6', '0cbda63139390bb9dbc7f679874e700789c3cad5', '27a87d0e843c863b59d0053ef4d6aa5afe470f97', '2cd0df8e563ea9ee533fe73207237c3a7d2a3f50', '3b35c7d188df791efe6650d85df2850d47e4b482', '34fcc7582a6fd5662ce5d387b90a690a71eca189', '6a77ffc900be0ca2ff93863db4ad4fc4060e1648'], 'cited_paper_id': ['e99fd9775ae760a58cc0b1492b1d07e7a5006b78', 'd903f2fd136e6cd08e2e7d8f565a16c496626026', '4e3a5a53715d20f587da65ed44a57a7b0ef78ca2', '501fae564febc17042d2bbe815b0a147e6339352', '5a29805e25dabb4d91effd2f6ff893eb6d6d9f32', '9930abd541f7c943aaf32cf496ca2fc74fca0309', '9aeb612064573970561d211747fe5e8712796c3b', 'c0e9eaec2955cf840c040baae65c4a25f1f6f126', 'None', '600183955ab9649630117933dbc8ece4269830a5', 'a7643eec065b8cbed08be5e8ecaa8f6a8ecb11fb', '4de0d7c959f881c3e43be54562d60af0172cefbf', '308bb15ee440fa4a515a4a0a94da08aac7eac400', 'bb248fb09b9d083f823e41b9aa279458cf685168', 'dc1792e5a09ee07d29e1908783c27506824a89ef', '45762f948c58a6969eee8ab92bb813b6ad0a72a0'], 'citation_excerpt_index': [1, 1, 1, 0, 0, 0, 0, 5, 0, 0, 0, 2, 0, 1, 2, 0], 'citation_id': ['43e8553881f0f6d27480f0bab2c43465b7927836>e99fd9775ae760a58cc0b1492b1d07e7a5006b78', '3236304ccc08771361e7459e431da419b0392c8e>d903f2fd136e6cd08e2e7d8f565a16c496626026', '01b514ecf50afd022e9cbfd948e0b9352ab8cd72>4e3a5a53715d20f587da65ed44a57a7b0ef78ca2', 'f424e78e62c0907263d4b35ec5aa09e28237fea4>501fae564febc17042d2bbe815b0a147e6339352', '4043bc0792c398a9dc5dbf1e6bc87552f0613f3e>5a29805e25dabb4d91effd2f6ff893eb6d6d9f32', 'd7b62277cba9cdcc7c33d562064fca6f8b7fd2e6>9930abd541f7c943aaf32cf496ca2fc74fca0309', '9f17b5e3dd2e49e9725f6c34b6e2cb466ebb6144>9aeb612064573970561d211747fe5e8712796c3b', 'cf43ab7995bb90d374fddcf917685ae5c757c13f>c0e9eaec2955cf840c040baae65c4a25f1f6f126', '972ed633b66aa93fa76043fde547bec654759b44>None', 'a09c20b269bcae23a839bab9f6719f47df50f2e6>600183955ab9649630117933dbc8ece4269830a5', '0cbda63139390bb9dbc7f679874e700789c3cad5>a7643eec065b8cbed08be5e8ecaa8f6a8ecb11fb', '27a87d0e843c863b59d0053ef4d6aa5afe470f97>4de0d7c959f881c3e43be54562d60af0172cefbf', '2cd0df8e563ea9ee533fe73207237c3a7d2a3f50>308bb15ee440fa4a515a4a0a94da08aac7eac400', '3b35c7d188df791efe6650d85df2850d47e4b482>bb248fb09b9d083f823e41b9aa279458cf685168', '34fcc7582a6fd5662ce5d387b90a690a71eca189>dc1792e5a09ee07d29e1908783c27506824a89ef', '6a77ffc900be0ca2ff93863db4ad4fc4060e1648>45762f948c58a6969eee8ab92bb813b6ad0a72a0']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  84, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  83,  69,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 120, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  69, 106,  ..., 261, 261, 261],\n",
      "         [259, 103, 115,  ..., 261, 261, 261],\n",
      "         [259, 112, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  83, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[ 6301,     2,     4,   758,   708,     5,  3574,    19, 42456,    38,\n",
      "            33,    82,     9,    56,    67,   143,  1233,     2,   130,  1504,\n",
      "            21,  6587,    20,     2,  8469,    21,   128,    20,     2,  2297,\n",
      "          6190,     0,     0,     0,     0,     0],\n",
      "        [ 2062,     2, 22888,   389,    42,   416,     4,  1014,  2124,  1813,\n",
      "             9,     4,  1018,  1035,     2,    32,    31,   228,    19,   139,\n",
      "            52,    92,  2150,    21,   341,    20,     2,   425,    51,   911,\n",
      "             4,  2376,   174,     3,     0,     0],\n",
      "        [29491,     2,   146, 19154,     2,  5324,     6, 29491,  1079,   580,\n",
      "          1020,     2,   580,   450,     6,   580,  3738,     2,   463,     8,\n",
      "           170, 43149,    11,    14,     3,    97,    18,  1181,     7,     3,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  144,    52,    24,   139,    10,   138,    82,    23, 25846,     8,\n",
      "           104,     7,    48,  6730,  7584,   224,  6730, 12886,  8234,     6,\n",
      "         25847,     6,  7936,     8,    68,     7,    18, 25848,    12,  3409,\n",
      "          3373,  1018,  6730, 12886,     3,     0],\n",
      "        [17839,  8145,  1414,     8, 30671,     7,    24,  6445,  1414,    17,\n",
      "           823,     9,     4,  1727,     5,     4,  3908,  2804,     6,   617,\n",
      "           193,     9,     4,  6554,    10, 17363,  3496,     5,   517,    21,\n",
      "          3189,    20,     3,     0,     0,     0],\n",
      "        [  323,     4,  1992,     5,  1296,     6,  3736, 15993,    66,    27,\n",
      "          1739,    23, 14238,  1384,     9,     4,  1968,     5, 10683,   111,\n",
      "          1296,    21,   295,    20,     2,    39,  2864,    40,    42,  1310,\n",
      "             4,  1992,     5,  3736, 15993,     3],\n",
      "        [18848, 10345,   999,     4,  1100,    94, 32430,  1347,   450,  1811,\n",
      "            17,   416,  6485,    19,  2453,   707,     5,  2288,   168,  1144,\n",
      "          1905,     9,     4,  2459,  2288,   420,     8,  6912,    11,    14,\n",
      "             3,     2,    63,     7,     3,     0],\n",
      "        [40703,   860,     6,  3955,     9,   453,  2291,  7198,  1792,   699,\n",
      "           781,    15,  2164,   825,    15,   904,    15,    15,  1792,   668,\n",
      "           447,  1680,  2490,     4, 24922,     5, 40704,    21,    57,    20,\n",
      "            21,    90,    20,     3,     0,     0],\n",
      "        [35108,    31,   284,    10,    59,     4,  2144,  6499,    21,  1787,\n",
      "            20,     2,     6,  4225,     2,   347,    12, 12539,    31,   284,\n",
      "            10,    59,    96,     4,  2007,  2144,  1836,    21,   526,    20,\n",
      "             3,     0,     0,     0,     0,     0],\n",
      "        [  394,    24,   713,   157,  1458,     8,    18,   645,    21,   237,\n",
      "             2,    90,     2,   129,     2,   128,     2,   169,    20,     7,\n",
      "            19,  2582,  3663,     9,     4,   117,     5,   634,  2457,     4,\n",
      "          3412,   211,     3,     0,     0,     0],\n",
      "        [  153,   691,    15, 16985,  1383,     2, 23701,    21,  9540,    20,\n",
      "             2,    18,     4,  5502,   532,     2,   201,    48,     4, 23702,\n",
      "          1383,     2, 23703,    21,   399,    20,     2,    10,  4403,     4,\n",
      "         23704,   532,     3,     0,     0,     0],\n",
      "        [  690,     4,    55,   480,     2, 12106,    37,   539,     9,     4,\n",
      "           992,  2229,    98,     6,     9,     4,  4620,     2,  1109,   146,\n",
      "          2513,  4526,    31,    42,   846,     8,  8108,    11,    14,     3,\n",
      "             2,   142,     7,     3,     0,     0],\n",
      "        [12188,   119,    28,     4,  4124,     6,  2262, 14289,    31,  2130,\n",
      "            19,    15,  3171,  3553,     5,     4, 25777,  4266,    10,  1299,\n",
      "         10275,   262,     8, 14613,    11,    14,     3,     2,  3336,     2,\n",
      "           256,     2,   104,     7,     3,     0],\n",
      "        [ 3890,    28,    55,   546,    12,    54,  2028,  2767,   980,   244,\n",
      "            21,   128,     2,   300,     2,   254,    20,     2,     4, 10886,\n",
      "            12,    54,   133,  1845,  2028,  5102,    54,    25,  3774,  8935,\n",
      "           545,     3,     0,     0,     0,     0],\n",
      "        [19862,     5,   157, 22782,   115,    10,   278,  4842,    30,    33,\n",
      "           985,     2,    19,   109,   774,  5300,     6,   320,   772,    10,\n",
      "          3834,    29,    10,  4996,    21,   341,    12, 21315,    20,     3,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  665,     2,     4,  7664,  1806, 37331,     8, 10826,     7,     8,\n",
      "         18304,    11,    14,     3, 39913,  2244,    10,   709,  2596,   902,\n",
      "            44,     4, 39914,  1397,    22,     4,  1180,  2356,    18,     4,\n",
      "            62,     3,     0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 2, 1, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['92b233e5eeec5a87fcdd6858b22818db8fc3effe', '320cae4955eb8cf09b434981eea48a6003dfbf93', '74159c9e5523f419f532af5f04a6371c26ec33d7', 'ea29c9cbcb8a1107f51d661293eecf5d2d6fcc12', '586340da84022480b3855ffd8a95489f8c618228', '3f0c84260f93a0cf5134539848f8dd4e7747f990', '7ec102746b50af4549ff328e649f7c9c875bcd2f', '28fdd82ace7063d8c1a3ee8c7e23509f5a79e762', '873ef9ff6b93bcf0490e495d74d9f8b8cf91ddcb', '1c20bf34d0840f1c46b9a64cda3b7d93b057895d', '24bdaf850afc1e4b269817f5b2278f62614b6847', '78df72c544579fbdc6f5c9a4b38434699e645873', 'a6d79865df14a94ed87c71bf65c4dd90871f4c24', '01da7ab3e60651d06ec5310b01b37de15209cffb', '8787fd7bf86e87065f38a91b7b1cb5a75f569de6', '2305bf2f335c0e2afd42fa3a83856847ab1b9b94'], 'cited_paper_id': ['30ee1475c50e6043ae21608906d0f0c67756029c', '007c4ee9f1cb8aa447c053e9193a70bc7a05fa5a', 'b1b08ccd3b49cd956f78773082ee4c16206b3488', 'None', '89056a119a9d07f3f2538cabc721eca4506cc95b', 'da4cb02e18f12c06b24d7a613a6e4f9110093572', '3da8310618b8d9488ab6d6ee10bfcce927a47891', 'd333d419b4c9fb8bcd3f253e69513667052d1a80', 'a68a19d90eb750f622abedc9c6543457a50957c7', '09aeb344a62b1b6f8b0908da2b392e7624668171', 'c1425c2ee0fb186340eda49596c912feabb5a7f6', 'a0c52ddd655648ddf0c426553bf0957e8abcc02a', '7e7a117918005eed0b7ae4e907e8bfdd1bc95471', '04b58bb061196d566acb2985659445f7a5985be2', 'a6876ac50089f0fd6b1db136bdc52082a0704014', '0b5eecaa7abedf6b1cacf52ce712d6a00b0ec38f'], 'citation_excerpt_index': [7, 0, 0, 0, 1, 8, 4, 0, 0, 0, 0, 6, 4, 0, 2, 0], 'citation_id': ['92b233e5eeec5a87fcdd6858b22818db8fc3effe>30ee1475c50e6043ae21608906d0f0c67756029c', '320cae4955eb8cf09b434981eea48a6003dfbf93>007c4ee9f1cb8aa447c053e9193a70bc7a05fa5a', '74159c9e5523f419f532af5f04a6371c26ec33d7>b1b08ccd3b49cd956f78773082ee4c16206b3488', 'ea29c9cbcb8a1107f51d661293eecf5d2d6fcc12>None', '586340da84022480b3855ffd8a95489f8c618228>89056a119a9d07f3f2538cabc721eca4506cc95b', '3f0c84260f93a0cf5134539848f8dd4e7747f990>da4cb02e18f12c06b24d7a613a6e4f9110093572', '7ec102746b50af4549ff328e649f7c9c875bcd2f>3da8310618b8d9488ab6d6ee10bfcce927a47891', '28fdd82ace7063d8c1a3ee8c7e23509f5a79e762>d333d419b4c9fb8bcd3f253e69513667052d1a80', '873ef9ff6b93bcf0490e495d74d9f8b8cf91ddcb>a68a19d90eb750f622abedc9c6543457a50957c7', '1c20bf34d0840f1c46b9a64cda3b7d93b057895d>09aeb344a62b1b6f8b0908da2b392e7624668171', '24bdaf850afc1e4b269817f5b2278f62614b6847>c1425c2ee0fb186340eda49596c912feabb5a7f6', '78df72c544579fbdc6f5c9a4b38434699e645873>a0c52ddd655648ddf0c426553bf0957e8abcc02a', 'a6d79865df14a94ed87c71bf65c4dd90871f4c24>7e7a117918005eed0b7ae4e907e8bfdd1bc95471', '01da7ab3e60651d06ec5310b01b37de15209cffb>04b58bb061196d566acb2985659445f7a5985be2', '8787fd7bf86e87065f38a91b7b1cb5a75f569de6>a6876ac50089f0fd6b1db136bdc52082a0704014', '2305bf2f335c0e2afd42fa3a83856847ab1b9b94>0b5eecaa7abedf6b1cacf52ce712d6a00b0ec38f']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 103, 112,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  71, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  54,  55,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 113, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  68, 106,  ..., 261, 261, 261],\n",
      "         [259, 116, 110,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 102, 117,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[30706,    24,     9,     4,   319,     5,   102,    52,    82,    18,\n",
      "           536, 27064,    21, 30707,    20,     2,    21,   341,    20,     2,\n",
      "            21,   399,    20,     6,    18],\n",
      "        [  544,     2,    15,   184,    62,    92,    17, 35055,  1045,  3178,\n",
      "            56,    84,    10,  6354,     4,  1731,  2357,    67,     4,   175,\n",
      "          1045,    21,  1834,    20,     3],\n",
      "        [12400,     5,  5584,  2928,    23, 18476,    12,   573,  4059,    31,\n",
      "            82,     9,   157,  2305,    21,   128,     2,   191,     2,   236,\n",
      "             2,   630,    20,     3,     0],\n",
      "        [    2,  5524,     7,  2576,  5171,     5, 17400,   120, 14933,  1666,\n",
      "             2,    50,    17,   110,    40,  3028,    10,  1531,  7171, 14933,\n",
      "           163,    21,  3754,    20,     3],\n",
      "        [  143,  1782,     2, 37317,     6,  7589,     8,   104,     7,  2975,\n",
      "             4, 37318,    94,  2106,    10,     4, 13922,     6,   746,     8,\n",
      "           661,     7,    59,  1015,     3],\n",
      "        [   21,  1071,    20,  9246,    37,   100,  4069,    28,   343,    10,\n",
      "           494,    10,   395,   837,  1425,     6,    46,  1588, 27252,    22,\n",
      "           447,   837,     8,   706,     3],\n",
      "        [ 9246,     5,   236,     6,   214,   974,    15,   196,    18,     4,\n",
      "           458,     5,    34, 12687,    12,  6141,  1625,     8, 21416,     6,\n",
      "         31634,  1376,     7,     3,     0],\n",
      "        [  665,     2,    43,   784,    21,    90,     2,  1012,    20,    10,\n",
      "          2468,     4,  1071,  1201,  1153,     9,     4,   208,   824,    18,\n",
      "           505,     3,     0,     0,     0],\n",
      "        [17751,    21, 26929,    12,   371,    20,    29,   499,   111,     4,\n",
      "          1344,  2273,     5,     4,  5484,    21,   346,    20,  6399,     4,\n",
      "          1150,     5,  1702,  2282,     3],\n",
      "        [ 1862,    65,     2, 35382,    24,   713,   292,     4,   101,  2312,\n",
      "         20417,    18,     4,   202,     5,   114,   140,  1938,    21, 35383,\n",
      "            20,     3,     0,     0,     0],\n",
      "        [  646,     4,  2556,   538,    16,     2,   385,    10,    21,   169,\n",
      "            20,     2,     4, 17342,   215,  1039,  2238,     8,  5965, 30593,\n",
      "             7,  4470,    10,  4875,     3],\n",
      "        [   26,  9468,     6, 60299,    16,   911,   121,     4,  2577, 17397,\n",
      "            16,  1111,    23,   278,  1610,  2618,     2,    50,    22, 24633,\n",
      "            21, 50683,    20,     3,     0],\n",
      "        [ 6755,   178,     5, 34793,     6, 16731,    38,    46,    33,   100,\n",
      "             9,   161,  3622,     6,  4503,  9937,    21,  9540,    20,     2,\n",
      "           463,     3,     0,     0,     0],\n",
      "        [42863,  3651,    38,    33,   122,   105,    10,   242, 13198,  4138,\n",
      "            21,  9889,    20,     6,   576,     4,  8064,    52,    21,   254,\n",
      "            20,     3,     0,     0,     0],\n",
      "        [   64,   133,    16,   350, 21064,    23,     4,  1036,     5,     4,\n",
      "           213,   719,   436,   602,    18, 38262,    21,  1172,     2,  1026,\n",
      "             2,  1335,    20,     3,     0],\n",
      "        [   26,  5117,    31,  4612,   620,   111,     4,  1647,   168,    34,\n",
      "         28720,   697,     2,    22,   100,   122,     8,   399,     2,   346,\n",
      "             7,     3,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['0cd88668fc28e1d5828a7a3e4b4e0c2721fa77e8', '0231adb17c3024ef897a1d97ab461c9f98f7b886', '47e516b8126dde8bd696509aa807f9da58a64d92', '3b35ca320e70b34845180f69096cc23f0752fc9b', '59f42f819ec46912d69554dacc0daa3742fa6bf7', '354048927e7f884092cfbf233e5316f87e9566d1', '57392c17117014785d6297c64babf811f501f024', '33e6eeec4cd55d49a355d41f585e736e616105ed', '2707175120ef1204a61c485f0ec84f8748cfc0c2', '33baceb49dbe4b52671fe0ecf7def0225d04fb77', 'ca6452209619a651c65919776688b9fbbf2a293a', 'd61c6e22a603715192d1989a9f1d8f958c694669', 'dfdf01c717026911658dbc0aa9d56025a982bd81', 'ec1e98f09ece1c0595deca70e9adbe46685f7850', '6c33bf1362167acd6c9a95021fc92b998849ad3d', '45b494f982aa56b15771b334ec617d684008665d'], 'cited_paper_id': ['None', '2abef0d4c69c6847bf0b6e1ed525e07d03adcdca', '15fb5139082c5ced0bc979a8a864a9271524d36a', 'e7ae8d642c71cd6b0a96740b0fd502dfae564d04', '477ce51a2fb3e4655625d96a17a3fe4ccf0cd304', 'bbf10259c77b8124715d50c73dac46756fed745f', '3f7dfdf8538cfc07af4be10bb7b975ef288244ae', '09e15bb266da86d0a9525d2a94ac0b38f0b53b88', 'cbdfe987b406ca40a3171f7f1b5f16ad4ba2fdd5', 'f78e1662c864ca31220fc2b0ddd88ab19014ff6e', '16dbaf87b0497693dff3dd58e891bdc75f4fadf5', '9567ac45b10b31a0d76498725e4b778e9d8be5f0', 'd70acb645ef074381d14bd23e0ce8861a84fc4f4', 'b5af4bf2fd53644e12e4345ea3cd7f4027ace764', 'c81d3f3602da2fbff05a3a4d1768de403a596030', 'f76b021b2e67dc2482230be64f5a8869835a2b78'], 'citation_excerpt_index': [0, 0, 1, 0, 2, 0, 1, 0, 2, 0, 14, 1, 0, 2, 1, 0], 'citation_id': ['0cd88668fc28e1d5828a7a3e4b4e0c2721fa77e8>None', '0231adb17c3024ef897a1d97ab461c9f98f7b886>2abef0d4c69c6847bf0b6e1ed525e07d03adcdca', '47e516b8126dde8bd696509aa807f9da58a64d92>15fb5139082c5ced0bc979a8a864a9271524d36a', '3b35ca320e70b34845180f69096cc23f0752fc9b>e7ae8d642c71cd6b0a96740b0fd502dfae564d04', '59f42f819ec46912d69554dacc0daa3742fa6bf7>477ce51a2fb3e4655625d96a17a3fe4ccf0cd304', '354048927e7f884092cfbf233e5316f87e9566d1>bbf10259c77b8124715d50c73dac46756fed745f', '57392c17117014785d6297c64babf811f501f024>3f7dfdf8538cfc07af4be10bb7b975ef288244ae', '33e6eeec4cd55d49a355d41f585e736e616105ed>09e15bb266da86d0a9525d2a94ac0b38f0b53b88', '2707175120ef1204a61c485f0ec84f8748cfc0c2>cbdfe987b406ca40a3171f7f1b5f16ad4ba2fdd5', '33baceb49dbe4b52671fe0ecf7def0225d04fb77>f78e1662c864ca31220fc2b0ddd88ab19014ff6e', 'ca6452209619a651c65919776688b9fbbf2a293a>16dbaf87b0497693dff3dd58e891bdc75f4fadf5', 'd61c6e22a603715192d1989a9f1d8f958c694669>9567ac45b10b31a0d76498725e4b778e9d8be5f0', 'dfdf01c717026911658dbc0aa9d56025a982bd81>d70acb645ef074381d14bd23e0ce8861a84fc4f4', 'ec1e98f09ece1c0595deca70e9adbe46685f7850>b5af4bf2fd53644e12e4345ea3cd7f4027ace764', '6c33bf1362167acd6c9a95021fc92b998849ad3d>c81d3f3602da2fbff05a3a4d1768de403a596030', '45b494f982aa56b15771b334ec617d684008665d>f76b021b2e67dc2482230be64f5a8869835a2b78']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  73, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 113, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 115,  ..., 261, 261, 261],\n",
      "         [259,  59, 260,  ..., 261, 261, 261],\n",
      "         [259,  88, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  99, 112,  ..., 261, 261, 261],\n",
      "         [259, 100,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 117,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 106,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[ 2000,     2,  2546,   174,     9,    95,    19,  1080, 11718,    31,\n",
      "          9983,  5092,     2,    32,    40,   242,     4,   196,     5,  9454,\n",
      "          1291,     6,   576,     4,   462,    94,  1732,   527,     2,   328,\n",
      "             6,   202,     6,  1454,    21,   662,    20,     3,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   64,    62,  6391,    28,   320,   146,  5866,    31,  1095,     9,\n",
      "            17,     4,  3133,    37,   307,  2743, 37144,   508,    67,  2087,\n",
      "          1479,    19,  2942,     8, 10338,    11,    14,     3,     2,    68,\n",
      "            13,  3006,    36, 42293,     2,    78,     7,     3,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 4378,    47,    93,  1709,  1385,  2148,   510,  4022,    18, 23729,\n",
      "             6,    18, 23730,    48,  7342,    59,   129,    21,   388,    20,\n",
      "             2,     6, 14997,   330,    48,  3566,    12, 14337,    12,  1099,\n",
      "            12,     6,  2378,    21,   221,    20,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 8772,  1280,     6,   597,  4102,   205,    43,   122,   100,     8,\n",
      "           128,     2,   236,     7,     2,   161,  8772,     8,  1073,  4958,\n",
      "           486,     7,    31,   267,   166,     4,  3745,     5,    34,  5825,\n",
      "         10865,    28,   446,  2632,   737,  1949,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [11929,     5, 21792,     2, 21793,     2,     6, 21794,   329,    37,\n",
      "           663,    19, 32622,    94,   719,    12, 20230,  2286,  2564,  8500,\n",
      "           719, 20978,    12, 18924, 13622, 11137,     5,  2286, 21795,     8,\n",
      "           128, 21796,     7,  5460,     2,    22,   122,   100,     8,   222,\n",
      "             7,     3,     0,     0],\n",
      "        [ 7493,     2, 12608,   244,    10,  2463,  4976,    22,   361,  7906,\n",
      "            29, 27571,  5305,     4,  2088,    12,    54,   177,  3146,     9,\n",
      "            39,    62,     2,   557,     9,    34,  3961,   374,     5,   538,\n",
      "             8,  8157,     6, 10072,    68,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [21058,   161,  5657,  2286,   835,     4,  1611,  1163,   431,     5,\n",
      "           161,  5657,    31,  4463,   111,     4,   149,  2607,     5,     4,\n",
      "           161,   328,  3373,   246,  1268,    23,     4,   894,  4047,  6357,\n",
      "            80,  1360,     8,   254,     2,   222,     7,     3,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   26,  7815,  1079,     4,    59,    28, 23346,     6,  6150,     8,\n",
      "            85,     7,     6, 23346,     8,    76,     7,     2,     4,  1529,\n",
      "             6,  3795,   115,    28,   541,    11,    14,     3,     8,    70,\n",
      "             7,     2,     6,    71,  6696,     2,   463,     3,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   88,   241,   716,     5,    39,  6737,    31,  5215,    12, 40693,\n",
      "            18,   543,  2294,    12,   619,  6001,     8,    15, 19884,    83,\n",
      "          8979,  8770,  8980, 38261,  5687,    12,    18,    12,   619,  1348,\n",
      "           149,   620,     9,    70,     2,   170, 12829,    11,    14,     3,\n",
      "          2843,     7,     3,     0],\n",
      "        [  224,    73,     7,    45,     9,    39,    62,    24,   292,   182,\n",
      "          2742,     6,    37,    54,    25,   102,    49,     8, 42591,    11,\n",
      "            14,     3,    63,    13, 42592,    11,    14,     3,    83,    13,\n",
      "          3667,    11,    14,     3,   104,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   93,    45,    15, 10832,  2911,    10, 12216,     4,  3644,   333,\n",
      "            17,  4684,     4,  4843,    10,  1841, 29126,    50,    17,    15,\n",
      "          1235,   185,  1433, 29127,    77,     5,  1093,    81, 29128,     8,\n",
      "          8432,    11,    14,     3, 11412,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   26,   114,   249,     5,  1446,     6,  2018,  1416,     9,  5831,\n",
      "          5742,    95,   516,     4,  2724,   219,     5,  7042,     2,     6,\n",
      "           176,  7042,   251,    31,   584,    10,  2161,  1306,   276,     4,\n",
      "           458,     5,  7345,  1446,  1416,     8,   191,     7,     3,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   64,   515,     5, 11796, 31197, 19146,    46,  8188,   147, 14213,\n",
      "           885,    21,   341,     2,   399,    20,     2,    69,     9,    71,\n",
      "         22112,   405, 10895,  2404,     6, 11796,  1129,    24,  1542,  1051,\n",
      "            21,   277,    20,     2,    22,  1173,   136,  7991,    21,   371,\n",
      "            20,     3,     0,     0],\n",
      "        [   41,    99,   289,     2,  2965,  4953,  3456,   639,    12,  4727,\n",
      "             8, 33136,   319,     7, 10885,    17,  8018,    19,   989,  1259,\n",
      "             9,   935,  4096,     8,  1706,   686,     7,  3950,  9700,  5352,\n",
      "             8, 16396,    11,    14,     3,   274,    13, 27266,    11,    14,\n",
      "             3,  3860,     7,     3],\n",
      "        [  153,    16,    46,  1463,    10,  1698,    17,     4,  1605,     5,\n",
      "         30220, 10948,  5602,     8,  1012,    73,     7,    92,   166,   571,\n",
      "          1854,     5,  6057,    16,  1087,    10,    17,     8,  1393,    73,\n",
      "             7,    92,   166,    90,  1854,     5,  6057,    21,   295,    20,\n",
      "             3,     0,     0,     0],\n",
      "        [ 1165,     2,    43,  3607,    17,  7240,   529,    15,   154,     5,\n",
      "          5141,     5,    15,   877,   912,    16,    15, 15205,    12, 32539,\n",
      "            16,  6874,    12,  4732,    12, 10978,     2,    15,   200,  1355,\n",
      "          1036,    16,  1288,    22,   819,     9,    21,   236,    20,     3,\n",
      "             0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['5061335d4b529a0222676443450c215cf2ec17e5', '052157cc6f9b1faee4edf6bf3908236b30cdebf3', 'dbfdbba44c6c2e8a9a2f40f3ba13efc440d56e14', '33faf9c0b0ea2292ec82800186ca82e54b087ecf', '550247561bf8376e9b5639b546b792788c78e0c5', '32d61d5e28d2769c6dfcc296473eb10484520bec', 'cab9106cabc965de5654e937fdd7108779669884', '388c8e6ba7646f46e499dffc00557cfe769a5dda', '1b69830499fe27ffa7e1752f76bf7a1b412f509d', '6cf8c878005b383009bc2c1366f37ac7ba4a1eec', 'ed603928cb3f313a58e3c36090e74d4fa37b0100', '62f9420cb7ce1327c2c8fcd1c48538ed87274cd2', 'e8b98c4799f4095d14a3eaa75e0ad464e2715aa5', '1e22584fc8f7f0deea6e96df287c37c37ba86c6b', 'd543ce5e35d1671e3df4f8703a1b5949bac800b6', 'b8bffa786710b52c95201796bade07fc2ad3f38d'], 'cited_paper_id': ['1e68bc018157a323cba632c8900a0a2abc2559d4', '3e042815478444b00b9ad534c0be190fcdd9d7d4', '368f3dea4f12c77dfc9b7203f3ab2b9efaecb635', '3c5f1e4b17a53cc4636cb9994b1c12fa0a409a47', '7e82b38e21c87b6a76a8549a36cd91cec5459a55', '76e63fddfa3b6f2d08ceb5b38ff9c4583103cbe9', 'd985d77098bce6ddba0dda6880dade803a1ffbc7', '23c6c94534378c204c0ee21fdaebd23fd4691bcf', '3dac6d4eb221945f009c543a65537513d186c5ed', 'd7b16091b800b035259e82296876124e9d9d8e3a', '3dcc3d1a44afc919d8afff2c9a598fd24a57b0d3', '983dfc44a86d441fb7ae5ec3b39e919ff8832b76', '5b349d4294ba4387cbbb237f87727850700c6970', 'f2e8507a54cb42a001465944fc7113c43bb0a61a', 'None', '0049b630e0bf4b14e76e36615c33aed0c39c3dd9'], 'citation_excerpt_index': [0, 1, 0, 1, 2, 0, 0, 9, 1, 0, 11, 3, 2, 1, 0, 1], 'citation_id': ['5061335d4b529a0222676443450c215cf2ec17e5>1e68bc018157a323cba632c8900a0a2abc2559d4', '052157cc6f9b1faee4edf6bf3908236b30cdebf3>3e042815478444b00b9ad534c0be190fcdd9d7d4', 'dbfdbba44c6c2e8a9a2f40f3ba13efc440d56e14>368f3dea4f12c77dfc9b7203f3ab2b9efaecb635', '33faf9c0b0ea2292ec82800186ca82e54b087ecf>3c5f1e4b17a53cc4636cb9994b1c12fa0a409a47', '550247561bf8376e9b5639b546b792788c78e0c5>7e82b38e21c87b6a76a8549a36cd91cec5459a55', '32d61d5e28d2769c6dfcc296473eb10484520bec>76e63fddfa3b6f2d08ceb5b38ff9c4583103cbe9', 'cab9106cabc965de5654e937fdd7108779669884>d985d77098bce6ddba0dda6880dade803a1ffbc7', '388c8e6ba7646f46e499dffc00557cfe769a5dda>23c6c94534378c204c0ee21fdaebd23fd4691bcf', '1b69830499fe27ffa7e1752f76bf7a1b412f509d>3dac6d4eb221945f009c543a65537513d186c5ed', '6cf8c878005b383009bc2c1366f37ac7ba4a1eec>d7b16091b800b035259e82296876124e9d9d8e3a', 'ed603928cb3f313a58e3c36090e74d4fa37b0100>3dcc3d1a44afc919d8afff2c9a598fd24a57b0d3', '62f9420cb7ce1327c2c8fcd1c48538ed87274cd2>983dfc44a86d441fb7ae5ec3b39e919ff8832b76', 'e8b98c4799f4095d14a3eaa75e0ad464e2715aa5>5b349d4294ba4387cbbb237f87727850700c6970', '1e22584fc8f7f0deea6e96df287c37c37ba86c6b>f2e8507a54cb42a001465944fc7113c43bb0a61a', 'd543ce5e35d1671e3df4f8703a1b5949bac800b6>None', 'b8bffa786710b52c95201796bade07fc2ad3f38d>0049b630e0bf4b14e76e36615c33aed0c39c3dd9']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 105,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 113, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  84, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 117,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  83, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 101,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 106, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,   421,   727,   706,     8,  9336,     7,     6,  1131,   727,\n",
      "           706,     8, 14688,     7,    28,     4, 13959,    37,   231,    10,\n",
      "           138,   267,    28,     4,   113,  1503,  5655,     5,  5690,  1806,\n",
      "         38267,     7,  1600,     2,    34, 35826,  1656,     8, 26135,     7,\n",
      "            31,  2244,    10, 20571,   166,     4, 13959,  1656,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  890,   137,    38,    46,   105,    17, 38192, 20273,    12, 24534,\n",
      "             2,    32,    16,  3636,     9, 42910,    91,     2,    38,    34,\n",
      "           206,  3162,    18, 14363,     2,   557,     9,    15,  1141,   518,\n",
      "             5, 14363,    19, 42911,   912,     2,    15,  7345,   762,     9,\n",
      "         42912,   386,  3552,     6, 12868,    12,   501,  1267,     8,  1898,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [35512,     6,  1281,    12, 35513,    99,   470,   914,     5,     4,\n",
      "           752,    12,  3245,     2,   867,    12,  2166,     2,     6,  1627,\n",
      "            12,  3245,     2,   784,    23,    34,  7927,     3,   752,    12,\n",
      "          3245,   948,    31,   281,    44,   343,     2,    22,     9,     4,\n",
      "            62,    23, 35514,    11,    14,     3,     8,    97,     7,     3,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1140,  4192,  1229,    17,    24,   676,    10,  2343,  1987,     6,\n",
      "           740,    10,   917,   171,  1620,     9,  7003,  2343,  2174,    24,\n",
      "           537,   764,   227,  1632,   164,  2343,  2389,     8, 23814,    11,\n",
      "            14,     3,     2,    79,    13,  4223,    11,    14,     3,     2,\n",
      "          2121,    13,  2022, 23815,    11,    14,     3,     2,   104,    13,\n",
      "         15358,    11,    14,     3,     2,   118,     7,     3],\n",
      "        [   35,  5098,  3339,  1440,    22,    15,   447,  1199,   363,  5148,\n",
      "          7058,     6,  7274,     9,  8107,     8,   170, 14617,    11,    14,\n",
      "             3,   995,    13,   971, 16928,    97,    13,  3006,     6, 16929,\n",
      "            79,     7,     2,    15,   184,   603,     5,  7274,     6,  2268,\n",
      "          7557,    23,  8107,   378,    17,  7274,   264,    27,   292,    34,\n",
      "         15286,  1965,     2,    35,     0,     0,     0,     0],\n",
      "        [  311,    52,  2782,    19,   102,   388,   410,   774,    17,    15,\n",
      "           258,   773,    10, 16761,  1773,  2394, 22574,  1372,     9,   120,\n",
      "          2087,     8,   541,    11,    14,     3,     2,    68,     7,     6,\n",
      "            17,    15,   258,  2548,     5, 14196,     9,   947,  1135,     9,\n",
      "           206, 22575,  1372,     9,   412,     8, 22576,    11,    14,     3,\n",
      "             2,    83,     7,     3,     0,     0,     0,     0],\n",
      "        [   90, 10092,  5301,  1120,   953,    12,   352,   323,     4,  3846,\n",
      "           814,   925,    18,     4,  1029,     6,  1381,     5,   195,  2535,\n",
      "             5,    53,    18,   108,   370,   211,   439,     2,   452,   211,\n",
      "           410,    30,   279,     4,  1314,     5,     4,  1192,  4606,     9,\n",
      "             8, 30605,    11,    14,     3,   113,     7,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1194,   184,  1906,    30,   105,    17, 14873,    30,  1612,  6767,\n",
      "             6,   352,    99,   587,     6,   386,  1675,  2288,   540,     8,\n",
      "          4710,     6,  8611,     2,   142,    13,  9560,    11,    14,     3,\n",
      "             2,    85,    13, 18337,     6,  4710,     2,    79,    13, 30532,\n",
      "         30533,     2, 30534,     2, 26949,     2, 30535,     2,   113,    13,\n",
      "         18338,     2,  1527,     2,  8805,     2,    36,    35],\n",
      "        [   26,   523,   251,     5,   192, 25070,     9,    39,    62,    16,\n",
      "           935,    10,    17,   267,    23,  6292,    11,    14,     3,     8,\n",
      "            87,     7,    44,  4108,     2,     6,    16,    46, 12170,    19,\n",
      "            52,    48, 16172,     8,  2245,    11,    14,     3,   198,    13,\n",
      "         11548,    12, 13404,    11,    14,     3,    70,     7,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   64,   986,   988,    16,   228,    19,   682,    53,    21,   346,\n",
      "            20,     6,     2,    18,   270, 11223,     2,  2233, 21292, 42892,\n",
      "             5,     4,  1956,   896,     8, 22893,  5182, 42893,    13, 22893,\n",
      "          5182,  1652,   896,     2,    15,   155,   120,  4628,     2, 33451,\n",
      "           155,  1652,   732,     7,    18,   108,  1652,  4740,     5,     4,\n",
      "         16033,     8,  1860,     0,     0,     0,     0,     0],\n",
      "        [   35,   807,   682,   392,    37,   841,    10,   698,     4,  6825,\n",
      "          1916,   150,    19,    86,  5365,     5, 12566,     2,    22,  1324,\n",
      "            47,     8,    57,     7,    26,   149,   232,  2938,     5,   369,\n",
      "            19,     4, 12633,  1754,     5,     4,  7430,   246,     8, 17002,\n",
      "             7,     2,    69,   774,   298,  1318,     8,  8712,    11,    14,\n",
      "             3,   104,     7,     3,     0,     0,     0,     0],\n",
      "        [  153,    38,   338,    33,   238,    17, 37703,   177,    25, 37704,\n",
      "         24655,   655,     4,  8334,     5,   107,   487,    10,  7928,   256,\n",
      "            12,  6556,  1432,     2,   557,     9,     4, 21954,     5,   615,\n",
      "           256,    12,  6556,     2,    32,    16,    15,   676,   652,     9,\n",
      "         14620,   712,     9,   317,    91,    21,   662,    20,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   41,   585,     2,    43,    37,   584,    10,  1310,   257,    10,\n",
      "          1172,    73,     5,     4,  3782,   349,     9,  6971, 34877,     2,\n",
      "             5,    32,  4282,   707,    31,     4,   101,   171, 11520,     2,\n",
      "            32,    16,     9,   375,    19,   102, 34878,     7,   152,     2,\n",
      "            51,    38,    33,   378,    17,  3782,   349,   185,    42,    27,\n",
      "          1739,    23, 13590,     3,     0,     0,     0,     0],\n",
      "        [  595,    55,    49,    30,  3521,  4675,    86,    28,    71,   188,\n",
      "             2,  1526,    17, 31007,     6, 40306,    37,  2122,     5,  8637,\n",
      "          6871,    25,    96,   468,  8251,    29,    25, 40307,   268,  6893,\n",
      "         33160,     8,   454, 11596,    11,    14,     3,   198,    13, 16977,\n",
      "            11,    14,     3,    79,    13, 40308,     2,    61,     2,    75,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1158,     2,   145,    38,    33, 11453,   581,     9,  2630,     6,\n",
      "          5449,  2530,  3412,  1447,     8, 18363,     7,   303,    18,  2717,\n",
      "          2209,   808,    18,   289,   146,     4,   987, 15357,   287,   272,\n",
      "            42,  3653,    21,   128,     2,   224,     2,   222,     2,   254,\n",
      "             2,   533,     2,   313,     2,   630,    20,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1600,     2,    51,    16,   171,    10,   768,    17,   101,    49,\n",
      "          3654,   214, 10428, 10373,   263,    10,  6662,  1874,   845,    30,\n",
      "            45, 40742,     7,   743,  4310,   370,    95,    19, 14378,     2,\n",
      "          4424,   264,    46,    27,  3228,    17,   145,    24,  1686, 14378,\n",
      "         40743,  2840,   193,     9,    39,   405,     5,  2445,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 1, 1, 0, 0, 2, 1, 0, 2, 2, 1, 0, 1, 2, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['cec9296bc76527cbb3e089683e2e73dcd219e672', '01eca65fa2cd4dce86de183c38ceafe4b2e5000a', '29248e78f2057ef835bb444c9be4a19829df9dc0', 'cf82d977a64226a15cca9fc0eea7de1e0078ce29', '4224c52c6fdc56de9a6512a4ae090ee739a85a7c', '440cd84e5d0b7f825bb7c37f0bf5d08ae74b05ab', 'd785135cbce67f217df1384c5363efd2cad1401a', 'd3ec746e4b2cc8fffc3cce7a9b5c0a7de44a168c', 'f1b376025a76b7b963f660e30d67311a9093e4ed', '06d0ae65c26cd0770f46b81a8d8f8daae7f04d59', '25a16f6fda8c4a6b685a3a99315cca3eb148eec2', '87b1af94b929c349f0edfadd012fd5dc9898b06a', '46def914a6300ed429e2df50349a60e17007bc3a', 'ab0930fc23c454f0099ee1280b23027e5a5658a5', '197bc2ca508c76ed2183c51ceb2ea6324a7df1a1', '2d713b4daaaeba1a1880961e289c4ed8a0da765a'], 'cited_paper_id': ['3d7c99040f3c4c3610955feb10e26e6f5e7dad5e', '2fd42779ada2f3166880ef26edb066505cf4b662', '62568ff0d30f5935f874a409cbf3ee3ddf3fea0a', 'efe167e81022b9fb2b41ea7de996515c26f94838', 'f54f92bf89f588cc69dc2fedf604f912a04f7f32', 'aaa755ce1aede91735d14134e213374a11df5ee7', 'aed0a148d5c6775f6b906b9b8a5d58dd6dac99d7', 'd04b2ec8089a6489bc9121f49d3106fa093fe4ea', '23e5d7986d48bd9e88ddf480a86c3826d39cc4a6', '37e7ba41fa4f19d0d75e054276dafd86f2e90d28', 'c08d82e0e656dadaa0c26b1a21fe57fa60bb84d8', '075e2e09c9ad011296c661d0afc6369a3c23a5b0', 'b2e26688906af9d75689aa8476627a533b6885d8', 'None', 'b34f1e4fafca82ce6740e14718eec338cfbd76de', 'b4847a212095e8bb97d0ce3209b3429cef5ea6a0'], 'citation_excerpt_index': [0, 0, 0, 19, 1, 0, 3, 4, 1, 3, 6, 0, 0, 0, 1, 1], 'citation_id': ['cec9296bc76527cbb3e089683e2e73dcd219e672>3d7c99040f3c4c3610955feb10e26e6f5e7dad5e', '01eca65fa2cd4dce86de183c38ceafe4b2e5000a>2fd42779ada2f3166880ef26edb066505cf4b662', '29248e78f2057ef835bb444c9be4a19829df9dc0>62568ff0d30f5935f874a409cbf3ee3ddf3fea0a', 'cf82d977a64226a15cca9fc0eea7de1e0078ce29>efe167e81022b9fb2b41ea7de996515c26f94838', '4224c52c6fdc56de9a6512a4ae090ee739a85a7c>f54f92bf89f588cc69dc2fedf604f912a04f7f32', '440cd84e5d0b7f825bb7c37f0bf5d08ae74b05ab>aaa755ce1aede91735d14134e213374a11df5ee7', 'd785135cbce67f217df1384c5363efd2cad1401a>aed0a148d5c6775f6b906b9b8a5d58dd6dac99d7', 'd3ec746e4b2cc8fffc3cce7a9b5c0a7de44a168c>d04b2ec8089a6489bc9121f49d3106fa093fe4ea', 'f1b376025a76b7b963f660e30d67311a9093e4ed>23e5d7986d48bd9e88ddf480a86c3826d39cc4a6', '06d0ae65c26cd0770f46b81a8d8f8daae7f04d59>37e7ba41fa4f19d0d75e054276dafd86f2e90d28', '25a16f6fda8c4a6b685a3a99315cca3eb148eec2>c08d82e0e656dadaa0c26b1a21fe57fa60bb84d8', '87b1af94b929c349f0edfadd012fd5dc9898b06a>075e2e09c9ad011296c661d0afc6369a3c23a5b0', '46def914a6300ed429e2df50349a60e17007bc3a>b2e26688906af9d75689aa8476627a533b6885d8', 'ab0930fc23c454f0099ee1280b23027e5a5658a5>None', '197bc2ca508c76ed2183c51ceb2ea6324a7df1a1>b34f1e4fafca82ce6740e14718eec338cfbd76de', '2d713b4daaaeba1a1880961e289c4ed8a0da765a>b4847a212095e8bb97d0ce3209b3429cef5ea6a0']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 102, 113,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 227, 129,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 111, 102,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[ 717,   24, 3014,  ...,    0,    0,    0],\n",
      "        [  35,    5, 4775,  ...,   35,    0,    0],\n",
      "        [ 775,  783,    5,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  88,  689,    9,  ...,    0,    0,    0],\n",
      "        [  26, 5852,  550,  ...,    0,    0,    0],\n",
      "        [ 890,   49,   30,  ...,    0,    0,    0]], device='cuda:0')}, 'labels': tensor([0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['48bff8eae05fb5369b0026742eaa79178e107fbb', '39d8e388224109f81f3ef8cfbd2c98510c07894e', 'a28270dc530162243ec04b03b79d7af862e6c7b7', '28de460cd76fc42f220dcc289ebe78c72b1d52a4', 'fa18c3fed3fd12245500814122a406eed7b66eca', '33cb20c89f0246ec9db4f0c038ba29e6dc1c76c2', 'ca553e48356333cdd5b9ad787e3eb6b67dc99f38', '0fc7122046b028d1b26cc1d6cedf59bac39affb9', '43763b0d91805b7beaedd79f44057b7b5ab8f0c9', 'fb938c1588cd2a4db72b97f9f1b27b731294e12f', '15773ea7112a6b3149fe55d7c9602b23375b3705', '8c6cce1fbc57de411affb7d09fe11b1d2c6e5861', '03c16bd50bba8468fceb06338cf2401e3d0aedc2', '1a222e6c1642c51dd6c527a91533a310a7d25fc7', '87ee0e22badbf753b4e2656a6840cb629ea2e701', 'ed3b55b5b937f4e201dcf62fe64b9b0b6dc7c64c'], 'cited_paper_id': ['bc6ad001c395e92920839e45dfd7e05ce69405d2', 'e8ae6c46403d86e8170ef9fc353f1ab643acc372', '65c59f68c0e41d3f91f9fc0c98270de414b9e792', 'bc879474e921fe52dd36815abe0f0089f28ddc70', '76fa9d010a94151202b0aa7ee3cfdc76065711f4', '7caf30852a3191f350d7acdc2f996d1db81b1b72', '96c2ad2361d4619b9b0e4de33faa9dded603f49d', 'b8d47b0c0b12dd77543e82e6bf6636ddd335cfea', 'd499c7c0d3b907c1bf7a6f61c239599c02d5a1df', '941f7c3c36dd13ebb7d3a0e48d2872e0f2e44c28', '78d26d223331a183fe108eaee8cf1b444e09e1b2', 'eac9c263d99f397dfc2518ac55f610130aac32a7', '4ce59c87f2669cf56c846778a477210cd278f8eb', '311db1e4f5fbefb1ac86618c6772194393acc134', '5ed47e8dad33d5222bd7004a06a1fd8df002ac57', '7f51a31f6acb467b0d3d39d5ab2a570033362a4b'], 'citation_excerpt_index': [8, 1, 0, 4, 1, 2, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0], 'citation_id': ['48bff8eae05fb5369b0026742eaa79178e107fbb>bc6ad001c395e92920839e45dfd7e05ce69405d2', '39d8e388224109f81f3ef8cfbd2c98510c07894e>e8ae6c46403d86e8170ef9fc353f1ab643acc372', 'a28270dc530162243ec04b03b79d7af862e6c7b7>65c59f68c0e41d3f91f9fc0c98270de414b9e792', '28de460cd76fc42f220dcc289ebe78c72b1d52a4>bc879474e921fe52dd36815abe0f0089f28ddc70', 'fa18c3fed3fd12245500814122a406eed7b66eca>76fa9d010a94151202b0aa7ee3cfdc76065711f4', '33cb20c89f0246ec9db4f0c038ba29e6dc1c76c2>7caf30852a3191f350d7acdc2f996d1db81b1b72', 'ca553e48356333cdd5b9ad787e3eb6b67dc99f38>96c2ad2361d4619b9b0e4de33faa9dded603f49d', '0fc7122046b028d1b26cc1d6cedf59bac39affb9>b8d47b0c0b12dd77543e82e6bf6636ddd335cfea', '43763b0d91805b7beaedd79f44057b7b5ab8f0c9>d499c7c0d3b907c1bf7a6f61c239599c02d5a1df', 'fb938c1588cd2a4db72b97f9f1b27b731294e12f>941f7c3c36dd13ebb7d3a0e48d2872e0f2e44c28', '15773ea7112a6b3149fe55d7c9602b23375b3705>78d26d223331a183fe108eaee8cf1b444e09e1b2', '8c6cce1fbc57de411affb7d09fe11b1d2c6e5861>eac9c263d99f397dfc2518ac55f610130aac32a7', '03c16bd50bba8468fceb06338cf2401e3d0aedc2>4ce59c87f2669cf56c846778a477210cd278f8eb', '1a222e6c1642c51dd6c527a91533a310a7d25fc7>311db1e4f5fbefb1ac86618c6772194393acc134', '87ee0e22badbf753b4e2656a6840cb629ea2e701>5ed47e8dad33d5222bd7004a06a1fd8df002ac57', 'ed3b55b5b937f4e201dcf62fe64b9b0b6dc7c64c>7f51a31f6acb467b0d3d39d5ab2a570033362a4b']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  52,  67,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  79,  98,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  80, 118,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 116, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 113, 112,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  68,  67,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 120, 102,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[12613,    22,   103,    22,     9,   612,   126,     8, 26224,    11,\n",
      "            14,     3,     2,   104,    13, 17316,    11,    14,     3,     2,\n",
      "            83,    13,   746,    11,    14,     3,     2, 26225,    11,    14,\n",
      "             3,     2,    63,     7,     2, 26226,    24, 12415,  3116,     3,\n",
      "             0,     0,     0],\n",
      "        [42418,     2,    15, 25585, 42419,    18,     4, 42420,     6, 25586,\n",
      "             2,    31,   841,   179,   102,    49,   997,    39,  1091,    10,\n",
      "            27,    15,   834,  3609,  4221,    44,     4, 25586,     8,  7317,\n",
      "            11,    14,     3,   151,    13, 42421,    11,    14,     3,    68,\n",
      "             7,     3,     0],\n",
      "        [  311,    52,   259,    17,     4,   552,   432,     5, 16183,    17,\n",
      "           389, 10597,     6,   138,    17,   389,    42,    31,  4049,  3579,\n",
      "           241,     2,     9,   685,    19,   102,  1458,    21,   571,    20,\n",
      "           883,    17, 16183,     5,   139,   432,    30,     4,   167,  4810,\n",
      "           373,     3,     0],\n",
      "        [35792,     8, 38237,     2, 38238,    12, 26122,    11,    14,     3,\n",
      "             2,    89,    13, 38239,    11,    14,     3,     2,    76,    13,\n",
      "          3608,    11,    14,     3,     2,    76,     7,    17,    30,    33,\n",
      "          1279,    45,     9,   246,   863,   400,     3,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  719,    12,  6569,  5946,    37,  1000,    19, 27704,     8, 27705,\n",
      "         27706,    10,  7082,    18,   719,    12, 13418, 17102,    13, 26256,\n",
      "            11,    14,     3,   132,     7,    10,   290,  4022,    10,    15,\n",
      "           814,     5,  2607,  3865,   540,     6,  1126, 16576,  3019,     4,\n",
      "          2001,   839,     3],\n",
      "        [   26,  1147,  1273,     5,   299,   691,   406,  9484,    12,   787,\n",
      "           194,    21,   295,     2,   494,     2,   254,     2,   240,     2,\n",
      "           399,    20,    32,    30,   338,   738,    15,   250,  1247,   981,\n",
      "           826,   124,    18,   801,   360,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [    2,   255,    13, 11568,    12, 15272,     6, 11017,     2,  5233,\n",
      "             7,    29,    23,  4802,     2,     6,  6579,     4,   886,     5,\n",
      "             2,    34,   148,   148, 14694,   734,  5901,     8,  1570,    11,\n",
      "            14,     3,     2,   367,    13, 10850,     6,  9244,     2,   274,\n",
      "             7,     3,     0],\n",
      "        [  665,     2,     4,  2071,     5, 12362,   531,     5,     4,  1467,\n",
      "             5,  2473,  1637,  1555,     4,   102,    21,    57,     2,    72,\n",
      "            20,   296,    17,  8168,     6, 11602,    24,   885,   663,    23,\n",
      "           488,   173,   326,     5,   445,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [ 1487,    39,  6936,    59,     2,  9039,    31,    92,    10,  1300,\n",
      "           387,    10, 12191, 10811,  2486,     2,  3758,    18,  1026,     2,\n",
      "          2147,     6,  1393,    73,     5,  2102,  2158,   496,     4,  2672,\n",
      "         22110,     2, 15263,     6,  2672,  3871,     2,   463,    21,   297,\n",
      "            20,     3,     0],\n",
      "        [   26,  1898,  1930,  1355, 10822,   263,    37,   490,    67,   343,\n",
      "             6,   273,    67,  6331,    37,   657,    22,   203,    12,  3387,\n",
      "          1930,     8,  6405,    11,    14,     3,     2,    68,    13, 13339,\n",
      "             6, 13081,     2,    63,     7,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [ 3463,    18,  1258,     2,  3392,     6,  2781,     5,     4,  1648,\n",
      "         45004,  3624,   246,     6,     4,    81, 18341,     2,  9114,   532,\n",
      "            37,    22,   122,   503,     8, 45005,    11,    14,     3,     2,\n",
      "            76,    13,  6197,    11,    14,     3,     2,    63,     7,     3,\n",
      "             0,     0,     0],\n",
      "        [    2,   390,     7,     9,   266,     6,    10,   796,   633,  2287,\n",
      "           248,     9,   331,     8,   955,    11,    14,     3,     2,    68,\n",
      "            13,   955,     6,  4773,     2,    75,    13,   746,     6,  1786,\n",
      "             2,    63,    13,  4412,    11,    14,     3,     2,    68,     7,\n",
      "             3,     0,     0],\n",
      "        [ 4736,     5,  7978,   854,     9,     4,  3197,     6,  5346,   144,\n",
      "           247,  1086,   138,   338,    82,     9,     4,  5346,     2,   146,\n",
      "             4,  5207,  3835,   128,  1483,    16,    46,   565,     8,  6407,\n",
      "            11,    14,     3,     2,    63,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  323,  2048,  1840,   962,   461,    54,    25,     4,   526,    73,\n",
      "          5888,   810,     5, 30422,    36, 30423,     8,   575,     7,    16,\n",
      "          1102,    10,  1226,    54,    25,    15,   195,   117,     5,   220,\n",
      "             2,    71,    52,    24,  5055,   228,    19,    60,   810,     3,\n",
      "             0,     0,     0],\n",
      "        [   26, 19873,  5107,    22,   304,   175,   440,    18, 15609,     2,\n",
      "         22899,     2,     6, 22900,     8,   222,     2,   313,     7,     2,\n",
      "           530,     4, 18015, 15372,  7161, 22901,     2, 22902,     2,     6,\n",
      "         22903,     8,   128,     2,   371,     2,   494,     7,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [   37,   872,    10,   511,   670,  1569,     9,   102,    49,     8,\n",
      "         37311,     2, 15961,     2, 37312,     2, 37313,     2,    36, 37314,\n",
      "             2,   118,    13, 37315,    11,    14,     3,     2,    75,     7,\n",
      "            37,   267,    23,    15,   137, 13609,    28,     4,   919,  2705,\n",
      "             3,     0,     0]], device='cuda:0')}, 'labels': tensor([1, 1, 2, 1, 1, 0, 0, 2, 1, 0, 1, 0, 0, 2, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['b65b51c796ed667c4c7914bf12b1926fd6bbaa0c', '7757285c6d16c92f318c0cffb996aaf13d81df0b', '49955b2a9e7b42ca61a6f0f1f888a79468c25361', '440a87ddd8a44f8cb07d36f87eeff32bc8425b28', '4a869eefba626d41997ee97dffc9174f4468a5b1', '18338cd6134f8b663574072da97cba18f3ab69e0', 'de55a5cd1616bf4539bf66936b34e90a594cabee', '15df16647fe08cfa55f6394466051a15de669bc0', '27ea0aa5f8d3e1dc7c449aceef59524dd32307b5', '88edbd25bbcb41311a5eb7553c9439c72f7bbc3f', '5ddd341c20f323d736e9b3899ad20561c9bdbeea', '1ed8042c32b484573035db874ee8db00b77ba326', '602d56f55b8c21475c9bf67e73c5d8e999ee9696', '41c7bdd249f2ec4747e8058a887093aa1de2adbb', '110777d2210aae5141710059f0f1b64a22c2bf8c', 'f52cfb33395198ee926d181bfb3ed3dd157f8f75'], 'cited_paper_id': ['8a23052c3e2e3f3ad0ed2b854e326162f9f17c0a', '9d87d83e29f83e6313fec1c63fdc77fe732936b5', '9d859a8c7783e3135d4377ae530512f932b6fea1', 'a7dbee568a136baf5661953a3870c5a64ae138aa', '119f3dd35aba1f07668714c08b0b8ad6a955d383', '39dc218eb5582e861e53c8451586786cfaca08ec', '32a089cfda93488dd4ce93bef85500d27e660d8d', '6df06870159aba56e4a428513000e7bc4de96003', '21cc7a2a24c33fe78ab21acf5ea2d548fa11b0d3', '8934adb4658ebb3061494086087f5428699feb3d', '8f2cfced117e54b3e1ba97b0e43f34e0ec747952', 'f08f08fab4db474ed6d556b908622d95afa2704f', 'd9bb6f5360b6e9413e5f675d4164e29a6040a7c0', 'None', 'c36df64ee3684de6c81c61463f6aabfdb09987d5', 'b8c3fdf1065d356b2af7b078aa09affe52686fdd'], 'citation_excerpt_index': [0, 0, 2, 2, 0, 2, 1, 1, 5, 0, 10, 3, 6, 0, 0, 0], 'citation_id': ['b65b51c796ed667c4c7914bf12b1926fd6bbaa0c>8a23052c3e2e3f3ad0ed2b854e326162f9f17c0a', '7757285c6d16c92f318c0cffb996aaf13d81df0b>9d87d83e29f83e6313fec1c63fdc77fe732936b5', '49955b2a9e7b42ca61a6f0f1f888a79468c25361>9d859a8c7783e3135d4377ae530512f932b6fea1', '440a87ddd8a44f8cb07d36f87eeff32bc8425b28>a7dbee568a136baf5661953a3870c5a64ae138aa', '4a869eefba626d41997ee97dffc9174f4468a5b1>119f3dd35aba1f07668714c08b0b8ad6a955d383', '18338cd6134f8b663574072da97cba18f3ab69e0>39dc218eb5582e861e53c8451586786cfaca08ec', 'de55a5cd1616bf4539bf66936b34e90a594cabee>32a089cfda93488dd4ce93bef85500d27e660d8d', '15df16647fe08cfa55f6394466051a15de669bc0>6df06870159aba56e4a428513000e7bc4de96003', '27ea0aa5f8d3e1dc7c449aceef59524dd32307b5>21cc7a2a24c33fe78ab21acf5ea2d548fa11b0d3', '88edbd25bbcb41311a5eb7553c9439c72f7bbc3f>8934adb4658ebb3061494086087f5428699feb3d', '5ddd341c20f323d736e9b3899ad20561c9bdbeea>8f2cfced117e54b3e1ba97b0e43f34e0ec747952', '1ed8042c32b484573035db874ee8db00b77ba326>f08f08fab4db474ed6d556b908622d95afa2704f', '602d56f55b8c21475c9bf67e73c5d8e999ee9696>d9bb6f5360b6e9413e5f675d4164e29a6040a7c0', '41c7bdd249f2ec4747e8058a887093aa1de2adbb>None', '110777d2210aae5141710059f0f1b64a22c2bf8c>c36df64ee3684de6c81c61463f6aabfdb09987d5', 'f52cfb33395198ee926d181bfb3ed3dd157f8f75>b8c3fdf1065d356b2af7b078aa09affe52686fdd']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 119,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69, 118,  ..., 261, 261, 261],\n",
      "         [259,  83,  79,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  68, 109,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  72,  98,  ..., 261, 261, 261],\n",
      "         [259, 102, 111,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259,  81,  69,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,   263,     5,     4,   615,   372, 34838,  2355,    21,   343,\n",
      "             2,    72,    20,     2, 30308,  2355,    21,   343,     2,    57,\n",
      "            20,     2,     6, 20929,  2355,    21, 28440,     2,    72,    20,\n",
      "            24, 11317,    10,   624,    15, 34839,  1993,  2581,     3,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 1828,   719,  1432,     2, 13883,  3624, 14494,  2228,    67,  7513,\n",
      "          3624,     2,     6,   583,     2,     4,  1454,     5,   214, 13883,\n",
      "          3624,  4591,   231,    10,  7513,  4591,    38,    33,  1618,    22,\n",
      "            15,  3435,     5,  6113,   719,   332,     8,  5255,    11,    14,\n",
      "             3,    70,     7,     3],\n",
      "        [ 2603,   410,     5,  8671,   397,     9, 14780,  5158,     8,   254,\n",
      "             2,   222,     7,  6683,  1177,    10,   395,  1123,  7056,     2,\n",
      "          1123,  3855,   117,     2,  2682,  4101,    80, 10939,     2,     6,\n",
      "          1892,  3326,     9,    65,    72, 14780,   894,   115,     3,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 3463,    18,  1258,     2,  3392,     6,  2781,     5,     4,  1648,\n",
      "         45004,  3624,   246,     6,     4,    81, 18341,     2,  9114,   532,\n",
      "            37,    22,   122,   503,     8, 45005,    11,    14,     3,     2,\n",
      "            76,    13,  6197,    11,    14,     3,     2,    63,     7,     3,\n",
      "             0,     0,     0,     0],\n",
      "        [14007,    16,    46,    15,  1865,   727,     5, 30823,  2325,     8,\n",
      "          3025,     6, 37711,     2,   118,     7,     6,    31,   338,   105,\n",
      "            10,    27,   435,    18,  1950,  3552,    44, 37712,     8, 11026,\n",
      "            11,    14,     3,     2,   190,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [32421,   414,  1921, 30226, 32422, 17700,     9, 14487,    26,  4808,\n",
      "           414,     5, 17701,    16,  1228,    42,    10,   576,  1567,    12,\n",
      "          2071,     5,     4,  1239,    69,  1015,  3603,     9,   107,  1513,\n",
      "            10, 14176,   162,     8, 11488,    11,    14,     3,     2,    70,\n",
      "             7,     3,     0,     0],\n",
      "        [  169,    73,    16,  1087,    10,    55,    82,   592,    80,  2696,\n",
      "            21, 16103,    20,     2,  1667,     4,  4631,   861,  1364,   285,\n",
      "           461,    54,    25,     4,   455,    12,   818, 11266,  1255,     6,\n",
      "           214,  2252,     5,   382,    19,  2799,     9,    39,   405,     3,\n",
      "             0,     0,     0,     0],\n",
      "        [   26,  5074,   247,    17,   161,  6014,  3346,  9543,    10,  4586,\n",
      "             9,  1082,    69,  3035,  1410,    12, 18870,    19,  4586,     9,\n",
      "           947,     8,  3843,     6,  2026,     2,   113,     7,   378,    17,\n",
      "          3946,   403,  1793,  9941,    19,  4586,     9,   947,     3,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [   26,   820,     5, 11570,    10,     4,  2652,     5,  6923,     9,\n",
      "          2018,  3699,    12,  8248,     6,     9, 21088,    12,   324, 33453,\n",
      "            38,    33,   238,     9,  1201,   115,     2,   261,     4,  2424,\n",
      "             5,    39,  1965,    16,   114,     8,   767,     2,  2047,     7,\n",
      "             3,     0,     0,     0],\n",
      "        [ 3346,    10,    34,  2266,    12,  1468,   336,     5,  8888,     2,\n",
      "          7102,     4,   518,    58,  8888,     6,   107,  2562, 18969,     7,\n",
      "            41,   253,     2, 15182, 35288,    19,  2021, 13650,     9,    65,\n",
      "            91,     8,    53,    42,   105,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [27437,  1469,    12,   434,  4782,    37, 10010,     6,  2844,     9,\n",
      "         14064, 10435,  1459,    45,    18,  7370,   123,    22,   100,   504,\n",
      "             2,     6,   122,     8, 27438,    11,    14,     3,     2,    79,\n",
      "            13, 27439,    11,    14,     3,     2,    76,     7,     3,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  112,     4,  1872,    12,   218,   472,     2,     4, 33121,  1238,\n",
      "             2,     4, 33122,   912,  1238,     2,     6,     4, 33123,  1238,\n",
      "             2,  9543,  1871,   120,   964,    37,   841,     6,   930,     2,\n",
      "            22,   122,   100,     8,    90,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 9097,     5,  1601,   175,   423,  3128,  9196,   559,   136,    81,\n",
      "          8004,  1171,    47,  2619,  6259,     8,  6133,    11,    14,     3,\n",
      "             2,    89,     7,     6,  2619,   168, 15646, 11015,     8,  6133,\n",
      "            11,    14,     3,     2,    76,     7,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  394,    16,    15,   241,   242,     9,     4,   163,     5, 38220,\n",
      "          1250,     9,     4, 14373,     6,  5384,     5,    95,  2632,  1057,\n",
      "         14783, 38221,     7,   152,     2,   136,     4,   594,   398,     5,\n",
      "         14685,   328,     2,   752, 38222,    16,     4,   101,  1049,   150,\n",
      "         17837,     3,     0,     0],\n",
      "        [27814,  1904,     5,     4, 11256,  1109,    16,   617,   193,    19,\n",
      "         27815,     7,    26,   193,   211,  3089,  1879,     9,    17,     4,\n",
      "          4413,   359,    31, 25100,    10, 10214,    25, 27816, 12056,   302,\n",
      "            19,     4,  2345,  1066,   931,    46,   288, 10214,    10,   434,\n",
      "             3,     0,     0,     0],\n",
      "        [12400,     5, 12870,    38,    33,    92,    10,   242,     4,   915,\n",
      "             5,  2765,  1100,  4167,   607,     9,  1082,     8, 21966,    11,\n",
      "            14,     3,   131,     7,     6,  3975,  1034,     9,     4,  5484,\n",
      "             9,   947,     8, 12871,    11,    14,     3,    63,     7,     3,\n",
      "             0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['beef379e2c87cebff7d96c80a3ab1f8d0f2ea4f2', '941df9dcd2d4ba6e6f641527e667a4bca4a9d23e', '326861d2fcb678c73ebdb8e065998cbab5f9f6e9', '5ddd341c20f323d736e9b3899ad20561c9bdbeea', '4b7fb669b26ad84ad0e373d2f86c092e4d484de0', 'b5a076b270d17b28cfb0a389bc503d12b5f64288', '9aed24e5ae0dba564ed6824c6f1002efd50b027e', 'efaa33b745b1420d6bf13873a4df09680c7984e0', 'ea549e03484e32bde134b81a393e41f2f4a4358b', '834bccb30cf1a6bc4bc90eae56a52dbe0c6ae58a', '762819dc64e6645ccc70cc12a3fab01991f78625', 'a2580213e98f7e52ca6deaf2350f35337918b5de', '015038751590ece620f549179941d32ba095296b', 'add5e7be3d6ebe9f978fe96e56b9a12d62bcdc49', 'd5e9bb418f5183ebcaf371efce583b2e710315ef', '6c3ef1022fbb6b38ab117a35741be05446819fd2'], 'cited_paper_id': ['146bb2ea1fbdd86f81cd0dae7d3fd63decac9f5c', '7449ebce258d5d0ac3e875a2fc20b7407d862f63', 'a81fc7d0035f1f651b8454f05274ebeee6dc6acc', '8f2cfced117e54b3e1ba97b0e43f34e0ec747952', 'cac61585d7387b0bc03739e06a69413021094014', '4044489d3f31cec999bc6cba9d7c7f91e511ffb2', '69e24119117961e4ae92961e2a0e3deed4218504', 'eb08d5a6852228a7b45deb22f1bf4dde945020c6', '6e3bc8d4687cef9229e3206cb786c0233ed7698c', '37ed03a41b15e5119c8f0ac76dce581e1cd23fb9', 'a1f61a980667f6634597412ae73861a3c92bd4da', 'f756821621011ae527d578399406bb1cc48b4068', 'ac640d57175a0af92ba0a4a538349f2e85bdba28', '5698bd0a2a6365e64ef89e2ed56d7e281d8c6785', '6aa6183f41837ccaed16951fe32e9e3e861a0356', '2ad37d4e710386fc101c999e570b18a26265e1dd'], 'citation_excerpt_index': [1, 1, 0, 10, 1, 3, 8, 11, 0, 0, 12, 0, 0, 0, 1, 1], 'citation_id': ['beef379e2c87cebff7d96c80a3ab1f8d0f2ea4f2>146bb2ea1fbdd86f81cd0dae7d3fd63decac9f5c', '941df9dcd2d4ba6e6f641527e667a4bca4a9d23e>7449ebce258d5d0ac3e875a2fc20b7407d862f63', '326861d2fcb678c73ebdb8e065998cbab5f9f6e9>a81fc7d0035f1f651b8454f05274ebeee6dc6acc', '5ddd341c20f323d736e9b3899ad20561c9bdbeea>8f2cfced117e54b3e1ba97b0e43f34e0ec747952', '4b7fb669b26ad84ad0e373d2f86c092e4d484de0>cac61585d7387b0bc03739e06a69413021094014', 'b5a076b270d17b28cfb0a389bc503d12b5f64288>4044489d3f31cec999bc6cba9d7c7f91e511ffb2', '9aed24e5ae0dba564ed6824c6f1002efd50b027e>69e24119117961e4ae92961e2a0e3deed4218504', 'efaa33b745b1420d6bf13873a4df09680c7984e0>eb08d5a6852228a7b45deb22f1bf4dde945020c6', 'ea549e03484e32bde134b81a393e41f2f4a4358b>6e3bc8d4687cef9229e3206cb786c0233ed7698c', '834bccb30cf1a6bc4bc90eae56a52dbe0c6ae58a>37ed03a41b15e5119c8f0ac76dce581e1cd23fb9', '762819dc64e6645ccc70cc12a3fab01991f78625>a1f61a980667f6634597412ae73861a3c92bd4da', 'a2580213e98f7e52ca6deaf2350f35337918b5de>f756821621011ae527d578399406bb1cc48b4068', '015038751590ece620f549179941d32ba095296b>ac640d57175a0af92ba0a4a538349f2e85bdba28', 'add5e7be3d6ebe9f978fe96e56b9a12d62bcdc49>5698bd0a2a6365e64ef89e2ed56d7e281d8c6785', 'd5e9bb418f5183ebcaf371efce583b2e710315ef>6aa6183f41837ccaed16951fe32e9e3e861a0356', '6c3ef1022fbb6b38ab117a35741be05446819fd2>2ad37d4e710386fc101c999e570b18a26265e1dd']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 106,  ..., 261, 261, 261],\n",
      "         [259, 102, 117,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  68, 122,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  80, 111,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         [259, 103,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 117,  98,  ..., 261, 261, 261],\n",
      "         [259, 116, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 112,  99,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[21974,   226,    17,   655,  9873,     5,  2577,   226,   172,  2972,\n",
      "           558,   406,     6,   711,   226,  1566,     8, 35306,    11,    14,\n",
      "             3,   142,    13,  6945,    36, 27188,    89,    13,  3474,    11,\n",
      "            14,     3,    79,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7472,    11,    14,     3,     8,   131,     7,    46,    82,    17,\n",
      "          6136,     5, 43000,   525,     4,  6022,    31,   273,    67,    57,\n",
      "            73,     9,  1045, 17534, 40772,   692,    12, 11562,     8, 43001,\n",
      "          1040,    80,  1759,   359,   589,     7,     3,     0,     0,     0,\n",
      "             0],\n",
      "        [24004,    10,  5660,  1754,     5, 25094,    31,   573,    23,  3375,\n",
      "          1473,   858,    48,    15,  3594,  2310,  2373,     5,  1872,   218,\n",
      "            21,   371,    20,     6,  6018,  6304,  3594,    22,  1288,     9,\n",
      "             4,   345,    72,     8,  3454,  1895,    72,     7,     3,     0,\n",
      "             0],\n",
      "        [    2,   151,     7,     6,     9,  1082,     8, 35073,     6, 13647,\n",
      "             2,    85,     7,     2,     6,    60,  3587,  2282,  3490,  4349,\n",
      "          1440,   715,     4,  2291,    12,   811,   398,   136,   744,   318,\n",
      "             5,     4,  1035,     8, 30567,     6, 37448,     2,   209,     7,\n",
      "             3],\n",
      "        [  690,     4,    55,   480,     2,     9,   270,    12,   904,    12,\n",
      "          1871, 29195,    91,     2,     4,   357,     5,  4421,     6,  3383,\n",
      "          1239,    23,   631,     5, 10026,    31,   501,    25,  7451, 14175,\n",
      "             6,  6125,     8,  2418,     7,     3,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [13106,   959,     6,   328,   287, 10725,  8433, 42715,    31,    45,\n",
      "            18,    96,   400,  1915,    18,     4,   601,    12, 11892, 42716,\n",
      "           400,     2,    32,    37,   281,    19, 42717,   986,  7519,    12,\n",
      "         42718,    21,   371,    20,     3,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [   26,  4510,   365,     6,   601,  4417,    30,    33,   105,    10,\n",
      "          1793,    19, 10724,  7670,     2,   940,    10,  1112, 10601,     6,\n",
      "             4,   598,     5,   275,  1112, 33763,     9, 25021,  3209,  1934,\n",
      "            91,     8,  9408,    11,    14,     3,     2,  5903,     7,     3,\n",
      "             0],\n",
      "        [19538, 20141,  1903,   180,  1034,    23, 24354, 13877,    21,   300,\n",
      "            20,     2,     6,     4,  1234,  1327, 13553,     2,    15,  1254,\n",
      "           363,     2,    10, 15513,   111,     4,  1922,     2,     6,  1424,\n",
      "             4,  1254,     5,   329,  1179,    10,  6006,  1980,  3858,     8,\n",
      "          1860],\n",
      "        [ 1252,  4802, 38384,    19,    15,   688,   182,  1892,  3162,     2,\n",
      "         12405,    16, 12154,   121,  2824,  2984,    16,   195,     2,   557,\n",
      "             9,   355,  2824,    12, 19068,  3470,     6, 40793, 14479, 20385,\n",
      "             8,  7139,    11,    14,     3,     2,   509,     7,     3,     0,\n",
      "             0],\n",
      "        [    2,    51,    66,  2847,  1744,    12,  8442,     2,   652,    12,\n",
      "          8442,     2,     6, 23758,     5,   652,    12,  8442,     7,     6,\n",
      "           583,   536,    10,   355,  3056,    18,   369,     8,  1210,    11,\n",
      "            14,     3,   190,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8772,  1280,     6,   597,  4102,   205,    43,   122,   100,     8,\n",
      "           128,     2,   236,     7,     2,   161,  8772,     8,  1073,  4958,\n",
      "           486,     7,    31,   267,   166,     4,  3745,     5,    34,  5825,\n",
      "         10865,    28,   446,  2632,   737,  1949,     3,     0,     0,     0,\n",
      "             0],\n",
      "        [    2,     9,   493,   506,    91,     2,     4,   357,  1143,    10,\n",
      "           749,  4143,    12,   781,    16,   285,    67,    17,   435,    18,\n",
      "          2388,   111,     4,   120,    12,   811,    29,    10,  9863,  6403,\n",
      "            21, 13454,    20,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [26303, 20665,     6,  1959,  2543,  1644,     6,  7606,   136,     4,\n",
      "          3413,     6, 33852,  2793,    13,   457, 33853,    24,  1686,    69,\n",
      "         33854,   166,   340,  9357,   374,    40,   680,     8, 26304,     6,\n",
      "         19310,    85,    13, 26305,     6, 19310,    89,     7,     3,     0,\n",
      "             0],\n",
      "        [  626, 10645,   498,  2614, 21809,  4935, 12801,    12,  4191,   165,\n",
      "           525,  4605, 17013,     2,    69,  2014,   269,  1340,    23, 23740,\n",
      "         29112,     8,  1532,    11,    14,     3,     2,   131,    13, 12550,\n",
      "            11,    14,     3,     2,    76,     7,     3,     0,     0,     0,\n",
      "             0],\n",
      "        [   64,  1597,   568,    17,     4,   636,     5,  5974,     8,  1979,\n",
      "             7,  1970,  2288,     9,     4,   450,   319,     5,    71,   856,\n",
      "             6,   765,    17,    15,   516,   319,     5,  2010,   172,   680,\n",
      "            18,    15,  2064,   319,     5,  9955,   464,     3,     0,     0,\n",
      "             0],\n",
      "        [  144,   856,  1568,   612,    53,   774,    17,   304,  2191,  1482,\n",
      "             5,   708,    24,  2160,     5, 42693,   166,  1175,  5659,     5,\n",
      "          9596,  4697,     9,   446,  1018,    18,  9596,  4697,    19,  2856,\n",
      "          2325,     8,   143,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0]], device='cuda:0')}, 'labels': tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['2dda28049d7f05f453f484a248f5a77d75efaa8b', '8384fd8ad01b0a5f310ca355d07610d147f7be77', '745c4f69c160823911589db740f1efbc61e88ab7', '39b24149276ea5eb525fc2566edf48aa1b9801f3', 'ef1535a64b39c591db87e3d82fb7128a8f39480b', 'e8ec8cb000898881dc5834fce4bb2d36f6465897', '91e70dd09e2f11ae1fe9d50a158e0897982c59f5', '85211f8a3f76eb3538fc74c096f3dee38b21da8c', '57f3ea4b5b6dc86750ca72fc33040b0ca684fb04', '89ac8e99a2211087619dbfecd61010f8c6d52609', '33faf9c0b0ea2292ec82800186ca82e54b087ecf', '4597b4241b139c79695bdb022c6806ea2e894bd8', 'e1a2cac8b713374f2e625f7ea0e571950de42f33', '09e0d57688dff5fafb510c85b5c78035f298d58f', 'cbc308bee74319c2bf4c2fa3c8efe0db2fe84dc6', '04bd0ceac333305cb6bf4a706f85e84e9e0db2bd'], 'cited_paper_id': ['4d07d4c8019ebc327a7bb611fba73b8e844928d0', '5e0a8d84a299dc7e6902020b8e40dbd0a25be15a', '0f973badc6a5bfb01d1a30913104d6e197fc2fff', '1d802bf1dbad5e2eeba97982a53a3504b41d9e71', 'c923028caac7d0f58db911a22a89a003e10453bb', 'e91ccca0986aaaf136ff8cfca0e3c30f891e9144', '4df6b3366a6941eb537d4990fa82e963205feca2', '7322791117d359c63adce5d011a55a24fbb0fd82', '0073ca1c9f85b23520e8b3c53f146533f6fe68a6', '7818128719147cfdb3a077088f03a4fd8914637c', '3c5f1e4b17a53cc4636cb9994b1c12fa0a409a47', 'd62d10f41febbb8be791d652c693d0b7ab2e1f3b', 'f285cefc813d7a4190a3a725ac07ca325b483e22', '3610fb9b112315fd8f771bfec66d2d18a13fa76f', 'f40a16c7d8ea7fd91219e897c75ede2665b617db', 'c71c93d89ffeeccf16be0ccb72b39348719ec306'], 'citation_excerpt_index': [2, 2, 0, 0, 8, 7, 4, 1, 0, 1, 1, 11, 0, 10, 7, 0], 'citation_id': ['2dda28049d7f05f453f484a248f5a77d75efaa8b>4d07d4c8019ebc327a7bb611fba73b8e844928d0', '8384fd8ad01b0a5f310ca355d07610d147f7be77>5e0a8d84a299dc7e6902020b8e40dbd0a25be15a', '745c4f69c160823911589db740f1efbc61e88ab7>0f973badc6a5bfb01d1a30913104d6e197fc2fff', '39b24149276ea5eb525fc2566edf48aa1b9801f3>1d802bf1dbad5e2eeba97982a53a3504b41d9e71', 'ef1535a64b39c591db87e3d82fb7128a8f39480b>c923028caac7d0f58db911a22a89a003e10453bb', 'e8ec8cb000898881dc5834fce4bb2d36f6465897>e91ccca0986aaaf136ff8cfca0e3c30f891e9144', '91e70dd09e2f11ae1fe9d50a158e0897982c59f5>4df6b3366a6941eb537d4990fa82e963205feca2', '85211f8a3f76eb3538fc74c096f3dee38b21da8c>7322791117d359c63adce5d011a55a24fbb0fd82', '57f3ea4b5b6dc86750ca72fc33040b0ca684fb04>0073ca1c9f85b23520e8b3c53f146533f6fe68a6', '89ac8e99a2211087619dbfecd61010f8c6d52609>7818128719147cfdb3a077088f03a4fd8914637c', '33faf9c0b0ea2292ec82800186ca82e54b087ecf>3c5f1e4b17a53cc4636cb9994b1c12fa0a409a47', '4597b4241b139c79695bdb022c6806ea2e894bd8>d62d10f41febbb8be791d652c693d0b7ab2e1f3b', 'e1a2cac8b713374f2e625f7ea0e571950de42f33>f285cefc813d7a4190a3a725ac07ca325b483e22', '09e0d57688dff5fafb510c85b5c78035f298d58f>3610fb9b112315fd8f771bfec66d2d18a13fa76f', 'cbc308bee74319c2bf4c2fa3c8efe0db2fe84dc6>f40a16c7d8ea7fd91219e897c75ede2665b617db', '04bd0ceac333305cb6bf4a706f85e84e9e0db2bd>c71c93d89ffeeccf16be0ccb72b39348719ec306']}\n",
      "{'citation_text': {'elmo': tensor([[[259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69,  72,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         [259, 116, 110,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  79,  87,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 118,  ..., 261, 261, 261],\n",
      "         [259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  50,  53,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 101,  98,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259, 118, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]], device='cuda:0'), 'tokens': tensor([[15223,     7,    31,    45,    10, 14529,  1615,     4, 13967,     6,\n",
      "          1251,    53,    28,    21,   297,    20,     3,     0],\n",
      "        [11671,  1812,    31,   663,    23,     4,   124,   100,    23,   955,\n",
      "            11,    14,     3,     8,  2443,     7,     3,     0],\n",
      "        [   41,   444,    10,     4,   504,   599,     2,     4,   422,    58,\n",
      "           405,   334,     6, 23387,  3317,    31,   270,     3],\n",
      "        [  702, 27675,   204, 33739,   107, 23911,  5069,     6,  7412,     4,\n",
      "           843,    51,  2979,    21,   222,    20,     3,     0],\n",
      "        [   57,    16,   423,     9,    55, 10437,    12,  1714,   433,     9,\n",
      "           253,    10, 24885,     8,   533,     7,     3,     0],\n",
      "        [   64,   599,    16,   139,    10,   138,    82,     9,  5106,  1180,\n",
      "            23,    55,   419,    21,   221,    20,     3,     0],\n",
      "        [14951,     6, 14951,  1699,     8, 35344,     7,  4341,    30,    33,\n",
      "           100,     9, 35345,     7,   775, 14951,     0,     0],\n",
      "        [  626,     5,     4,  1680,    16,    17,     4,   437,    59,   941,\n",
      "           109,  1494,  1930,    21,   222,    20,     3,     0],\n",
      "        [ 6453,  8009,    12,  8155, 10119,    31,    46, 16066,     8,  4219,\n",
      "            11,    14,     3,   132,     7,     3,     0,     0],\n",
      "        [ 6210,  3943, 23543, 24590,    59,    32,  5311,    18,    65,    95,\n",
      "             9,     4,   123,    21,   295,    20,     3,     0],\n",
      "        [ 6210,  3943, 23543, 24590,    59,    32,  5311,    18,    65,    95,\n",
      "             9,     4,   123,    21,   295,    20,     3,     0],\n",
      "        [ 7666,  1683,    37,  6565,    18,    57,  7116,     6,  1184,  1683,\n",
      "            18,   313,  3040,     8,   191,     2,  2069,     3],\n",
      "        [ 1556, 14786,     8,  7451,     7, 14175,     8,  2418,     7,     2,\n",
      "           180, 26789,  1253, 20165,  2886,     3,     0,     0],\n",
      "        [38024,    16,    46,    45,    10,   972,     4,   710,  7180,    18,\n",
      "            15,   307,   262,     5, 38025,   409,     3,     0],\n",
      "        [ 1705,    21,   254,    20,   141,  4949,  3362,   124,  3882, 11392,\n",
      "            10,  2233,   823,    15,   195,   443,     0,     0],\n",
      "        [   93,   560,    74,     5, 11267,  4567,    21,   254,    20,     6,\n",
      "          4639,  3993,  4177,  1752,    18,    65,   400,     3]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 1, 2, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['43b02723a14f38cf3060af20b7d6d576563380c8', '72db776932b5aa4889eb68f84ac5cdc1138429a2', 'becc13a1588ba61e2e53ce21efe0b286da68cc9b', 'e2b1971d1c50117549c1e2d2f2b5cc3c395120c9', 'fa433ab09d7dc26f36f34a2d0364034ce18a3e36', '6ba6d11ff15dd5e7f50fc34aabe336099cbfcba7', 'b399867c56c1512fdca33228f9bab117d7fe9607', 'c32b5f8d400cdfd4459b0dfdeccf011744df0b4b', '560c67b8d5c6e4b2809fbbd308d373366241ea86', '638fafc27d5b0d7c5cd719bd3ba51bec9db4bb5c', '638fafc27d5b0d7c5cd719bd3ba51bec9db4bb5c', 'b039291c4b41c6c735b7e443cedf89e9f6cac95e', 'ef1535a64b39c591db87e3d82fb7128a8f39480b', '55b670850842e5750eef9fdd85c388091389e300', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5'], 'cited_paper_id': ['55899ffa1ca17fd8ba86a6298a245723ddb22038', '7fc86bb2e1efa0eae319ba9aa25698edfcf16328', '7e4300ad0fc8350d90bd8de7b45c718f211e3870', '260b50bf2bbd82e8c80acc4c0ebc73ecbd0279af', 'cf06ac7ff09cf23b3b339e83d9561a8fe8a4b5e2', 'f49f570bc97a499ab3f31fb3a8cc975ad6d93c46', '05cdcdefc3cd70ad3d4f29350c95c2021f4c2753', '5cf2fa811b4b6d5e83e6e3d9af27cacb82c4510b', 'b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '35c1ae44da7ca399aaeb11e6c80fc371f8c8aa92', '35c1ae44da7ca399aaeb11e6c80fc371f8c8aa92', 'd7a4025a169b089ce180cfce339762a52db6d254', 'c923028caac7d0f58db911a22a89a003e10453bb', '613ff1ee9d80f1bafecec207386929dc47b03175', '4448616a83a88c54e1ffddf0390716630f9a4b70', '4448616a83a88c54e1ffddf0390716630f9a4b70'], 'citation_excerpt_index': [2, 5, 0, 2, 0, 4, 4, 1, 8, 0, 0, 10, 1, 2, 6, 2], 'citation_id': ['43b02723a14f38cf3060af20b7d6d576563380c8>55899ffa1ca17fd8ba86a6298a245723ddb22038', '72db776932b5aa4889eb68f84ac5cdc1138429a2>7fc86bb2e1efa0eae319ba9aa25698edfcf16328', 'becc13a1588ba61e2e53ce21efe0b286da68cc9b>7e4300ad0fc8350d90bd8de7b45c718f211e3870', 'e2b1971d1c50117549c1e2d2f2b5cc3c395120c9>260b50bf2bbd82e8c80acc4c0ebc73ecbd0279af', 'fa433ab09d7dc26f36f34a2d0364034ce18a3e36>cf06ac7ff09cf23b3b339e83d9561a8fe8a4b5e2', '6ba6d11ff15dd5e7f50fc34aabe336099cbfcba7>f49f570bc97a499ab3f31fb3a8cc975ad6d93c46', 'b399867c56c1512fdca33228f9bab117d7fe9607>05cdcdefc3cd70ad3d4f29350c95c2021f4c2753', 'c32b5f8d400cdfd4459b0dfdeccf011744df0b4b>5cf2fa811b4b6d5e83e6e3d9af27cacb82c4510b', '560c67b8d5c6e4b2809fbbd308d373366241ea86>b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '638fafc27d5b0d7c5cd719bd3ba51bec9db4bb5c>35c1ae44da7ca399aaeb11e6c80fc371f8c8aa92', '638fafc27d5b0d7c5cd719bd3ba51bec9db4bb5c>35c1ae44da7ca399aaeb11e6c80fc371f8c8aa92', 'b039291c4b41c6c735b7e443cedf89e9f6cac95e>d7a4025a169b089ce180cfce339762a52db6d254', 'ef1535a64b39c591db87e3d82fb7128a8f39480b>c923028caac7d0f58db911a22a89a003e10453bb', '55b670850842e5750eef9fdd85c388091389e300>613ff1ee9d80f1bafecec207386929dc47b03175', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5>4448616a83a88c54e1ffddf0390716630f9a4b70', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5>4448616a83a88c54e1ffddf0390716630f9a4b70']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 103, 102,  ..., 261, 261, 261],\n",
      "         [259, 122, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  50,  55,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         [259, 103, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  49, 260,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 119,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 100,  98,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   88,   452,   286,  3230,     2,    15,  4401,    59,    31,   141,\n",
      "            18,     4, 18947,   660,  2910,  2734,     8,    57,     2,    90,\n",
      "             7,     3,     0,     0,     0],\n",
      "        [10342,   694,    31,   465,    48,     4,  1060,   694,   926,     5,\n",
      "         12775,     2,    15, 24002,   395,     5,   937,    12,   359,  1060,\n",
      "           694,    21,   295,    20,     3],\n",
      "        [   41,  2146,   336,     2,    65,    81,  6932,   306,    15,   703,\n",
      "          3114,     5,     4,   711,   464,     5,     4,   507,    21,   662,\n",
      "            20,     3,     0,     0,     0],\n",
      "        [    2,    77,    12,  3489,   949,    21,   300,    20, 19815,    15,\n",
      "           840,  3489,     5,    15,  1833,   644,   534,   505,    19,   973,\n",
      "          1240,     0,     0,     0,     0],\n",
      "        [   93,    46,    45,    34,   160,    54,  3409,     8, 27805,     7,\n",
      "            98,    21,   630,    20,    21,   767,    20,    32,    31,   239,\n",
      "            23, 13806,    11,    14,     3],\n",
      "        [   57,     6,   301,    57,     7,     2,    43,    45,    15,   391,\n",
      "         45072,     8, 17364,     6, 17842,     2,   654,     7,     6,   732,\n",
      "            12,  2146,  1589,  1361,     3],\n",
      "        [ 3391,   178,  1916,    53, 42987,    21,   237,    20,    31,  8743,\n",
      "            28,     4,   246,   178, 35906,     8, 35907,     7,   814,     8,\n",
      "          9533,     3,     0,     0,     0],\n",
      "        [   88, 21116,    62,     5,  1842, 20479,   997,    15,   114,   117,\n",
      "             5, 35908,     2,   130,    46, 20360,     8,  7554,    11,    14,\n",
      "             3,     2,   118,     7,     3],\n",
      "        [11411,   904,    12,  2125,    24,    54,    25,   391,  1226,   741,\n",
      "            48,     4,  8434,     8,  2258,     7,   197,  1923,     8,   695,\n",
      "             7,   635,     3,     0,     0],\n",
      "        [  132,     7,     9,  8044,     2,     6,  5647,     9,  1250,     8,\n",
      "          4219,    11,    14,     3,   132,     7,    37,   338,   997,    22,\n",
      "          3636, 20925,     3,     0,     0],\n",
      "        [    5,   246,   863,   111, 37681,   928,    16,    10,    74,     4,\n",
      "         15670, 16891,  1767,   636,     8, 16927,     6, 14292,   390,     7,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [ 9762,     2,  6819,    12,   501,  2471,   115,    37,   267,    23,\n",
      "          3383,  5562,    34,   880,  1274,    12,   501,  1494,    59,    48,\n",
      "             4,   512,  1274,   119,     3],\n",
      "        [13413,    31,    46, 14624,  2507,   642,  2798,    12,   324, 22759,\n",
      "             9,  1045,     8,  4938,    11,    14,     3,     2,    79,     7,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [  343,     6, 31668,  2475,     5,     4,   149,   208,   491,   942,\n",
      "             4,   167,  1283,    22,   102,    49,    21,   277,     2,   221,\n",
      "            20,     3,     0,     0,     0],\n",
      "        [   64,  3191,    16,     9,  1128,    19,     4,  2967,   741,    23,\n",
      "         29295,    11,    14,     3,     8,   131,     7,     6, 31368,     8,\n",
      "            68,     7,     3,     0,     0],\n",
      "        [  144,   914,    37,  2263,    45,     9,     4, 11767,    12,   174,\n",
      "          2588,    18, 19102,  1663,    10,  2709,  6127,   907,    21,   191,\n",
      "            20,     3,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 2, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['1eaf1bd4454c4c155a43bb8726ecc8a3b12b460c', '0f811605238713a03a80e3b2c7ee0b4209648985', 'b91b70dec0abfcd70889b4dd0cd45aede00500b5', '440c73adbdbf8caed0bb6c34e7487c7617939907', 'b60bd6086848ab2d21bf0589e5d02aa8748a0d82', '735e780a46e7ef7735907393dca142cab02a3c88', '6477fc3b69c677286d2f705553d13a82a59376dc', '8fa395d7ac3dbba558d5b73dd53185cccea8bb28', '258873a1605d396db6308f7f2822f1a317def2e8', '560c67b8d5c6e4b2809fbbd308d373366241ea86', '7b424c17ab760c0b0480af4531322d7ff46eddb4', '343f8452a462c855e90e2197a66c71613f09a8ad', '952660f4a305ebc8bc46ea23dd1ea41464d6681f', '4c6d41b5241a2d80b993632d7e89acdb9fedef74', '727620e57b933d3af9d36be18f5ce82b3d7f1de5', '29c7c2ed27a532405bbd86308d3536d169b115d2'], 'cited_paper_id': ['a1d4dbb2e6de1be785c1687115ab3b81e89fddf7', '3b27aa570198f8dc86c4a0aaf4befe1bdac3aa3c', '32b823d8813d7c58b2c556466de1cc41c1096f5c', '493093d26a0ef150b28ec15309c91d5c5cf19b60', '932e47c83f4466cac2f37e3ad80e13fabd6ca423', '3bb73407096cbb0f5d884eb108d694b43580004b', 'c7bf9db2b86007f7f2bc5857304bb6fd3ca80d10', 'f4d9d6e1e243f66a3009acafa8d7b0d13254f488', 'f9cce2ca192180e1a404a7577752a9c8ea8259ed', 'b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '8424d658b31b9c3b308b14297d03f9f850226570', '88009fb591e3477c2cacfdd71efef0091576a1e0', '6b1223f442606ef04c8c04b36f1cdc0efb14c560', '45ee8db9be57b97522566b1d1f6d2433cc464b72', '685d8020e2f8a97766247563cb93e994016f3fd1', '4b1625b81743bd004522c447587152d3cc94e415'], 'citation_excerpt_index': [0, 0, 0, 3, 0, 0, 4, 1, 0, 16, 0, 0, 12, 4, 1, 0], 'citation_id': ['1eaf1bd4454c4c155a43bb8726ecc8a3b12b460c>a1d4dbb2e6de1be785c1687115ab3b81e89fddf7', '0f811605238713a03a80e3b2c7ee0b4209648985>3b27aa570198f8dc86c4a0aaf4befe1bdac3aa3c', 'b91b70dec0abfcd70889b4dd0cd45aede00500b5>32b823d8813d7c58b2c556466de1cc41c1096f5c', '440c73adbdbf8caed0bb6c34e7487c7617939907>493093d26a0ef150b28ec15309c91d5c5cf19b60', 'b60bd6086848ab2d21bf0589e5d02aa8748a0d82>932e47c83f4466cac2f37e3ad80e13fabd6ca423', '735e780a46e7ef7735907393dca142cab02a3c88>3bb73407096cbb0f5d884eb108d694b43580004b', '6477fc3b69c677286d2f705553d13a82a59376dc>c7bf9db2b86007f7f2bc5857304bb6fd3ca80d10', '8fa395d7ac3dbba558d5b73dd53185cccea8bb28>f4d9d6e1e243f66a3009acafa8d7b0d13254f488', '258873a1605d396db6308f7f2822f1a317def2e8>f9cce2ca192180e1a404a7577752a9c8ea8259ed', '560c67b8d5c6e4b2809fbbd308d373366241ea86>b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '7b424c17ab760c0b0480af4531322d7ff46eddb4>8424d658b31b9c3b308b14297d03f9f850226570', '343f8452a462c855e90e2197a66c71613f09a8ad>88009fb591e3477c2cacfdd71efef0091576a1e0', '952660f4a305ebc8bc46ea23dd1ea41464d6681f>6b1223f442606ef04c8c04b36f1cdc0efb14c560', '4c6d41b5241a2d80b993632d7e89acdb9fedef74>45ee8db9be57b97522566b1d1f6d2433cc464b72', '727620e57b933d3af9d36be18f5ce82b3d7f1de5>685d8020e2f8a97766247563cb93e994016f3fd1', '29c7c2ed27a532405bbd86308d3536d169b115d2>4b1625b81743bd004522c447587152d3cc94e415']}\n",
      "{'citation_text': {'elmo': tensor([[[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  69,  68,  ..., 261, 261, 261],\n",
      "         [259, 103, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 115,  ..., 261, 261, 261],\n",
      "         [259, 101,  98,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 227, 129,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  85,  80,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259, 227, 129,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         [259,  99, 122,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 103,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         [259, 109, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   35, 12382,   234,  ...,     0,     0,     0],\n",
      "        [ 9222,    53,  1280,  ...,     2,    35,     0],\n",
      "        [   35, 12359,     6,  ...,    16,    35,     0],\n",
      "        ...,\n",
      "        [   26,   204,    17,  ...,     3,     0,     0],\n",
      "        [  205,   378,    23,  ...,     0,     0,     0],\n",
      "        [22912,   233,   285,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['1695be1beb54bd821bdc511c4e3f1b83cbd59159', '873945f3516489157adecf300a379199f50318b8', 'f36300a29107655359ffb8ed2db04c93dada24aa', '18eea59972f7d6e937d98ccc2424d81be2129998', '8e8ae21e5037bd6683ffc9fd74af69bd1a3caa62', '26420ec3d87ab5cce2f6439c368e6cfab4dbd4e0', 'bc30837249cec5c08135a691adae91029b90d7ee', '55e8e01dcb4d886fc46bf8d1b909355c080307ed', '728dca6baef091394f8defcf31e7bd462089d146', '42573358ca9bacee4faaf2d661ab63b22f23a644', 'd9f3207db0c79a3b154f3875c9760cc6b056904b', 'c600b0131dedf511e769d493f94aa66ef6338387', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab', '8f146171c9d6ce082589bf45759204a33fa6494b', 'f2a1c1704f9587c94ed95bc98179dc499e933f5e', '3450c7e9a6d8688ac76fb5f31ceed0270c88d868'], 'cited_paper_id': ['feb0883f43151c871fe73e8c2b84ab3efa6499ce', 'b414ce2f3a6659c611b53290caddf1035e498b5f', 'aac9fb0178847fc4e17a1acdd5d9662ff53b9c94', '42e317c43d6fdd27a726deb6f6489c823a1c1642', '2d274069727fc97ceb9ee63900591447297ab966', 'ed36122184056b9dbc518e3b59444e0f1b913acc', 'e2dd59400d00756b42a56bc5a6c09d40558720a2', 'ae277fdf3c34f05b869119974846fa11243326c4', '9c24894daa14ea91350e06f4378a47199706b883', '0760fed3ac924a8540a8f8761665853eb93b206d', '2cc6ff899bf17666ad35893524a4d61624555ed7', '608624ceb50db5383631e6683a5c50a1f02ee37b', 'c14be2a7007e022da13889d804a540d0c0c34264', '6f04e7388117ce4263ab24706c3f7f8e0f4f1955', '574e659da7f6c62c07bfaaacd1f31d65bd75524c', '3e7af4307ffa0dc06a4dc1f07d95c9f8c29ec472'], 'citation_excerpt_index': [1, 1, 9, 0, 0, 0, 7, 0, 0, 0, 4, 0, 3, 0, 1, 0], 'citation_id': ['1695be1beb54bd821bdc511c4e3f1b83cbd59159>feb0883f43151c871fe73e8c2b84ab3efa6499ce', '873945f3516489157adecf300a379199f50318b8>b414ce2f3a6659c611b53290caddf1035e498b5f', 'f36300a29107655359ffb8ed2db04c93dada24aa>aac9fb0178847fc4e17a1acdd5d9662ff53b9c94', '18eea59972f7d6e937d98ccc2424d81be2129998>42e317c43d6fdd27a726deb6f6489c823a1c1642', '8e8ae21e5037bd6683ffc9fd74af69bd1a3caa62>2d274069727fc97ceb9ee63900591447297ab966', '26420ec3d87ab5cce2f6439c368e6cfab4dbd4e0>ed36122184056b9dbc518e3b59444e0f1b913acc', 'bc30837249cec5c08135a691adae91029b90d7ee>e2dd59400d00756b42a56bc5a6c09d40558720a2', '55e8e01dcb4d886fc46bf8d1b909355c080307ed>ae277fdf3c34f05b869119974846fa11243326c4', '728dca6baef091394f8defcf31e7bd462089d146>9c24894daa14ea91350e06f4378a47199706b883', '42573358ca9bacee4faaf2d661ab63b22f23a644>0760fed3ac924a8540a8f8761665853eb93b206d', 'd9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6ff899bf17666ad35893524a4d61624555ed7', 'c600b0131dedf511e769d493f94aa66ef6338387>608624ceb50db5383631e6683a5c50a1f02ee37b', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab>c14be2a7007e022da13889d804a540d0c0c34264', '8f146171c9d6ce082589bf45759204a33fa6494b>6f04e7388117ce4263ab24706c3f7f8e0f4f1955', 'f2a1c1704f9587c94ed95bc98179dc499e933f5e>574e659da7f6c62c07bfaaacd1f31d65bd75524c', '3450c7e9a6d8688ac76fb5f31ceed0270c88d868>3e7af4307ffa0dc06a4dc1f07d95c9f8c29ec472']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 101,  98,  ..., 261, 261, 261],\n",
      "         [259, 118, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 109,  98,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 113,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  85, 105,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 103,  98,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  80, 121,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69,  98,  ..., 261, 261, 261],\n",
      "         [259, 104,  98,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,    53,    45,     9,    39,    62,    24,    28,     4, 24709,\n",
      "            12,  1295,    21, 11357,     8,   207,     7, 21163,     9, 40236,\n",
      "            20,    21,   297,    20,     3,     0,     0,     0],\n",
      "        [   26,   753,   175,   764,   736,    16,   551,     4, 42639,     6,\n",
      "         10007,     4,  3634,   434,   357,     8,  6299,    11,    14,     3,\n",
      "            89,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26,  3536,  3933,    84,     9,    71,    62,    31,  4000,  3040,\n",
      "            18,  7367,     2,    32,    16,   688,  1466,    67,    17,    82,\n",
      "            23,    55, 30302,    12,   399,    20,    64,     0],\n",
      "        [ 6766,     4, 24506,    12, 24507,   443,    16, 23440,   100,     2,\n",
      "           201,  1216,   119,    40,    27,    92,     9,     8,  8911,    11,\n",
      "            14,    63,     7,     3,     0,     0,     0,     0],\n",
      "        [34893,    24,    92,    10,  2576, 34894, 15206,     6,   749,  1531,\n",
      "          4599,   559,     9,   928,     8,   746,    11,    14,     3,  3666,\n",
      "            13,  4009,    11,    14,     3,    97,     7,     3],\n",
      "        [   57,    90,   507,  1005,     5,     4,  1298,   189,     4,  2613,\n",
      "          3938,    25,  8800,    66,  3814,   618,  1593,     6,  1118, 17830,\n",
      "            21,   300,     2,   254,     2,   295,    20,     3],\n",
      "        [   64,  9739,    10,   760,   116,    21,   341,     2,   494,    20,\n",
      "            32,  2339,     4,   445,    10,     4, 14538,   324,    23,     4,\n",
      "          2279,   754,     3,     0,     0,     0,     0,     0],\n",
      "        [   93,   470,     4,  1604,  1808,    10,  6892,   355,   559,    10,\n",
      "           984,   978,  4025,   672,    28,   446,   199,   233,  1270,  1650,\n",
      "            60,  2059,   260,    52,    21,   300,    20,     3],\n",
      "        [ 1203,     4,   554,     5,    15, 32802,  6172,   697,     2, 32803,\n",
      "          4595,  9199,    31,   930,    22,   100,    23,    71,  1315,     8,\n",
      "         32804,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [  144,   804,    24,   106, 15581,     9,    15,  3062,   430,    23,\n",
      "           616,     5,  1855,  1601,   115,     8, 18315, 18316, 18317,   113,\n",
      "            13, 26915,    97,     7,     3,     0,     0,     0],\n",
      "        [   90,  5453,  2628,   775,   208,   116,   141,     9,     4,  4397,\n",
      "            37,   985,    25,     4, 45204,   540,     2, 45205,     2, 45206,\n",
      "             6, 45207,    21,  9970,    20,     3,     0,     0],\n",
      "        [   93,   284,    15,   795,  1465,   133,    48,     4,   148,   379,\n",
      "             5,  1987, 31002,   874,     8, 31003,    13,    21,   494,     2,\n",
      "           571,    20,     7,     3,     0,     0,     0,     0],\n",
      "        [ 1493,   893,   166,  3784,     2,    91,    37, 13169,     6, 10678,\n",
      "           165,    31,   465,     9,  7841,    48,  5543,     2,    22,   100,\n",
      "           122,     8,   221,     7,     3,     0,     0,     0],\n",
      "        [   41,   585,     2,  5857,   666,    24,    42,   584,    10,  2882,\n",
      "           455,    28,  2206,  1218,     8,  8734,   260,     7,     8, 40546,\n",
      "            11,    14,     3,    79,     7,     3,     0,     0],\n",
      "        [14825,   397,   193,     9,  1060,  2437,  6948,   666,    66, 20428,\n",
      "             4, 50663,     5, 11673,   407,   621,     4,   196,     5, 47667,\n",
      "            21,   240,     2,   224,    20,     3,     0,     0],\n",
      "        [ 1120,  9169,   906,    31,    15,  9123,  1373,    28,    15,    62,\n",
      "            23, 31716,     6, 36301,    20,    32,    31,  3660,    10,  1439,\n",
      "             4,   327,   934,   405,     3,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 1, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['842ab535bb343bb38b8cef69f47ced0ff244bc89', '19df226147c7cb885a5a8c0e4eac9982321f6cfa', 'fde1475917a617a9bff61a315bc5a7d52e5fe997', '3482f1c9c2180cd5edc1fa8bfbe2480ccaea92dd', 'de3ce4b8f80cf1ec464ada492b578e2a91e21640', 'c5c49f3d189e63ff31305cff7973fc1cb113a065', '1a2114515c8aee2fb46a56fbffba0f2285570d02', '18f5102c3629f5717bf8011b398c3d50e0c09860', 'cb5444dc23a16794c67c675250d83cf165b9af99', '62c99fc9ccaa39c95301b51ab17f44c2999b6a9b', '3681cf18350d348acb4b27db3af37e7428670df9', '6ba0365c952e5131a853dd2cea103f6f13818222', 'd09ff12115d7a5bc3bbec4e1131f8961cf593bd6', '1e483299b18e8d786fac29b44f04af8f69494a75', '601e3cc86fd0d0071a89cfd3173883f1c69dfb69', 'f76349ad19e0d519d70fee7fc5a7e1250c570bd5'], 'cited_paper_id': ['59ed47501df9f524cf928dc82c4c2fd8b7822f25', '8f923e09c919a9d18c61c4bbfd1c1c556134d06c', 'b2774d2cc0df880d6ba864460a47e5dbbcbc0edc', '0891bece3a201c5d0897e8b1d12264eb0b820dcd', '03deebf175f34a88c200a0ef39d0aca8e4ade8e2', 'c60bd24a1c685c8211e339314ed7b3e7579bbec9', '72716e49b923a84db430e100feb7f6cb975f3302', '86b7d222ddc6559a170d71e8be9470428035e81e', '78ef58020ed1c309b6a628a848fd8348734fa537', '115166bfaa6aa94cd7ffc24b8e5766e52768f096', 'b62430598576f433ed7b4c5c3d44000c236feab0', '58806a244b5b10468cb4183a6f3855429548cc3d', '99515560477e474f2105f1930097e83f0ef47384', '05ff72126f935d857bd07b8280319eef4b688ddb', '7889c9d6699535681ff7832fc0099477f822949a', '4cd703675677ac58f5254b6d0e066defb726c7e9'], 'citation_excerpt_index': [0, 0, 0, 6, 1, 6, 4, 0, 0, 0, 7, 1, 0, 0, 3, 0], 'citation_id': ['842ab535bb343bb38b8cef69f47ced0ff244bc89>59ed47501df9f524cf928dc82c4c2fd8b7822f25', '19df226147c7cb885a5a8c0e4eac9982321f6cfa>8f923e09c919a9d18c61c4bbfd1c1c556134d06c', 'fde1475917a617a9bff61a315bc5a7d52e5fe997>b2774d2cc0df880d6ba864460a47e5dbbcbc0edc', '3482f1c9c2180cd5edc1fa8bfbe2480ccaea92dd>0891bece3a201c5d0897e8b1d12264eb0b820dcd', 'de3ce4b8f80cf1ec464ada492b578e2a91e21640>03deebf175f34a88c200a0ef39d0aca8e4ade8e2', 'c5c49f3d189e63ff31305cff7973fc1cb113a065>c60bd24a1c685c8211e339314ed7b3e7579bbec9', '1a2114515c8aee2fb46a56fbffba0f2285570d02>72716e49b923a84db430e100feb7f6cb975f3302', '18f5102c3629f5717bf8011b398c3d50e0c09860>86b7d222ddc6559a170d71e8be9470428035e81e', 'cb5444dc23a16794c67c675250d83cf165b9af99>78ef58020ed1c309b6a628a848fd8348734fa537', '62c99fc9ccaa39c95301b51ab17f44c2999b6a9b>115166bfaa6aa94cd7ffc24b8e5766e52768f096', '3681cf18350d348acb4b27db3af37e7428670df9>b62430598576f433ed7b4c5c3d44000c236feab0', '6ba0365c952e5131a853dd2cea103f6f13818222>58806a244b5b10468cb4183a6f3855429548cc3d', 'd09ff12115d7a5bc3bbec4e1131f8961cf593bd6>99515560477e474f2105f1930097e83f0ef47384', '1e483299b18e8d786fac29b44f04af8f69494a75>05ff72126f935d857bd07b8280319eef4b688ddb', '601e3cc86fd0d0071a89cfd3173883f1c69dfb69>7889c9d6699535681ff7832fc0099477f822949a', 'f76349ad19e0d519d70fee7fc5a7e1250c570bd5>4cd703675677ac58f5254b6d0e066defb726c7e9']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         [259, 112,  99,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  80, 118,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 103, 106,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 102,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   64,  1011,   116,    18,  1386,  6590,    58,   973,  3879,    21,\n",
      "           371,     2,  1172,     2,   659,    20,     2,   280,    48,  2260,\n",
      "             6,  1152,  1046,    28,   759,  1148,   415,     6,   395,  3470,\n",
      "             3,     0],\n",
      "        [  342,    31,   267,    48,     4,   347,    12, 12539,  2346,     2,\n",
      "            32,    38,    33,   239,    10,   960,  2405,   834,    12,   732,\n",
      "         35847,   180,   871,  1856,    21,   630,    12,   662,    20,     3,\n",
      "             0,     0],\n",
      "        [  205,    50,     2,   628,   123,     5,  9252,    23,  9439,    12,\n",
      "          1558,    40,   576,  1014,   287,     6,   438,  1148,   407,  2333,\n",
      "          1384,     9,   507,  1586,     6,  1005,    21,  9971,    20,     3,\n",
      "             0,     0],\n",
      "        [22757,    12,    54, 33426,  2179,    40,  1148,    53,   496,  2687,\n",
      "          2594,     5,   157, 24878,    13,   396,     2,    65,   829,   442,\n",
      "           471,    56,   469,    22,   687,     9,    21,   191,    20,     3,\n",
      "             0,     0],\n",
      "        [ 3576,  3576,    37,  6619,     6,   369,  4531,    22,   377,     5,\n",
      "             4,   195,     2,  3225,  3432, 31123,  1343,     5,     4,  5894,\n",
      "         31124,  8537,  1204,     8,  5490,    11,    14,     3,    63,     7,\n",
      "             3,     0],\n",
      "        [   93,   350,   736,     4,  5647,   602,   325,     9,    71,   102,\n",
      "           439,     2,    32,   411,     4,  3636,  4737,  5647,   602,     9,\n",
      "          2883,  6453,     8,  4219,    11,    14,     3,   132,     7,     3,\n",
      "             0,     0],\n",
      "        [   21,   300,    20,    30,  1127,    15,   195,    53,   154,     5,\n",
      "          7528,   302,     2,  7405,  1069,    15,   319,     5,   332,  3333,\n",
      "            67,    17,    45,    23,   327,  2395,  7528,   360,   162,     3,\n",
      "             0,     0],\n",
      "        [   26,  1326,  2547,     9,  6205,     6,  3734,     8,    63,     7,\n",
      "             6,    39,  1646,    40,  7138,     4, 11271, 11457,  1394,     5,\n",
      "          3512,     6,  1154,    25,    15,   293,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [ 7238, 19063,  1849,    10,   182,  1541,     9,  1932,     6,  2049,\n",
      "           640,  4113,  2460,     5,   206,  2832,   397,    44,  1541, 30862,\n",
      "             8,  5716,    11,    14,     3,     2,  5174,     7,     3,     0,\n",
      "             0,     0],\n",
      "        [  626,     5,     4,   467,  2063,    23,  1340,     5, 13749,  1496,\n",
      "         14342,     9,   947,    66,    27,     4,  2386,  1794,     5, 20492,\n",
      "           189,     4,  1109,   146, 22081,    91,    24,   573,    21, 16360,\n",
      "            20,     3],\n",
      "        [  743,     4,  1308,    31, 11180,     2,    43,   465,     4,  4993,\n",
      "           262,    23,    48,     4,   167,   124,    22,   100,   504,     8,\n",
      "         38326,    11,    14,     3,    70,     7,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   41,   253,     2, 16102,  3187,    38,    33,   150,    19,   618,\n",
      "          1593,     6,    15,  1078,  3550,     9,  3011,     8,  1575,     7,\n",
      "             6,   737,  2545,     8,  1012,     7,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  781,    12, 37162,     2,    32,    38,    33,  5254,  1594,     9,\n",
      "             4,   631,     5,  4437,    12,   793,  1311,     2,    16, 13879,\n",
      "          1714,    23,  4376,    12,  5686,     8,   659,     7,     3,     0,\n",
      "             0,     0],\n",
      "        [  311,   102,   439,   259,    17,     4,   901,  4737,  4125,     5,\n",
      "          2883,  6453,  8009,    12,  8155, 10119,    31,    46, 16066,     8,\n",
      "          4219,    11,    14,     3,   132,     7,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   64,   599,    16,     9,  1128,    19,     4,    52,     5,   881,\n",
      "            12,  3491,    49,     9,   278,   998,    28,  6581,     2,  2822,\n",
      "             2,     6,  1504,    21,   224,    12, 33922,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [  770,    49,   243,    71,    52,   774,    17,  4143,    12,   781,\n",
      "          1721,    34,   171,   219,     9,  1852,    28,  6327,  2397,   708,\n",
      "            23,  4611,    10,  1170,     4,  1505,    21, 37429,    20,     3,\n",
      "             0,     0]], device='cuda:0')}, 'labels': tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 2], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['61c87ab40835f7439b7f775efa19798b4f124e1d', '52f941a672436335e30587ef96f0bb3aec0d5129', 'a7ecbb4b04344102d5b60b3a02fcdab476510a1d', 'fddf963e6d38a65b2017ecc5eb4c2e94aca46d64', 'ce5e40ddeb4fd7949aaeb507a66ac27887d12b95', '560c67b8d5c6e4b2809fbbd308d373366241ea86', '3ea1f4960d78101aeae7fc604862ba478e3d11b9', 'c530edac57ffa39997801a600c486eb231a87a6d', 'bb3074e425bfaf99eb204c6130e9a54eee9dec15', '743a1befaf5e2cd2e5a9162432909b221a1e695c', '624e6de05b43da1a74665a5e8bb4cc29d6801f6b', 'b4cc2bc53a4c5f3b7851b90c1eaa04cd40c4896d', 'fc77de1769f24466ed1ed49c85f1b0a60f0c49b6', '560c67b8d5c6e4b2809fbbd308d373366241ea86', 'b1a43ee3ef40196e0e73ac305495fa4aaaefdd9b', 'adbcc12a04e608f88b1dcb12568207fe5398f520'], 'cited_paper_id': ['b34ed4e673a44d41168bb7168c314b0cf027e8e9', '80b64b4bcc67d2d375e2914c5e4d263fd9c40365', '7ea83ac623c5c7f5f7b38b3ca5d243b74fdef823', '277e402473c61e4455beb5ae68585d9aafb2cc7c', 'be59cc09630da876d2dfada6165711f5bd19506f', 'b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '85c158797e0819f8f33c9832e3c1e392c2071415', '21b324399af869ff28634117eaaeaccfd52d371c', '11c8eb51792645248ca534461912d88079f7ad4f', '8bd0c05a7acb2d7764d188dc0efa65402421956e', '7f697a5d630575a4df0a0c71266496a905f2d5d3', '19975d8b06a8152c61840cbe044aca9e271cfea1', '5c6e1299d0b4645b1d6dd6a9db59ca725128226b', 'b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '4ad2ee4dd60d0e13e144756c94c635f561ef1f61', '2326f0b32885b151ed126731f810ec71dc421676'], 'citation_excerpt_index': [0, 0, 0, 0, 4, 19, 0, 9, 3, 1, 0, 0, 0, 17, 0, 0], 'citation_id': ['61c87ab40835f7439b7f775efa19798b4f124e1d>b34ed4e673a44d41168bb7168c314b0cf027e8e9', '52f941a672436335e30587ef96f0bb3aec0d5129>80b64b4bcc67d2d375e2914c5e4d263fd9c40365', 'a7ecbb4b04344102d5b60b3a02fcdab476510a1d>7ea83ac623c5c7f5f7b38b3ca5d243b74fdef823', 'fddf963e6d38a65b2017ecc5eb4c2e94aca46d64>277e402473c61e4455beb5ae68585d9aafb2cc7c', 'ce5e40ddeb4fd7949aaeb507a66ac27887d12b95>be59cc09630da876d2dfada6165711f5bd19506f', '560c67b8d5c6e4b2809fbbd308d373366241ea86>b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '3ea1f4960d78101aeae7fc604862ba478e3d11b9>85c158797e0819f8f33c9832e3c1e392c2071415', 'c530edac57ffa39997801a600c486eb231a87a6d>21b324399af869ff28634117eaaeaccfd52d371c', 'bb3074e425bfaf99eb204c6130e9a54eee9dec15>11c8eb51792645248ca534461912d88079f7ad4f', '743a1befaf5e2cd2e5a9162432909b221a1e695c>8bd0c05a7acb2d7764d188dc0efa65402421956e', '624e6de05b43da1a74665a5e8bb4cc29d6801f6b>7f697a5d630575a4df0a0c71266496a905f2d5d3', 'b4cc2bc53a4c5f3b7851b90c1eaa04cd40c4896d>19975d8b06a8152c61840cbe044aca9e271cfea1', 'fc77de1769f24466ed1ed49c85f1b0a60f0c49b6>5c6e1299d0b4645b1d6dd6a9db59ca725128226b', '560c67b8d5c6e4b2809fbbd308d373366241ea86>b0fe8d2727db77f58bc430fef29aba3308ecd3f2', 'b1a43ee3ef40196e0e73ac305495fa4aaaefdd9b>4ad2ee4dd60d0e13e144756c94c635f561ef1f61', 'adbcc12a04e608f88b1dcb12568207fe5398f520>2326f0b32885b151ed126731f810ec71dc421676']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259,  98, 104,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         [259, 101, 115,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  73, 122,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         [259, 113, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  50,  53,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  81,  98,  ..., 261, 261, 261],\n",
      "         [259,  98, 117,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 102,  ..., 261, 261, 261],\n",
      "         [259, 115, 106,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 122,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  144,    52,  2782,    19,     4,    59,   141,    23,  3389,    11,\n",
      "            14,     3,    21,   300,    20,     2,     6,   216,  1133,    23,\n",
      "            55,  6312,    21, 35697,    20,     2,    32,  2074,     4,  5710,\n",
      "           598,   136, 19205, 13429,     3],\n",
      "        [20300,    31,   281,  6021,    44,  1026,  1905,   365,     2,    22,\n",
      "           100,     8,   277,     7,     2,     6,     4,  2325,    37,  6886,\n",
      "            44,   182, 21061,     8,   371, 11540,     2,   343,     3,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [   94,    21,   254,    20,    62,  2101,   179,     2,     9,   253,\n",
      "            10,   234,    60,  2321,  8123,     2,   666,     9,   601,    37,\n",
      "         11723, 10259,    10,  1882,    15,   359,   589,   374,     5,   343,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [   26,  1592,  1094,    18, 10483,    16, 50657,    12,   365,     8,\n",
      "           170,   345,    57,    13,  6396,    11,    14,     3,     2,    76,\n",
      "             7,     2,    32,  2375,   387,    28, 18419,    12, 12160,  1094,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [10067,    11,    14,     3,     8,    97,     2,    87,     7,    45,\n",
      "            81,   326,     5, 15594, 30500,     8, 30501,  7390,    80, 30502,\n",
      "             7,     2,    15,  1492,   582,     6,    15,  2441,   582,    17,\n",
      "           539, 13297,  5617, 30503,     3],\n",
      "        [ 9851, 25790,    30,  1293,  1336,   289,     5,    50,   804,     8,\n",
      "         24648,    11,    14,     3,   255,    13, 27154,    11,    14,     3,\n",
      "           151,    13, 25791,     6,  5938,   142,    13, 27155,    11,    14,\n",
      "             3,   113,     7,     3,     0],\n",
      "        [   26,  4377,   926,     5,   782, 28441,     8,  4377,    79,     7,\n",
      "            16,  1512,    10, 26825,  6240,    17,   537,  3918,    12,  3301,\n",
      "           578,  5877,  1388,    10,    27,   499,  1196,   227,  1602,     3,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [13709,    16,    15,   304,   175,     2,    22,    51,  3809,    34,\n",
      "          1622,     5, 13960,   120,  1518,     8,  4855,    11,    14,     3,\n",
      "             2,    75,     7,     2,     6,    16,   687,   350,  1083,     3,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  311,   247,  1568,    15,  5552, 24651,     5,  1770,   720,     6,\n",
      "           266, 21953,   902,    17,  2817,   241,  6598,     5,     4,   405,\n",
      "           337, 10700,   710,    10,  1770,   720,    21,   224,    20,     3,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [   26, 10137,    37,   216,  3844,    10,  2325,     6,  6565,  6021,\n",
      "            19,     4,  3322,  9412,    22,   100,   122,     8, 13993,    11,\n",
      "            14,     3,     2,   309,    13,  5841,    11,    14,     3,     2,\n",
      "            61,     7,     3,     0,     0],\n",
      "        [ 5520,  1659,    26,   946,  3496,    38,   657,     4,  9503,     5,\n",
      "            15,   117,     5, 31141,   115,     5,   441,  1538,   445,     8,\n",
      "         13192,    11, 23734,    13, 11027,    11, 17010,    13,  7558,     6,\n",
      "          5109,  2121,     7,     3,     0],\n",
      "        [   26,  2607,    80,  9557,   622,     5,     4, 36063,  9724,   329,\n",
      "            37,   663,    28,  4022,     5,    60,  1163,   540,    19,   901,\n",
      "          2001,   540,    48,     4, 43081,   874,    21,   346,    20,     3,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [ 6040,    90,     6,   129,   193,     9, 17054,  1014,  1916,    28,\n",
      "             4,  1099,     2,  1399,  5049,   310,  2699,     6,  2543,   287,\n",
      "             2,   463,     2,   105,    19,     4, 16548,    59,  1856,    28,\n",
      "            21,   297,    20,     3,     0],\n",
      "        [ 3275,    44,    34,   206,   196,     5,  1008, 22877,    66,   583,\n",
      "          1511,    28,    50,   340,  3486, 42856,   556,   401,    65,    95,\n",
      "          1511,    56,    28,  2108,    32,   558,     4,   196,     5,  5853,\n",
      "            21,   295,    20,     3,     0],\n",
      "        [16378,  2750,     5,  3917,    29,  5739,     9, 10242,    10,   109,\n",
      "           730,   789,    38,    33,  1293,     9,   239,   613,     6,   185,\n",
      "            27,   292,    22,     4,  1680,    18,     4,  4991,  2671,   545,\n",
      "             8,  1026,     7,     3,     0],\n",
      "        [32940,     5,     4, 18408,   246,   910,    33,    82,     9,   147,\n",
      "            49, 16918,    17,     4,   450,     5, 32941,  2283,    31,    92,\n",
      "            10,    27,   387,   214,     9,    95,   232,   231,    19,  1257,\n",
      "            21, 32942,    20,     3,     0]], device='cuda:0')}, 'labels': tensor([2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['1b3a2bd4d70a025505ada1561df13629addd2c81', 'cac1b86d4f6a0f1019e9389c36cd9bad7891945a', '48b662f8e34fe3c1057796a6f85222f5470aef49', '4445cba251a0c983b76acb84d3c48ca8713c65b9', 'ed3b55b5b937f4e201dcf62fe64b9b0b6dc7c64c', '7327e81309f45d446c0f4ddb044916482ad0ddaa', 'af1f99bf354d7c547b82ddaad9b87d6f90fb8d69', '7ea35436e261fc4d48fdcada0a8eb9c1f8c1a93b', '7ae0e372012f54068df241a789cbae872d0517d5', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9', 'd45b18f6600ac7e4b23f6c8db773206725b36897', '8d14b763c8e43b458555aaa1fe16ed3570f9beb2', '43b02723a14f38cf3060af20b7d6d576563380c8', 'a82bc36d7132381f20c95f04e089f65e611ee957', '479dc05177890fd662ff59969b18104f2f6abe3c', '2eb4969576aa13487c087bcadfce196a46a96405'], 'cited_paper_id': ['None', 'bb05718f2dfb539ff1b5c8e6ab8d19c47667b676', '2b01ba16d3225aa99c04ef65a7f771d4b36075af', 'b83fc70119b548fbd5ad03093eb3add669c8716a', '7f51a31f6acb467b0d3d39d5ab2a570033362a4b', '1517fd8ec6df6ce77e02751ee77dc5d892ad0dfb', 'a151fcaa3d003321d6e09602a927fc434d19b032', '25aa4a143d373d371cc8fa3a2d550a0649d8c94c', '97eb64d521d80c58775a35632b7a512d66f96842', '6d6bb93872a190de290f259e63587db4f17d539c', 'ef6024c89420ef17fa3432c2b744f4c7634a795a', '092759f15088a18d41c700de4676ce868a31042c', '55899ffa1ca17fd8ba86a6298a245723ddb22038', '82b22c37fd463e96342fbcb385c76a7b279ff75d', '63046407d63d4aefd198f38ca2b0d294723b0f50', 'f375431b6149f1d5b2013ab305619799bcb4eefc'], 'citation_excerpt_index': [0, 1, 6, 6, 1, 1, 1, 10, 2, 6, 5, 0, 1, 1, 1, 7], 'citation_id': ['1b3a2bd4d70a025505ada1561df13629addd2c81>None', 'cac1b86d4f6a0f1019e9389c36cd9bad7891945a>bb05718f2dfb539ff1b5c8e6ab8d19c47667b676', '48b662f8e34fe3c1057796a6f85222f5470aef49>2b01ba16d3225aa99c04ef65a7f771d4b36075af', '4445cba251a0c983b76acb84d3c48ca8713c65b9>b83fc70119b548fbd5ad03093eb3add669c8716a', 'ed3b55b5b937f4e201dcf62fe64b9b0b6dc7c64c>7f51a31f6acb467b0d3d39d5ab2a570033362a4b', '7327e81309f45d446c0f4ddb044916482ad0ddaa>1517fd8ec6df6ce77e02751ee77dc5d892ad0dfb', 'af1f99bf354d7c547b82ddaad9b87d6f90fb8d69>a151fcaa3d003321d6e09602a927fc434d19b032', '7ea35436e261fc4d48fdcada0a8eb9c1f8c1a93b>25aa4a143d373d371cc8fa3a2d550a0649d8c94c', '7ae0e372012f54068df241a789cbae872d0517d5>97eb64d521d80c58775a35632b7a512d66f96842', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9>6d6bb93872a190de290f259e63587db4f17d539c', 'd45b18f6600ac7e4b23f6c8db773206725b36897>ef6024c89420ef17fa3432c2b744f4c7634a795a', '8d14b763c8e43b458555aaa1fe16ed3570f9beb2>092759f15088a18d41c700de4676ce868a31042c', '43b02723a14f38cf3060af20b7d6d576563380c8>55899ffa1ca17fd8ba86a6298a245723ddb22038', 'a82bc36d7132381f20c95f04e089f65e611ee957>82b22c37fd463e96342fbcb385c76a7b279ff75d', '479dc05177890fd662ff59969b18104f2f6abe3c>63046407d63d4aefd198f38ca2b0d294723b0f50', '2eb4969576aa13487c087bcadfce196a46a96405>f375431b6149f1d5b2013ab305619799bcb4eefc']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 100, 106,  ..., 261, 261, 261],\n",
      "         [259,  73,  66,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 117,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  41, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         [259, 110, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         [259,  99, 122,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 119,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,  4830,  3886,    38,    46,    33,    92,    10,  1801, 16468,\n",
      "            91,    10,  5053,     4,  1266,  4490,    21,   191,    20,     2,\n",
      "             6,   558,     4,  1579,     5,  9294,  1054,     2,   130, 20420,\n",
      "             2,     6, 24718,   365,    21,   143,    20,     3,     0],\n",
      "        [ 6378,  2840,     8, 27537,     7,    37,  1002,    18,  2749,   631,\n",
      "          1916,    23,  2242,    60,   487,    10,  2568,   108,   391,  4903,\n",
      "            48,    34,  6928,    12, 10099,   124,     8,  4223,    11,    14,\n",
      "             3,     2,  2121,     7,     3,     0,     0,     0,     0],\n",
      "        [  775,    49,    25,  1269,     5,   298,   847,  4950,     4,   435,\n",
      "           332,   789,  1303,   208,    37,  2762,     9,    77,    21, 26023,\n",
      "            20,     6,   477,    31,  2762,     9,    81,   332,   789,    21,\n",
      "           277,    20,     8,   460,     3,     0,     0,     0,     0],\n",
      "        [ 1524,   612,   126,     8,  8128,    11,    14,     3,     2,    63,\n",
      "            13, 30363,     6, 14526,     2,    83,    13, 30364,     6, 14828,\n",
      "             2,  3900,     7,     2,    43,  7466,   106,  8053,    17,   680,\n",
      "            44,   524,   128,   833,     9,     4,  1983,     3,     0],\n",
      "        [   26,   636,     5,   801,  1450,  5152,     2,    44,   524,     9,\n",
      "           377,     2,    10,   257,   854,     5,     4,  3134,  1239,  1622,\n",
      "         27063,     9, 13383,  4931,    91,     8,  9589,    11,    14,     3,\n",
      "             2,    79,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   88,   457, 14999,    12,   218,  2256,    17,    31,   325,    23,\n",
      "           605,    10,     4,   141,  6128,   515,     9,     4,   248,     2,\n",
      "            31, 16514,    12, 16113,     8,  3002,    11,    14,     3,     2,\n",
      "            78,     7,     8,  1393,     2,   867,   155, 22075,     3],\n",
      "        [   33,   105,    17,   945, 10679,    19, 17799,  2014,  1063,   618,\n",
      "           598,    21,  9827,    20,     2,  1921,  2218,  1081,    21, 11205,\n",
      "            20,     6,  1221,  2872,     6,  4280,     5,     4,  1356,   434,\n",
      "            21, 13454,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [21869,     6,  4483,  3063, 16021,    24,   423,     9,    51,     8,\n",
      "         16410,    11,    14,     3,     2,    89,    12,    79,    13,   746,\n",
      "            11,    14,     3,     2,    70,    13,  5371,    11,    14,     3,\n",
      "             2,    75,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26,    52,     5,    39,    62,  1568,     6,  2208,     4,   247,\n",
      "             5,    55,    49,     8, 31014,    11,    14,     3,    97,    13,\n",
      "         29000,    11,    14,     3,    61,     7,   978,     4,  7783,     5,\n",
      "          3675,   553,     5, 17927,    53,     3,     0,     0,     0],\n",
      "        [   26,  6576, 19252,    30,    33, 19253,    23,     4, 19886,  6702,\n",
      "          5517,     6,    24,   471,   285,     6, 13773,     8, 19887,    11,\n",
      "            14,     3,    63,    13,  5810,    11,    14,     3,    78,    13,\n",
      "         19888,    36, 19889,    83,     7,     3,     0,     0,     0],\n",
      "        [ 2529,    19,   102,   410,     8,  3060,    11,    14,     3,     2,\n",
      "           118,     2,   132,     7,     2,    43,    92,    17,  7834,  6458,\n",
      "         14570,  1135,     9,   241,  6553,     5,  2574,     8,   301, 28605,\n",
      "             2,   658,    13, 14570,  1528,     7,     3,     0,     0],\n",
      "        [  153,    16,   213,    17,  4595,  3234,     2,     9,   253,    10,\n",
      "          2333,  2264,   434,    91,    10,   960,  1292,    23,     4, 30383,\n",
      "           636,     2,    46,   188,     9,  1950,  5814,     8,   873,     2,\n",
      "          1787,     7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [18600,   564,  1836,   423,     9,     4,  2516,   436,   579,     5,\n",
      "         18601,     8, 31320,    11,    14,     3,     2,   209,     7,    24,\n",
      "          2079,     9,     4,   504,    12,  1288, 18601,     8, 12820,     9,\n",
      "           301,    90,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [  394,    24,   265,   373,  2078,   177,     5,   421,   165,    18,\n",
      "           317,  3787,     2,   130,   911, 27640,  1987,     2,   359,  1812,\n",
      "             2,   421,  1818,     2,  3232,     2, 38381,     2,     6,  2810,\n",
      "             8,   191,    12,   224,     7,     3,     0,     0,     0],\n",
      "        [  205,   378,    23,   157,   419,     2,     4,  2495, 30603,    40,\n",
      "           188,    28,    34,   594,  3613,    12,  2932,   931,    10,  1331,\n",
      "           670,  7915,     6,   168,    84,  6986,   111,    34, 14262,  2507,\n",
      "           636,    21, 30604,    20,     3,     0,     0,     0,     0],\n",
      "        [ 1907,     4,   251,     5,   106,     4,  6943,  3526,    10,     4,\n",
      "          2682,    16,   741,     9,    15,   457,   652,     2,    19,    15,\n",
      "          2717,  4738,  1949,   497,     8,  5006,     7,   882,    44,    86,\n",
      "          1059,    21,   129,    20,     3,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['0aed965c7237c6199cec304ec985efcf6753e152', 'cf82d977a64226a15cca9fc0eea7de1e0078ce29', '7d68f7c021b14e955049989f1132c3f1f0a03fb0', '8286f4d4e3cca04367f6d6a8e4381e1f2800a641', 'ac98889274074aaffe68806613f94400764cc392', '940c6c24739dac029f3c20d2df7c5749d3832a8f', '6fb06cd519b017d10af1c1a281339f1937d0d2c1', '7c9eedc102d73eeffb07410efeaa590c0b04c1fe', '8bad55b05cbe22fb15a11aaf1d63108c6263dfcf', '2b80f65e936e58979de232164026543edb2a79e8', '929a7548464ce1d9d785abbe35da34842c0133e6', '9d48119099466f1af2f94a8b195f1d1d480081d4', 'e26309d3c9c6d5324b3a7b2f4d2d444daa7c598a', '19c40d2913c2b37d788fecbe3ff6e9bc9b9309a9', 'a2e15eae099c09a6ced8648717946c017448f4e7', '5ebb3df9bbf84ae86987ee49c386695a49f58950'], 'cited_paper_id': ['f26a94e01c0f635d45f74121cbf9059a7201c81a', 'efe167e81022b9fb2b41ea7de996515c26f94838', '7e86590820e4ce2884e843df4453eb81f8e25d24', '62da761c51f567634969d9fd1e0e4a66d79b946f', 'e79c496d57be7fd821df67996a40c5579ed81450', '389351a2554fb22ab0102f740850fd2a0fbc236e', '18e7d7a03846d581c57ffd4077a1ec7e3c14bb06', 'cf6b7a930c422ee1e7ea96c01be20770f2d937d1', '74f317704cd4b5612edc3502f886841e6cb46bcd', '8f01119d68d6a980ec1608e905be6e4f58cb328a', '21096eb950bdff77308ad3924d69b681589bdc91', '43f852ab7c4c2e8dacda7ad116274f8dbc5f72cb', '192a5af24f95a45c550c0ccabd4e468a5638b37e', '04c5f0d24c88ce7dbd5d34bdb855e171fde19399', '8cbbc3864c5948abb809ce73c46a1ccb74e0f4b7', '378096ff5a43e294489efdcb191d3aeee566ad5d'], 'citation_excerpt_index': [1, 4, 2, 0, 1, 1, 0, 0, 0, 6, 0, 0, 1, 0, 0, 0], 'citation_id': ['0aed965c7237c6199cec304ec985efcf6753e152>f26a94e01c0f635d45f74121cbf9059a7201c81a', 'cf82d977a64226a15cca9fc0eea7de1e0078ce29>efe167e81022b9fb2b41ea7de996515c26f94838', '7d68f7c021b14e955049989f1132c3f1f0a03fb0>7e86590820e4ce2884e843df4453eb81f8e25d24', '8286f4d4e3cca04367f6d6a8e4381e1f2800a641>62da761c51f567634969d9fd1e0e4a66d79b946f', 'ac98889274074aaffe68806613f94400764cc392>e79c496d57be7fd821df67996a40c5579ed81450', '940c6c24739dac029f3c20d2df7c5749d3832a8f>389351a2554fb22ab0102f740850fd2a0fbc236e', '6fb06cd519b017d10af1c1a281339f1937d0d2c1>18e7d7a03846d581c57ffd4077a1ec7e3c14bb06', '7c9eedc102d73eeffb07410efeaa590c0b04c1fe>cf6b7a930c422ee1e7ea96c01be20770f2d937d1', '8bad55b05cbe22fb15a11aaf1d63108c6263dfcf>74f317704cd4b5612edc3502f886841e6cb46bcd', '2b80f65e936e58979de232164026543edb2a79e8>8f01119d68d6a980ec1608e905be6e4f58cb328a', '929a7548464ce1d9d785abbe35da34842c0133e6>21096eb950bdff77308ad3924d69b681589bdc91', '9d48119099466f1af2f94a8b195f1d1d480081d4>43f852ab7c4c2e8dacda7ad116274f8dbc5f72cb', 'e26309d3c9c6d5324b3a7b2f4d2d444daa7c598a>192a5af24f95a45c550c0ccabd4e468a5638b37e', '19c40d2913c2b37d788fecbe3ff6e9bc9b9309a9>04c5f0d24c88ce7dbd5d34bdb855e171fde19399', 'a2e15eae099c09a6ced8648717946c017448f4e7>8cbbc3864c5948abb809ce73c46a1ccb74e0f4b7', '5ebb3df9bbf84ae86987ee49c386695a49f58950>378096ff5a43e294489efdcb191d3aeee566ad5d']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 112,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         [259, 103, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  79,  84,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         [259,  99, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  84,  79,  ..., 261, 261, 261],\n",
      "         [259, 103, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  69, 106,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  72, 115,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259, 113,  98,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  217,  1075,    18,  1533,     5,  1954,   445,     2,     4,   479,\n",
      "            45,    23,  5335,    11,    14,     3,     8,   142,     7,     6,\n",
      "         23629,    12, 10401,     2,  5335,     2, 30915,     2,     6, 30916,\n",
      "             8,   113,     7,    37,   292,   880,    22,     4,  3305,     5,\n",
      "             4,   327,    62,    37,   139,    10,    60,  3668,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 7247,    46,  3346,  1068,    10,    96, 11911,  5079,    21,   129,\n",
      "             2,   222,    20,     2,     6,   201,     4,   342,   830,    18,\n",
      "          7247,   436,    38,    42,    33,  3883,   325,     2,    51,    16,\n",
      "           213,    10,    27,  1514,  1472,     4, 26855,     2,   401,   246,\n",
      "           128,  1372,  3627,   835,     4,   149, 21763,  5815,    24,  1422,\n",
      "            18,  7247,   436,    21,   222,    20,     3,     0],\n",
      "        [   35, 12772,    18,  3171,  7697,     5,     4, 12950,    88,    12,\n",
      "           964,     8,   281,    10, 22247,     4,   177,     5,  2539,  2960,\n",
      "            25,     4,   507,  1534,     6,     2,  1958,     2,   604,     4,\n",
      "           675,    58,     4,  4661,     6, 12950,    88,    12,   964,     7,\n",
      "            30,    33,   239,     9, 15024,     8, 17076,   209,    13,  5140,\n",
      "             6,  4829,  3769,     7,     3,     0,     0,     0],\n",
      "        [    2,  5946,  9588,    28,  6346,  4103,     7,    29,   279,    10,\n",
      "          1418,  2001,  1562,     2, 27253,     6,   246,    12,   178,   163,\n",
      "            40,   106,    27,   741,    19,   109,   782,     5,  9492,     2,\n",
      "            17,    16,     2,    19,   637,   649,     8,  4791,     6,  2788,\n",
      "             2,    75,    13,  8113,    11,    14,     3,     2,    83,    13,\n",
      "         16443,    11,    14,     3,     2,   118,     7,     3],\n",
      "        [ 4614,    57, 13633,   976,    72,   733,    57,  2017,   681,     2,\n",
      "         25850,    12,    57,     6, 22173,    12, 47803,  4113,  1466, 19260,\n",
      "             2,   530, 47804,  2622,     6, 14607,    12, 13432,   259,  3008,\n",
      "         19260,     8,   301, 25536,     7,     8,  5947,    11,    14,     3,\n",
      "             2,    79,    13,  6292,    11,    14,     3,     2,    87,    13,\n",
      "          7450,    11,    14,     3,     2,    76,     7,     3],\n",
      "        [ 1838,     6,  2089,  1183,    49,    24,   250,  3981,   136,     4,\n",
      "           149,  1565,     5,  1411,     5,     4,  1037,    13,    51,    38,\n",
      "            33,  4689,    17,   145,    24,   109,   966, 10869,     5, 16044,\n",
      "             2,   130,    15,  3870,  2055,    12,  5179,  1525,  2718,     2,\n",
      "         12292, 28751,   966,     2,    29,   265,  4617,   966,    21,   297,\n",
      "            20,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  144,    52,     2,   139,    10,   138,   267,    23, 18989,    11,\n",
      "            14,    21,   297,    20,     9,   120,  1367,     6,    23, 18990,\n",
      "            21,   277,    20,     9, 32885, 18991,    88, 14903,   178,   515,\n",
      "             2,  1338,   243,    10,     4,   458,     5,    15,   420,   186,\n",
      "             9, 13116,  9584,     2,    99,     9,     4, 18992,     6, 18993,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    2,  5946,  9588,    28,  6346,  4103,     7,    29,   279,    10,\n",
      "          1418,  2001,  1562,     2, 27253,     6,   246,    12,   178,   163,\n",
      "            40,   106,    27,   741,    19,   109,   782,     5,  9492,     2,\n",
      "            17,    16,     2,    19,   637,   649,     8,  4791,     6,  2788,\n",
      "             2,    75,    13,  8113,    11,    14,     3,     2,    83,    13,\n",
      "         16443,    11,    14,     3,     2,   118,     7,     3],\n",
      "        [ 2452,     5,     4,   327,    52,     5,  9050,   177,  1301,    28,\n",
      "             4,  7744, 22123,  4316,   291,    19,     4,   102,   247,     5,\n",
      "          9050,   177,  1301,    28,    15,  7744,    12,   441,   881,    12,\n",
      "          5746,  4316,   291,     8, 10170,    11,    14,     3,     2,   190,\n",
      "             7,     2,     4,   419,  2771,    17,    51,    16,    15,  3548,\n",
      "          1591,    17,     4,     0,     0,     0,     0,     0],\n",
      "        [14924,  1269,     5,     4, 11202,    22,    15,   395,     5, 16908,\n",
      "         16909,    11,    14,     3,     8,   190,     7,   736,     4,  1104,\n",
      "          1521,     5,   837,  1517,  2368,    17,   395,   837,    28,    86,\n",
      "          3239,   197,  1526,     2,    15,   322,    12,   439,  4984,   333,\n",
      "             8,  3079,  3185,  2703,     7,     2,    15,  8921,    12,  4190,\n",
      "            35,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   26,   208,   372,    37,    54,    25,     4,  5151,  1163,    98,\n",
      "          1452,    23,  9316,     6, 29383,    12, 27641,     8,   428,     7,\n",
      "            47,     8,    15,     7,   884,     5,    15,   480,  5151,     2,\n",
      "             8,   256,     7,  1055,     5,    15,   480,  5151,     2,     6,\n",
      "             8,   781,     7,  2954,     5,    15,   480,  5151,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 3022,    12,   196,   709,  1849,    10,     4,  1204,    37,  1387,\n",
      "            73,   273,   335,    10,   922,   257,  4824,    74,   580,    10,\n",
      "            15,   176,    12,  1204,   175,   232,     2,   313,    73,   273,\n",
      "           335,    10,   922,   257,  6310,    74,     2,     6,   526,    73,\n",
      "           273,   335,    10,   922,   257,    55,  1091,    74,     8, 11499,\n",
      "            11,    14,     3,     2,    78,     7,     3,     0],\n",
      "        [  152,     2,     4,    52,     5,    49,    23, 27364,     6, 27365,\n",
      "            20, 19163,     6, 27366,    20,  3927, 18542, 27367,    11, 27368,\n",
      "            20, 27369,    11, 27370,    20, 27371,    11, 27372,    20, 27373,\n",
      "            11, 27374,    20, 27375,    11, 19164,    20,     6, 17967,     6,\n",
      "         27376,    20,    24,     9,  8695,    19,     4,   504,    52,     3,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [22771,   290,   138,   100,   504,    18,   358,     8,   212,    39,\n",
      "            16,     4,   858,   437,     2,   425,  5665,   825,   271,    42,\n",
      "          1349,     7,    29,   719,     8,   212, 37749,   858,    16,    45,\n",
      "             7,     2,  2695,     4,  1867,  1271,  1224,   764,  3392, 14300,\n",
      "             5,    86,   437,   540,     8,  5824,    36, 22772,     2,   142,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  135, 12896,   415,    16,    15,  2037,    18,  2407,     5,   623,\n",
      "            16,  4129,    25,   189,    15,   331, 12918,   134,     8,  6512,\n",
      "             2,    61,     2,  1240, 10656,     7,     6,    16,   588,   703,\n",
      "            18,  2463,   181,  2621,   183,    32,  1189,    16,   213,     8,\n",
      "          3079,     2,    76,    13, 13455,     2,    68,     7,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  205,  2768,     2,  1115,     5,    39,   386,    24,  1498,    18,\n",
      "          2333,   283,    25,   895,   684,  6236,     5,   928,     8, 19785,\n",
      "            11,    14,     3,   390,     7,     2,     6,   110,  1079,    77,\n",
      "             5,     4,   101,   171,   232,     5,  2768,   150,    19,  7561,\n",
      "          3117,  1640,     6, 16954,     9,   812,     8,   864,    11,    14,\n",
      "             3,    70,     7,     3,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['95746f1690aac138821596f863097e851d462976', '03026676cf30464b9c5f8e24e5d6d4348d46a994', '114de63c96176358b8cd3c99aa744c86f0eeced7', '39c68a095d58f0cd5f54e942fee4b22a9c2fd9fe', 'd6228aa33ada378031b06729a718aabe0a80e1de', 'bf76273127eb57c35ffb2c708e3df7e5f9e9115b', 'f48888eb870eba77917d34efc79bbcedd4bbb411', '39c68a095d58f0cd5f54e942fee4b22a9c2fd9fe', 'f0d2da8e0bde5ab25944209b341b878ca5a7e2d3', '9f24d2e12bad753bdc4b8771ec2ffeedf273abe6', '3cb202ba8a32e2a46224143e4d8c51940c12040c', 'd192abf533edb3781cfb5f3215592fbc08cb7c2b', 'c5707d1dd230d01ba95869477cf3e69a9732c585', 'c08c0603f1d7424b539fd0334ef6466914573b75', 'e300bde47ff38b78bd09fc3566e9c3b5a0aa21e5', 'f9b16a66516145a285e3df02b5e0aeb92e7a7bfd'], 'cited_paper_id': ['a7a252d73ff0f63ae9d444cded332c8c41552e28', '903aae8adc61e5b2cbdd349b6527f693b5cd5d99', '7ffdab1930ccf68c10be4cf9a9ffdb933c9dd516', '7c77cd228aef0769225ede4056c91726153bf986', 'dbd605458b9a35250d7e45c5ad01be0b99f1d676', 'fc5c9fde1703d262d0208928a4549aef67706d4f', '6990deef767a4ae50034232f0901d59d9e79770f', '7c77cd228aef0769225ede4056c91726153bf986', '1ecddb1adffb4446831ef6f93e87b232aec0dd21', '51de056e1fc4e625293989e45e36e000b33021ce', '7692234b9da12db49774a1a5c355e68c9003cd21', 'fb3aad7f63ad9d98ccde41a2168d10750ff47685', 'e3dd5368152f9f9c62fe2904531b18bf6fa28b33', 'e79d82d6236711a2a3811b074904319ee7fb4f48', '6cd197b734868a247cbe0564c4e856d68bc8652c', '7ec112e4ee5cdd50fabe7607581c0b49c5cc2306'], 'citation_excerpt_index': [7, 0, 3, 6, 3, 2, 0, 6, 0, 0, 1, 4, 4, 0, 4, 0], 'citation_id': ['95746f1690aac138821596f863097e851d462976>a7a252d73ff0f63ae9d444cded332c8c41552e28', '03026676cf30464b9c5f8e24e5d6d4348d46a994>903aae8adc61e5b2cbdd349b6527f693b5cd5d99', '114de63c96176358b8cd3c99aa744c86f0eeced7>7ffdab1930ccf68c10be4cf9a9ffdb933c9dd516', '39c68a095d58f0cd5f54e942fee4b22a9c2fd9fe>7c77cd228aef0769225ede4056c91726153bf986', 'd6228aa33ada378031b06729a718aabe0a80e1de>dbd605458b9a35250d7e45c5ad01be0b99f1d676', 'bf76273127eb57c35ffb2c708e3df7e5f9e9115b>fc5c9fde1703d262d0208928a4549aef67706d4f', 'f48888eb870eba77917d34efc79bbcedd4bbb411>6990deef767a4ae50034232f0901d59d9e79770f', '39c68a095d58f0cd5f54e942fee4b22a9c2fd9fe>7c77cd228aef0769225ede4056c91726153bf986', 'f0d2da8e0bde5ab25944209b341b878ca5a7e2d3>1ecddb1adffb4446831ef6f93e87b232aec0dd21', '9f24d2e12bad753bdc4b8771ec2ffeedf273abe6>51de056e1fc4e625293989e45e36e000b33021ce', '3cb202ba8a32e2a46224143e4d8c51940c12040c>7692234b9da12db49774a1a5c355e68c9003cd21', 'd192abf533edb3781cfb5f3215592fbc08cb7c2b>fb3aad7f63ad9d98ccde41a2168d10750ff47685', 'c5707d1dd230d01ba95869477cf3e69a9732c585>e3dd5368152f9f9c62fe2904531b18bf6fa28b33', 'c08c0603f1d7424b539fd0334ef6466914573b75>e79d82d6236711a2a3811b074904319ee7fb4f48', 'e300bde47ff38b78bd09fc3566e9c3b5a0aa21e5>6cd197b734868a247cbe0564c4e856d68bc8652c', 'f9b16a66516145a285e3df02b5e0aeb92e7a7bfd>7ec112e4ee5cdd50fabe7607581c0b49c5cc2306']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  49,  49,  ..., 261, 261, 261],\n",
      "         [259,  99, 102,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 120, 106,  ..., 261, 261, 261],\n",
      "         [259, 110, 122,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 113, 102,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 118,  ..., 261, 261, 261],\n",
      "         [259, 118, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  98, 117,  ..., 261, 261, 261],\n",
      "         [259, 120, 120,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  66, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[32485,    58,     4,   851,     6,   908, 32486,    20,   323, 32487,\n",
      "            16,    42,   584,    10,  2736,   731,  8989,   914,     9,  3016,\n",
      "            19, 32488,     3],\n",
      "        [  152,     2,   157,    49,    21, 34834,    20,     5,  4649,    95,\n",
      "            19,     6,   337,  8988,   235,    30,    92,   139,    52,     9,\n",
      "          1500,     3,     0],\n",
      "        [   26,  1007,    45,     9,     4,  1636,     5,     4,  1752,    37,\n",
      "         14263,     2,  8029,     2, 12548, 29414,  1007,    21,   143,    20,\n",
      "             3,     0,     0],\n",
      "        [   10,     4,   101,   921,   727,    10,  1815,     4,   186,     8,\n",
      "          5843,     6,  4734,    75,    13,  5843,    11,    14,     3,    78,\n",
      "             7,     3,     0],\n",
      "        [   41,   253,     2,    99,  6045,     6,  1538,   445,    37,   465,\n",
      "            19,     4, 11224,  5187,  5415,     8,  9056,     7,    21,   341,\n",
      "            20,     3,     0],\n",
      "        [  690,     4,    55,   480,     2, 15205,    12,  4883,  2041,    24,\n",
      "            42,  2903,  4883,     2,  3469,    15,   875,  4387,     9,    21,\n",
      "           236,    20,     3],\n",
      "        [23712,    58, 12342,     6,  4601,   230,    10,   206,  1610,   931,\n",
      "            29,  3978,  3341,  8509,    98,    52,     9,  1939,   397,    21,\n",
      "           129,    20,     3],\n",
      "        [   64,  1097,   574,  3264,     4,  2215,   248,    25,  9853,     8,\n",
      "          6003,    11,    14,     3,    61,    13, 13978,    11,    14,     3,\n",
      "            87,     7,     3],\n",
      "        [  184,    49,    30,   105,    17,  3577,  1209,   185,    27,    22,\n",
      "           114,    22,   383,    73,    21,    57,     2,   128,    20,     3,\n",
      "             0,     0,     0],\n",
      "        [   26,   123,  6376,  3255,    25,     4,   819,    12,   611, 33161,\n",
      "             8, 33162,    11,    14,     3,     2,    79,     7,  3569,   354,\n",
      "            44, 13668,     3],\n",
      "        [ 4959,    11,    14,     3,     8,    78,     7,    62,    39,   875,\n",
      "            23,  2630,    81,   171,  7178,  2149,    47,  3248,  8512,     6,\n",
      "          4799,     3,     0],\n",
      "        [    2,   190,     7,     2,   792, 12614,  6233,     8,  5532,    11,\n",
      "            14,     3,     2,    61,     7,     2, 18613,     8,  3053,    11,\n",
      "            14,     3,     0],\n",
      "        [15282, 17429,     9, 12505,  7516,  2072,  6975,  2488, 17899,    37,\n",
      "          1871,    22,   100,    23, 20412,    11,    14,     3,     8,    70,\n",
      "             7,     3,     0],\n",
      "        [25049,     2,  3027,     9,   102,    49,     8, 25050,     2, 25051,\n",
      "         25052,     6, 25053,     7,     8,   388,     2,   341,     7,     3,\n",
      "             0,     0,     0],\n",
      "        [   26,   123,  6376,  3255,    25,     4,   819,    12,   611, 33161,\n",
      "             8, 33162,    11,    14,     3,     2,    79,     7,  3569,   354,\n",
      "            44, 13668,     3],\n",
      "        [14257,     4,  2209,   531,     5,  4831,    40,  7258,    10,  1643,\n",
      "             4,  1104,   636,     5,     4, 19688,   204,    21,   221,    20,\n",
      "             3,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['c43bc225d4c26f15eb7a05db8df524fbba5e2797', '425af424a1f897af5939fd3b5b881289ea5dbfc9', '47d121a5106e3c5683d2bc8415b9a1c15fced71e', '837e203c03e8c7aca1d6a5eff16da685f83fa807', 'd21ed6a2508cd5081910f966da8ffbf8a601436b', 'b8bffa786710b52c95201796bade07fc2ad3f38d', 'afbb49132ce36d29d3d52aea4f6b5e10473317d3', '42ef0baa77aebd11e00f46e04a94e9d95761887b', '46a958eac10a8786975ed6b853401d2433a43252', 'bc176bbf1167617f61672f0a2fa4a4c6f0d5bb7c', '10dd055d4276a7c2f17192717a22d824783c48cb', '7b0ca6f15e76f285cc19efd2305cb1ec9e16a5b5', 'd2b09bbfddcfab30318f362d94a98b63fd4b049f', '2c437cb33335a8e6be80be83fe01a6a3ba64543d', 'bc176bbf1167617f61672f0a2fa4a4c6f0d5bb7c', 'c3031c64fd8ea73554f927f43a957382e96194a2'], 'cited_paper_id': ['68a799116f2e0ccb881ab91210d54d81c0ade6eb', 'ddfd6f08e4cc3d49ef22e7921a20ad5e6da80998', '54801c260df5221a9de533d371d3edcc358b4050', '9c7168cb9caf4dbb9c9e4455f4b0bc8a5304fab1', '51523a9c19398e4ee1aaed797506b4b14244b510', '0049b630e0bf4b14e76e36615c33aed0c39c3dd9', 'db8220e495734572dba566c5222426db9b156093', '78d39f397495764485866f3f23463945d008309e', '978b56b8515e4806e17e5423ae389b9f9fbe0332', 'bbb3e9ba5ef638777c6cbab3f5cda021c8a4d812', '0d10e553c0a46e7384b3c34dc45bb063843a8300', 'df90f3e882609d15c298251608a5b48b69efb3b8', '17bdefb607e88dac868d7a4c87cfe1c53efe7e80', '8c65d72e1785ecce3271e0c703a32b380be81933', 'bbb3e9ba5ef638777c6cbab3f5cda021c8a4d812', 'a722cdc838c2d425b466635e81ae917b679c7065'], 'citation_excerpt_index': [2, 0, 0, 6, 0, 3, 1, 0, 0, 0, 9, 10, 0, 4, 0, 0], 'citation_id': ['c43bc225d4c26f15eb7a05db8df524fbba5e2797>68a799116f2e0ccb881ab91210d54d81c0ade6eb', '425af424a1f897af5939fd3b5b881289ea5dbfc9>ddfd6f08e4cc3d49ef22e7921a20ad5e6da80998', '47d121a5106e3c5683d2bc8415b9a1c15fced71e>54801c260df5221a9de533d371d3edcc358b4050', '837e203c03e8c7aca1d6a5eff16da685f83fa807>9c7168cb9caf4dbb9c9e4455f4b0bc8a5304fab1', 'd21ed6a2508cd5081910f966da8ffbf8a601436b>51523a9c19398e4ee1aaed797506b4b14244b510', 'b8bffa786710b52c95201796bade07fc2ad3f38d>0049b630e0bf4b14e76e36615c33aed0c39c3dd9', 'afbb49132ce36d29d3d52aea4f6b5e10473317d3>db8220e495734572dba566c5222426db9b156093', '42ef0baa77aebd11e00f46e04a94e9d95761887b>78d39f397495764485866f3f23463945d008309e', '46a958eac10a8786975ed6b853401d2433a43252>978b56b8515e4806e17e5423ae389b9f9fbe0332', 'bc176bbf1167617f61672f0a2fa4a4c6f0d5bb7c>bbb3e9ba5ef638777c6cbab3f5cda021c8a4d812', '10dd055d4276a7c2f17192717a22d824783c48cb>0d10e553c0a46e7384b3c34dc45bb063843a8300', '7b0ca6f15e76f285cc19efd2305cb1ec9e16a5b5>df90f3e882609d15c298251608a5b48b69efb3b8', 'd2b09bbfddcfab30318f362d94a98b63fd4b049f>17bdefb607e88dac868d7a4c87cfe1c53efe7e80', '2c437cb33335a8e6be80be83fe01a6a3ba64543d>8c65d72e1785ecce3271e0c703a32b380be81933', 'bc176bbf1167617f61672f0a2fa4a4c6f0d5bb7c>bbb3e9ba5ef638777c6cbab3f5cda021c8a4d812', 'c3031c64fd8ea73554f927f43a957382e96194a2>a722cdc838c2d425b466635e81ae917b679c7065']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  56, 260,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 100, 109,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 100,  98,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  80, 118,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         [259, 118, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   93,   193,    34,   548,     5,  5898,    94,    21,   767,     2,\n",
      "           662,    20,  1013,     2,   876,    48,  7769,     6,  5898,    94,\n",
      "            21,   191,    20,     2,     6,  7769,     2,  5898,     6, 13123,\n",
      "         12576,   647,    21,   240,     2,   224,    20,  2711,     3],\n",
      "        [ 2062,     2,   184,   410,    30,   105,    17,  8769,    24,  9941,\n",
      "           324,   136,  1729,  3036,    23,  1648,  3373,   828,     6,    55,\n",
      "          1254,   220,   159,    15,   636,    17,  1334, 31584,   660,  3210,\n",
      "             8, 21110,     7,     8,   129,    12,   191,     7,     3],\n",
      "        [  112,     4,   203,    12,  5166,   644,    42,     9, 25535,     7,\n",
      "             2,    15,  1483,    12,   406,  6067,  3516,   497,    31,   411,\n",
      "             9,    21,   254,    20,    10,  1563,    19,     4, 19580, 18890,\n",
      "         21756,    19, 24419,  8891,     6,  2721,     3,     0,     0],\n",
      "        [ 2493,   109,  1014,    29,   609,   263,     9,   420,   287,     9,\n",
      "            86,   613,    28,  8186,    21,    90,    20,     2,  1504,    21,\n",
      "           129,    20,     2,     6,  8192, 15191,    21,   128,    20,    24,\n",
      "           354,     9,     4,   248,     3,     0,     0,     0,     0],\n",
      "        [   26,   636,     5,   801,  1450,  5152,     2,    44,   524,     9,\n",
      "           377,     2,    10,   257,   854,     5,     4,  3134,  1239,  1622,\n",
      "         27063,     9, 13383,  4931,    91,     8,  9589,    11,    14,     3,\n",
      "             2,    79,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [ 2402,   183,  4104,    10,  9871,    31,   267,    28,     4, 29558,\n",
      "          4018,     6,     4,   547,    12,    10,    12,   547,  2626,     2,\n",
      "             9,  1128,    19,     4,   116,     5,     4,  5548,  5829,  2603,\n",
      "         14335,  2828,    21,   237,    20,     3,     0,     0,     0],\n",
      "        [23462,    29, 13950,    12,   324,  5698,  1042,  3400,    19,    84,\n",
      "             6,   235,     2,   284,   716,     5, 13950,     8, 23463,    11,\n",
      "            14,     3,    85,     7,     2,     6,     4,  9791,   951,   156,\n",
      "             8, 23464,    11,    14,     3,    87,     7,     3,     0],\n",
      "        [   41,     4,  1651,    23,  7524,    11,    14,     3,     8,    63,\n",
      "             7,     6, 21409,    11,    14,     3,     8,   104,     7,    65,\n",
      "           532,    37,   897,    25,     4,   803,     5,   122,   503,  2705,\n",
      "            28,   937,  7280,   532,     3,     0,     0,     0,     0],\n",
      "        [  112,     4,  6838,   443,     2,     4,  4229,   800,  1276,    23,\n",
      "         25875,     6,  2646,    16,    42,   225,    12,     5,    12,     4,\n",
      "            12,   771,     3, 27243,     2,    43,   272,    42,  2061,    60,\n",
      "          4229,   800,    18,     4,  6838,   443,     3,     0,     0],\n",
      "        [   26,   820,     5,    65,   299,    38,  1480,    10,    15,   184,\n",
      "             6,  3729,  1585,    10,   823,     6,  1643,  2637,   115,    18,\n",
      "            74,     9,   123,     5,   120,  1367,    53,    21,   169,     2,\n",
      "           237,    20,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  152,     2,     4,  2535,     5,     4,    55,   858,   811,  1765,\n",
      "             6,     5,  2816,  1148,   491,    46,  1630,     9,  1086,    19,\n",
      "             4,   716,     5, 14046,     8,  2936, 14329,     6,  9207,   661,\n",
      "            13, 11419,    11,    14,     3,   654,     7,     3,     0],\n",
      "        [11682,  1262,    73,     5,     4,  1022,  9119,     5, 28610,  2828,\n",
      "           660,     2,     4,  9337,  2314,  5145,     9, 10382, 13598,  8493,\n",
      "             8, 26960,    11,    14,     3,     2,    76,    13, 15568,    11,\n",
      "            14,     3,     2,  2850,     7,     2,    31,   325,     3],\n",
      "        [ 1524,   612,   126,     8,  8128,    11,    14,     3,     2,    63,\n",
      "            13, 30363,     6, 14526,     2,    83,    13, 30364,     6, 14828,\n",
      "             2,  3900,     7,     2,    43,  7466,   106,  8053,    17,   680,\n",
      "            44,   524,   128,   833,     9,     4,  1983,     3,     0],\n",
      "        [   26,   980,   124,   882,     9, 38243,    16,    54,    25,     4,\n",
      "         16854,    80, 16855,   303,    21,   371,    20,     6,  6618,   114,\n",
      "          7344,   469,    10,   714,  1632,   164, 38244,     6,  1161,   246,\n",
      "          7278,    21,   399,    20,     3,     0,     0,     0,     0],\n",
      "        [  890,   211,   410,    21,    72,     2,    90,     2,   129,     2,\n",
      "           128,     2,   169,     2,   191,     2,   240,    20,    46,    30,\n",
      "           378,     4, 23529,   219,     5, 11194,     9, 11194,    12,   150,\n",
      "         10093,     3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  311,   133,   691,  5164,    21,   222,    20,    10,  1031,  2736,\n",
      "           625,    12,   156, 37813,     2,    22,   103,    22,    10,  1784,\n",
      "           330,   227,    86,  1115,     5,     4, 42704,   158, 17285,     2,\n",
      "           337,     4,   442,    18,   252,    53,  2105,     3,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 2, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['c9411482609c16153ee6642525cbe322036f323d', 'd11fff30a8adc0038aa7a055f3d62590c3a24dad', '2fb715ff40d616a5d65377cc17d4d3575d2bb60a', '830157c71825e0906b0e3e5f9c565ea965096029', 'ac98889274074aaffe68806613f94400764cc392', '342ea82f11b98024daf36247ad1691e80af71851', '816955405f63453a81e481a3570b2d22d9a33fc6', '1596994f7c0cc63dd33ecac9bae63cbcab4e31f0', '69092affc3461a38eb05cf7982f104eb30b0492c', '16af5414d1589437c9df5aa039995ea9580f9097', '95fa0ad59301387b16cc9cd08cb96401ba25a933', 'eccd15f42cfb14931b12b19ac04e02306ed6a650', '8286f4d4e3cca04367f6d6a8e4381e1f2800a641', '7aac02178d32f3f49e7b0836722a3755d6c60c1f', '3bea480852ea26efa410b833852e32dd0f2b8cf4', 'bbcd2956f6a94ba54852a1e7205cde66779bb79e'], 'cited_paper_id': ['c7c7eb67ff0527cfac32ced00dcf7df09efe8b39', '52c60a34aec92623dbef2098816c60735f657cc0', 'd1b08a6774a9447e6de63db9099c1eac56975ca4', '15c32aad9abd96ed9d250e4d76c997dd05433237', 'e79c496d57be7fd821df67996a40c5579ed81450', '1f7430e2477318a88e346313347f7c936f699c8a', '6117d25f8cfc7498f77cdef52f4d2ec3fe08ca01', 'a0003d3b8be9c44a96cf44599d5c473afd7f131c', '5a9075363e4c66d42ec67113d8d4e310b31632a7', '093382c01716447b742aeaeb3417c0b491857716', 'e71d78841cf5887fbddca95bfb5cbfc8ddd0ade8', '886815ec30569a7a7214248f4b88aaa1bd43ba32', '62da761c51f567634969d9fd1e0e4a66d79b946f', '29f765c85dddc5a90ebf52555b44ddf62176ed04', '4a9432105f2e93a925a0196f5bbace814002e8c9', 'b6b52abae729bb7cc909d0378230f9d1158ad303'], 'citation_excerpt_index': [1, 1, 0, 0, 1, 0, 0, 12, 4, 2, 1, 3, 0, 0, 0, 0], 'citation_id': ['c9411482609c16153ee6642525cbe322036f323d>c7c7eb67ff0527cfac32ced00dcf7df09efe8b39', 'd11fff30a8adc0038aa7a055f3d62590c3a24dad>52c60a34aec92623dbef2098816c60735f657cc0', '2fb715ff40d616a5d65377cc17d4d3575d2bb60a>d1b08a6774a9447e6de63db9099c1eac56975ca4', '830157c71825e0906b0e3e5f9c565ea965096029>15c32aad9abd96ed9d250e4d76c997dd05433237', 'ac98889274074aaffe68806613f94400764cc392>e79c496d57be7fd821df67996a40c5579ed81450', '342ea82f11b98024daf36247ad1691e80af71851>1f7430e2477318a88e346313347f7c936f699c8a', '816955405f63453a81e481a3570b2d22d9a33fc6>6117d25f8cfc7498f77cdef52f4d2ec3fe08ca01', '1596994f7c0cc63dd33ecac9bae63cbcab4e31f0>a0003d3b8be9c44a96cf44599d5c473afd7f131c', '69092affc3461a38eb05cf7982f104eb30b0492c>5a9075363e4c66d42ec67113d8d4e310b31632a7', '16af5414d1589437c9df5aa039995ea9580f9097>093382c01716447b742aeaeb3417c0b491857716', '95fa0ad59301387b16cc9cd08cb96401ba25a933>e71d78841cf5887fbddca95bfb5cbfc8ddd0ade8', 'eccd15f42cfb14931b12b19ac04e02306ed6a650>886815ec30569a7a7214248f4b88aaa1bd43ba32', '8286f4d4e3cca04367f6d6a8e4381e1f2800a641>62da761c51f567634969d9fd1e0e4a66d79b946f', '7aac02178d32f3f49e7b0836722a3755d6c60c1f>29f765c85dddc5a90ebf52555b44ddf62176ed04', '3bea480852ea26efa410b833852e32dd0f2b8cf4>4a9432105f2e93a925a0196f5bbace814002e8c9', 'bbcd2956f6a94ba54852a1e7205cde66779bb79e>b6b52abae729bb7cc909d0378230f9d1158ad303']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259,  74,  84,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 118,  ..., 261, 261, 261],\n",
      "         [259,  99, 112,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 105,  98,  ..., 261, 261, 261],\n",
      "         [259,  99, 102,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  68, 102,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  50,  58,  ..., 261, 261, 261],\n",
      "         [259,  60, 260,  ..., 261, 261, 261],\n",
      "         [259,  87,  47,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  58,  54,  ..., 261, 261, 261],\n",
      "         [259,  86,  84,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   41,     4,  7687,   391,     8,  6467,    11,    14,     3,     2,\n",
      "           104,     7,     2, 12028,    40,  3717,    27,  5760,    29,  1783,\n",
      "           496,  1421,  2869,     3],\n",
      "        [   64,   188,    16,     9,  1128,    19,   101,    49,    21, 14191,\n",
      "            20,   425,   109,   578,   272,    42,  1568,    39,   957,    21,\n",
      "           143,    20,     3,     0],\n",
      "        [   30,    33,   141,    22,   373,  4320,    10,     4,  8734,  2815,\n",
      "             2,  1068,  3098,   107,   373,  9748,     6, 15903,    21,    57,\n",
      "            20,     3,     0,     0],\n",
      "        [  141,    15,   515,  1107,   215,    17,   492,   426,   409,  1394,\n",
      "            23,  2081,   321, 24794,     5,   437,   545,    21,   129,    20,\n",
      "             3,     0,     0,     0],\n",
      "        [   64,   188,    16,     9,   444,    19,     4,   186,     5, 40228,\n",
      "           564,    25,  6256, 19103,  5990,  1968,   111,  2449, 40229,     8,\n",
      "           388,     7,     3,     0],\n",
      "        [20478,  5365,   290,  3851,    29,  2944,  8310,     2,  5743,  9869,\n",
      "             2,    15,  3051,  9202,  1702,     6, 22735,   474, 22736,    21,\n",
      "            72,    20,     3,     0],\n",
      "        [ 2393,    93,    46,  3360,   276,   400,    25,     4,  2393,   104,\n",
      "           314,    53,   154,    21,   128,    20,     2,    32,    38,    57,\n",
      "             3,     0,     0,     0],\n",
      "        [24580,  1143,    31,   841,    22,     4,   552,     5,     4,   263,\n",
      "           267,     9,     4,  1251,     5, 19010,     9,    21,  1393,    20,\n",
      "             3,     0,     0,     0],\n",
      "        [ 8322,  3147,     6,   536,    10,  7997,     5,  3519,   446,     8,\n",
      "          5486,     2,    68,    13, 10524,     6, 16393,     2,    76,     7,\n",
      "             3,     0,     0,     0],\n",
      "        [ 1574,  1120,  2176, 17373,  9137,   486,    37,  9254, 30695,     6,\n",
      "          1000,    48,     4,   627,   874, 30696,     8,  7264,     2,   274,\n",
      "             7,     3,     0,     0],\n",
      "        [ 8322,  3147,     6,   536,    10,  7997,     5,  3519,   446,     8,\n",
      "          5486,     2,    68,    13, 10524,     6, 16393,     2,    76,     7,\n",
      "             3,     0,     0,     0],\n",
      "        [   21,   191,    20,   512,  1177,    19,     4, 17089,  1895,     5,\n",
      "            60,   507,   535,   548,     6,    43,    45,    51,    18,     4,\n",
      "           535,   204,     3,     0],\n",
      "        [13787, 23898,     7,    10, 24985,     7,    40,    27,   806,  2506,\n",
      "            48,   299,     5, 24986,     2, 24987,     2,     6, 24988,    21,\n",
      "          1787,    20,     3,     0],\n",
      "        [ 7516,    37,  3107,    25,    15, 28447,  1138,     8, 10968,  7066,\n",
      "             7,    22,   100,   122,     8,  3135,    11,    14,     3,     2,\n",
      "            76,     7,     3,     0],\n",
      "        [   26,  1166,     5,   935,  9357, 11394,     8,  2472,  8223,    13,\n",
      "          5792,    11,    14,     3,    78,     7,     2,   490,  1738,     8,\n",
      "          2472,  6744,    13,  6514],\n",
      "        [ 2142, 17827,     7,   485, 20292,     9,    78,    54,    25,  1090,\n",
      "             9,   297,   438,  3530,     6,    59,   637,    21,   630,    20,\n",
      "             3,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 2, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['dfc2be0a46fc009e5053dcc0d581f37677cbe3ff', '05b911454b50fd97fab7c2a1ecc4ecf0e232f2ec', 'd7b6753a2d4a2b286c396854063bde3a91b75535', '026b7cae6eb1dfa570ddc4100135ff7b5023b6de', '7eebd869d9a5124ea54d505cc9202d2e7a623a20', '785d26e6592278f48c9eb68eb1e3388788c76b32', 'e57e58569dcede6b8af27bc468f06a249371ea75', '8673d4d5c0b71aed52661a102cefafb88d18df4d', '2594d5a4fe56fd16b141fc870ffa202daee78435', '2f836dd9b1fc766206c6e75cb9b295eb5b647bef', '2594d5a4fe56fd16b141fc870ffa202daee78435', '5b354179c5a44f4da7e6e162506888d58e462010', 'c7c27ef10e0ecc6b63b40fc7dea2c6acf48f294f', '69ae64d68e33c7353a78d8b92699764237899293', 'd9f3207db0c79a3b154f3875c9760cc6b056904b', '4e687843401f339f6b5e8ae35626d0d0ef0b3e7e'], 'cited_paper_id': ['016293fd7901a77538fc361d8c4fa49aefc4cabd', '8b1dca3ba6a60f855ab760dc8a6ef986dc3c5efc', '128cb6b891aee1b5df099acb48e2efecfcff689f', '0b29c289bc5f0fa7e51090d1ad00654754b68b94', '6bc005167304a410c19c447d355a25c2004e24f3', '35c27b0c0db73af7303c0a95efa90479afb04fed', '38211dc39e41273c0007889202c69f841e02248a', 'aff90697871e8267fd656bcbc1c3edac419200c1', '14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '489f1c42927dca534bc78c0754fa30ad51605d9a', '14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '9869351af2dfc3cb04b0937ea6c3078fa9e71a50', '037f27dcddb927e3c49fd51d49f45bf6625234e6', 'ffda69667078442320c9fe84edf1417ca539f668', '2cc6ff899bf17666ad35893524a4d61624555ed7', 'e10d07fb294bce937f481acb05bfa970a0427a47'], 'citation_excerpt_index': [0, 0, 3, 4, 0, 0, 0, 0, 10, 3, 10, 1, 9, 0, 2, 0], 'citation_id': ['dfc2be0a46fc009e5053dcc0d581f37677cbe3ff>016293fd7901a77538fc361d8c4fa49aefc4cabd', '05b911454b50fd97fab7c2a1ecc4ecf0e232f2ec>8b1dca3ba6a60f855ab760dc8a6ef986dc3c5efc', 'd7b6753a2d4a2b286c396854063bde3a91b75535>128cb6b891aee1b5df099acb48e2efecfcff689f', '026b7cae6eb1dfa570ddc4100135ff7b5023b6de>0b29c289bc5f0fa7e51090d1ad00654754b68b94', '7eebd869d9a5124ea54d505cc9202d2e7a623a20>6bc005167304a410c19c447d355a25c2004e24f3', '785d26e6592278f48c9eb68eb1e3388788c76b32>35c27b0c0db73af7303c0a95efa90479afb04fed', 'e57e58569dcede6b8af27bc468f06a249371ea75>38211dc39e41273c0007889202c69f841e02248a', '8673d4d5c0b71aed52661a102cefafb88d18df4d>aff90697871e8267fd656bcbc1c3edac419200c1', '2594d5a4fe56fd16b141fc870ffa202daee78435>14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '2f836dd9b1fc766206c6e75cb9b295eb5b647bef>489f1c42927dca534bc78c0754fa30ad51605d9a', '2594d5a4fe56fd16b141fc870ffa202daee78435>14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '5b354179c5a44f4da7e6e162506888d58e462010>9869351af2dfc3cb04b0937ea6c3078fa9e71a50', 'c7c27ef10e0ecc6b63b40fc7dea2c6acf48f294f>037f27dcddb927e3c49fd51d49f45bf6625234e6', '69ae64d68e33c7353a78d8b92699764237899293>ffda69667078442320c9fe84edf1417ca539f668', 'd9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6ff899bf17666ad35893524a4d61624555ed7', '4e687843401f339f6b5e8ae35626d0d0ef0b3e7e>e10d07fb294bce937f481acb05bfa970a0427a47']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  67,  98,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 103, 106,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  80, 117,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 105, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73,  50,  ..., 261, 261, 261],\n",
      "         [259,  99, 106,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 112,  99,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 115,  ..., 261, 261, 261],\n",
      "         [259, 116, 106,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]]], device='cuda:0'), 'tokens': tensor([[ 1207,    25,   122,   503,    52, 20984,   283,  6079,     6, 42444,\n",
      "           178,     6, 14225,     6, 32627, 42445,     9, 30446,   915,    21,\n",
      "           297,     2, 42446,    20,     2,    43,     0,     0,     0],\n",
      "        [   26,   149,   682,  1853,    10, 34852,     4,   769,   636,     5,\n",
      "          6537,   352,  3589,    28,  6019,  2248,    49,     8,  4532,    11,\n",
      "            14,     3,     2,    63,     7,     3,     0,     0,     0],\n",
      "        [   64,    16,   228,    19,   122,    82,    52,     8, 36229,    11,\n",
      "            14,     3,     2,   113,    13, 36230,     6,  1527,     2,    87,\n",
      "            13, 36231,     6, 36232,     2,   190,     7,     3,     0],\n",
      "        [  129,    73,     7,   382,    19, 12766,  4482,   233,  4029,     8,\n",
      "             4,  7309,    62,    45,   176,  1257,    13, 13035,    11,    14,\n",
      "             3,     2,    79,     7,     3,     0,     0,     0,     0],\n",
      "        [  217,  1124,    39,  1875,   666,     8,   224,  1333,     6,   240,\n",
      "          1444,     7,   281, 14521,     9,     4,  4087,   707,    22,   100,\n",
      "           122,     8,   873,     7,     3,     0,     0,     0,     0],\n",
      "        [19642,    21, 18928,    11,    14,     3,     2,   316,    20,  3264,\n",
      "             4,    98,  5848,    23,   127,   348,  1255,   189,     4,   574,\n",
      "             5, 10374,   671,   417,    59,     3,     0,     0,     0],\n",
      "        [ 6914,   683,    30,   805,    65,   479,    18,    55,   344,    50,\n",
      "            22,   511,  5260,    21,   300,    20,     2,    29,  3554, 19804,\n",
      "           754,    21,   222,    20,     3,     0,     0,     0,     0],\n",
      "        [10376,     5,  3383,  1828,    15,  3155,  1004,     2,  3383,    31,\n",
      "           663,    48,     4,   167,   635,    22,    38,    33,   122,   100,\n",
      "             8, 19940,    11,    14,     3,   209,     7,     3,     0],\n",
      "        [   93,   122,    82,    17,    39,   515,    16,     4,   188,     5,\n",
      "           173,   178,     5,  9661,    80,  9662,     9,   218,    57, 12945,\n",
      "             8,  8765,    11,    14,     3,    79,     7,     3,     0],\n",
      "        [ 4059,    38,    33,   105,    10,  1300,    10,  1451,  4599,   642,\n",
      "          1956,  3402,  4774,    50,    22,  6149,    21, 21213,    20,     6,\n",
      "            10,  2568,  1505,  1367,    21, 21770,    20,     3,     0],\n",
      "        [12757,     6,  6234,     5, 22127,   329,     8, 15545,     6, 15546,\n",
      "             2,   390,    13, 16536,     6,  7651,     2,   309,    13,  7652,\n",
      "            12,  7725,     6,  7651,     2,   428,     7,     3,     0],\n",
      "        [30706,    24,     9,     4,   319,     5,   102,    52,    82,    18,\n",
      "           536, 27064,    21, 30707,    20,     2,    21,   341,    20,     2,\n",
      "            21,   399,    20,     6,    18,     0,     0,     0,     0],\n",
      "        [12201,  7108,    10,   922,   884,   136,  4120,     2,    69,     2,\n",
      "            19,     4,  5786,     5,   207,   517,  1817,     2,    16, 14636,\n",
      "          1111,  1943,  4092,     8,  6215,     2,    63,     7,     3],\n",
      "        [ 4414,     2,   396,     2,    30,    92,    15,   748,    67,   740,\n",
      "          1853,     5,  4123,  1550,     8, 16095,    11,    14,     3,    78,\n",
      "             2, 11415,    11,    14,     3,   132,     7,     3,     0],\n",
      "        [23998,   436,    49,    47, 12400,     5,  4221,    12,   324,  1892,\n",
      "          3184,    31,   465,     9, 11154,    91,  2680,     4, 23998,    48,\n",
      "             4,   124,   100,     9,    21,   346,    20,     3,     0],\n",
      "        [   93,  2290,    39,   186,     9,    21,   371,    20,    13,   136,\n",
      "           210,     2,    60,   124,    40,   188,     9,   109,  1115,     5,\n",
      "             4,  3795, 10719,    10,  2819,   252,   210,   507,     3]],\n",
      "       device='cuda:0')}, 'labels': tensor([0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['340300238e998780678ad5f97c8e1807be13766d', '0751ca9d7eb15f21e90374b6fcdc299948d2111e', '78b13ce1ac839e44b69b65125c9e342debc6cea5', '32f1eae0b439b4138030464580776428020f3998', 'a2c3de455c882a92868b7b6e7e5c7b303551dd3a', '7659b9a095f9710c85243fd1a506c62263b91a6e', 'b067f0d6b86875639c6cbd568cf0077124e64dc7', '2bb1c8249ecb499e0f8e1a7e5fe3222f6a026304', '0fd548a07b8d113f5f6a6255abe191668120ac53', '8549f3526917c14994cd25af7668b49a79c50a7e', '2bb2505c500ea1382402cd8bf423a8a8715e1f0c', '0cd88668fc28e1d5828a7a3e4b4e0c2721fa77e8', '191c39c62582891a2566b06bc3c1d88ea472c581', '4a7abe00115bcee0d615d88fbd4d891671a009f1', '7119b00e3e901c828fe67fdf97d3e0d17e5e7e8d', 'c4b477f669c1e58394ebf4915f7eb59c770b0fcb'], 'cited_paper_id': ['560e28cb2e297629602a33fd6358703dfc8711a3', '6520584cb0d400b610e60c6195c0abb66cf7de11', 'None', '8425e35c51e6325d19c108ff6a43812a6e417296', '42f4cef937ab22acef516f0e5f5779397df91074', 'bb75de5280ff9b0bbdd74633b9887d10fbe0ae10', '420c1e183e5ce4e45c9c14075b925974a5d55d3c', '7bdb19b32e19cacc937b0b16ab57ab943c6a7c5c', '74809ba2f3834024b56f5b0784655b1435708c60', '575ee2415035c44c0f1ffc1de85232e1c3e26783', '7e98ff7d7eddadc7f32a776a66585475e6d236f4', 'None', '81652485e54c489c5d106d278ae28a6c784992c8', '720895e0bb8f2a9f6b84e0a8248e4b85feaf6ae2', 'c3022a787a04bdea801dbc2b4bd254e9dcbf5db8', '7c989cda97694cd13d10b92ff1813362e2750197'], 'citation_excerpt_index': [2, 0, 0, 1, 1, 0, 1, 3, 6, 3, 3, 0, 2, 3, 0, 3], 'citation_id': ['340300238e998780678ad5f97c8e1807be13766d>560e28cb2e297629602a33fd6358703dfc8711a3', '0751ca9d7eb15f21e90374b6fcdc299948d2111e>6520584cb0d400b610e60c6195c0abb66cf7de11', '78b13ce1ac839e44b69b65125c9e342debc6cea5>None', '32f1eae0b439b4138030464580776428020f3998>8425e35c51e6325d19c108ff6a43812a6e417296', 'a2c3de455c882a92868b7b6e7e5c7b303551dd3a>42f4cef937ab22acef516f0e5f5779397df91074', '7659b9a095f9710c85243fd1a506c62263b91a6e>bb75de5280ff9b0bbdd74633b9887d10fbe0ae10', 'b067f0d6b86875639c6cbd568cf0077124e64dc7>420c1e183e5ce4e45c9c14075b925974a5d55d3c', '2bb1c8249ecb499e0f8e1a7e5fe3222f6a026304>7bdb19b32e19cacc937b0b16ab57ab943c6a7c5c', '0fd548a07b8d113f5f6a6255abe191668120ac53>74809ba2f3834024b56f5b0784655b1435708c60', '8549f3526917c14994cd25af7668b49a79c50a7e>575ee2415035c44c0f1ffc1de85232e1c3e26783', '2bb2505c500ea1382402cd8bf423a8a8715e1f0c>7e98ff7d7eddadc7f32a776a66585475e6d236f4', '0cd88668fc28e1d5828a7a3e4b4e0c2721fa77e8>None', '191c39c62582891a2566b06bc3c1d88ea472c581>81652485e54c489c5d106d278ae28a6c784992c8', '4a7abe00115bcee0d615d88fbd4d891671a009f1>720895e0bb8f2a9f6b84e0a8248e4b85feaf6ae2', '7119b00e3e901c828fe67fdf97d3e0d17e5e7e8d>c3022a787a04bdea801dbc2b4bd254e9dcbf5db8', 'c4b477f669c1e58394ebf4915f7eb59c770b0fcb>7c989cda97694cd13d10b92ff1813362e2750197']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         [259,  41, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 122,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 109, 102,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  68, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259,  81, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 117,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 109,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 110, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,    59,     8, 12616,     6, 17046,     2,    70,    13, 18583,\n",
      "            11,    14,     3,     2,    75,     7,    31,    54,    25,     4,\n",
      "         11430, 11217,  6879, 13467,     8, 18584,     7,     8,  8394,    11,\n",
      "            14,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [32940,     5,     4, 18408,   246,   910,    33,    82,     9,   147,\n",
      "            49, 16918,    17,     4,   450,     5, 32941,  2283,    31,    92,\n",
      "            10,    27,   387,   214,     9,    95,   232,   231,    19,  1257,\n",
      "            21, 32942,    20,     3,     0,     0,     0,     0],\n",
      "        [ 3885,    31,  3145,    10,   974,    15,  2723,  9124,     5,     4,\n",
      "           482,    19,  2826,  4462,    21,   125,     2,  1532,     6,  6968,\n",
      "             2,   113,    13,  3915,     6,  1532,     2,    97,    13,  1532,\n",
      "            11,    14,     3,     2,    85,    20,     3,     0],\n",
      "        [ 3022, 13999,  5427,    28,   640,    12,  6243,  1325,    30,    33,\n",
      "           238,     9,  1336,    49,     8, 35234,    11,    14,     3,    75,\n",
      "            13, 12179,    11,    14,     3,    83,    13,  1800,    11,    14,\n",
      "             3,   118,     7,     3,     0,     0,     0,     0],\n",
      "        [  144,    52,    24,     9,   685,    19, 11441,   122,    82,    18,\n",
      "         19659,   540,     8,   722,    11,    14,     3,     2, 45531,     6,\n",
      "         45532,     2,    83,    13, 45533,    11,    14,     3,     2,   104,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [   26,   487,     5, 23976,    10,  2786,     4,   178,     5,  5852,\n",
      "          1054,     2,  1526,     4,  3349,  4167,   915,   363,     2,  8843,\n",
      "             2,    38,    33,  1756,     9,    99,  8644,     6, 15419,  2087,\n",
      "            21,   143,     2,   533,    20,     3,     0,     0],\n",
      "        [   41,    39,  1110,     2,    71,    52, 15817,  7760,    19,     4,\n",
      "           599,    17, 31719,     6, 31720,    24,    42,   584,    10,  1581,\n",
      "         13741,  1234,     9,   120,   952,   400,     8, 31721,     6,  8874,\n",
      "             2,    68,     7,     3,     0,     0,     0,     0],\n",
      "        [ 1243,     4, 16583,   304,   675,    58, 21417,     6,  6484,     5,\n",
      "             4,  1892,   235,   990,    51,  1241,   335,    17,  6455,   397,\n",
      "          4879,    28,  6440,    19,  3641,   990,  3441,    10,   192,   545,\n",
      "             5,   792,  1289,     8,  9725,   428,     7,     3],\n",
      "        [  728,     4,    52,    37,    82,     9,     8,  8784,    11,    14,\n",
      "             3,    76,   825,     7,     9,  1225,     2,   777,    43,   106,\n",
      "          3997,  1031,     4,    52,     2,    19,    15,   331,   570,    25,\n",
      "          2659,   518,     3,     0,     0,     0,     0,     0],\n",
      "        [  112,  8083,     5, 17861,    91,     2,   952,  9353,    37,  4884,\n",
      "            48,  2277,  8724,  4045,     8, 21109,     7,    19,  1390,    12,\n",
      "          8569,  5714,    91,     8, 32918,    36, 32919,     2,   661,    13,\n",
      "          5841,    11,    14,     3,     2,    61,     7,     3],\n",
      "        [ 4659, 15795,   268,  5486,     8,    68,     7,    30,  1984,  4693,\n",
      "           984,   978,  9678,   944,  9691, 13620,     2,    71,   137,  5921,\n",
      "           529,     4,   177,     5, 20227,   403,    27,   588,  2448,    18,\n",
      "             4, 29521, 13620,     3,     0,     0,     0,     0],\n",
      "        [32986, 32987,     8, 32988,     2, 32989,   242,     7,  3284,    77,\n",
      "             5,     4,  1099,  4231,  1897,     5,  2805,  3640,     8,  1571,\n",
      "            11,    14,     2,    61,    13, 27169,     6, 15677,     2,    68,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 3121,    73,     5, 14675,  2958,   175, 16146,     7,  5576,     5,\n",
      "             4, 12302,   568,    17,     4,   450,     5,     4, 16147,  3296,\n",
      "             9,   175,   486,    16,  6166,   501,    47,  1443,  9887,     5,\n",
      "          2168,  3537,     2,   237,     3,     0,     0,     0],\n",
      "        [ 4736,     5,  7978,   854,     9,     4,  3197,     6,  5346,   144,\n",
      "           247,  1086,   138,   338,    82,     9,     4,  5346,     2,   146,\n",
      "             4,  5207,  3835,   128,  1483,    16,    46,   565,     8,  6407,\n",
      "            11,    14,     3,     2,    63,     7,     3,     0],\n",
      "        [  153,    16,    46,   171,    10,  4391,    71,    53,    19,     4,\n",
      "           638,    17,   109,  1414, 22126,  5780,   424, 15329,  2299,  1364,\n",
      "            15, 11809,     2,   508,    67,   478,     2,  1266,    12,  5256,\n",
      "          1658,    21,   222,     2,   571,    20,     3,     0],\n",
      "        [  323,     4,   465,   263,    24,  1083,     4,  4578,   156,     8,\n",
      "         11955,     6,  2788,    85,     7,     2,    77,   264, 21943,   623,\n",
      "          2210,    66,  2905,    28,    34,  3225,  2671,     5,   730, 11361,\n",
      "             9,  4199,  1580,     3,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 2, 0, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['29cd81b4d95c3c99d2d27629e2acf0f5e3c2ec17', '2eb4969576aa13487c087bcadfce196a46a96405', '599de37e6628fd9e2f42eff08de73e85fc9e3e10', 'b66eb0bfa520726f50d86a62388c086c7046a6cd', 'cfb8d1580c6b099ddb7e575b48b35868eb2d1c03', 'd67d3f2b315999a87d5e8956ba754f9d1d7f88ff', 'f1a9ae501575363f79e555c5bf6daa3de2f093b2', '0f9f0fec5e2d944821c825437f48f83f356e5055', '922f2fb5ebc5d7d8e08b087bdd4df2855bdd4b48', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9', '2594d5a4fe56fd16b141fc870ffa202daee78435', 'aad54bab7e130c6ff074a93e17e06aacfa17df7e', 'cf0174fcb83c9c65b6e736b2c10ee615dc8f8993', '602d56f55b8c21475c9bf67e73c5d8e999ee9696', 'dbda2b32dd5eb3e63c96243d0a81c7d9248bf2b9', '3b1fee9510b99585557de0d30852ae1e75cbbd26'], 'cited_paper_id': ['549965db135e62ba1de843f6aa68d5b04bf3e850', 'f375431b6149f1d5b2013ab305619799bcb4eefc', 'd55c95cedf9904a2776b682518c24b4d4d96bec7', 'd8431c25f60a51517a29162ed70df2de35ee156f', '3b05b86247b92bcac943e77fd2ae3a5c1e770f7b', 'cbd59360917490ea9a05feea6419340a36dc0427', '1946902a6eb14c679524c70afd44665568e92c3d', 'd0117b1034a7c431fbd7454e13ee0c5064e21ee7', '73f8d428fa37bc677d6e08e270336e066432c8c9', '6d6bb93872a190de290f259e63587db4f17d539c', '14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '989704240988ed42cf4cada69f2f9a6eecd6b15c', 'a3ad3b4609bb8bf85c8c2115cb76d0e5cd16df12', 'd9bb6f5360b6e9413e5f675d4164e29a6040a7c0', 'a6574ccbb62b943a2f199be5a196161a5d345610', '14665674e2db3e3b7b16ebe7ecab87bfdf7c0e41'], 'citation_excerpt_index': [0, 7, 10, 0, 0, 1, 0, 0, 8, 10, 2, 0, 0, 6, 7, 2], 'citation_id': ['29cd81b4d95c3c99d2d27629e2acf0f5e3c2ec17>549965db135e62ba1de843f6aa68d5b04bf3e850', '2eb4969576aa13487c087bcadfce196a46a96405>f375431b6149f1d5b2013ab305619799bcb4eefc', '599de37e6628fd9e2f42eff08de73e85fc9e3e10>d55c95cedf9904a2776b682518c24b4d4d96bec7', 'b66eb0bfa520726f50d86a62388c086c7046a6cd>d8431c25f60a51517a29162ed70df2de35ee156f', 'cfb8d1580c6b099ddb7e575b48b35868eb2d1c03>3b05b86247b92bcac943e77fd2ae3a5c1e770f7b', 'd67d3f2b315999a87d5e8956ba754f9d1d7f88ff>cbd59360917490ea9a05feea6419340a36dc0427', 'f1a9ae501575363f79e555c5bf6daa3de2f093b2>1946902a6eb14c679524c70afd44665568e92c3d', '0f9f0fec5e2d944821c825437f48f83f356e5055>d0117b1034a7c431fbd7454e13ee0c5064e21ee7', '922f2fb5ebc5d7d8e08b087bdd4df2855bdd4b48>73f8d428fa37bc677d6e08e270336e066432c8c9', 'cc56eae2528bb87fe4adabf1a4487b8636e767b9>6d6bb93872a190de290f259e63587db4f17d539c', '2594d5a4fe56fd16b141fc870ffa202daee78435>14ae303b271f189e54ef5089b7b2d9dd22d54ce0', 'aad54bab7e130c6ff074a93e17e06aacfa17df7e>989704240988ed42cf4cada69f2f9a6eecd6b15c', 'cf0174fcb83c9c65b6e736b2c10ee615dc8f8993>a3ad3b4609bb8bf85c8c2115cb76d0e5cd16df12', '602d56f55b8c21475c9bf67e73c5d8e999ee9696>d9bb6f5360b6e9413e5f675d4164e29a6040a7c0', 'dbda2b32dd5eb3e63c96243d0a81c7d9248bf2b9>a6574ccbb62b943a2f199be5a196161a5d345610', '3b1fee9510b99585557de0d30852ae1e75cbbd26>14665674e2db3e3b7b16ebe7ecab87bfdf7c0e41']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259, 112, 118,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 103, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         [259, 227, 129,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  80, 118,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259,  98, 104,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69, 106,  ..., 261, 261, 261],\n",
      "         [259, 111, 102,  ..., 261, 261, 261],\n",
      "         [259, 111, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  323,    71,    52,  ...,     3,     0,     0],\n",
      "        [  152,     2,  5055,  ...,     0,     0,     0],\n",
      "        [   26,  2623,   194,  ...,  7256,  3605,    35],\n",
      "        ...,\n",
      "        [  311,    52,  2782,  ...,     0,     0,     0],\n",
      "        [29293,   269,   158,  ...,     0,     0,     0],\n",
      "        [  665,     2,     4,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['1ec3f8306c419abe3fec0be68973947be34435b2', '2051356ab3b598e148ad2ef4a82bfb88eb29f5e3', '24fe18db8ad1c3b1d77a73b1fea0f9a471434bf7', 'ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b', '2b80f65e936e58979de232164026543edb2a79e8', '1cb10d6d52502084cb4d8e00111d0ed8955b98ac', 'fbe2e93b5fd0fd0de2d70e1d7f72fb2726089767', 'f9fe13905c5ac93723c8ac041bdb6ce560343899', 'acf25d8891760616a5d1b1559d417da5a828eb8e', '2594d5a4fe56fd16b141fc870ffa202daee78435', '38f75407e33adf753372ad61a05761abff2bd9b1', 'd192abf533edb3781cfb5f3215592fbc08cb7c2b', '602d56f55b8c21475c9bf67e73c5d8e999ee9696', '440cd84e5d0b7f825bb7c37f0bf5d08ae74b05ab', '2b17452f6a3f4091902d181399299538b299bf14', '2aa09a39a333f7f0fd0c141b2805f574a83b532e'], 'cited_paper_id': ['1149e7c8f5794cb46aa362136f4298d06c8ef826', 'fc5e3ad866cff397fe564e2f165adf6ba240ab3a', '57220e5e1106b295bab12105c79f6307ab220e0f', 'b6642e19efb8db5623b3cc4eef1c5822a6151107', '8f01119d68d6a980ec1608e905be6e4f58cb328a', '7d32e3cb0dbcf2ea9e82747629d6ed929fcb94f3', '91a0b51a40eeb061d51e141503a7432acdc8ca5e', '536420458ac98229a602054db9e9b5320c60c29d', '0caf766f329fd37a699a5c3ec62aebb1c9d44f1a', '14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '8067ef3a4a8c620f615368408a811747cacb15dc', 'fb3aad7f63ad9d98ccde41a2168d10750ff47685', 'd9bb6f5360b6e9413e5f675d4164e29a6040a7c0', 'aaa755ce1aede91735d14134e213374a11df5ee7', 'c1bb9e5e9c34fc42c66382fb0215a2ee0d588201', '9a6e4cfedde7ad5f810d857afeb45cc4ec3ccc1b'], 'citation_excerpt_index': [0, 0, 0, 3, 5, 13, 0, 1, 2, 7, 0, 4, 3, 0, 2, 2], 'citation_id': ['1ec3f8306c419abe3fec0be68973947be34435b2>1149e7c8f5794cb46aa362136f4298d06c8ef826', '2051356ab3b598e148ad2ef4a82bfb88eb29f5e3>fc5e3ad866cff397fe564e2f165adf6ba240ab3a', '24fe18db8ad1c3b1d77a73b1fea0f9a471434bf7>57220e5e1106b295bab12105c79f6307ab220e0f', 'ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642e19efb8db5623b3cc4eef1c5822a6151107', '2b80f65e936e58979de232164026543edb2a79e8>8f01119d68d6a980ec1608e905be6e4f58cb328a', '1cb10d6d52502084cb4d8e00111d0ed8955b98ac>7d32e3cb0dbcf2ea9e82747629d6ed929fcb94f3', 'fbe2e93b5fd0fd0de2d70e1d7f72fb2726089767>91a0b51a40eeb061d51e141503a7432acdc8ca5e', 'f9fe13905c5ac93723c8ac041bdb6ce560343899>536420458ac98229a602054db9e9b5320c60c29d', 'acf25d8891760616a5d1b1559d417da5a828eb8e>0caf766f329fd37a699a5c3ec62aebb1c9d44f1a', '2594d5a4fe56fd16b141fc870ffa202daee78435>14ae303b271f189e54ef5089b7b2d9dd22d54ce0', '38f75407e33adf753372ad61a05761abff2bd9b1>8067ef3a4a8c620f615368408a811747cacb15dc', 'd192abf533edb3781cfb5f3215592fbc08cb7c2b>fb3aad7f63ad9d98ccde41a2168d10750ff47685', '602d56f55b8c21475c9bf67e73c5d8e999ee9696>d9bb6f5360b6e9413e5f675d4164e29a6040a7c0', '440cd84e5d0b7f825bb7c37f0bf5d08ae74b05ab>aaa755ce1aede91735d14134e213374a11df5ee7', '2b17452f6a3f4091902d181399299538b299bf14>c1bb9e5e9c34fc42c66382fb0215a2ee0d588201', '2aa09a39a333f7f0fd0c141b2805f574a83b532e>9a6e4cfedde7ad5f810d857afeb45cc4ec3ccc1b']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  83,  98,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 117, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  54, 260,  ..., 261, 261, 261],\n",
      "         [259,  66, 111,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  83,  79,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  50,  58,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 115,  ..., 261, 261, 261],\n",
      "         [259,  83, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 100, 102,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259,  68,  69,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  51,  53,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[35719,   934,   260,     8,   143,     7,    31,   281,    18,     4,\n",
      "           535,     5,  4900,   539,   329,     8, 35720,     7,   234,    15,\n",
      "            81,    12,   456,  4491,   293,     3,     0,     0,     0,     0],\n",
      "        [  128,   702,   160,     5,   822,    48,     4,   462,    12,   173,\n",
      "         17422,   462,  2525,  3235,  1656,     9,    95,  2632, 11490,    16,\n",
      "           105,    21,   240,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [  719,  2117,     2,  2265,  1254,    12,   858,     2,     6,  6859,\n",
      "           123,  3954,   719,    31,  1016,    28,  7751,    91,   234,     4,\n",
      "           116,     5, 21068,    11,    14,     3,     8,   198,     7,     3],\n",
      "        [  775,   666,    37,   851,    12, 18933,   385,    10,     4,  9829,\n",
      "         13629,  2703,    21,   726,    20,     6,  2794,    15,  1982,  2739,\n",
      "            12,  1246,  1180,    18, 22632,    10,  2089,     3,     0,     0],\n",
      "        [16765,    31,    92,   168,    12,   539,     9,  3011,   317,    21,\n",
      "           313,     2,   630,    20,     2,  8689, 11905,     6,   618,   120,\n",
      "           772,    21, 34862,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [   93,    74,     4,  7916,    54,   933,  5052,     8, 30608,     7,\n",
      "            21,    57,    20,     5,     4,  1247,   819,   611,   574,  7162,\n",
      "            21,   224,    20,    18,    71,   505,     3,     0,     0,     0],\n",
      "        [ 9746,     2,    11,    14,    46,   259,    17,  7151,    31,     4,\n",
      "           101,   171,   363,     9,   621,  8066,   348,     6,     4,  5477,\n",
      "            10,  2339,    29,   417, 12585,     8,   630,     7,     3,     0],\n",
      "        [  205,   376,     9,    21,   236,    20,     2,    15,   877,   912,\n",
      "            16, 47570,   212, 47571,     7,   155, 47572,     7,     2,    18,\n",
      "          1072,   324, 14538,  1627,     5,  2510,     0,     0,     0,     0],\n",
      "        [  569, 10894,    18, 10297,    15,  1199,   229,    44,   836,     5,\n",
      "          6972,    12,  2220,    17,    24,     9,     4,   319,     5,     4,\n",
      "         31147,    22,   105,   122,     8,    90,     2,   191,     7,     3],\n",
      "        [ 2529,    19, 29621,    11,    14,     3,     8,  4290,     7,     2,\n",
      "           919,   709,     9,     4,  1204,   232,     9,    39,    62,    37,\n",
      "           307,   214, 25072,  2802,   735,    23,     4, 23996,     3,     0],\n",
      "        [   90,  5453,  2628,   775,   208,   116,   141,     9,     4,  4397,\n",
      "            37,   985,    25,     4, 45204,   540,     2, 45205,     2, 45206,\n",
      "             6, 45207,    21,  9970,    20,     3,     0,     0,     0,     0],\n",
      "        [18040,   855,    24,   171,     9,     4,   817,     5,    21, 17326,\n",
      "             6,    21, 38589,     9,  5372,  3396,    12,  5658,    91,     8,\n",
      "           277,     2,   388,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26,   603,   755,  2074,    96,  1231,   281,   136,     4,   603,\n",
      "             2,  1717,   196,     5,   861,     2,     6,   566,   107, 12207,\n",
      "             2, 10180,     2,     6, 15404,    21,   297,    20,     3,     0],\n",
      "        [ 5402,   235, 19968,     5, 14314,  2193,     9, 22272,  1223,  1235,\n",
      "          7676,  1045,    31,   324,    23, 21442,    22,   100,   122,     8,\n",
      "         22273,    11,    14,     3,   142,     7,     3,     0,     0,     0],\n",
      "        [   91,   539, 23610,     9,  8206,    19, 23611, 14627,    91,     9,\n",
      "             4,  1098,     5, 22770,     6,     9,     4,   458,     5, 23612,\n",
      "          4134,    21,     8,    72,     7, 23613,    20,     3,     0,     0],\n",
      "        [   21,   346,    20,   259,    17,     2,    18,    39,  1096,     5,\n",
      "          1027,   308,   671,     2,   374,    12,  3120,  1539,    40,    27,\n",
      "           281,  8643,    48,    34,   929,  4823,   215,     3,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['fe4616d6aafc51182b29a9c316b5263428c78cf8', '9e078ee7c0e24bbbe0009bce3174dee06a5d440e', '2ad71f1dc2d5e515c4950f974d58294544aeccd4', 'b649c288a1d462fa8989a00f0e3586c355cae350', '30377db1a691d7481f098f28de925719526430e4', '059ae9f412826ea0b2be5d9379981fd1e97f13ee', 'b8ad040357eaae50c8efbe3cc8ae9d93b800db2d', 'b8bffa786710b52c95201796bade07fc2ad3f38d', '518865ff46726c9f26d62f8ebb007f1b0e283806', '63e49e0adb60701f8f8004dfb867edd1edfac74d', '3681cf18350d348acb4b27db3af37e7428670df9', 'a67c354e045f7c099c66238ae7b4b1fb74e77989', '409d3ba6c491c51ca45fc8a7273015432571192c', 'e9e1691f28a16cef81c3222cf1acb3a02a45d01c', '48aad9731fe6e0dfeb52672fab0c656121da2069', '1f35f0400d6d112e3b27231d0d9241258efd782d'], 'cited_paper_id': ['98969903990c9284bed00757b46cdb5f575a0e43', 'c14837c7f03add6100f1058023469212e4429452', 'c6b728d9170c68e85a0e23ead1a526ae01102abe', '75c2f465d59739dbc06b70fd34dc3c1b2336103e', '24edb0c67a2c99dd5ff01fab5ef0be02b568652b', '722fcc35def20cfcca3ada76c8dd7a585d6de386', 'e18666bf07e60f7414838aed88c0d35510bce67c', '0049b630e0bf4b14e76e36615c33aed0c39c3dd9', '29810e197fd6fb50a8acf2c6c5fc9d5f2c691dcb', '931b43e57787f7dfe3619931afdbfcd60921948f', 'b62430598576f433ed7b4c5c3d44000c236feab0', '72cfe9cd8e489d04dfb617a2a226c2e4bb45430d', '10aa0fd041168687e0a22b4e77d7623cf447b15e', '6167fd0e24174b54c623ee793bac97bc7dc80fd5', 'ccc0081fdfdaf2a88233b683fa5eff2ab139ed09', '361c28521f94c2f45fc1f5d49c0c150bee3778d8'], 'citation_excerpt_index': [0, 4, 0, 0, 0, 2, 0, 0, 5, 0, 7, 3, 0, 5, 6, 3], 'citation_id': ['fe4616d6aafc51182b29a9c316b5263428c78cf8>98969903990c9284bed00757b46cdb5f575a0e43', '9e078ee7c0e24bbbe0009bce3174dee06a5d440e>c14837c7f03add6100f1058023469212e4429452', '2ad71f1dc2d5e515c4950f974d58294544aeccd4>c6b728d9170c68e85a0e23ead1a526ae01102abe', 'b649c288a1d462fa8989a00f0e3586c355cae350>75c2f465d59739dbc06b70fd34dc3c1b2336103e', '30377db1a691d7481f098f28de925719526430e4>24edb0c67a2c99dd5ff01fab5ef0be02b568652b', '059ae9f412826ea0b2be5d9379981fd1e97f13ee>722fcc35def20cfcca3ada76c8dd7a585d6de386', 'b8ad040357eaae50c8efbe3cc8ae9d93b800db2d>e18666bf07e60f7414838aed88c0d35510bce67c', 'b8bffa786710b52c95201796bade07fc2ad3f38d>0049b630e0bf4b14e76e36615c33aed0c39c3dd9', '518865ff46726c9f26d62f8ebb007f1b0e283806>29810e197fd6fb50a8acf2c6c5fc9d5f2c691dcb', '63e49e0adb60701f8f8004dfb867edd1edfac74d>931b43e57787f7dfe3619931afdbfcd60921948f', '3681cf18350d348acb4b27db3af37e7428670df9>b62430598576f433ed7b4c5c3d44000c236feab0', 'a67c354e045f7c099c66238ae7b4b1fb74e77989>72cfe9cd8e489d04dfb617a2a226c2e4bb45430d', '409d3ba6c491c51ca45fc8a7273015432571192c>10aa0fd041168687e0a22b4e77d7623cf447b15e', 'e9e1691f28a16cef81c3222cf1acb3a02a45d01c>6167fd0e24174b54c623ee793bac97bc7dc80fd5', '48aad9731fe6e0dfeb52672fab0c656121da2069>ccc0081fdfdaf2a88233b683fa5eff2ab139ed09', '1f35f0400d6d112e3b27231d0d9241258efd782d>361c28521f94c2f45fc1f5d49c0c150bee3778d8']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  70, 103,  ..., 261, 261, 261],\n",
      "         [259, 113, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 113,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 112, 115,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 112,  ..., 261, 261, 261],\n",
      "         [259,  98, 119,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  79, 118,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[15936, 25518,   226,   264, 15513,   114,  4107,     5,  2497,  4929,\n",
      "             8, 13903,     7,   111,    60, 15550,  4298,   337,  4242,   672,\n",
      "             2,     6,    44,     4,   167,    84,   749,   195,  2535,     5,\n",
      "          4298,     8, 25519,    11,    14,     3,     2,    75,    13,  5082,\n",
      "            11,    14,     3,     2,   316,     7,     3,     0,     0,     0],\n",
      "        [   41,   245,    10,  6354,  2001,   843,    18,    15,   307,   246,\n",
      "            48,    15,  4130,  2187,     2,    15,   839,  2187,    38,    10,\n",
      "           149,    27,   325,    28,  3930,     8,    29,    55,  1912,    50,\n",
      "            22,  7559,    12, 11753,     2, 33446,    21,    72,    20,    29,\n",
      "          8976,    21,    90,    20,     7,     3,     0,     0,     0,     0],\n",
      "        [  217,  1249,  2143,     9,   265,    12,   757,   123,   557,    28,\n",
      "           537,  7658,  1229,     8,  2809,    12, 33373,     6,  5454,   404,\n",
      "             7,     2,    15,   258,   262,   926,    31,   679,    18,   108,\n",
      "           370,    23,  1552,     4,   648,     5,    87,  2217,  2404,     6,\n",
      "           426,  2488,   432,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [   64,  4023,   181,   456,   395,    38,    33,   122,    45,    10,\n",
      "          1346,  4282,  6115,     9,  1289,     2,  2868,   283,     2,  3235,\n",
      "             2,     6,  3662,     9,  6115,     9,    96,    12,   655,     6,\n",
      "          3050,   283,     9,    39,  2173,    21, 38255,    20,     2,     6,\n",
      "            55,    49,    21,   346,    12,   571,    20,     3,     0,     0],\n",
      "        [  690,     4, 22616,  1096,   291,     2,    43,  2015,     4,   538,\n",
      "             5,     4,  3716,   789,    19,  1654,  4385,    18,  5587,     2,\n",
      "           234, 26911,    11,    14,     3,     8,    68,     7,     3,    93,\n",
      "           439,   140,    25,    96,   789,    22,   103,    22,    25,     4,\n",
      "          3194,  1710,     5,  3716,   789,     3,     0,     0,     0,     0],\n",
      "        [28902,     5,     4,  1028,   486,   784,    15,  1111, 27206,     8,\n",
      "          1799,     7,   635,    10,  1749,  2513,    18, 28903,  1108,     2,\n",
      "           201,  4508,     5,     4, 30909, 20397,   423,    15,   221,    73,\n",
      "          2031,     5,     4,  3379,  7201,   475,    23, 21988,     9,    57,\n",
      "           867, 11220,     8, 30910,    11,    14,     3,    61,     7,     3],\n",
      "        [ 1207,  1009,    39,   603,     5, 10351,     2,   289,    37,  6351,\n",
      "           111,   208,   211,    12,   592,  2133,  6594,    56, 12350,   474,\n",
      "          2188, 18946,     5, 19653,     2,     4,   101,  6813,     5,    32,\n",
      "           435,    17,    99, 18330, 26935, 12552,     4,   211,    22,   910,\n",
      "         19653,    21,   240,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [ 1862,     4,  4235,  8332, 35744,   405,     2,     4,    74,     5,\n",
      "            15,  6937,   755,    38,    33,   872,    10,   762,     4,   782,\n",
      "             5,  1066,  1482,    32,  3673,     4,  8489,  2756,     6,    31,\n",
      "           150,    19,    15,  5130,   762,     9,     4,  1209,     5, 16525,\n",
      "           879,    21,   295,    20,     3,     0,     0,     0,     0,     0],\n",
      "        [ 1484,     2,   807,  2963,  1234,   602,    18,  6993,    12,  2148,\n",
      "          3764,    37,   846,     9,  2072, 29382,    54,    25,     4,  2079,\n",
      "          1733,   752,    80, 15773,     6,   208,   276,     5,    65,   807,\n",
      "           602,    37,  1514,     9,  2963, 16726,   532,     8,  6442,    11,\n",
      "            14,     3,    68,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26, 23012, 12049, 11081,    19,  1331,    12,  3216,  2547,    24,\n",
      "           745,  5847,    28,     4,  8657,   186,     8,   195,  2231,  5072,\n",
      "             2,    21,   240,    12,   224,    20,     7,     6,  1070,   855,\n",
      "             8,  8295,    12,     9,     6,   204, 25063,     2,    21,   224,\n",
      "            12,   143,    20,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26, 30637,     7,   986,    31,    15, 11956,     5,  2057, 30638,\n",
      "             6,  2057, 14817,     8, 25690,  2649,  1377,  9463,     7, 17347,\n",
      "           964,    37,  1554,  4884,    48,   258, 16404,   858,     8,   346,\n",
      "             2,   383,     7,    19, 30639,  2148,    10,     4,   246,     5,\n",
      "           581,     3,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [19857,     8,   301,    90,     7,     2,   228,    19,     4,   102,\n",
      "           188,     5,  2060,    11,    14,     3,     8,   113,     7,     3,\n",
      "          6157,     5,   114,   163,     5,  4468, 45322,     8,   976,     7,\n",
      "             6, 40644,     8, 38201,     7,    46,  3013,   120,  1367,     8,\n",
      "           301,    90,     7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 7210,  1921,  5288,   328,     5,  1446,  6030,     9,  1082,     6,\n",
      "          8606,     9,  2912,   159,    15,   628,  9583,    12,   501,   636,\n",
      "             2,    69,  2324,     5,    15,    12, 17915,     2,    32,    16,\n",
      "            42,   539,     9,  1446,  6030,     8,  5516,    11,    14,     3,\n",
      "             2,    83,     7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  205,    15,   188,     2,  1015,     5, 10237,     4,  3386,     2,\n",
      "           109,   419,   439,  6008,    22,   361,  2517,    29,  5664,   212,\n",
      "           145,    16,    15,   618,    29,  2313,   440,    44,     4,  3386,\n",
      "            21,    72,     2,    90,     2,   128,     2,   371,     2,   383,\n",
      "            20,     3,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   41,  6910,   400,     2, 37163,    92,    17,   106, 11122, 12503,\n",
      "            40,    42,   970,  5135,  1645,    52,     2,     6,  2995,    23,\n",
      "            21,   236,    20,     2,    43,  2554,  2080,    12,  4028,   667,\n",
      "           482,    19,  9787,    12, 12503,    80, 37164,    12, 12503,    54,\n",
      "           124,     9,     4,   234,   400,     3,     0,     0,     0,     0],\n",
      "        [ 5216,   244,    30,    33,  3876,     2,   130, 12964,  2813,   116,\n",
      "            21,  3189,     2,  6587,    20,     2,  2722,   507,    59,    12,\n",
      "            54,   116,    21,  7026,    20,     2,   314,    12,    54,   116,\n",
      "            21,   191,    20,     6,  2722,  2226,    59,    12,    54,   116,\n",
      "            21, 22221,    20,     3,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['15ac5bcd9ca900dc948e969558670084e3d560e0', '247529f16eeda88cc76d19c49d38c633c8f17288', '5ac4248e04f8114d235bced554f30280769a18fb', '3094a311b4f00b8c4286a6793170718aa3fd6e6f', '3b608cc1943f9a07a47d13ea2f1e67b447030567', 'ea35a1ce915a97bb435fc0e8b0d5ac0e0c8c43da', 'ccd89d1b9cdcf7191c351e75be26946291b3b1dc', 'cb880695a3dcea216d827ecc2300cc0186840e18', 'bd51b37b0a1c520f0463535e63232e9336cf0a90', 'da4e91333ecd7b3068eb68e136ef7c889b7167ce', '75d944cbeae530e4f5b8dd398e504ae9493d48c0', '898a524f2ea0579ef33e7264a6e938ab968e1d1e', '901077d4ad9080b04cc178eea5c459a75ca79bdd', 'd4c59add0930ea22c0f5a6a8983274e3ff8e883a', '32a37b57be457f782f9b79f4bca7015ac59b8f09', '683c12293b08763e025116a43656b7c7a45517f8'], 'cited_paper_id': ['5297cce880dad7881b5f4c16b683f971363f009a', '41088dd73ae7ad8baac9323c5dcbf6cb12be2a9d', '6dafd5109302187750f800d5b94fdd2da5362cb6', '7cc6b7ad8a501e7387510eaf9f3c8a0ea3c8f773', 'c829b63a3ae72a47e1953e1295826c7b2f93bf50', '317ad22b126315ea9d8165de2ad64175bf3f221b', 'a2fd43e836881838aa9bf05b6eaebad239d59957', 'cfdf067994e42344e042dd2397806f1e299b2c3b', 'da0746558cecaad6681c199c44b8ed7d128848e5', 'f38fce19253f496bfa3d6eb99831338c2275aec0', 'bf8fff85c818620e1288c6183308d199dbb7ba66', 'e6790bb859751e91d443696e0e78354d260955fd', '4e3427bd6cc0dd0290be6c146b46bda6ad05403f', '9fd5ac1a8bb44b0c3eed35ea646ad8598b10b918', '846996945fc33abebdcbeb92fe2fe88afb92c47e', '609c724521bd2791df36cc133b8bddab1381a3e6'], 'citation_excerpt_index': [1, 1, 0, 0, 1, 0, 1, 0, 3, 0, 0, 0, 1, 3, 0, 0], 'citation_id': ['15ac5bcd9ca900dc948e969558670084e3d560e0>5297cce880dad7881b5f4c16b683f971363f009a', '247529f16eeda88cc76d19c49d38c633c8f17288>41088dd73ae7ad8baac9323c5dcbf6cb12be2a9d', '5ac4248e04f8114d235bced554f30280769a18fb>6dafd5109302187750f800d5b94fdd2da5362cb6', '3094a311b4f00b8c4286a6793170718aa3fd6e6f>7cc6b7ad8a501e7387510eaf9f3c8a0ea3c8f773', '3b608cc1943f9a07a47d13ea2f1e67b447030567>c829b63a3ae72a47e1953e1295826c7b2f93bf50', 'ea35a1ce915a97bb435fc0e8b0d5ac0e0c8c43da>317ad22b126315ea9d8165de2ad64175bf3f221b', 'ccd89d1b9cdcf7191c351e75be26946291b3b1dc>a2fd43e836881838aa9bf05b6eaebad239d59957', 'cb880695a3dcea216d827ecc2300cc0186840e18>cfdf067994e42344e042dd2397806f1e299b2c3b', 'bd51b37b0a1c520f0463535e63232e9336cf0a90>da0746558cecaad6681c199c44b8ed7d128848e5', 'da4e91333ecd7b3068eb68e136ef7c889b7167ce>f38fce19253f496bfa3d6eb99831338c2275aec0', '75d944cbeae530e4f5b8dd398e504ae9493d48c0>bf8fff85c818620e1288c6183308d199dbb7ba66', '898a524f2ea0579ef33e7264a6e938ab968e1d1e>e6790bb859751e91d443696e0e78354d260955fd', '901077d4ad9080b04cc178eea5c459a75ca79bdd>4e3427bd6cc0dd0290be6c146b46bda6ad05403f', 'd4c59add0930ea22c0f5a6a8983274e3ff8e883a>9fd5ac1a8bb44b0c3eed35ea646ad8598b10b918', '32a37b57be457f782f9b79f4bca7015ac59b8f09>846996945fc33abebdcbeb92fe2fe88afb92c47e', '683c12293b08763e025116a43656b7c7a45517f8>609c724521bd2791df36cc133b8bddab1381a3e6']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 102,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 120, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         [259,  99, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  84, 106,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 113,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 106,  47,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  91, 112,  ..., 261, 261, 261],\n",
      "         [259,  98, 115,  ..., 261, 261, 261],\n",
      "         [259, 100, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 260,  ..., 261, 261, 261],\n",
      "         [259, 109,  98,  ..., 261, 261, 261],\n",
      "         [259, 116, 100,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   41,     4,   340,  7831,     2, 20982,    21,   295,    12,   277,\n",
      "            20,  9564,     4,   353,   478,  7319,     5, 11697, 10233,    10,\n",
      "          1031,    15,  7319,    17,    31, 16812,  3141,    69, 28514,  2856,\n",
      "             3,     0],\n",
      "        [ 3361,   126,    25, 31265,     8,  5140,     6,  4829,  2189,     7,\n",
      "             6, 11680,     8,  5140,     6,  4829,   113,     7,    38,   788,\n",
      "          1097,  1470,  2582,    25,     4,   263, 31266,     6, 11680,     3,\n",
      "             0,     0],\n",
      "        [  394,    66,    27,   147,  1680,    18,    39,   861,     2,    42,\n",
      "            96, 10563,     2,    69,   861,    40,    46,    27,  2277,     2,\n",
      "         14262,     6, 19791,     8, 16082,     2,    87,     7,     3,     0,\n",
      "             0,     0],\n",
      "        [11799,   172,    27,   588,  1463,    22,     2,   268,    55, 13057,\n",
      "          1000,     8, 16341, 13058,    12,  7243,    11,    14,     3,    83,\n",
      "            13,  8390,    11,    14,     3,   104,     7,     2,     0,     0,\n",
      "             0,     0],\n",
      "        [   41,   473,     5,  1152,  1036,     2,     4,    59,  5392,   291,\n",
      "            25, 19028,    40,    27,   806,     9,  3663,    84, 23546,    10,\n",
      "             4,   262,     5,     4,  1359,   334,    21,    57,    20,     3,\n",
      "             0,     0],\n",
      "        [   26,  1237,     5, 19932,   664, 11150,   120,  1367,   324,    23,\n",
      "         29475,    38,    33,   105,    10,    30,    15,   304,   186,     9,\n",
      "             4,   235,     5,  4149,  3623,    21,   399,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [   64,    66,    27,  2354,  1739,    23,     4,   585,    17,  3280,\n",
      "             6, 16495,    95,    24,   280,    56,   335,    10,    27,  1554,\n",
      "           841,    18, 33213,    21,   297,    20,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   26, 32629,   291, 32630,     4,  9325,     6,   993,    49,    17,\n",
      "           172,  2094,    22,   816,  1699,    18,     4,    59,     8, 17314,\n",
      "            11,    14,     3,     2,    85,     7,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [ 3986,    12,  1239,  2347,   130, 18855,     2,    32,  1903, 15803,\n",
      "            50,    22,   781,    12,  7321,     6, 23993,     2,    30,    33,\n",
      "            45,     9,  9936,   298,  1038,    19,  5130,   962,    21,   399,\n",
      "            20,     3],\n",
      "        [ 3432,    12,  2573,  2031,     9, 11119,    38,    33,    45,    10,\n",
      "            62,   792,  1852,   373,     6,   611,    12,  6578,  1117,     8,\n",
      "          4009,    11,    14,     3,  3186,     7,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [12757,     6,  6234,     5, 22127,   329,     8, 15545,     6, 15546,\n",
      "             2,   390,    13, 16536,     6,  7651,     2,   309,    13,  7652,\n",
      "            12,  7725,     6,  7651,     2,   428,     7,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [  153,   287,   772,    10, 10064,     2, 30230,     2, 34776,     6,\n",
      "         34777,     2,     6,   107,   165,    16,   103,  3013,    23, 30231,\n",
      "           564,     2, 32429,     6, 30232,    21,   191,     2,   240,    20,\n",
      "             3,     0],\n",
      "        [   41,   253,     2, 16102,  3187,    38,    33,   150,    19,   618,\n",
      "          1593,     6,    15,  1078,  3550,     9,  3011,     8,  1575,     7,\n",
      "             6,   737,  2545,     8,  1012,     7,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  728,    34,  1116,  1297,   117,     5,   540,    37,  3461,    44,\n",
      "            96,    84,   751,    21,   300,    20,     2,    43,   768,     4,\n",
      "          2146,   379,     5,     4,  2594,    44,    84,   904,     2,  1860,\n",
      "             0,     0],\n",
      "        [45117,   895, 45118,  7415,    30,    46,    33,    82,     8, 24638,\n",
      "            11,    14,     3,    68,     7,     2,    69,     4,   298,  2424,\n",
      "             9,     4,   275,   353,    16,  4603,     3,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   88,   195,   333,   682,    62,    31,   606,     9,     8, 11822,\n",
      "            11,    14,     3,    68,     7,     2,    69,   824,    45,     9,\n",
      "             4,    62,    24,    42,  4300,   354,     3,     0,     0,     0,\n",
      "             0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['917237ec23249b823336f1de5910b766ac4d6d19', '114de63c96176358b8cd3c99aa744c86f0eeced7', '5a400a46c6a3fb93f82b82bb96ba81f17d1ae514', 'd8f915342dee431558368107381583a6db146135', '54e8c97c057e8894e2f60d11b734145838e9c0b4', '9476f7e9efaaedcd3ca28f9f07c8cace17bb6f54', '8d955cf85cccf86ec83802b893a6adc9507459d5', 'c763fec6f36f59fa900b35870c7e6635333b60e9', '4d29e6f308d374381099cd0960fea27a6a04dfe6', 'c73ba50857f08d2a8262b3f6a3e3de5b6bc50027', '2bb2505c500ea1382402cd8bf423a8a8715e1f0c', '72ae22792dd0e55ce4ec007998298cbbfb007ae1', 'b4cc2bc53a4c5f3b7851b90c1eaa04cd40c4896d', 'ca4d2aef7421153f0f2c93db54a3e06a4942d329', '333c515d1e5dee428e9ccc224b704311de72f46b', 'a8631ba39f7b793821f3826561c75c8760c63ecc'], 'cited_paper_id': ['ab58b90b71f9a6ce1618f6a30a4d6a74cf1e58c0', '7ffdab1930ccf68c10be4cf9a9ffdb933c9dd516', 'a92c0ea977d22215f515e12a49c9fb58948748ad', 'da1bfc89bdd64622df21b78a99235ec0d2512ba7', '21c52b0fd9292170640e4cb41cba4bac55dce3ed', 'e879778b1865a0f545c7fdcaafc7fd352ea90daa', '481b91ee6d0a96360e816644543172a555b9af11', '672b34de6e1bdb3c54710f8033074f49e0a2d0c8', '43456ee83df5eb7339113a318a579f99a4c12e8d', '51474c521cd1ba63e235cc34ec7001ef7e4fb247', '7e98ff7d7eddadc7f32a776a66585475e6d236f4', '71be0d1a3a8559a2f2724688cc06194840fdfaba', '19975d8b06a8152c61840cbe044aca9e271cfea1', 'a0ecd52bfe814e4941617cb23ba53b88a15397c7', 'e804969e7601b199aaedcd9a4292078fc102f06b', '8171e6651c80359e878f31d290825064a7430c9c'], 'citation_excerpt_index': [8, 12, 0, 4, 1, 0, 5, 1, 1, 0, 3, 0, 0, 2, 1, 2], 'citation_id': ['917237ec23249b823336f1de5910b766ac4d6d19>ab58b90b71f9a6ce1618f6a30a4d6a74cf1e58c0', '114de63c96176358b8cd3c99aa744c86f0eeced7>7ffdab1930ccf68c10be4cf9a9ffdb933c9dd516', '5a400a46c6a3fb93f82b82bb96ba81f17d1ae514>a92c0ea977d22215f515e12a49c9fb58948748ad', 'd8f915342dee431558368107381583a6db146135>da1bfc89bdd64622df21b78a99235ec0d2512ba7', '54e8c97c057e8894e2f60d11b734145838e9c0b4>21c52b0fd9292170640e4cb41cba4bac55dce3ed', '9476f7e9efaaedcd3ca28f9f07c8cace17bb6f54>e879778b1865a0f545c7fdcaafc7fd352ea90daa', '8d955cf85cccf86ec83802b893a6adc9507459d5>481b91ee6d0a96360e816644543172a555b9af11', 'c763fec6f36f59fa900b35870c7e6635333b60e9>672b34de6e1bdb3c54710f8033074f49e0a2d0c8', '4d29e6f308d374381099cd0960fea27a6a04dfe6>43456ee83df5eb7339113a318a579f99a4c12e8d', 'c73ba50857f08d2a8262b3f6a3e3de5b6bc50027>51474c521cd1ba63e235cc34ec7001ef7e4fb247', '2bb2505c500ea1382402cd8bf423a8a8715e1f0c>7e98ff7d7eddadc7f32a776a66585475e6d236f4', '72ae22792dd0e55ce4ec007998298cbbfb007ae1>71be0d1a3a8559a2f2724688cc06194840fdfaba', 'b4cc2bc53a4c5f3b7851b90c1eaa04cd40c4896d>19975d8b06a8152c61840cbe044aca9e271cfea1', 'ca4d2aef7421153f0f2c93db54a3e06a4942d329>a0ecd52bfe814e4941617cb23ba53b88a15397c7', '333c515d1e5dee428e9ccc224b704311de72f46b>e804969e7601b199aaedcd9a4292078fc102f06b', 'a8631ba39f7b793821f3826561c75c8760c63ecc>8171e6651c80359e878f31d290825064a7430c9c']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 117, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259, 119, 106,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  83, 102,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  83,  79,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 118,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 103, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  50,  58,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  56,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  46, 260,  ..., 261, 261, 261],\n",
      "         [259, 112, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 122,  ..., 261, 261, 261],\n",
      "         [259, 120,  98,  ..., 261, 261, 261],\n",
      "         [259, 113, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  323,     4,    84,    12,  5645,     5,     4,   127,  1909,    45,\n",
      "             9,    39,    62,    37,   471,  3008,    67,   138,    82,    18,\n",
      "          2752,   607,    23, 12782,     6, 28454,    21,   494,    20,     8,\n",
      "         18274,     3],\n",
      "        [ 1158,     2,  5515,    38,    33,   141,    22,    15,   124,    18,\n",
      "             4,  1675,  1180,     5,  6073,    12,  2854,  5134,     8,   474,\n",
      "          1823,  5549,    11,    14,     3,    61,     2, 15994,     7,     3,\n",
      "             0,     0],\n",
      "        [ 1705,     2, 11149,   545,  1630, 21081,     6, 10398,     9,     4,\n",
      "          5729, 16881,  3411,     5,  6147,     8, 21082,    11,    14,     3,\n",
      "             2,    97,    13,  1089,     2,    79,    13, 21083,     2,   142,\n",
      "             7,     3],\n",
      "        [    2,    85,     7,     8,  5660, 31218,  3924,     7,     2,    32,\n",
      "          2945,    10,     4,  5660, 31219,  6239,     5,  9216,     2,  4510,\n",
      "            23,  7202,     8,  8301,    11,    14,     3,     2,    63,     7,\n",
      "             3,     0],\n",
      "        [   26,   101,   321,  3207,   186,    31, 27048,     7,   909,  4361,\n",
      "           660,  1343,    45, 27049,   191,  1040,  3467,  1732,  1554,     6,\n",
      "            15,   795,  1248,     5,   143,  1040,   212,   103, 13380,     3,\n",
      "             0,     0],\n",
      "        [30903,  2272,    34,  7420, 20396,   414,  2122,     5, 30904, 30905,\n",
      "             2,    23,  4817,     4,  3026,     5,  1374,   506,    91,    17,\n",
      "            46,  2307,  1991,    12,  5479,    21, 11370,    20,     3,     0,\n",
      "             0,     0],\n",
      "        [  112, 40685,     2,     4, 40686,  1813,   706,     8,   222,     7,\n",
      "            38,  1756, 22924,     9,  5518,    15,   462,    94, 17517,   366,\n",
      "          1050,     6,  5148,   196,    80,  1511,   817,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [  152,     2,     9,   812,     2, 14542,     6, 14850,    24,     4,\n",
      "           101,   799,  2379,     8,  1598,    11,    14,     3,     2,    70,\n",
      "            13, 10384,     6, 10385,     2,    70,     7,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [   64, 10686,    19,    55,    53,    25, 18619,   178,     8,   169,\n",
      "             7,     6,    66,  1310,    39,  3219,    94,   694,    10,  4629,\n",
      "           441,    80,  5261,  4996,     8,   128,     2,   191,     7,     3,\n",
      "             0,     0],\n",
      "        [   93,   698,     4,   504,  2534,    19,     4,   391,   265,  1913,\n",
      "           127,   124,     8, 19541,     7,   411,     9,    21,   662,    20,\n",
      "           146,    43,   768,     4,   757,   200,   310, 26242,  2648,     3,\n",
      "             0,     0],\n",
      "        [  626,  1447,    59,    17, 10684, 18343,    16, 21832,    20,     2,\n",
      "            32,   520,    15,   270,   154,     5,  5091,   414,  1651,    50,\n",
      "            22,  4114,     2,  6305,     2,    29,  4677,  1703,     3,     0,\n",
      "             0,     0],\n",
      "        [ 4322,    19,     4,    52,     5, 45152,  2188,  1302,    11,    14,\n",
      "             3,     2,     4,    52,     5,     4,   193,    62,   362,   139,\n",
      "           786,    18,     4, 45153,   670,     6,  5755,  4876,     3,     0,\n",
      "             0,     0],\n",
      "        [  311,    52,    24,     9,   685,    19,     4,   247,     5,    15,\n",
      "            62,     9,  6307,    32,    46,   679,   182,   891,  1770,  2742,\n",
      "            18, 33938,  1631,  2154,     8, 33939,    11,    14,    78,     7,\n",
      "             3,     0],\n",
      "        [  144,   464,     5,  7665,    12,  1931, 18919,    24,   228,    19,\n",
      "           102,    52,   267,    19, 32607, 18919,     2,    32,   897,    15,\n",
      "           139,  1143,    18, 20973,     8,    90,     2,   129,     2,   494,\n",
      "             7,     3],\n",
      "        [ 9693,    12,    77,   543,  6758,   540,     5,  1689, 18971,     6,\n",
      "           295,     5,  1689, 16120,     8,  6636,  1169, 27409,     2,  4562,\n",
      "             6,  3606,    76,     7,    37,   470,     9,     4,   553,     3,\n",
      "             0,     0],\n",
      "        [20300,    31,   281,  6021,    44,  1026,  1905,   365,     2,    22,\n",
      "           100,     8,   277,     7,     2,     6,     4,  2325,    37,  6886,\n",
      "            44,   182, 21061,     8,   371, 11540,     2,   343,     3,     0,\n",
      "             0,     0]], device='cuda:0')}, 'labels': tensor([1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['7b84de729396dafbd9902a863813cf07ddff699a', '00eea3644491b0fcf74c49aa211fa2a24a6e3d3e', '812e50bdbc19a822b0619ea835bed77415782d4b', 'f7a458748ce8daca1930912c26285ca39a36ad82', '75fb49518192587b03cca16d996506a9a997f3a7', 'b4c73f7217d5099f0aa4c36320c6fe17f364f426', '6358f0aec6c21ca97720874711e14333d5c4e346', '41d69df1533f4ae4ef6157e6645ad37f3c540ce0', '768520fe0920db22991096b81c53b4b0423ca5c1', '14d2501d3639b574322a4271e5aa70a5ad43efb1', '210e3d0418b1cc4f6ecf8fcfcf0f754cb65c1305', 'f17cbc3e145757d64c3028c275c5d5adff923b14', 'b2ed3cc8f4621e47413f56cb328ca15aaff6bb00', '6e7cf7181c75a7de90f590a91cb6a6aec7721c3c', '1a5f3c7ce21bd8dafdc9a79b2741bcd5d7f4564e', 'cac1b86d4f6a0f1019e9389c36cd9bad7891945a'], 'cited_paper_id': ['d008272a8213ee67673e986a23e99d14ca836958', '2271b873cf8e52856c38eae82751d2b1421007c5', '5f19115ea3ee17d6d2a9288412fc6165932cea91', 'ae68f41cc1cf623107fc3535caa245090003ba03', 'e6041be47be40538a69bc1ac8147b6a38b617d97', '489d3df3a9d5e6108096afea5a6c51049d0a61ea', '1973e61143d9c7155a7a52b14bb8b8958a741d49', 'c1e05d9fa428e6b081081d4d4948ef498259047a', 'feead8af080fe6c945340da209b3f642c0678769', '02091e924c05f839a4311bb50c25b573e1045548', '4721ad0db596f3f78ddb31b4305ddbde35f8f181', '128d27ca0af3e57632b075ff6dccd5780ae7a0d1', 'None', '306ecee52cdc5c5f00093b9906acb97f6f82b866', '1e553964ccc8ccc090450aaebe1c87aaacf9ec83', 'bb05718f2dfb539ff1b5c8e6ab8d19c47667b676'], 'citation_excerpt_index': [1, 7, 3, 2, 0, 6, 0, 3, 3, 0, 0, 0, 0, 5, 12, 1], 'citation_id': ['7b84de729396dafbd9902a863813cf07ddff699a>d008272a8213ee67673e986a23e99d14ca836958', '00eea3644491b0fcf74c49aa211fa2a24a6e3d3e>2271b873cf8e52856c38eae82751d2b1421007c5', '812e50bdbc19a822b0619ea835bed77415782d4b>5f19115ea3ee17d6d2a9288412fc6165932cea91', 'f7a458748ce8daca1930912c26285ca39a36ad82>ae68f41cc1cf623107fc3535caa245090003ba03', '75fb49518192587b03cca16d996506a9a997f3a7>e6041be47be40538a69bc1ac8147b6a38b617d97', 'b4c73f7217d5099f0aa4c36320c6fe17f364f426>489d3df3a9d5e6108096afea5a6c51049d0a61ea', '6358f0aec6c21ca97720874711e14333d5c4e346>1973e61143d9c7155a7a52b14bb8b8958a741d49', '41d69df1533f4ae4ef6157e6645ad37f3c540ce0>c1e05d9fa428e6b081081d4d4948ef498259047a', '768520fe0920db22991096b81c53b4b0423ca5c1>feead8af080fe6c945340da209b3f642c0678769', '14d2501d3639b574322a4271e5aa70a5ad43efb1>02091e924c05f839a4311bb50c25b573e1045548', '210e3d0418b1cc4f6ecf8fcfcf0f754cb65c1305>4721ad0db596f3f78ddb31b4305ddbde35f8f181', 'f17cbc3e145757d64c3028c275c5d5adff923b14>128d27ca0af3e57632b075ff6dccd5780ae7a0d1', 'b2ed3cc8f4621e47413f56cb328ca15aaff6bb00>None', '6e7cf7181c75a7de90f590a91cb6a6aec7721c3c>306ecee52cdc5c5f00093b9906acb97f6f82b866', '1a5f3c7ce21bd8dafdc9a79b2741bcd5d7f4564e>1e553964ccc8ccc090450aaebe1c87aaacf9ec83', 'cac1b86d4f6a0f1019e9389c36cd9bad7891945a>bb05718f2dfb539ff1b5c8e6ab8d19c47667b676']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88,  66,  ..., 261, 261, 261],\n",
      "         [259, 102, 111,  ..., 261, 261, 261],\n",
      "         [259, 100, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  98,  99,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  84, 117,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         [259, 120, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  890,    49,    30,   238,    17,  3008,  7552,    40,  6110,  1809,\n",
      "           140,   230,    10,  3926,  1453,     5,     4,   409,  2204,     2,\n",
      "           557,     9,   566,     9,    99, 18591,  1226,     6, 13145,     8,\n",
      "         38176,    11,    14,     3,     2,    75,     2,    83,    13, 35736,\n",
      "            36, 31281,     2,   104,     7,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [ 8772,  2376,    91,     6, 25898,    30,    86,  3138,   373,    93,\n",
      "         18497,  2376,    91,     6, 20446,     9,   161,  3999,   754,     2,\n",
      "          2369,   609,     2,     6,  1028,  5217,    23, 37871, 35441,   597,\n",
      "          4102,   234,    15,  1399,   133,    19,    15,   694,     5,   143,\n",
      "           129,     8,   128,     2,   236,     2,   295,     7,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [   26,   906,  2375,  1321,    28,     4,   802, 37675,     9,    17,\n",
      "            15, 37676, 37677,     8, 19053,     7,   229,  2249,    31,   470,\n",
      "            18,   108,  1780,   179,     9,  6530,   948,     5,     4,  2356,\n",
      "             2,  3212,   389,    42,  3773,  9007, 13145,     6,  2710,    10,\n",
      "           974,   110,   389,    42,  2183,    21,   383,    20,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [ 1478,   444,     2,     4,   357,     5,  1934,    91,     6,  2476,\n",
      "            23, 17873,  5542,   364,    42,  1978,    15, 37685,   518,     2,\n",
      "            22,     4,   601,    12, 21124,     6,  1294,    12, 21124,     5,\n",
      "         17873,  1827,  1087,   527,     8, 37686,    11,    14,     3,     2,\n",
      "            63,    13,  2936, 37687,    11,    14,     3,     2,    63,     7,\n",
      "             3,     0,     0],\n",
      "        [ 1679,     5,     4,   468, 35220, 13355,   353,  1174,   244,     2,\n",
      "          1526, 24604,     2,  1750,     2,  2424,     6,   724,    11,    14,\n",
      "             3,     2,    16,   882,    19,   468,   213,  6589,    12,    54,\n",
      "           203,    12,   628,   478,  1174,   479,     8, 28768,     2,  9257,\n",
      "             2, 35221,     6,  8230,     7,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [ 9246,    66,   738,    56,  1804,   166,  1732,  7088,     5,     4,\n",
      "          4940,  2911,   291,    18,   157,  1854,     8,  7525,    11,    14,\n",
      "             3,   132,     7,    13,    39,  7088,    16,     5,  1431,    42,\n",
      "          3520,    18,   101, 42511,    49,     2,    32,   780,   922,  1182,\n",
      "             9,    15,   258,  4763,     6,  4247,    10,   395,   953,    12,\n",
      "           235,   861,     3],\n",
      "        [ 7656,   730, 16112,     2,    18,   160,     2,    16,   335,    56,\n",
      "           321,    25, 10285,     8,   556,    25,   270,  1462,    13,   170,\n",
      "           971, 16928,    97,    13,  3006,     6, 16929,    79,     6,  2409,\n",
      "          6915,     7,     6,   403,  1292, 27356,  8107,  1496,  7274,    29,\n",
      "          7058,     9,   266,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [ 1198,   338,     2,    43,   325, 18920,  5647,   602,     9, 15972,\n",
      "          4257,    12,  2773,     6,  1164,  3780,   398,   356,     9, 10506,\n",
      "          6453,     2,    34,  1944, 10507, 21788,     8,  4219,    11,    14,\n",
      "             3,   132,     7,     2,    32,    31,     4,   149,   439,   774,\n",
      "             4,  1077,     5,  1281,    12,  5478,  4737,  5647,    25,  1778,\n",
      "           356,     3,     0],\n",
      "        [26982,     6, 28636,    37,   679,    18,     4,  3480,   532,    48,\n",
      "             4, 35088,  9811,    28,     4, 22666,  2679,    21,  1834,    20,\n",
      "             2,    19,  3502,  1232,    18,  3895,   553,     6,  4281,   615,\n",
      "           372,    45,    10,   857,    18,  9339,  2010,     8, 35089,    13,\n",
      "            21,  2147,    20,     7,     3,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [   64,   954,    10,     4,   598,     5,    15, 47773,     2,   146,\n",
      "            15,  5465, 26127,  7464,    19,  2264, 33525,    16, 38241,    10,\n",
      "            15,  1773, 26127,  1887,    19,  1531,  1021, 11182,     2,   114,\n",
      "          9209,   461,     2,     6,  9438, 33525,     8,  6329,    11,    14,\n",
      "             3,    61,    13, 20468,     6, 21221,    68,     7,     3,     0,\n",
      "             0,     0,     0],\n",
      "        [  595,    55,    49,    30,  3521,  4675,    86,    28,    71,   188,\n",
      "             2,  1526,    17, 31007,     6, 40306,    37,  2122,     5,  8637,\n",
      "          6871,    25,    96,   468,  8251,    29,    25, 40307,   268,  6893,\n",
      "         33160,     8,   454, 11596,    11,    14,     3,   198,    13, 16977,\n",
      "            11,    14,     3,    79,    13, 40308,     2,    61,     2,    75,\n",
      "             7,     3,     0],\n",
      "        [  112,  1257,     2,    96,   208,  3594,  1354,    37,   985,     9,\n",
      "             4,   457,    12,  4209,   858,     3, 17926,   173,    10, 36050,\n",
      "             2, 14568,     6, 12148,     8,   345,    57,     7,    37,   918,\n",
      "            54,    25,     4,  9114,   540,    28,    71,   102,  3297,     8,\n",
      "          6197,    11,    14,     3,     2,    63,     7,     3,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  632,     9,    21,   237,    20,     4,   419,  3211,   409, 13628,\n",
      "            44,  2767,   156,     2,    43,  5819,   760,  6206,  1637,  3528,\n",
      "             6,    23,  1929,   109,    56,   225,   119,    10,     4, 11343,\n",
      "             9,    15,  6206,  1637,   755,     2,  3211,   409, 13628,    44,\n",
      "          6206,  1475,   156,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [   35,     6,    66,  2246,   477,  1224,   171,  1190,    58,  1939,\n",
      "           397,     6,  6543,   525,     4, 10872, 17387,    98, 17862,    72,\n",
      "             8,  5947,    11,    14,     3,     2,    79,     7,     2,  7824,\n",
      "          8923,   163,     5,  2665,   111,     4,  7016,  3664,    10, 16439,\n",
      "          1956, 15657,    10,  1768,     4,    35,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [   41,  1098,     5,  5728,   165,     2,  4731,    16,   407,   387,\n",
      "           492,   179,     5,    15,  6418,  1672,     5, 27606,    91,   159,\n",
      "             4,  5091, 18049,     8,  3686,    11,    14,     3,     2,   198,\n",
      "            13, 11920,    11,    14,     3,     2,   198,    13,  2592,    11,\n",
      "            14,     3,     2,    97,    13,  3667,     6,   724,     2,    68,\n",
      "             7,     3,     0],\n",
      "        [ 8582,  2633,    37,  6627,    12,  4383, 11437,  7808,  3241,  2219,\n",
      "            25,    15,  2833,  4573,    12,  2113,  1138,    17,  2169,     4,\n",
      "         13775,    10,  2301,     6,  2736,   154,     4, 11437,  3457,    10,\n",
      "            15, 10751,  2237,     8,   170,  4880,     2,   724,    36, 11586,\n",
      "             2,    78,    13,   724,     6,  4880,     2,    75,     7,     3,\n",
      "             0,     0,     0]], device='cuda:0')}, 'labels': tensor([2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['6e99f811d7817287226a134bd05a826d09fcbc98', '33faf9c0b0ea2292ec82800186ca82e54b087ecf', 'b4600f3270e040eedacd8619c1400a77ab001ef7', '92dfb10d64df2a6becc00aa3b16d0d2187e150bc', '3220c81f677d83b268473baba34123303174b8ad', '917767e7e78b56764648d403f7fb5137f47c34af', '4224c52c6fdc56de9a6512a4ae090ee739a85a7c', '560c67b8d5c6e4b2809fbbd308d373366241ea86', '7b402c04c69e1719b7a5e3ec722f4b20a655b222', '636476286d6a98b5f782732d169bf431fec94b7f', 'ab0930fc23c454f0099ee1280b23027e5a5658a5', '5ddd341c20f323d736e9b3899ad20561c9bdbeea', '586db52bed2b3e31e6d386da64cc09f93d6b6032', '7dbda04780112a3820cd304dd44f7686dd12fdea', '0012d808e76e1cd0e5ddeea10824a0811942a7e5', 'd2453e86d9eb0c2961d97753acd2c8462b22e1ce'], 'cited_paper_id': ['3c045042469071b9d21230fcfe5ee598fc3ddd39', '3c5f1e4b17a53cc4636cb9994b1c12fa0a409a47', 'fff94a0ce14254174dfc1a313b6af1b324b8a21e', 'dcb78229a4f7f8a56559b805a9c8e67161e5b677', '28bbebd29cecd174aeaa3a45b73b6c036200d550', '08b0f8f0a6310467ca72b59cf67521fa689bc0f1', 'f54f92bf89f588cc69dc2fedf604f912a04f7f32', 'b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '86aaef532a0a99a86d83d3b10cf229ce7c45c31d', '2fe7a659d8ce9e6f024cebdf27511c8355c6ec10', 'None', '8f2cfced117e54b3e1ba97b0e43f34e0ec747952', '0ed62848d5c9e01f692c0c0b3851848ac7bb0764', '9808ff163bc008673fc7f6cd067eaf5f38ae0a52', '53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', '9b0628d503edf994bdfd285d283c63df1222ceef'], 'citation_excerpt_index': [0, 7, 0, 0, 0, 3, 2, 4, 0, 7, 0, 0, 5, 3, 2, 3], 'citation_id': ['6e99f811d7817287226a134bd05a826d09fcbc98>3c045042469071b9d21230fcfe5ee598fc3ddd39', '33faf9c0b0ea2292ec82800186ca82e54b087ecf>3c5f1e4b17a53cc4636cb9994b1c12fa0a409a47', 'b4600f3270e040eedacd8619c1400a77ab001ef7>fff94a0ce14254174dfc1a313b6af1b324b8a21e', '92dfb10d64df2a6becc00aa3b16d0d2187e150bc>dcb78229a4f7f8a56559b805a9c8e67161e5b677', '3220c81f677d83b268473baba34123303174b8ad>28bbebd29cecd174aeaa3a45b73b6c036200d550', '917767e7e78b56764648d403f7fb5137f47c34af>08b0f8f0a6310467ca72b59cf67521fa689bc0f1', '4224c52c6fdc56de9a6512a4ae090ee739a85a7c>f54f92bf89f588cc69dc2fedf604f912a04f7f32', '560c67b8d5c6e4b2809fbbd308d373366241ea86>b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '7b402c04c69e1719b7a5e3ec722f4b20a655b222>86aaef532a0a99a86d83d3b10cf229ce7c45c31d', '636476286d6a98b5f782732d169bf431fec94b7f>2fe7a659d8ce9e6f024cebdf27511c8355c6ec10', 'ab0930fc23c454f0099ee1280b23027e5a5658a5>None', '5ddd341c20f323d736e9b3899ad20561c9bdbeea>8f2cfced117e54b3e1ba97b0e43f34e0ec747952', '586db52bed2b3e31e6d386da64cc09f93d6b6032>0ed62848d5c9e01f692c0c0b3851848ac7bb0764', '7dbda04780112a3820cd304dd44f7686dd12fdea>9808ff163bc008673fc7f6cd067eaf5f38ae0a52', '0012d808e76e1cd0e5ddeea10824a0811942a7e5>53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', 'd2453e86d9eb0c2961d97753acd2c8462b22e1ce>9b0628d503edf994bdfd285d283c63df1222ceef']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  88, 105,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  84,  67,  ..., 261, 261, 261],\n",
      "         [259, 120, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  74, 260,  ..., 261, 261, 261],\n",
      "         [259,  46, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  75, 112,  ..., 261, 261, 261],\n",
      "         [259,  99,  98,  ..., 261, 261, 261],\n",
      "         [259, 104, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113,  73,  ..., 261, 261, 261],\n",
      "         [259, 109, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  743,   176,    56,   207,  3118,  2990,     2,    43,  6207,    10,\n",
      "          6134,  1163,     8, 37773,    11,    14,     3,     2,    78,    13,\n",
      "         20400,    11,    14,     3,     2,    70,     7,     3],\n",
      "        [   26, 15260,    19, 29634,  3062,    59,  8271, 25080,  8271,    37,\n",
      "          1873,    45,     9,  2199,  2322,     5,  1702,  2282,   115,    19,\n",
      "          1365,   962,    21, 15261,    20,     3,     0,     0],\n",
      "        [   26,   347,    12,  4818,    16,    15, 29614,   395,     5,   332,\n",
      "             5,   517,     2,   173,    10,   397,     2, 18674,     6,  1479,\n",
      "         10073,    21,   297,     2,   277,    20,     3,     0],\n",
      "        [ 4839,  1540,    16,   321,    10,    99,   920,   166,  1724,    69,\n",
      "             4,  1507,     5,     4,  1540,  1241,   490,     9,  2104,    67,\n",
      "             9,  4649,  1625,     8,   399,     7,     3,     0],\n",
      "        [  595,   244,  1124,     4,   655,     5, 10063,    99,  1146,     6,\n",
      "          2955,  2038,    47,     4, 34774,    21,  2898,    20,     6, 34775,\n",
      "            21,  4197,    20,   162,     3,     0,     0,     0],\n",
      "        [   93,   439,    52,    19,    99,     4,    21,   533,    20,     6,\n",
      "            21,   494,    20,  2641,     5,     4,  2230,     5,    21,   254,\n",
      "            20,    22,     4,  1168,   459,  2230,     3,     0],\n",
      "        [   41,   623,  1324,     2,    43,   439,     4,  2252,     5,     4,\n",
      "          1038,    32,  1480,    10,     4,  2963,   711,  1707,    22,   307,\n",
      "             9,    21, 45222,     3,     0,     0,     0,     0],\n",
      "        [16378,  2711,     5,     4,   115,     5, 13708,     8,   695,     7,\n",
      "             2,  4955,     8,    97,     7,     6, 22174,    36, 17958,     8,\n",
      "            89,     7,    24,   239,     3,     0,     0,     0],\n",
      "        [  702,  8285,     8,    29,  3746,     7, 23977,  3649,    16,    46,\n",
      "            34,   838,  1096,     5, 18638,    18,     4,   600,  1767,     8,\n",
      "         29576,    11,    14,     3,     2,   198,     7,     3],\n",
      "        [  217,  2720,    39,  1151,    43,  2103,    28,   953,    12,   678,\n",
      "           115,    17,    43,   972,    23,   210,   223,   337, 21790, 14539,\n",
      "         12130,    18,   157,  7828,     3,     0,     0,     0],\n",
      "        [  785,     2,    43,    46,    45,    15,   675,    12,    54,   308,\n",
      "            12,   535,     8, 25746,     7,    21,   222,    20,    10,  1379,\n",
      "            15,   481,   757,     8,  4409,     7,    59,     3],\n",
      "        [ 6865,     6,  4701,     8,   132,     7,   238,    17,    99,  1897,\n",
      "           876,   680,   121,  7411,  5783,    24,  1006,    22,  4145,  2341,\n",
      "            25,    60,  6989,     3,     0,     0,     0,     0],\n",
      "        [   41,     4,  5346,     2,    39,  1628,  1483,  7161, 13161,     2,\n",
      "             6,    51,    16,  2161,  7531,   534, 15053,   598,     8,  6407,\n",
      "            11,    14,     3,     2,    63,     7,     3,     0],\n",
      "        [  152,     2,   228,    19,   102,   410,    21,   346,    20,     2,\n",
      "          5321,    31, 11930,     9, 37578,   964,     2,   883,    39,    16,\n",
      "            42,    15,  2814,   636,     3,     0,     0,     0],\n",
      "        [ 8676,    54, 10519,    74,    15,    81,    12,   652,  6035,    21,\n",
      "         30564,    20,    13,    29,  1704,    15,  1027,    59,    18,    99,\n",
      "           344,    21, 28606,    20,     3,     0,     0,     0],\n",
      "        [   26,  1541,  5943,  1965,    46,  2223,   180,  9468,     6,    52,\n",
      "             9,  1832,  1652,  2439,     5,   173,   356,     2,   556,     5,\n",
      "         15965,    21,   143,    20,     3,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['c379d0e999263417b3336977c6ac0f02cc543b4a', '2707175120ef1204a61c485f0ec84f8748cfc0c2', '4c6d41b5241a2d80b993632d7e89acdb9fedef74', 'b87242f0262d3ac76b06653bd65a45f0db715378', '268f9c5c5f980d9e97420454f1c57cdebb0ab0af', 'c09f51a6e8a10964d44adcd2a325e8382219253d', '432cf408877fa94000efe2ddd850b9df487599eb', 'f20cf27f1c49917aff7ea08f7715f28e37e067b0', 'fac2c1f5da0e8c9a5854c306af76a516de36b7d5', 'a1030e6e0e6995768dbcafedc712a59db090d2b4', '605ea2ca03496d6b9c0cf84706728757ec8c57b5', '90e3135b8b3ae3871c2d272a5971b703174bcd96', '602d56f55b8c21475c9bf67e73c5d8e999ee9696', 'a828f4add27fe61eccf15e1b6626825b42f24def', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5', 'b6c83898d88378ce0fddedba00f72ded67e946f4'], 'cited_paper_id': ['6744ad2e6dfa2fb82993a23ea968e090904955bd', 'cbdfe987b406ca40a3171f7f1b5f16ad4ba2fdd5', '45ee8db9be57b97522566b1d1f6d2433cc464b72', 'cda133c0f0a8581bb534615bf683d34479142cd6', '07a249b5f48113f232162e2b0e7baccc53e4511b', '38bef2a04234bf5ac194c05985418e3b6add70d6', '7f801e0979ec0409ac84806cbff4a70b83104fd5', '91695bee521ee44b2c08a87d9693953afc26583f', 'f63534f5bf8f59c809410b94a031ca4c99309d0b', '74fee9eb42bdc3b0605934943071bbea7f92bd1b', '0e78b20b27d27261f9ae088eb13201f2d5b185bd', '466e2d457c348272f138f0aa48618c85b563a3fc', 'd9bb6f5360b6e9413e5f675d4164e29a6040a7c0', 'fd6db9a231183cc6c48b027d652b518bdcdc634a', '4448616a83a88c54e1ffddf0390716630f9a4b70', '0bf7cde487dad25a8008a0c8629e5ca371df3c3c'], 'citation_excerpt_index': [1, 6, 2, 0, 0, 0, 0, 8, 1, 0, 3, 2, 5, 4, 12, 15], 'citation_id': ['c379d0e999263417b3336977c6ac0f02cc543b4a>6744ad2e6dfa2fb82993a23ea968e090904955bd', '2707175120ef1204a61c485f0ec84f8748cfc0c2>cbdfe987b406ca40a3171f7f1b5f16ad4ba2fdd5', '4c6d41b5241a2d80b993632d7e89acdb9fedef74>45ee8db9be57b97522566b1d1f6d2433cc464b72', 'b87242f0262d3ac76b06653bd65a45f0db715378>cda133c0f0a8581bb534615bf683d34479142cd6', '268f9c5c5f980d9e97420454f1c57cdebb0ab0af>07a249b5f48113f232162e2b0e7baccc53e4511b', 'c09f51a6e8a10964d44adcd2a325e8382219253d>38bef2a04234bf5ac194c05985418e3b6add70d6', '432cf408877fa94000efe2ddd850b9df487599eb>7f801e0979ec0409ac84806cbff4a70b83104fd5', 'f20cf27f1c49917aff7ea08f7715f28e37e067b0>91695bee521ee44b2c08a87d9693953afc26583f', 'fac2c1f5da0e8c9a5854c306af76a516de36b7d5>f63534f5bf8f59c809410b94a031ca4c99309d0b', 'a1030e6e0e6995768dbcafedc712a59db090d2b4>74fee9eb42bdc3b0605934943071bbea7f92bd1b', '605ea2ca03496d6b9c0cf84706728757ec8c57b5>0e78b20b27d27261f9ae088eb13201f2d5b185bd', '90e3135b8b3ae3871c2d272a5971b703174bcd96>466e2d457c348272f138f0aa48618c85b563a3fc', '602d56f55b8c21475c9bf67e73c5d8e999ee9696>d9bb6f5360b6e9413e5f675d4164e29a6040a7c0', 'a828f4add27fe61eccf15e1b6626825b42f24def>fd6db9a231183cc6c48b027d652b518bdcdc634a', '823a49c10ce0e05613afbe8bbda7b7219e43d2c5>4448616a83a88c54e1ffddf0390716630f9a4b70', 'b6c83898d88378ce0fddedba00f72ded67e946f4>0bf7cde487dad25a8008a0c8629e5ca371df3c3c']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  76,  70,  ..., 261, 261, 261],\n",
      "         [259,  88,  80,  ..., 261, 261, 261],\n",
      "         [259,  59, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85,  98,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         [259, 120, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  50,  58,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  66, 103,  ..., 261, 261, 261],\n",
      "         [259,  99, 106,  ..., 261, 261, 261],\n",
      "         [259, 102, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 112,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259, 120, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  81, 115,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  144,    52,   243,   247,     9,     4,   248,    17,  1031,  2172,\n",
      "             9,  2239,   352,     5,   878,  1317,   178,     9,   382,    19,\n",
      "          2799,     8, 11543,    11,    14,     3,     2,    68,    13, 10843,\n",
      "            36, 26209,     2,    70,     7,     2,    69,  6113, 18953,  1533,\n",
      "             8,  2025, 15602,    11,    14,     3,     2,   274,    13, 17805,\n",
      "            11,    14,     3,     2,    89,     7,     3,     0],\n",
      "        [27165, 28822,    47, 28823,  1922,    13, 27166,  1922,    13,  2921,\n",
      "          8523, 28824,    13, 28825, 15289, 19759, 12595,   966,   749,  1113,\n",
      "          2460,     5,   409,  1540,  1087,    10,  1578,   787,  3256,  7764,\n",
      "             8, 17406,     6,  6726,     2,   255,    13,   971,  2075, 28826,\n",
      "            11,    14,     3,     2,    87,    13,  8728,     6,  6726,     2,\n",
      "            70,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [ 8782,  1001,    19,   296,    17, 20383,     4, 16446,    52,     9,\n",
      "           120,   262,   689,     9,  1235,     2,    69,    42,  1106,  2912,\n",
      "             2,    65,  1149,    12,   173,   177,   243,    15,   219,     5,\n",
      "         10976,   162,     9,     4,   202,     5,     4,   478,  8771,     5,\n",
      "             4,   380,     8, 21967,    11,    14,     3,     2,   367,    13,\n",
      "          4525,    11,    14,     3,     2,   131,     7,     3],\n",
      "        [ 1252,  3133,   788,    15,  1530,  1168, 27147,    25,    15,  4526,\n",
      "          1834,  6270,     2,   108,    31, 22750,    19,  1666,     6,    15,\n",
      "         27148,  8826,  5181,  8243,    10,  4069, 27149,  9260,     6,  2811,\n",
      "          2884,    19,    15,  1407,  3128,    98,    22,   122,   100,     8,\n",
      "          2608,    11,    14,     3,     2,  1979,     2, 13352,     2,   256,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [   26,   327, 27798,     9,  2160,  1163,    24,     4,   932,   175,\n",
      "          7350,   199,    30,   239,     2,  3628,  1399,     2,     6,  6489,\n",
      "             4,  2052,     5,   891,  1440,   115,    22,    15,   269,   636,\n",
      "           830,    18,  2264,     2,   929,   932,   175,     8,  8400,     2,\n",
      "            97,    13, 26354,    11,    14,     3,    78,    13, 15813,    11,\n",
      "            14,     3,   151,     7,     3,     0,     0,     0],\n",
      "        [ 4667,  2397,   356,    24,   584,    10,  2540, 15399,    10,   719,\n",
      "             8, 22232,     2, 22233,     2, 26273,     6, 26274,     7,    21,\n",
      "            90,     2,   346,     2,   662,    20,     6,   208,  2540,  1068,\n",
      "            10, 11911,  1372,   540,     8, 12575,     2,  7247,     6, 26275,\n",
      "             7,    21,   129,     2,   222,     2,   371,     2,   494,    20,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   35,  3292,  2486,     5,  1892,    28,     4,  3691,   230,    10,\n",
      "             4,   206,  3965,   601,     2,  3292,  1028, 14922,     2,   492,\n",
      "          2018,  8421,     5,  1892,     6,   206,   426,  1296,  1892,   230,\n",
      "            10,   206,   180,  1468,   664, 11730,  1892,    19,   493, 28755,\n",
      "          1892,   163,     8, 30731,     6, 30732,     2,   131,     7,     3,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  743,  3554,  2581,   634,    18,   123,     2,    43,   739,    25,\n",
      "           138,  7494,   621,  5732,    10, 31458,  1640,    29,   138,   797,\n",
      "          1288,    23,    55,   419,     8, 31459,     6, 31460,    70,    13,\n",
      "          3474,    11,    14,     3,    78,    13, 31461,    11,    14,     3,\n",
      "            83,    13, 31462,    11,    14,     3,   104,     7,     8,   345,\n",
      "            72,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [32822,    12,   225, 32823,   478,  2718,    16,  1051,    19,  3182,\n",
      "           140,     9,    99,  1065,   666,     6,     9,  1476,    50,    22,\n",
      "          2104,     2, 18390,    94,   283,     6,  3076,     8, 32824,    11,\n",
      "            14,     3,     2,    83,    13, 32825,    11,    14,     3,     2,\n",
      "           104,    13,  7745,    11,    14,     3,     2,   118,    13,  6130,\n",
      "            11,    14,     3,     2,   190,     7,     3,     0],\n",
      "        [   35,   279,   212,     4,   214,   810,    16,    56,  3062,     2,\n",
      "             4,   405,     5,     4,  7061,  2017,  9794,    16,    23,   176,\n",
      "           616,  3778,    13,   107,   319,    16,   250,   516,     2,   107,\n",
      "           998,    24,  7366,     6,  5760,     2,     6,     4,  4898,    28,\n",
      "           350,  2151,   374,     6,   161,  2982,  2826, 16733,     8,  4271,\n",
      "            11,    14,     3,   104,     7,     3,     0,     0],\n",
      "        [ 1401,     2,    51,    38,    33,   238,    17, 18007,  2730,   954,\n",
      "            10,  2507,   642,  8156,  3514,    23,  4982,     8,  2418,     2,\n",
      "          2595,     7,     2,   530, 50699,   412,     2,     9,    32, 18007,\n",
      "            40,    42,    27,  1374,     2,  2421,    10,   175,     4,  2235,\n",
      "             5,     4,  4825,    12,   304,  5205, 10725,  8433,     8,  2013,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [   64,   355,   675,     2,    50,    17,    56,   304,   552, 13029,\n",
      "          1920,  6151,    19,    15,    56,   355,   552,  7509,     2,    16,\n",
      "             9,   685,    19,   102,    49,     8,  8374,    11,    14,     3,\n",
      "             2,    78,    13,  8289,    11,    14,     3,     2,    79,     7,\n",
      "             2,   883,    17,     4,  1507,     5,  4928,   631,   566,    19,\n",
      "             4,  1507,     5,   621,  5546,  5424,     3,     0],\n",
      "        [ 2839,     9,     8,  4726,    11,    14,     3,     2,   509,    13,\n",
      "         13784,    11,    14,     3,     2,   509,     7,     2,     4,   706,\n",
      "           174, 26175,     7,    40,    42,    27,    45,    22,    15,  2412,\n",
      "            10,   698,    86, 17537,     5,     4,   741,   379,     2,    22,\n",
      "            51,    16,   501,    25,     4,   173,  4746,     5,     4,  1027,\n",
      "           379,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1252,  3133,   788,    15,  1530,  1168, 27147,    25,    15,  4526,\n",
      "          1834,  6270,     2,   108,    31, 22750,    19,  1666,     6,    15,\n",
      "         27148,  8826,  5181,  8243,    10,  4069, 27149,  9260,     6,  2811,\n",
      "          2884,    19,    15,  1407,  3128,    98,    22,   122,   100,     8,\n",
      "          2608,    11,    14,     3,     2,  1979,     2, 13352,     2,   256,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [  217,  1357,   529,     4, 13966,    12,  2394,     6, 30698,  3812,\n",
      "           120,  3004,  1623,    25,  7167,  4466,  1627,     2,   870,    12,\n",
      "          6982,     2, 21899,     5,  3812,    91,    37,  1018,    19, 28729,\n",
      "             8,  3720,     2,   684,  7823,     7,     2,    15,  1627,     2,\n",
      "           870,    12,  6982,  1622,     2,    22,   122,   100,     8,   236,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [ 4106,     2,    50,   479,    30,    33,    45,     9,    15,   582,\n",
      "             5,  1191,   352,   344,     2,   130,   187,  1904,     6,  1055,\n",
      "           637,    21,   295,    20,     2,   981,   725,    21,   237,    20,\n",
      "             2,   515,  3449,    21,   873,    20,     6,   165,   360,     8,\n",
      "           425,    42,  2455,  3989,   294,     7,    21, 25745,    20,     3,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['45aaad1ce30b0ab97d335bf71b239a54c09f69f0', 'bfd36aab3354dc707e0e3d1bb2e303d80763be7a', 'ffe9fbf5e1db48cdeb03b2790249a3ee0ecc960a', '2abb3ef949447de470e7872d8e61de9ab00948b8', 'acf25d8891760616a5d1b1559d417da5a828eb8e', '03026676cf30464b9c5f8e24e5d6d4348d46a994', 'c19c99872aa4e69fb11b0fdb959487c680437011', 'af30d246af7ee7d52015b584384b8bcc64eef7aa', 'b2281224afb3a90f31fdbd980e43f3abd5789d28', '1e07b16fb589780721887f60271a8b1c2868fb8b', '32060e8f72341783bafbde9bf6e8cad832a66d19', '45701ff05d3ed583a658f18aa998944c1d4eee7a', 'c14687575d73745afea49899565009f12ae62dfb', '2abb3ef949447de470e7872d8e61de9ab00948b8', '21eff5d5f5555a0dcf67c538c65a5e07cc954c5f', '83cbd79c00fab69033f124cf9f2a822e27562ce7'], 'cited_paper_id': ['06689c4f9d8a2fa2d78a4a70301684e4e676c9fb', '204d5520270562a13510f3a8f9e38cc4e6dab858', 'b4f3597485b8e161af04ce27f3d23ad2cbe90ccc', '1c757b123d4b491ce71b8463a997e78a653887c1', '0caf766f329fd37a699a5c3ec62aebb1c9d44f1a', '903aae8adc61e5b2cbdd349b6527f693b5cd5d99', '7015ffe2755c638484478260f70c89cae8e28083', '96ea870bf18b34e5ebfaabd998a2ac766fd4c832', 'cd250aac6cf8a2e8808e0f687627690f81aa4c29', '40c5741dc18ca03e625306b5bbf6622d097176a3', 'd29581f95617749aa150e6cb626e77027319f4ef', 'f89d87e5f4d58e9bb7d576ec6ae34a84240b9c5e', '5e57b8879a83e91af5daef8737ccda0c9556fd7e', '1c757b123d4b491ce71b8463a997e78a653887c1', 'a502f5919d1ca7d3d567e053d1f0032a6466d152', '3e971afd36fbfdd80c34d708865bf1903145fcee'], 'citation_excerpt_index': [0, 1, 3, 5, 2, 3, 2, 0, 1, 1, 0, 2, 8, 5, 4, 0], 'citation_id': ['45aaad1ce30b0ab97d335bf71b239a54c09f69f0>06689c4f9d8a2fa2d78a4a70301684e4e676c9fb', 'bfd36aab3354dc707e0e3d1bb2e303d80763be7a>204d5520270562a13510f3a8f9e38cc4e6dab858', 'ffe9fbf5e1db48cdeb03b2790249a3ee0ecc960a>b4f3597485b8e161af04ce27f3d23ad2cbe90ccc', '2abb3ef949447de470e7872d8e61de9ab00948b8>1c757b123d4b491ce71b8463a997e78a653887c1', 'acf25d8891760616a5d1b1559d417da5a828eb8e>0caf766f329fd37a699a5c3ec62aebb1c9d44f1a', '03026676cf30464b9c5f8e24e5d6d4348d46a994>903aae8adc61e5b2cbdd349b6527f693b5cd5d99', 'c19c99872aa4e69fb11b0fdb959487c680437011>7015ffe2755c638484478260f70c89cae8e28083', 'af30d246af7ee7d52015b584384b8bcc64eef7aa>96ea870bf18b34e5ebfaabd998a2ac766fd4c832', 'b2281224afb3a90f31fdbd980e43f3abd5789d28>cd250aac6cf8a2e8808e0f687627690f81aa4c29', '1e07b16fb589780721887f60271a8b1c2868fb8b>40c5741dc18ca03e625306b5bbf6622d097176a3', '32060e8f72341783bafbde9bf6e8cad832a66d19>d29581f95617749aa150e6cb626e77027319f4ef', '45701ff05d3ed583a658f18aa998944c1d4eee7a>f89d87e5f4d58e9bb7d576ec6ae34a84240b9c5e', 'c14687575d73745afea49899565009f12ae62dfb>5e57b8879a83e91af5daef8737ccda0c9556fd7e', '2abb3ef949447de470e7872d8e61de9ab00948b8>1c757b123d4b491ce71b8463a997e78a653887c1', '21eff5d5f5555a0dcf67c538c65a5e07cc954c5f>a502f5919d1ca7d3d567e053d1f0032a6466d152', '83cbd79c00fab69033f124cf9f2a822e27562ce7>3e971afd36fbfdd80c34d708865bf1903145fcee']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  84,  88,  ..., 261, 261, 261],\n",
      "         [259,  48, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  51,  49,  ..., 261, 261, 261],\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         [259, 102, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259,  89, 118,  ..., 261, 261, 261],\n",
      "         [259, 102, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 109,  98,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  77, 106,  ..., 261, 261, 261],\n",
      "         [259, 101,  98,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,  5573,     5,   790,    16,     4,  6156,    84,     8,    57,\n",
      "             7,    29,     4,    84,  1702,   435,    18,     4,  3640,     5,\n",
      "            34,   716,     5,  5866,  1512,    10,    17,  2136,     9,     4,\n",
      "           440,     3,     0,     0,     0,     0,     0],\n",
      "        [   26,  8385,    80,  8586,     6, 12320,  2987,  5336,  2197,    30,\n",
      "            33,   105,    10,  7301,    10,     4,  3371,   329,     9,    15,\n",
      "         11134,   501,  1485,     6,  2664,     9,    60,  1729,   854,    21,\n",
      "          6922,    20,     3,     0,     0,     0,     0],\n",
      "        [   64,  1450,  2943,    10,    15,  1375,  1125,    12,   854,     5,\n",
      "             4, 12118, 11517,     9, 15558,  2508,     2,    32,    16,   830,\n",
      "            10,  2568,     4,  2268,  3217,   874,     9, 11518,  2508,     8,\n",
      "         12119,    11,    14,     3,    78,     7,     3],\n",
      "        [  217,  1249,     4,   442,    18, 11792,  1693,     2,    77,    40,\n",
      "           350, 23798,  4174,   194,    50,    22,    15,   258,  5717,    18,\n",
      "            34,   187,     2,   539,     9,   473,     5, 19865,     6, 38149,\n",
      "            21,   224,     2,   191,    20,     3,     0],\n",
      "        [22938,     5,   114,  1199,   251,     5,  1201,   356,     2,  1122,\n",
      "           989,  1259,     6,  2205,  1259,     2, 12445,     6,    55,  4842,\n",
      "            24,     4,    55,  1680,    10,  1882,   107,  4308,   227,  5737,\n",
      "             8, 35852,     2,    61,     7,     3,     0],\n",
      "        [ 4322,    10,    55,  5404,  3657,     2,  6147,    16, 15697,  3090,\n",
      "            10, 13410,     2, 40304,     2,  2056,     5, 40305,     6,  3621,\n",
      "             2,     6,    15,   537,  4991,  2573,  1230,     8,  3200,    97,\n",
      "             7,     3,     0,     0,     0,     0,     0],\n",
      "        [  831,  6316, 25916,  4390,     7,  1238,  2644,     8,  3686,    11,\n",
      "            14,     3,     2,   198,    13, 11920,    11,    14,     3,     2,\n",
      "           198,    13,  2592,    11,    14,     3,     2,    97,    13,  3667,\n",
      "             6,   724,     2,    68,     7,     3,     0],\n",
      "        [ 1114,  7852,  3722,    24, 15759,     8, 10986,    11,    14,     3,\n",
      "             2,   255,    13,   722,    11,    14,     3,     2,   113,     7,\n",
      "             6,  2700,   157,  1234,  1936,   602,     8, 20582,    11,    14,\n",
      "             3,     0,     0,     0,     0,     0,     0],\n",
      "        [  646,    43,  2300,    15,  5011,   195,  5162,    32,  9881, 27383,\n",
      "            58,    96,  6321,  1354,     2,  4213,    57, 22859,    10,     4,\n",
      "           987,  2006,    12,  1609,   215,    21,   383,    20,    23,  4310,\n",
      "            96,  2154,  2324,     3,     0,     0,     0],\n",
      "        [  152,     2,     4,   455,  1853,    66,    27,  2469,   490,    67,\n",
      "            39,   212,     2,    22,    38,    33,   105,   122,     2,  3212,\n",
      "          1388,    10,   168,    12,   439,    60,   421,   165,    48, 19966,\n",
      "            21,   571,    20,     3,     0,     0,     0],\n",
      "        [   41,     4, 12510,     2,     4,  1503, 28418, 14499,  4899,  2683,\n",
      "           340,   294,     5,  6237,    19, 20172,   261,    17,  6486,     6,\n",
      "           880,   418,    16, 20173,     8, 13564,     6, 20911,    68,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0],\n",
      "        [   64, 24011,    40,    27,  1025,    23,     4,   871,   416,     5,\n",
      "             4, 31740, 10733,    17,  1173,  1009,     4,  5195,  6173,  7934,\n",
      "          1486,   664,    23,     4,   543,  4277,     5,     4, 31741,    21,\n",
      "         31742,    20,     3,     0,     0,     0,     0],\n",
      "        [15942,     9,  3219,   163,    37,   663,    23,   455,    84,   858,\n",
      "          3392,     5,  9426,     5,   581,   166,  3015,     5,   426,  5079,\n",
      "             2,    22,   122,  1216,     8, 18889,    11,    14,     3,    68,\n",
      "             7,     3,     0,     0,     0,     0,     0],\n",
      "        [   26,   342, 32870,     5,     4,  1430,  1836,    24,   679,    22,\n",
      "           806,   610,    21,   221,    20,    48,   265,   342,  4022,     2,\n",
      "           361,    28,     4, 32871,   814,    21,   399,    20,     2,    29,\n",
      "          5116,    23,     4,   384,     3,     0,     0],\n",
      "        [ 1524,  1571,    11,    14,     3,     8,   118,     7,     2,    43,\n",
      "            45,   950,     5,   119,     8,  4526,     7,    10,   395,     4,\n",
      "           686,    58,  1273,   162,   267,   159,  8515,   127,     2,     6,\n",
      "           138,  1516,  9894,     9,    65,  1790,     3],\n",
      "        [ 8267,    53,    30,   114,  1069,  1020,     2,     6,   261,     4,\n",
      "         26318,   133,    16,    15,  1329, 27774,    18, 27775,   853,    28,\n",
      "          8267,    53,     8,  1139,    11,    14,     3,     2,  2728,     7,\n",
      "             3,     0,     0,     0,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['3d2b783107c45ad6b201ef09e549f161e5c2bbbb', '04aaca2e9284f6a51de78e0cbc5fbc2c43348a39', '478bd10d96ed7cc50fabae1fd6da100525410c34', 'ffdddf8a39bd1b0dd65cfb0e090ee6337d5b2350', '99a76c4da41f60b9ea38e14672298bfcd8b922bb', '1ebfdd5e4520b00fef2b7ed1c6769da34256b13b', '0012d808e76e1cd0e5ddeea10824a0811942a7e5', '2b6f7a4b0a17fbe26bd2c5a86c209aefe9ab90cb', '11dba738253fd6d6461fc50e825b1fec7f94272e', '84ec5cac47cae049137ac5b4a945324c7f1db71a', '21a1e6d00e97974961b6416002443f175db7fee2', 'b2a8408af4bb2de1305cd3e736147199e4abc8de', '9925c85a92d2ceb1af5b620f15cf69ba7283b29f', '4573d8089a87e443903c5518bb283f8792e1a318', '09ba834b0a7a64e344e6ea5812e673a906289ffc', '7ae3cd759606bcc52cc7632773a393bb616a4cfc'], 'cited_paper_id': ['fdc650b26cc9d9ae43b57a8fe65a1213cdb14e8c', '425688f5400dc532230fd7293fed1dd3bcf09ceb', '82adea97cc7d912926709a9c71dc5ff45b833820', '9714062de869e00c2ab31289b049b2f21c11e5fd', 'd98169cb59d2cc3360d35296332f4d208b39f105', '6534758c49394c82858dd4db5268d2e0ac4f79b1', '53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', '37d4f42e18a8d092a646dd7f378c6232d2dc9a1d', '15b2c44b3868a1055850846161aaca59083e0529', 'a563aac4a9f97ca6424b89c6ce534094263ca911', '734715f85748a87a9808c740393a4be43de7b152', '744e757a2ceb28e93e3db0b1e02a021b3e241077', '8ae484d38a252778c315ee046b2065d957808e92', '125fd22448e7235969870745d957d522f545eed3', '6f9c96d4ffec300f71fbcb5302c0b7b30bf23429', '55bea487827c28aaaf713017c499e4f33aed62fd'], 'citation_excerpt_index': [2, 0, 3, 1, 0, 4, 4, 2, 4, 11, 1, 3, 0, 0, 4, 2], 'citation_id': ['3d2b783107c45ad6b201ef09e549f161e5c2bbbb>fdc650b26cc9d9ae43b57a8fe65a1213cdb14e8c', '04aaca2e9284f6a51de78e0cbc5fbc2c43348a39>425688f5400dc532230fd7293fed1dd3bcf09ceb', '478bd10d96ed7cc50fabae1fd6da100525410c34>82adea97cc7d912926709a9c71dc5ff45b833820', 'ffdddf8a39bd1b0dd65cfb0e090ee6337d5b2350>9714062de869e00c2ab31289b049b2f21c11e5fd', '99a76c4da41f60b9ea38e14672298bfcd8b922bb>d98169cb59d2cc3360d35296332f4d208b39f105', '1ebfdd5e4520b00fef2b7ed1c6769da34256b13b>6534758c49394c82858dd4db5268d2e0ac4f79b1', '0012d808e76e1cd0e5ddeea10824a0811942a7e5>53bec9f572ae3b40e8c881b8f5fdb255ccbb9fb3', '2b6f7a4b0a17fbe26bd2c5a86c209aefe9ab90cb>37d4f42e18a8d092a646dd7f378c6232d2dc9a1d', '11dba738253fd6d6461fc50e825b1fec7f94272e>15b2c44b3868a1055850846161aaca59083e0529', '84ec5cac47cae049137ac5b4a945324c7f1db71a>a563aac4a9f97ca6424b89c6ce534094263ca911', '21a1e6d00e97974961b6416002443f175db7fee2>734715f85748a87a9808c740393a4be43de7b152', 'b2a8408af4bb2de1305cd3e736147199e4abc8de>744e757a2ceb28e93e3db0b1e02a021b3e241077', '9925c85a92d2ceb1af5b620f15cf69ba7283b29f>8ae484d38a252778c315ee046b2065d957808e92', '4573d8089a87e443903c5518bb283f8792e1a318>125fd22448e7235969870745d957d522f545eed3', '09ba834b0a7a64e344e6ea5812e673a906289ffc>6f9c96d4ffec300f71fbcb5302c0b7b30bf23429', '7ae3cd759606bcc52cc7632773a393bb616a4cfc>55bea487827c28aaaf713017c499e4f33aed62fd']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         [259,  99, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  69, 106,  ..., 261, 261, 261],\n",
      "         [259, 100, 112,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73,  98,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259,  76, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259,  70,  54,  ..., 261, 261, 261],\n",
      "         [259, 113, 115,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  54,  46,  ..., 261, 261, 261],\n",
      "         [259, 110, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  85, 120,  ..., 261, 261, 261],\n",
      "         [259, 101, 106,  ..., 261, 261, 261],\n",
      "         [259, 100, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  717,    30,    33,   325,    22,    77,     5,     4,   447,  4898,\n",
      "            10,     4,  1166,     5,  3881,     6,  5586,  1818,     8,  6639,\n",
      "            11,    14,     3,     2,   131,    13, 15940,    11,    14,     3,\n",
      "             2,    85,     7,     3,     0],\n",
      "        [12751,  5988,  9848,    22,    15,   124,    19,     4,   531,     5,\n",
      "          2442,  2386,  6260,     2,   462,  5030,     2,   462,  6091,     6,\n",
      "          2120,  7764,    38,    33,    82,     9,    83,    21,   297,    20,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [ 4710,     6,  8611,     8,   142,     7,    92,    17,     9,  1257,\n",
      "             2,     4, 10754, 19929,    44,  2467,  8817,  1766,  2158,     2,\n",
      "           201,     9, 14873,     2,    51, 18652,   257,    10,  4571,  2158,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [   41,     4,   291,    45,    23,  3705,    11,    14,     3,     8,\n",
      "           132,     7,     2,   483,    37,  2135,    10,  7556, 13401,  5354,\n",
      "          9867,    81,  2430,     5,     4,   167,  1274,    10,    15,  5297,\n",
      "          7481,     3,     0,     0,     0],\n",
      "        [ 7329,  5388,    95,    19, 24547,   206,   163,     5,   614,    12,\n",
      "         32767,     6,   614,    12, 21052,    37,  2392,    19, 12566,     6,\n",
      "             4,  7917,    25,    65,   289,    24,   100,     9,  8712,    11,\n",
      "            14,     3,   104,     3,     0],\n",
      "        [ 1137,    10,    27,  1135,    28,     4,  6303,     5, 25789,   475,\n",
      "           178,     9, 12394,    91,     2,   776,    15,  2024,   596,    19,\n",
      "         11570,    25,  1740, 10714,    21,   300,    20,     2,    21,   254,\n",
      "            20,     3,     0,     0,     0],\n",
      "        [  205,   378,    23,   157,   419,     2,     4,  2495, 30603,    40,\n",
      "           188,    28,    34,   594,  3613,    12,  2932,   931,    10,  1331,\n",
      "           670,  7915,     6,   168,    84,  6986,   111,    34, 14262,  2507,\n",
      "           636,    21, 30604,    20,     3],\n",
      "        [   93,  1955,    17,     4, 29078,   475,    16, 23725,    44,    84,\n",
      "           904,   155,   343,     6,    74,     4,  3443,  6510,  2230,    21,\n",
      "           571,    20,    10,  1176,  8891,    44,  1561,    12,  1657,  1059,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [  260,    18,  8196,    16,  1362,    48,     4,  4491,  9386, 22157,\n",
      "           497,     8, 22928,     2,    76,     7,     2,     6,    18, 31366,\n",
      "            48,     4,  5547,  2600, 13210,   497,     8,  2551,    11,    14,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [ 2114,     2,  9600, 23588, 20382,   765,    17,  3068,  1029,    16,\n",
      "            15,   447,  7686,     5,     4,  1340,   204,     8,   541,    11,\n",
      "            14,     3,     2,    70,    13,  4816,    11,    14,     3,     2,\n",
      "            63,     7,     3,     0,     0],\n",
      "        [ 1224, 14546,    29,  1047,  1023,     5,  2908,    49,   485,  4359,\n",
      "             8, 15583,    11,    14,     3,     2,   448,     7,     2,     4,\n",
      "          1848,     5,   138,  2596,   619,     8, 16813,    11,    14,     3,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [   61,     7,     6,    51,    16,    46,   292,    15,   577,  4538,\n",
      "            17,    40,   576,    22,   471,    22,  2047,    73,     5,     4,\n",
      "         16391,     5,  3090,  1535,     8,  9117,    11,    14,     3,    61,\n",
      "             7,     3,     0,     0,     0],\n",
      "        [   41,     4,  1164,  1518,  2793,     5, 37472,    91,     2, 21847,\n",
      "          3585, 28632,  2910,     2,  7025,     2,     6,     4,   180,  1239,\n",
      "            88,  1185,   159,   107,   120,   562,   472, 21847,    12,   669,\n",
      "             8, 37473,     7,     3,     0],\n",
      "        [   26, 22022,   180, 40281,  2397,   246,   178,     6,  5081,     4,\n",
      "          3421,  1767,   464,     5, 16479,     6, 27257,     2,    32,    24,\n",
      "           447,  5444,   356,     5,  3571,  2279,    91,    21, 23674,    20,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [13894,    56,   280,    44,  1164,  3780,   398,     8, 13574,   602,\n",
      "             7,     8,  4219,    11,    14,     3,   132,     7,    67,  4257,\n",
      "            12,  3780,   398,     8,  9206,   602,    13,    39,    62,     7,\n",
      "             3,     0,     0,     0,     0],\n",
      "        [ 1493,  1161,  2987,    12,  5336,  2197,     5,     4, 35700,   498,\n",
      "            12,     4, 12320,     6,  8385,    80,  8586,  2987,  5336,  2197,\n",
      "            12,    24,  1594,     9,     4,   854,     5,  3371,   246,  1254,\n",
      "            21,  6922,    20,     3,     0]], device='cuda:0')}, 'labels': tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['20d4e4ed3fe881e79da4571fcc3aa8bc6e83b99c', 'd10a5a0f04c063a85e28f711c37e9606aef1a414', 'd3ec746e4b2cc8fffc3cce7a9b5c0a7de44a168c', 'ed60fe5cf0b2947f812a3d19d533d0f644b67b0d', '25a16f6fda8c4a6b685a3a99315cca3eb148eec2', '9ef65a9bca42e1ccd1c57729fad12e1e0f3cc6dc', 'a2e15eae099c09a6ced8648717946c017448f4e7', '1e7e4a194cbdf3a4ebd6899d9505d92095398072', 'cd7b3acd54d6026bdc4b4be7089558682b511777', '9d1c38923868aad077de91a389a27f72d592d329', '0fa2a11a83b922e2a4f18b93e02311c571d6cf9e', 'e630311c0ca0d19549bd0959fedd924d929fba85', '3b84a687734bf3428f6e5badc14442405aca40d6', 'ac7f29379b51a0681b60a9846b14d32ba9a42574', '560c67b8d5c6e4b2809fbbd308d373366241ea86', '04aaca2e9284f6a51de78e0cbc5fbc2c43348a39'], 'cited_paper_id': ['18aed8693441c7211cf111d0523a6311ef797129', 'b15ccdb7254f9112bba41969c45b0ddcad9fa6bf', 'd04b2ec8089a6489bc9121f49d3106fa093fe4ea', '5af4e6e8d6e7a25cb37a9d52e87a1f28b4464e04', 'c08d82e0e656dadaa0c26b1a21fe57fa60bb84d8', '9ba502def891eaad42828692c654c6e5ebe36658', '8cbbc3864c5948abb809ce73c46a1ccb74e0f4b7', '6b2e3c9b32e92dbbdd094d2bd88eb60a80c3083d', '0bc50d75597b99999634d909009153673deff56d', 'badee7f8b87dbf9d38775bebaad489d664fe0ef3', '2a13a0b2886934881fb53c3d277b613697ea5ffa', '2cb9f88cf6425013c7c976fbb8b65bcbbff0d7e9', 'b760aedd474d8e95bb8e7841c2c0fd43082901eb', '70f3cda14c45c0f74e60b8f004d72dc25a5e3ba1', 'b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '425688f5400dc532230fd7293fed1dd3bcf09ceb'], 'citation_excerpt_index': [3, 8, 1, 11, 7, 1, 0, 0, 0, 6, 1, 3, 5, 0, 11, 7], 'citation_id': ['20d4e4ed3fe881e79da4571fcc3aa8bc6e83b99c>18aed8693441c7211cf111d0523a6311ef797129', 'd10a5a0f04c063a85e28f711c37e9606aef1a414>b15ccdb7254f9112bba41969c45b0ddcad9fa6bf', 'd3ec746e4b2cc8fffc3cce7a9b5c0a7de44a168c>d04b2ec8089a6489bc9121f49d3106fa093fe4ea', 'ed60fe5cf0b2947f812a3d19d533d0f644b67b0d>5af4e6e8d6e7a25cb37a9d52e87a1f28b4464e04', '25a16f6fda8c4a6b685a3a99315cca3eb148eec2>c08d82e0e656dadaa0c26b1a21fe57fa60bb84d8', '9ef65a9bca42e1ccd1c57729fad12e1e0f3cc6dc>9ba502def891eaad42828692c654c6e5ebe36658', 'a2e15eae099c09a6ced8648717946c017448f4e7>8cbbc3864c5948abb809ce73c46a1ccb74e0f4b7', '1e7e4a194cbdf3a4ebd6899d9505d92095398072>6b2e3c9b32e92dbbdd094d2bd88eb60a80c3083d', 'cd7b3acd54d6026bdc4b4be7089558682b511777>0bc50d75597b99999634d909009153673deff56d', '9d1c38923868aad077de91a389a27f72d592d329>badee7f8b87dbf9d38775bebaad489d664fe0ef3', '0fa2a11a83b922e2a4f18b93e02311c571d6cf9e>2a13a0b2886934881fb53c3d277b613697ea5ffa', 'e630311c0ca0d19549bd0959fedd924d929fba85>2cb9f88cf6425013c7c976fbb8b65bcbbff0d7e9', '3b84a687734bf3428f6e5badc14442405aca40d6>b760aedd474d8e95bb8e7841c2c0fd43082901eb', 'ac7f29379b51a0681b60a9846b14d32ba9a42574>70f3cda14c45c0f74e60b8f004d72dc25a5e3ba1', '560c67b8d5c6e4b2809fbbd308d373366241ea86>b0fe8d2727db77f58bc430fef29aba3308ecd3f2', '04aaca2e9284f6a51de78e0cbc5fbc2c43348a39>425688f5400dc532230fd7293fed1dd3bcf09ceb']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
      "         [259, 108, 102,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259,  98, 111,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 260,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         [259, 110,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  50, 260,  ..., 261, 261, 261],\n",
      "         [259,  41, 260,  ..., 261, 261, 261],\n",
      "         [259, 100, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259, 119,  98,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  68, 122,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         [259, 116, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  78, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 116, 112,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   26,  8596,   549,  3842,    25,  5164,  1885,    24,   876,   570,\n",
      "            25,     4, 31181,   321,  6926,     8, 15733,     7,    54,  3842,\n",
      "             2,   130,     4, 15733,  3842,     6,   107,  1417,    21, 31182,\n",
      "            20,    10,   604,     4,   549,   332,     3,     0,     0,     0],\n",
      "        [  205,    34,   160,     2,    43,  1346,     4,   494,  7080, 17786,\n",
      "         30430,     5,     4,  6234, 17786,   414,     5,     4, 30431,     5,\n",
      "          3494,  2550,  2795,  6933,  1505,     2, 30432,  3085, 30433,     8,\n",
      "         30434,    11,    14,     3,     2,   209,     7,     3,     0,     0],\n",
      "        [  347,  2130,  1959,    28,   295,   392,     2,    96,     5,    32,\n",
      "           233,  6298, 18485,     8,   203,    12,  9950,   277,  1441, 13752,\n",
      "            13,  5020,  2892,     7,     2,    57, 35992,  4497,   166,     4,\n",
      "          2336,     5,     4,    62,     3,     0,     0,     0,     0,     0],\n",
      "        [18018,  7854,     6, 11564,     7,   121, 14689,    15,  2421, 14368,\n",
      "            16,  1944,   764,     6,  3176,    28,   236,    73,    10,  4204,\n",
      "            73,     9,     4,   248,     6,   662,    73,     9,     4,   193,\n",
      "           592,     8, 33545,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   88,   122,   239,  2111,    59,    21,   388,    20,    31,  4160,\n",
      "            10,   810,     4,  2444,  4733,     5,   283,   227,   666,    19,\n",
      "          2191,     6,    44,   196,     5,  2349,     2,    69,   199,    37,\n",
      "         18073,    18,     2,    29, 36109,     5,     2, 38498,     8,  1860],\n",
      "        [18064,  1890,  4854,    18, 22204,    65,  4911,    37,  1362,    22,\n",
      "           100,     9,    21,   399,    20,     2,    19,     4,   148,   148,\n",
      "          1981,   134,  2020,     5,    99,     4,   149,     6,   457,  1890,\n",
      "          4854,  1397,    22,     4,  1208,  2068,     3,     0,     0,     0],\n",
      "        [  813,  1178,     9,     4, 23322,  2870,    37, 15159,  2188,  4479,\n",
      "            22,  2227,    15, 17249,  1658,   139,    10,    17,     5, 44899,\n",
      "             8, 20139,     7,  2622,     8, 44900, 44901,    11,    14,     3,\n",
      "           131,    13,  8874,    11,    14,     3,   131,     7,     3,     0],\n",
      "        [  311,    52,  1568,     4,   171,   219,     5, 19870,   787,  3256,\n",
      "           158,     9,     4,   352,     5,  1317,  1218,    21, 19226,    20,\n",
      "             6,    24,   228,    19,   296,    17, 12877,     5, 19871,   188,\n",
      "             9,  1416,     5,    17,   158,    21, 40794,    20,     3,     0],\n",
      "        [25994,    21,  2587,    23, 21239,     4,  1127, 10427, 16494,     9,\n",
      "         22853, 20276,     8, 11166,     7,    20,    29,  3167,  4343,     8,\n",
      "         13188,     6, 14183,     7,   324, 31138,  1372,     9, 31139,     8,\n",
      "         15714,     2, 15217,     7,     3,     0,     0,     0,     0,     0],\n",
      "        [   88,  1632,   164, 10674,     5, 18230,     2, 42660,     2,  7902,\n",
      "          2881, 23609,     6,   242,     9,   831,    12,  6580,     8,   474,\n",
      "          3561,     6,  3806,     2,    79,     7,     2,  2458, 12604,     4,\n",
      "           673,     9,     4,   854,    58,    39,   204,     6,  2651,     3],\n",
      "        [  205,     9,   102,   400,     8,   474,  1823,  5549,    11,    14,\n",
      "             3,  2728,     2,    63,     7,     2,  5515,    19, 37321,     2,\n",
      "         37322,     2,     6, 37323,   206,  3096, 13581,  1289,     6,   492,\n",
      "         10231,   121,   231,    10,  1257,     8,   345,    57,     7,     3],\n",
      "        [ 8331, 17360, 10017,     9,     4, 17361,     5,   447, 12828,   386,\n",
      "           456,   347,   180,    21,  9451,    20,     2,     6, 27317,     6,\n",
      "         27318,     2,    81,    55,   161, 18513,     2,    30,    33,  1594,\n",
      "             9, 17362,    21,   371,    20,     3,     0,     0,     0,     0],\n",
      "        [    2,    75,     7,     2,  9038,     8, 45129,    36, 45130,     2,\n",
      "            75,     7,     2,  3424,     8,  5532,    11,    14,     3,     2,\n",
      "            61,    13, 45131,    11,    14,     3,     2,    89,     7,     2,\n",
      "          2115,  9101,     8,  9586,    11,    14,     3,     0,     0,     0],\n",
      "        [   57,     8, 22677,    12, 22678,     7,     9,  8418, 11130,     2,\n",
      "           846,   122,     9,    39,  8418,    48, 15245,    21,   236,    20,\n",
      "             2,    31,  2324,   846,     9,    71, 21868,   553,     6,   713,\n",
      "           105,    10,  1079,    15,   474,  6925,   871,  2196,     3,     0],\n",
      "        [24004,    10,  5660,  1754,     5, 25094,    31,   573,    23,  3375,\n",
      "          1473,   858,    48,    15,  3594,  2310,  2373,     5,  1872,   218,\n",
      "            21,   371,    20,     6,  6018,  6304,  3594,    22,  1288,     9,\n",
      "             4,   345,    72,     8,  3454,  1895,    72,     7,     3,     0],\n",
      "        [  651,     2,  3455,  6250,     9,     4, 37895,  2345,     4,  1438,\n",
      "          3077,     6,  4558,    91,    66,   917,    15,   219,     9,    15,\n",
      "          1112,  1491,  2329,    22, 10528,     5,  1438,   328,     8, 21135,\n",
      "            11,    14,     3, 10269,     7,     3,     0,     0,     0,     0]],\n",
      "       device='cuda:0')}, 'labels': tensor([0, 1, 0, 0, 1, 1, 0, 2, 1, 0, 2, 0, 0, 1, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['845cf76f206f77c1e415478ac1ffa6a9a7012f65', 'd0795090c47fbb8913e365dac816271f4bc4d4be', 'ec895429daeec3e37d531a6dbbc0d9b83947d19b', '9e92fc73392d4aea262aa6bae77ab379c79b37b7', '8e15085ce2516da3133a08cb87d2f62a9af497b3', '52fdfce0f6f82b40947065f0ed30560bb6793c6a', '7a9bf55cf151a07a0ca8237e765ba0d1412c73ee', 'efd27b067552d9a58702a63b0724ec52b309719c', 'a0b814bf15018765b6496ce1786dd640f512fe3f', '51c7b381edeec1f0fb4e3c3f7a4d5a5bf2a49a28', '00eea3644491b0fcf74c49aa211fa2a24a6e3d3e', 'c1e8d6f81188cd22f16972e3afb8cb051e9a4182', '7b0ca6f15e76f285cc19efd2305cb1ec9e16a5b5', '4fa6bc9e73e52f4e7a4f165b2f4799eb05c31aa2', '745c4f69c160823911589db740f1efbc61e88ab7', '7d53a24af17569b11cc49d26ceaf75aefb0566ad'], 'cited_paper_id': ['4a19358ae23379109c673275161644ca1ea760ac', '93f237179c4524e315c3f03a717767f113f97ea6', 'e69c9d7bf9bb5f5c6e6fffb27630bbe831a7b833', '2521ee9b9ba1bf7dfd4341259b97f383827fecc9', '4c6560a8a85809e5446b5c3d8498ffc07ffc7357', '86a516f1311b1ea6656980253106b464e1bba4a9', 'e232a3393e6366652d41b8619b6ffd7b240194e3', '84ea651e58aa63221f62d1a58a8e6c5e4ff1680c', 'e37654b0642229918711d43ca8e08095ea83c793', '01994833ad94026b07221b3ae0e57783c016b67d', '2271b873cf8e52856c38eae82751d2b1421007c5', '07a04ec4a979acbf67ef9b08fe4b4bc8098232b8', 'df90f3e882609d15c298251608a5b48b69efb3b8', 'fc6f38bd4724635723ffe8518f2be1a8f3085ea5', '0f973badc6a5bfb01d1a30913104d6e197fc2fff', 'f96e40f804e2764ad75d87a430b61a810616eef7'], 'citation_excerpt_index': [0, 1, 4, 0, 0, 2, 5, 0, 0, 8, 6, 1, 5, 11, 0, 1], 'citation_id': ['845cf76f206f77c1e415478ac1ffa6a9a7012f65>4a19358ae23379109c673275161644ca1ea760ac', 'd0795090c47fbb8913e365dac816271f4bc4d4be>93f237179c4524e315c3f03a717767f113f97ea6', 'ec895429daeec3e37d531a6dbbc0d9b83947d19b>e69c9d7bf9bb5f5c6e6fffb27630bbe831a7b833', '9e92fc73392d4aea262aa6bae77ab379c79b37b7>2521ee9b9ba1bf7dfd4341259b97f383827fecc9', '8e15085ce2516da3133a08cb87d2f62a9af497b3>4c6560a8a85809e5446b5c3d8498ffc07ffc7357', '52fdfce0f6f82b40947065f0ed30560bb6793c6a>86a516f1311b1ea6656980253106b464e1bba4a9', '7a9bf55cf151a07a0ca8237e765ba0d1412c73ee>e232a3393e6366652d41b8619b6ffd7b240194e3', 'efd27b067552d9a58702a63b0724ec52b309719c>84ea651e58aa63221f62d1a58a8e6c5e4ff1680c', 'a0b814bf15018765b6496ce1786dd640f512fe3f>e37654b0642229918711d43ca8e08095ea83c793', '51c7b381edeec1f0fb4e3c3f7a4d5a5bf2a49a28>01994833ad94026b07221b3ae0e57783c016b67d', '00eea3644491b0fcf74c49aa211fa2a24a6e3d3e>2271b873cf8e52856c38eae82751d2b1421007c5', 'c1e8d6f81188cd22f16972e3afb8cb051e9a4182>07a04ec4a979acbf67ef9b08fe4b4bc8098232b8', '7b0ca6f15e76f285cc19efd2305cb1ec9e16a5b5>df90f3e882609d15c298251608a5b48b69efb3b8', '4fa6bc9e73e52f4e7a4f165b2f4799eb05c31aa2>fc6f38bd4724635723ffe8518f2be1a8f3085ea5', '745c4f69c160823911589db740f1efbc61e88ab7>0f973badc6a5bfb01d1a30913104d6e197fc2fff', '7d53a24af17569b11cc49d26ceaf75aefb0566ad>f96e40f804e2764ad75d87a430b61a810616eef7']}\n",
      "{'citation_text': {'elmo': tensor([[[259,  66, 116,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  54,  50,  ..., 261, 261, 261],\n",
      "         [259,  94, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 101,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  92, 260,  ..., 261, 261, 261],\n",
      "         [259,  54, 260,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  68, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259, 101, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  88, 102,  ..., 261, 261, 261],\n",
      "         [259, 111, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 103,  ..., 261, 261, 261],\n",
      "         [259,  79, 118,  ..., 261, 261, 261],\n",
      "         [259, 106, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[ 205,    4,   62,  ..., 1575,   20,    3],\n",
      "        [  41,  253,    2,  ...,    0,    0,    0],\n",
      "        [  21,  128,    2,  ...,    3,    0,    0],\n",
      "        ...,\n",
      "        [5972,    2,  837,  ...,    0,    0,    0],\n",
      "        [  93, 1698,   17,  ...,    0,    0,    0],\n",
      "        [ 646, 5325,   16,  ...,    0,    0,    0]], device='cuda:0')}, 'labels': tensor([1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['85232b6c04019d79bd8fd026ffcc5aa8cb32e3cc', 'f473f30f0bf35b7e97874cefc66e9a6dacc4eae8', '94659456972d7504326758440bb3eb3cb66a9f1c', '8369c3c6028a948e1175a047eed5be4c6eee7f75', 'a8208eb340215e0b7b4d28b8234401ea58d6c41a', '96d59f09d602d930beddbc2785972d443efa4d93', '32f783b7f4771f754ddb7d4ac8c26688b25cf1c8', 'a89979ef0ef381c7b97cedc145fc0624d824cc1f', 'fdf8e61876d6db8df40d8a809a6c8ec6e9f9541a', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab', 'af5d6fe5daa2b7ec7482a2e5fbe27929a1f14de7', '4c700869e4ab2020d15d2ebec2ee0776fce3410a', '1b4174f4c7f100bbb3b2cf57c2531af47e963fbe', '90910fda9a026ff80f248208efc880cc9dfb0c33', '1859eb9273884fc6934da520f8b5e80fd5500f9e', 'e06c8966e57806d20fc9329f16636b2fac2469b8'], 'cited_paper_id': ['e597a3ad0a671490fbdb8abf180370de434ef08a', 'f5191ac6456c5df72545a8ddee851f0c4fbe378f', '8186eead8bc72a692a8dbcce9e0dd120d5c898b6', '44e9ecd959b1c72f1fe469e6b915ee55ac986a52', '0c9b3452dc32b86d28a29ec0c0471bb29a3ec449', '723a4b4f3019cd5a5f8546925d8cf4478a0d03b7', '38f57995a5b7b37c041140c2c512dd36e2e93e38', 'f986e697ab036562fa61ab501ab4c2a64ddc6494', '87feadcddffff7ef6a3f0cc4d48bd33fb05758da', 'c14be2a7007e022da13889d804a540d0c0c34264', 'f75e422caae42a7fabd1e6117a72bed4d54cc709', '6ebd21b7abe728491a59e19a177f5b539bfed7e2', '1cd8130dca6cc1c98d2fac8b37ff1b9c664887d2', '974c64594b6e0381c96186a594406e9fbbe2f4af', '6c0f105bd664bd41ed8e0c4a9784a98b6953026a', 'e4675af68d613dc95ae1c192ed154307a0d3d7be'], 'citation_excerpt_index': [4, 3, 0, 3, 1, 5, 4, 1, 0, 7, 8, 7, 0, 2, 2, 4], 'citation_id': ['85232b6c04019d79bd8fd026ffcc5aa8cb32e3cc>e597a3ad0a671490fbdb8abf180370de434ef08a', 'f473f30f0bf35b7e97874cefc66e9a6dacc4eae8>f5191ac6456c5df72545a8ddee851f0c4fbe378f', '94659456972d7504326758440bb3eb3cb66a9f1c>8186eead8bc72a692a8dbcce9e0dd120d5c898b6', '8369c3c6028a948e1175a047eed5be4c6eee7f75>44e9ecd959b1c72f1fe469e6b915ee55ac986a52', 'a8208eb340215e0b7b4d28b8234401ea58d6c41a>0c9b3452dc32b86d28a29ec0c0471bb29a3ec449', '96d59f09d602d930beddbc2785972d443efa4d93>723a4b4f3019cd5a5f8546925d8cf4478a0d03b7', '32f783b7f4771f754ddb7d4ac8c26688b25cf1c8>38f57995a5b7b37c041140c2c512dd36e2e93e38', 'a89979ef0ef381c7b97cedc145fc0624d824cc1f>f986e697ab036562fa61ab501ab4c2a64ddc6494', 'fdf8e61876d6db8df40d8a809a6c8ec6e9f9541a>87feadcddffff7ef6a3f0cc4d48bd33fb05758da', 'bb21e98f4b1b7bc5a2e89fda1139d98763d78bab>c14be2a7007e022da13889d804a540d0c0c34264', 'af5d6fe5daa2b7ec7482a2e5fbe27929a1f14de7>f75e422caae42a7fabd1e6117a72bed4d54cc709', '4c700869e4ab2020d15d2ebec2ee0776fce3410a>6ebd21b7abe728491a59e19a177f5b539bfed7e2', '1b4174f4c7f100bbb3b2cf57c2531af47e963fbe>1cd8130dca6cc1c98d2fac8b37ff1b9c664887d2', '90910fda9a026ff80f248208efc880cc9dfb0c33>974c64594b6e0381c96186a594406e9fbbe2f4af', '1859eb9273884fc6934da520f8b5e80fd5500f9e>6c0f105bd664bd41ed8e0c4a9784a98b6953026a', 'e06c8966e57806d20fc9329f16636b2fac2469b8>e4675af68d613dc95ae1c192ed154307a0d3d7be']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "background_P: 0.6600, background_R: 0.8408, background_F1: 0.7395, method_P: 0.5904, method_R: 0.4153, method_F1: 0.4876, result_P: 0.4412, result_R: 0.1613, result_F1: 0.2362, average_F1: 0.4878, aux-sec--introduction_P: 0.3951, aux-sec--introduction_R: 0.8377, aux-sec--introduction_F1: 0.5369, aux-sec--conclusion_P: 0.4211, aux-sec--conclusion_R: 0.0452, aux-sec--conclusion_F1: 0.0816, aux-sec--experiments_P: 0.2400, aux-sec--experiments_R: 0.0465, aux-sec--experiments_F1: 0.0779, aux-sec--method_P: 0.4286, aux-sec--method_R: 0.0441, aux-sec--method_F1: 0.0800, aux-sec--related work_P: 0.0225, aux-sec--related work_R: 0.0400, aux-sec--related work_F1: 0.0288, aux-sec--average_F1: 0.1611, aux-worth--False_P: 0.8835, aux-worth--False_R: 0.9972, aux-worth--False_F1: 0.9369, aux-worth--True_P: 0.0000, aux-worth--True_R: 0.0000, aux-worth--True_F1: 0.0000, aux-worth--average_F1: 0.4684, loss: 0.9381 ||:   1%|          | 50/5714 [01:07<1:35:58,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259, 111, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  66, 109,  ..., 261, 261, 261],\n",
      "         [259, 106, 117,  ..., 261, 261, 261],\n",
      "         [259, 105,  98,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  71, 112,  ..., 261, 261, 261],\n",
      "         [259, 117, 105,  ..., 261, 261, 261],\n",
      "         [259,  98, 116,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  84, 106,  ..., 261, 261, 261],\n",
      "         [259, 117, 112,  ..., 261, 261, 261],\n",
      "         [259, 112, 118,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  80, 119,  ..., 261, 261, 261],\n",
      "         [259, 112, 103,  ..., 261, 261, 261],\n",
      "         [259,  67,  68,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [259,  42, 260,  ..., 261, 261, 261],\n",
      "         [259,  47, 260,  ..., 261, 261, 261],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  70, 109,  ..., 261, 261, 261],\n",
      "         [259, 103, 112,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[   41,     4,   158,   557,    28,    96,    65,   804,   721,     4,\n",
      "           161, 45318,   721,     4,  1112,   491,     2,    50,    22,   356,\n",
      "             2,   719,     2,    29,  2379,     2,  2094,    22,   754,     6,\n",
      "            60,   804,    24,   868,  5745,    22,  2721,     8, 12615,    75,\n",
      "            13, 10388,    11,    14,    83,    13, 25877,    11,    14,   509,\n",
      "             7,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  323,    51,    38,    33,   105,    23,  8634,    12,  8480,    11,\n",
      "            14,     3,     8,    83,     2,   104,     7,    17,    99,  3898,\n",
      "             6,  9320,    24,   423,     9,   787,  2425,     2,    43,  3947,\n",
      "            17,     4, 12001,    66,   334,   816,   318,     6,  9051,    51,\n",
      "             2,    69,    51,    16,   213,    17,   787,   175,  1334,     4,\n",
      "          1456,     5,   265,   269,   162,     8, 33137,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  112,     4, 21143,     5, 35292, 11579,  1058,    53,     2, 35293,\n",
      "            16,  2385,    19,     4, 13693, 28838, 30861,  1320,     8, 35294,\n",
      "             7,    21,    90,    12,   128,    20,     2,    32,   925,    18,\n",
      "          7960,     4, 12402,  2308,     4, 35295,     8, 27178,     7, 11579,\n",
      "          1058,  2967,     5,     4,    86,   475,  4684,    44,     4, 22762,\n",
      "            59,  1059,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   41,   245,    10,   260,     4,   219,     5, 35712,     9,     4,\n",
      "          1432,     5, 16524,     6, 35713,    23,     4, 13459,    12, 35714,\n",
      "            98,     2, 35715,  1728,     8,   669,    12, 20535,     7,  2122,\n",
      "             5,  1773, 16142,    19,    39,   226,     8, 35716,    11,    14,\n",
      "             3,   695,    13, 35717,    11,    14,     3,   448,     7,    37,\n",
      "            45,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  890,  2452,     5,  6532,   546,    21,   143,    20,     2,   246,\n",
      "           178,   545,    21,   236,    12,   300,    20,     2,     6,   246,\n",
      "           174,    21,  6054,    20,    58, 42946,     6,    55,  6620,   792,\n",
      "           226,    30,   378,    17,   471,     5,     4, 14264,   202,   874,\n",
      "            17,    38,    33,  1002,     9,  2072,     2, 42947,     6,  4630,\n",
      "          9005,     9,     4,   753,   321,  6926,     5,  6893, 18492,     3,\n",
      "             0,     0],\n",
      "        [   35, 27132,   879,    30,  3441,    10,  7371,     4,   327,  1566,\n",
      "             6,   379,     5,  2520,   226,     9,    99,     4, 10652,     8,\n",
      "          9144,   198,    13,  5810,    11,    14,     3,   151,     2,    78,\n",
      "            13,  7142,    11,    14,     3,    76,    13, 10075,    70,     2,\n",
      "            63,     2,    83,    13, 10221,    36, 18349,    83,     7,     6,\n",
      "          7654,   532,     8, 27133,    11,    14,     3,    70,     2,    35,\n",
      "             0,     0],\n",
      "        [   88,   117,     5,    49,    30,  9552,     9, 21745,     4, 21746,\n",
      "         11137,  4067, 15932,    25,     4,  1147,  3083,     2, 21747,     2,\n",
      "           435,    18,   114,   163,     5,  3392,     8,   301, 14813,     7,\n",
      "             8,   474, 16757,     6,  7651,     2,   575,    13, 15545,     6,\n",
      "         15546,     2,   390,    13,  7652,    12,  7725,    11,    14,     3,\n",
      "             2,   390,    13,  7652,    12,  7725,     6,  7651,     2,   428,\n",
      "             7,     3],\n",
      "        [  112,     4,  1560,  2974,   211,     2,    22,     4,  1837,    24,\n",
      "          2541,     9,  1023,     2,     9,   245,    10,   970,    15,  1420,\n",
      "           605,     2,    43,   284,     4,  1560,   429,  1379,    45,    23,\n",
      "          5358,    11,    14,     3,     8,    61,     7,    10,    71,    59,\n",
      "             6,    10,     4,    59,     5,  5358,    11,    14,     3,     8,\n",
      "            61,     7,   267,    28, 31273,     3,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [   26,   167,    52,    37,   267,    23,  3987,     6, 35868,    21,\n",
      "           494,    20,     6,    23, 33593,    12, 35869,    21,   254,    20,\n",
      "             2,   199,   389,    42,   731,   252,   673,     9,     4, 16170,\n",
      "           801,  1916,     5,    15,    72,     6,   129,    73,   644,     5,\n",
      "         35870,    29,    15, 35871,     8,   155,  8750,    73,   644,     7,\n",
      "             6,    15, 35872,     8,   155,   129,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  890,    49,     9,    71,  1315,    30,   788,    17,  3303,  8920,\n",
      "             6,  6656,     2,  9542,    10,   161,  3303, 26129,     6, 19159,\n",
      "             2,   463,     2,    24,     4,   101,   171,  3303,  3347,  1498,\n",
      "            18,     4, 45346,     5,  7150,     9, 11921,  1063,     8,  5585,\n",
      "            11,    14,     3,     2,  2850,    13,  2489,    11,    14,     3,\n",
      "             2,    85,    13,  9440,     6, 10235,     2,    70,     7,     3,\n",
      "             0,     0],\n",
      "        [    8,    90,     7,   153,  3448,  4481,    17,     4,   759,  6484,\n",
      "          1017,    40,    27,   741,    23,  2841,   116,     8, 20151,     6,\n",
      "         20152,     2,   118,     7,     2,   396,     2,    43,    30,    15,\n",
      "          1057,  5800,    54,    25,     4,   102,   808,     9,  2089,     6,\n",
      "          7363,    49,     8, 10480,    11,    14,     3,     2,    78,    13,\n",
      "         20153,    11,    14,     3,     2,   190,     7,     3,     0,     0,\n",
      "             0,     0],\n",
      "        [32725,     5,    49,   997,    17,     4,  1417,     5, 32726,    37,\n",
      "           150,    19,    86,   196,     5,  8607,     2,  2868,   283,     2,\n",
      "          2949,     2,     6, 17291,     2,   506,  2917,     5, 32727,    31,\n",
      "           150,    19,   285,   196,     5,  8607,     6, 19665,    21,   224,\n",
      "             2,   143,     2,   277,     2,   388,     2,   371,     2,   346,\n",
      "            20,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  927,     2,    10,  3947,     4,   505,    18,     4,  2051,   140,\n",
      "             2,     4, 10760,    18,    99, 23965,    12, 23966,     6, 23967,\n",
      "            37,  2790,    48,   465,  1033,  5822,   229,   408,     8,   533,\n",
      "             7,    10,  1075,     4,   511,     5, 11093,   203,    12,  2396,\n",
      "           140,     5,     4,  1033,    98,     6,   731,   212,  3119,    31,\n",
      "          1179,    10,   970,    34,  1101,  1287,    10,   790,    12,   417,\n",
      "             3,     0],\n",
      "        [ 1043,    10,    71,    52,     2,   836,     5, 25781, 11748,    57,\n",
      "             2, 23572, 11748,    57,     6, 19049, 11748,    57,     5,  7842,\n",
      "          1119,   136,     4,   952,   398,     5,  3931,     9, 27136,  2644,\n",
      "           389,    42,   555,    25,     4,  1605,     5, 16924,  5051,     4,\n",
      "          3159,   521,     9,    15,   184,    62,     8, 17402,    11,    14,\n",
      "             3,    75,     7,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [10348,     5, 12549,     9,     4,  1934,    12,   268,     2,  5094,\n",
      "           472,    12,  2680, 28772,   737,   317,    91,    16,   213,    10,\n",
      "           536,    10,    15,    56,  7908,     6,  7681,  1658,  1002,    23,\n",
      "             4,   598,     5,  2369,   562, 28773,     6, 30743,    17,    24,\n",
      "          1546,     9, 18422,  1950,     6,    46,  9211,     6, 12549,     8,\n",
      "           371,     2,   313,     2,   630,     2,   662,     2,  1172,     7,\n",
      "             3,     0],\n",
      "        [26181,    18,  2016,    37,  1235,    95,  2392,    19,  2104,    29,\n",
      "         26182,  1625,   385,    10,  3433,  1951,   608,   166,    15, 15393,\n",
      "          3719,     5,  9819,     6, 12039,  3039,     8, 26183,     7,    21,\n",
      "           254,    20,     6,    23,  1936,    58,    81,  7591, 21353,   199,\n",
      "            37,  3966,    10,     4,   178,    52,    44,     4,    84,     5,\n",
      "           842,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]], device='cuda:0')}, 'labels': tensor([0, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 2, 1, 2, 0, 1], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['f3ee10d77b2902a5856ec3854fd946fd75f4316c', '0546b87aef157bf494f5e75c959235abe11f1e1b', '2229e1dbc8cc9694a2c3ee905610db45802f0b10', 'f9eb2ed2859fa428882086b5031d92e70dd66d4a', '0fdf66abd99ba484de3b0a548e5056ad4ded598d', '2b80f65e936e58979de232164026543edb2a79e8', '2bb2505c500ea1382402cd8bf423a8a8715e1f0c', '672e74fab235de7e680d04b97a272442c39be81a', '95671b460641dcc9f3005b9da4205f584b78f7cc', '77cc5c7417526334a60494acd658dcbf377cae1d', '9efebeada238948c156bb066fab1b2bc174f2f29', '49abe8312557893b0b21dd278f705143422e46ac', '0a9bde599ce0b68dd0ca3d41fe1e328e5c2c8eb3', 'd286db5e1f697245f7d89f21991a16dd1206f728', 'aab326884c65b09274891f94f71d3cb620346f87', 'd5c3093d68614d83785b520a087b379e8334a075'], 'cited_paper_id': ['3d188c6936ad6dd478e01f2dd34bb2167f43e7d7', '2a178f45f4e668ac32cc13ffc4ce998da33af2b1', '3aa13b47a5a77f94340862a3d519a07192d22212', 'b2ec8034e4f666dd42db739795131f594588ac04', 'a5c61fa6c13242645e0671c45c9e7bd2df9e0fa3', '8f01119d68d6a980ec1608e905be6e4f58cb328a', '7e98ff7d7eddadc7f32a776a66585475e6d236f4', '46f639a94c571af887b3cf5b4f7283bc7db2237a', 'None', 'ced7e3c1f9c912dca5751664c86a7587b58b0854', '0230905979a5e3fdb60e74bd505e79ac0746ec56', '37971b42d771d3cfd0efcbf81172464f8fd07ec3', '12df8d0e64a0a5dc209195e9f92b16a7cb3445f8', '65445a8c6af6d1eb664f171ffa960fe0a5f6b9d4', '76c45f67dcb8a9299c0a191cf611d551a8148921', '46c0660db9a3bd806ae697b0220476df8dab57c5'], 'citation_excerpt_index': [5, 0, 0, 0, 0, 8, 4, 4, 0, 4, 6, 1, 0, 0, 13, 0], 'citation_id': ['f3ee10d77b2902a5856ec3854fd946fd75f4316c>3d188c6936ad6dd478e01f2dd34bb2167f43e7d7', '0546b87aef157bf494f5e75c959235abe11f1e1b>2a178f45f4e668ac32cc13ffc4ce998da33af2b1', '2229e1dbc8cc9694a2c3ee905610db45802f0b10>3aa13b47a5a77f94340862a3d519a07192d22212', 'f9eb2ed2859fa428882086b5031d92e70dd66d4a>b2ec8034e4f666dd42db739795131f594588ac04', '0fdf66abd99ba484de3b0a548e5056ad4ded598d>a5c61fa6c13242645e0671c45c9e7bd2df9e0fa3', '2b80f65e936e58979de232164026543edb2a79e8>8f01119d68d6a980ec1608e905be6e4f58cb328a', '2bb2505c500ea1382402cd8bf423a8a8715e1f0c>7e98ff7d7eddadc7f32a776a66585475e6d236f4', '672e74fab235de7e680d04b97a272442c39be81a>46f639a94c571af887b3cf5b4f7283bc7db2237a', '95671b460641dcc9f3005b9da4205f584b78f7cc>None', '77cc5c7417526334a60494acd658dcbf377cae1d>ced7e3c1f9c912dca5751664c86a7587b58b0854', '9efebeada238948c156bb066fab1b2bc174f2f29>0230905979a5e3fdb60e74bd505e79ac0746ec56', '49abe8312557893b0b21dd278f705143422e46ac>37971b42d771d3cfd0efcbf81172464f8fd07ec3', '0a9bde599ce0b68dd0ca3d41fe1e328e5c2c8eb3>12df8d0e64a0a5dc209195e9f92b16a7cb3445f8', 'd286db5e1f697245f7d89f21991a16dd1206f728>65445a8c6af6d1eb664f171ffa960fe0a5f6b9d4', 'aab326884c65b09274891f94f71d3cb620346f87>76c45f67dcb8a9299c0a191cf611d551a8148921', 'd5c3093d68614d83785b520a087b379e8334a075>46c0660db9a3bd806ae697b0220476df8dab57c5']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "background_P: 0.6590, background_R: 0.8410, background_F1: 0.7390, method_P: 0.5930, method_R: 0.4232, method_F1: 0.4939, result_P: 0.4412, result_R: 0.1546, result_F1: 0.2290, average_F1: 0.4873, aux-sec--introduction_P: 0.3952, aux-sec--introduction_R: 0.8408, aux-sec--introduction_F1: 0.5377, aux-sec--conclusion_P: 0.4211, aux-sec--conclusion_R: 0.0444, aux-sec--conclusion_F1: 0.0804, aux-sec--experiments_P: 0.2692, aux-sec--experiments_R: 0.0526, aux-sec--experiments_F1: 0.0881, aux-sec--method_P: 0.4286, aux-sec--method_R: 0.0438, aux-sec--method_F1: 0.0795, aux-sec--related work_P: 0.0225, aux-sec--related work_R: 0.0385, aux-sec--related work_F1: 0.0284, aux-sec--average_F1: 0.1628, aux-worth--False_P: 0.8845, aux-worth--False_R: 0.9972, aux-worth--False_F1: 0.9375, aux-worth--True_P: 0.0000, aux-worth--True_R: 0.0000, aux-worth--True_F1: 0.0000, aux-worth--average_F1: 0.4687, loss: 0.9358 ||:   1%|          | 51/5714 [01:08<2:06:15,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation_text': {'elmo': tensor([[[259,  80, 117,  ..., 261, 261, 261],\n",
      "         [259, 116, 117,  ..., 261, 261, 261],\n",
      "         [259, 106, 111,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259, 102, 121,  ..., 261, 261, 261],\n",
      "         [259,  46, 260,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  74, 111,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         [259, 115, 102,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[259,  78, 112,  ..., 261, 261, 261],\n",
      "         [259, 102, 111,  ..., 261, 261, 261],\n",
      "         [259, 103, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259, 227, 129,  ..., 261, 261, 261],\n",
      "         [259,  98, 260,  ..., 261, 261, 261],\n",
      "         [259, 105, 106,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[259,  73, 112,  ..., 261, 261, 261],\n",
      "         [259,  45, 260,  ..., 261, 261, 261],\n",
      "         [259,  68,  87,  ..., 261, 261, 261],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], device='cuda:0'), 'tokens': tensor([[  813,    49,   974,  ...,     0,     0,     0],\n",
      "        [   35,  1105,    12,  ...,     0,     0,     0],\n",
      "        [   41,    15,   184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [14403,   514,  2182,  ...,     0,     0,     0],\n",
      "        [   35,    15,   114,  ...,     0,     0,     0],\n",
      "        [  152,     2,  7160,  ...,     0,     0,     0]], device='cuda:0')}, 'labels': tensor([0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'), 'year_diff': tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]], device='cuda:0'), 'citing_paper_id': ['acf4f8e5546446508c0f22bd5e386abb1e91426b', 'dfdeea8ce2e3ef25084c297a09027e9d2bb1491e', 'bc09324695e21a5c6c2f77b81bb8b7d0c2e58e85', '313014452115e7d12c257ae017f98c271704e1cd', '7c3ec8affe80beb015f6355faad57799bf206459', '1ed8042c32b484573035db874ee8db00b77ba326', 'ab6665d32ada3143ffe4985e4d918ec7abfa8a52', '1edc7af9eaa7fe9da79f0605652cfd4443a0cad4', '64b2069cf07d668f4783f80563084db3731b0b13', 'a5c4f62837e32674059921a8d7e528da5f48ef57', 'e2010a4da5383bf702241481447e9c2dd1c57bb5', 'f8aea2f05f28ca6d45924decc3886908eebe50a8', '4e5f84bfa0d127307a43fe99f68167052de382a2', '7cbf19a0ee49cca394f2688d0f9dfb9fb656ce74', '9462acef826a6b495fe8fb281660ee4418bb840e', '1cb10d6d52502084cb4d8e00111d0ed8955b98ac'], 'cited_paper_id': ['09310473ea701efa2a538e2aa1a5c1d000075be3', 'aa53d8ec6cbe937cec842ce1f02853895ba56c3f', '5eb143b29f153d9c2bb042793094af6a029af21c', 'bcd879be69bd36cbf80b5b7c4f551d042c1b045c', '3005dabe03d5b8c434f102b821349c2a7c23c5dc', 'f08f08fab4db474ed6d556b908622d95afa2704f', '3081f5cf281cc86470f0ac36c73de029cbc4ea35', '34be3ccc2ba9343126638a5df3f7dea6e42fe9a4', 'e4cb35c9b23af4f9e42b95b111c5b3aa03dc5753', '0f8dd4f27c07b81495b92e58ff1f8ac909a4d594', 'cf6401ae06ab9f566ef5b7f8c5be97ddef7f4f4a', '410e4b3334e9ef76ff29d49f178d23895a908501', '24858dbe8234645ff9b453afaf7335cf492ce4b5', '22699ffcc2d091f53dea61d5193424f538459e0a', '21aaceb3fc27e8cc831e25191d967daa0d8962bf', '7d32e3cb0dbcf2ea9e82747629d6ed929fcb94f3'], 'citation_excerpt_index': [4, 10, 6, 0, 0, 11, 4, 0, 0, 0, 1, 2, 0, 1, 11, 2], 'citation_id': ['acf4f8e5546446508c0f22bd5e386abb1e91426b>09310473ea701efa2a538e2aa1a5c1d000075be3', 'dfdeea8ce2e3ef25084c297a09027e9d2bb1491e>aa53d8ec6cbe937cec842ce1f02853895ba56c3f', 'bc09324695e21a5c6c2f77b81bb8b7d0c2e58e85>5eb143b29f153d9c2bb042793094af6a029af21c', '313014452115e7d12c257ae017f98c271704e1cd>bcd879be69bd36cbf80b5b7c4f551d042c1b045c', '7c3ec8affe80beb015f6355faad57799bf206459>3005dabe03d5b8c434f102b821349c2a7c23c5dc', '1ed8042c32b484573035db874ee8db00b77ba326>f08f08fab4db474ed6d556b908622d95afa2704f', 'ab6665d32ada3143ffe4985e4d918ec7abfa8a52>3081f5cf281cc86470f0ac36c73de029cbc4ea35', '1edc7af9eaa7fe9da79f0605652cfd4443a0cad4>34be3ccc2ba9343126638a5df3f7dea6e42fe9a4', '64b2069cf07d668f4783f80563084db3731b0b13>e4cb35c9b23af4f9e42b95b111c5b3aa03dc5753', 'a5c4f62837e32674059921a8d7e528da5f48ef57>0f8dd4f27c07b81495b92e58ff1f8ac909a4d594', 'e2010a4da5383bf702241481447e9c2dd1c57bb5>cf6401ae06ab9f566ef5b7f8c5be97ddef7f4f4a', 'f8aea2f05f28ca6d45924decc3886908eebe50a8>410e4b3334e9ef76ff29d49f178d23895a908501', '4e5f84bfa0d127307a43fe99f68167052de382a2>24858dbe8234645ff9b453afaf7335cf492ce4b5', '7cbf19a0ee49cca394f2688d0f9dfb9fb656ce74>22699ffcc2d091f53dea61d5193424f538459e0a', '9462acef826a6b495fe8fb281660ee4418bb840e>21aaceb3fc27e8cc831e25191d967daa0d8962bf', '1cb10d6d52502084cb4d8e00111d0ed8955b98ac>7d32e3cb0dbcf2ea9e82747629d6ed929fcb94f3']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "03/30/2024 11:39:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'type': 'embedding', 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'embedding_dim': 100, 'trainable': 'false'}, 'elmo': {'type': 'elmo_token_embedder', 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5', 'do_layer_norm': 'true', 'dropout': 0.5}} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:40:58 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'type': 'embedding', 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'embedding_dim': 100, 'trainable': 'false'}, 'elmo': {'type': 'elmo_token_embedder', 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5', 'do_layer_norm': 'true', 'dropout': 0.5}} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'dataset_reader_aux2': {'type': 'scicite_cite_worthiness_data_reader', 'with_elmo': 'true'}, 'trainer': {'cuda_device': 0, 'grad_clipping': 5, 'num_epochs': 10, 'optimizer': {'rho': 0.95, 'type': 'adadelta'}, 'patience': 4, 'validation_metric': '+average_F1'}, 'train_data_path_aux2': 'scicite_data/scaffolds/cite-worthiness-scaffold-train.jsonl', 'random_seed': '21016', 'train_data_path_aux': 'scicite_data/scaffolds/sections-scaffold-train.jsonl', 'dataset_reader_aux': {'type': 'scicite_section_title_data_reader', 'with_elmo': 'true'}, 'iterator': {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'}, 'numpy_seed': 5000, 'iterator_aux': {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'}, 'train_data_path': 'scicite_data/train.jsonl', 'mixing_ratio': '0.05', 'dataset_reader': {'multilabel': 'false', 'type': 'scicite_datasetreader', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'}, 'mixing_ratio2': '0.05', 'iterator_aux2': {'batch_size': 16, 'sorting_keys': [['citation_text', 'num_tokens']], 'type': 'bucket'}, 'pytorch_seed': 8000, 'validation_data_path': 'scicite_data/dev.jsonl', 'model': {'citation_text_encoder': {'bidirectional': True, 'dropout': 0.3, 'hidden_size': 100, 'input_size': 1124, 'num_layers': 2, 'type': 'gru'}, 'classifier_feedforward': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 3], 'input_dim': 200, 'num_layers': 2}, 'classifier_feedforward_2': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 5], 'input_dim': 200, 'num_layers': 2}, 'classifier_feedforward_3': {'activations': ['linear', 'linear'], 'dropout': [0, 0], 'hidden_dims': [20, 2], 'input_dim': 200, 'num_layers': 2}, 'data_format': 'scicite_flat_jsonlines', 'elmo_text_field_embedder': {'elmo': {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'}, 'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}}, 'lexicon_embedder': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'vocab_namespace': 'lexicon_ids'}, 'multilabel': 'false', 'report_auxiliary_metrics': 'true', 'text_field_embedder': {'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}}, 'type': 'scaffold_bilstm_attention_classifier', 'use_lexicon_features': 'false', 'use_sparse_lexicon_features': 'false', 'with_elmo': 'true'}, 'test_data_path': 'scicite_data/test.jsonl', 'evaluate_aux_on_test': 'true', 'evaluate_on_test': 'true'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.params -   type = basic\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.params -   embedder_to_indexer_map = None\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.params -   allow_unmatched_keys = False\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.params -   token_embedders = None\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'type': 'scicite_cite_worthiness_data_reader', 'with_elmo': 'true'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:41:22 - INFO - allennlp.common.params -   dataset_reader_aux2.type = scicite_cite_worthiness_data_reader\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'elmo': {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'}, 'tokens': {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'}} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.type = basic\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.embedder_to_indexer_map = None\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.allow_unmatched_keys = False\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.token_embedders = None\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': 'true', 'dropout': 0.5, 'options_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:41:46 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.type = elmo_token_embedder\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.options_file = https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.weight_file = https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.requires_grad = False\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.do_layer_norm = true\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.dropout = 0.5\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.namespace_to_cache = None\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.projection_dim = None\n",
      "03/30/2024 11:41:48 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.elmo.scalar_mix_parameters = None\n",
      "03/30/2024 11:41:48 - INFO - allennlp.modules.elmo -   Initializing ELMo\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 100, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz', 'trainable': 'false', 'type': 'embedding'} and extras {'vocab': <scicite.training.vocabulary_multitask.VocabularyMultitask object at 0x7f43da64f6a0>}\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.type = embedding\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.num_embeddings = None\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.vocab_namespace = tokens\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.embedding_dim = 100\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.projection_dim = None\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.trainable = false\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.padding_index = None\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.max_norm = None\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.norm_type = 2.0\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.scale_grad_by_freq = False\n",
      "03/30/2024 11:42:10 - INFO - allennlp.common.params -   model.elmo_text_field_embedder.tokens.sparse = False\n",
      "03/30/2024 11:42:10 - INFO - allennlp.modules.token_embedders.embedding -   Reading pretrained embeddings from file\n",
      "0it [00:00, ?it/s]\n",
      "400000it [00:02, 186781.10it/s]\n",
      "\n",
      "03/30/2024 11:42:13 - INFO - allennlp.modules.token_embedders.embedding -   Initializing pre-trained embedding layer\n",
      "03/30/2024 11:42:14 - INFO - allennlp.modules.token_embedders.embedding -   Pretrained embeddings were found for 38133 out of 142711 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_model(params, serialization_dir, file_friendly_logging, recover)\n",
    "\"\"\"\n",
    "Trains the model specified in the given :class:`Params` object, using the data and training\n",
    "parameters also specified in that object, and saves the results in ``serialization_dir``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "params : ``Params``\n",
    "    A parameter object specifying an AllenNLP Experiment.\n",
    "serialization_dir : ``str``\n",
    "    The directory in which to save results and logs.\n",
    "file_friendly_logging : ``bool``, optional (default=False)\n",
    "    If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n",
    "    down tqdm's output to only once every 10 seconds.\n",
    "recover : ``bool``, optional (default=False)\n",
    "    If ``True``, we will try to recover a training run from an existing serialization\n",
    "    directory.  This is only intended for use when something actually crashed during the middle\n",
    "    of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "best_model: ``Model``\n",
    "    The model with the best epoch weights.\n",
    "\"\"\"\n",
    "prepare_environment(params)\n",
    "\n",
    "create_serialization_dir(params, serialization_dir, recover)\n",
    "prepare_global_logging(serialization_dir, file_friendly_logging)\n",
    "\n",
    "check_for_gpu(params.get('trainer').get('cuda_device', -1))\n",
    "\n",
    "params.to_file(os.path.join(serialization_dir, CONFIG_NAME))\n",
    "\n",
    "all_datasets, all_datasets_aux, all_datasets_aux2 = datasets_from_params(params)\n",
    "# print(all_datasets)\n",
    "datasets_for_vocab_creation = set(params.pop(\"datasets_for_vocab_creation\", all_datasets))\n",
    "datasets_for_vocab_creation_aux = set(params.pop(\"auxiliary_datasets_for_vocab_creation\", all_datasets_aux))\n",
    "datasets_for_vocab_creation_aux2 = set(params.pop(\"auxiliary_datasets_for_vocab_creation_2\", all_datasets_aux2))\n",
    "\n",
    "\n",
    "mixing_ratio = params.pop_float(\"mixing_ratio\")\n",
    "mixing_ratio2 = params.pop_float(\"mixing_ratio2\")\n",
    "\n",
    "cutoff_epoch = params.pop(\"cutoff_epoch\", -1)\n",
    "\n",
    "for dataset in datasets_for_vocab_creation:\n",
    "    if dataset not in all_datasets:\n",
    "        raise ConfigurationError(f\"invalid 'dataset_for_vocab_creation' {dataset}\")\n",
    "\n",
    "logger.info(\"From dataset instances, %s will be considered for vocabulary creation.\",\n",
    "            \", \".join(datasets_for_vocab_creation))\n",
    "vocab_instances_aux = [\n",
    "    instance for key, dataset in all_datasets_aux.items()\n",
    "    for instance in dataset\n",
    "    if key in datasets_for_vocab_creation_aux\n",
    "]\n",
    "vocab_instances_aux.extend([\n",
    "    instance for key, dataset in all_datasets_aux2.items()\n",
    "    for instance in dataset\n",
    "    if key in datasets_for_vocab_creation_aux2\n",
    "])\n",
    "vocab = VocabularyMultitask.from_params(\n",
    "        params.pop(\"vocabulary\", {}),\n",
    "        (instance for key, dataset in all_datasets.items()\n",
    "         for instance in dataset\n",
    "         if key in datasets_for_vocab_creation),\n",
    "        instances_aux=vocab_instances_aux\n",
    ")\n",
    "model = Model.from_params(vocab=vocab, params=params.pop('model'))\n",
    "\n",
    "# Initializing the model can have side effect of expanding the vocabulary\n",
    "vocab.save_to_files(os.path.join(serialization_dir, \"vocabulary\"))\n",
    "\n",
    "iterator = DataIterator.from_params(params.pop(\"iterator\"))\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "iterator_aux = DataIterator.from_params(params.pop(\"iterator_aux\"))\n",
    "iterator_aux.index_with(vocab)\n",
    "\n",
    "iterator_aux2 = DataIterator.from_params(params.pop(\"iterator_aux2\"))\n",
    "iterator_aux2.index_with(vocab)\n",
    "\n",
    "validation_iterator_params = params.pop(\"validation_iterator\", None)\n",
    "if validation_iterator_params:\n",
    "    validation_iterator = DataIterator.from_params(validation_iterator_params)\n",
    "    validation_iterator.index_with(vocab)\n",
    "else:\n",
    "    validation_iterator = None\n",
    "\n",
    "# TODO: if validation in multi-task need to add validation iterator as above\n",
    "\n",
    "train_data = all_datasets.get('train')\n",
    "validation_data = all_datasets.get('validation')\n",
    "test_data = all_datasets.get('test')\n",
    "\n",
    "train_data_aux = all_datasets_aux.get('train_aux')\n",
    "validation_data_aux = all_datasets_aux.get('validation_aux')\n",
    "test_data_aux = all_datasets_aux.get('test_aux')\n",
    "\n",
    "train_data_aux2 = all_datasets_aux2.get('train_aux')\n",
    "validation_data_aux2 = all_datasets_aux2.get('validation_aux')\n",
    "test_data_aux2 = all_datasets_aux2.get('test_aux')\n",
    "\n",
    "trainer_params = params.pop(\"trainer\")\n",
    "no_grad_regexes = trainer_params.pop(\"no_grad\", ())\n",
    "for name, parameter in model.named_parameters():\n",
    "    if any(re.search(regex, name) for regex in no_grad_regexes):\n",
    "        parameter.requires_grad_(False)\n",
    "\n",
    "frozen_parameter_names, tunable_parameter_names = \\\n",
    "               get_frozen_and_tunable_parameter_names(model)\n",
    "logger.info(\"Following parameters are Frozen  (without gradient):\")\n",
    "for name in frozen_parameter_names:\n",
    "    logger.info(name)\n",
    "logger.info(\"Following parameters are Tunable (with gradient):\")\n",
    "for name in tunable_parameter_names:\n",
    "    logger.info(name)\n",
    "\n",
    "trainer = MultiTaskTrainer2.from_params(model=model,\n",
    "                                        serialization_dir=serialization_dir,\n",
    "                                        iterator=iterator,\n",
    "                                        iterator_aux=iterator_aux,\n",
    "                                        iterator_aux2=iterator_aux2,\n",
    "                                        train_data=train_data,\n",
    "                                        train_data_aux=train_data_aux,\n",
    "                                        train_data_aux2=train_data_aux2,\n",
    "                                        mixing_ratio=mixing_ratio,\n",
    "                                        mixing_ratio2=mixing_ratio2,\n",
    "                                        cutoff_epoch=cutoff_epoch,\n",
    "                                        validation_data_aux=validation_data_aux,\n",
    "                                        validation_data_aux2=validation_data_aux2,\n",
    "                                        validation_data=validation_data,\n",
    "                                        params=trainer_params,\n",
    "                                        validation_iterator=validation_iterator)\n",
    "# print(trainer._cuda_devices[0])\n",
    "evaluate_on_test = params.pop_bool(\"evaluate_on_test\", False)\n",
    "evaluate_aux_on_test = params.pop_bool(\"evaluate_aux_on_test\", False)\n",
    "params.assert_empty('base train command')\n",
    "\n",
    "try:\n",
    "    metrics = trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    # if we have completed an epoch, try to create a model archive.\n",
    "    if os.path.exists(os.path.join(serialization_dir, _DEFAULT_WEIGHTS)):\n",
    "        logging.info(\"Training interrupted by the user. Attempting to create \"\n",
    "                     \"a model archive using the current best epoch weights.\")\n",
    "        archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n",
    "    raise\n",
    "\n",
    "# Now tar up results\n",
    "archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n",
    "\n",
    "logger.info(\"Loading the best epoch weights.\")\n",
    "best_model_state_path = os.path.join(serialization_dir, 'best.th')\n",
    "best_model_state = torch.load(best_model_state_path)\n",
    "best_model = model\n",
    "best_model.load_state_dict(best_model_state)\n",
    "\n",
    "if test_data and evaluate_on_test:\n",
    "    logger.info(\"The model will be evaluated using the best epoch weights.\")\n",
    "    test_metrics = evaluate(\n",
    "            best_model, test_data, validation_iterator or iterator,\n",
    "            cuda_device=trainer._cuda_devices[0] # pylint: disable=protected-access\n",
    "    )\n",
    "    for key, value in test_metrics.items():\n",
    "        metrics[\"test_\" + key] = value\n",
    "\n",
    "elif test_data:\n",
    "    logger.info(\"To evaluate on the test set after training, pass the \"\n",
    "                \"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\")\n",
    "\n",
    "if test_data_aux and evaluate_aux_on_test:\n",
    "    # for instance in test_data_aux:\n",
    "    #     instance.index_fields(vocab)\n",
    "    # for instance in test_data_aux2:\n",
    "    #     instance.index_fields(vocab)\n",
    "    test_metrics_aux = evaluate(best_model, test_data_aux, iterator_aux,\n",
    "                                cuda_device=trainer._cuda_devices[0])  # pylint: disable=protected-access\n",
    "    test_metrics_aux2 = evaluate(best_model, test_data_aux2, iterator_aux2,\n",
    "                                 cuda_device=trainer._cuda_devices[0])  # pylint: disable=protected-access\n",
    "\n",
    "    for key, value in test_metrics_aux.items():\n",
    "        metrics[\"test_aux_\" + key] = value\n",
    "    for key, value in test_metrics_aux2.items():\n",
    "        metrics[\"test_aux2_\" + key] = value\n",
    "\n",
    "elif test_data_aux:\n",
    "    logger.info(\"To evaluate on the auxiliary test set after training, pass the \"\n",
    "                \"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\")\n",
    "\n",
    "dump_metrics(os.path.join(serialization_dir, \"metrics.json\"), metrics, log=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac296ebc-f37b-46dd-a12e-789913357946",
   "metadata": {},
   "source": [
    "### Datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9dacd45-6634-4603-9376-8ff8544be1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params.from_file('experiment_configs/custom_config.json', \"\")\n",
    "data = datasets_from_params(params)\n",
    "# from scicite_datasetreader text_to_instance() -> Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6eea471f-b389-4ace-93c1-f7b9a27bc837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation_text': <allennlp.data.fields.text_field.TextField at 0x7f43f9581dd8>,\n",
       " 'labels': <allennlp.data.fields.label_field.LabelField at 0x7f4766e9fda0>,\n",
       " 'year_diff': <allennlp.data.fields.array_field.ArrayField at 0x7f4766e9f128>,\n",
       " 'citing_paper_id': <allennlp.data.fields.metadata_field.MetadataField at 0x7f4766e9f438>,\n",
       " 'cited_paper_id': <allennlp.data.fields.metadata_field.MetadataField at 0x7f4766e9f8d0>,\n",
       " 'citation_excerpt_index': <allennlp.data.fields.metadata_field.MetadataField at 0x7f4766e9f6d8>,\n",
       " 'citation_id': <allennlp.data.fields.metadata_field.MetadataField at 0x7f43ea086908>}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['train'][0].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2715604f-5a13-4b62-96f1-dcd80ff71f37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In,\n",
       " the,\n",
       " study,\n",
       " by,\n",
       " Hickey,\n",
       " et,\n",
       " al,\n",
       " .,\n",
       " (,\n",
       " 2012,\n",
       " ),\n",
       " ,,\n",
       " spikes,\n",
       " were,\n",
       " sampled,\n",
       " from,\n",
       " the,\n",
       " field,\n",
       " at,\n",
       " the,\n",
       " point,\n",
       " of,\n",
       " physiological,\n",
       " robinson,\n",
       " et,\n",
       " al,\n",
       " .,\n",
       " :,\n",
       " genomic,\n",
       " regions,\n",
       " influencing,\n",
       " root,\n",
       " traits,\n",
       " in,\n",
       " barley,\n",
       " 11,\n",
       " of,\n",
       " 13,\n",
       " maturity,\n",
       " ,,\n",
       " dried,\n",
       " ,,\n",
       " grain,\n",
       " threshed,\n",
       " by,\n",
       " hand,\n",
       " ,,\n",
       " and,\n",
       " stored,\n",
       " at,\n",
       " 20C,\n",
       " to,\n",
       " preserve,\n",
       " grain,\n",
       " dormancy,\n",
       " before,\n",
       " germination,\n",
       " testing,\n",
       " .]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['train'][1].fields['citation_text'].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "231a6337-7afe-4271-90fc-ccc6197bbf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'background'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['train'][0].fields['labels'].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15ffded2-6a0f-41e4-a272-f5cb86535262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pearson, s, rs, may, ,]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_instances_aux[0].fields['citation_text'].tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a9a93e5-d6b5-4f3a-ae2a-cb257c36ce10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab._token_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4013d645-b4b8-4a22-b2fd-91d461a5d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = DataIterator.from_params(params.pop(\"iterator\"))\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "iterator_aux = DataIterator.from_params(params.pop(\"iterator_aux\"))\n",
    "iterator_aux.index_with(vocab)\n",
    "\n",
    "iterator_aux2 = DataIterator.from_params(params.pop(\"iterator_aux2\"))\n",
    "iterator_aux2.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b7772b9-532a-4827-9165-d66b60a46d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<allennlp.data.iterators.bucket_iterator.BucketIterator at 0x7f43dd1c7668>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1048237f-4ef0-447d-98cb-2ddc8f7274d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data[0].fields['citation_text'].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e19caa3-dc96-4f74-b4db-84ee7c053ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_shuffle = True\n",
    "train_generator = iterator(train_data,\n",
    "                                 num_epochs=1,\n",
    "                                 shuffle=_shuffle)\n",
    "\n",
    "train_generator_aux = iterator_aux(train_data_aux,\n",
    "                                         num_epochs=1,\n",
    "                                         shuffle=_shuffle)\n",
    "train_generator_aux2 = iterator_aux2(train_data_aux2,\n",
    "                                      num_epochs=1,\n",
    "                                          shuffle=_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dc401b9-3d89-4a7c-8c53-629cdaeb7034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataIterator.__call__ at 0x7f479239a8e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8882ab83-dcd0-4a70-ae82-f5de1e680045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_training_batches=1\n",
    "train_generator_tqdm = Tqdm.tqdm(train_generator,\n",
    "                                 total=num_training_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25dc9b3b-ce7c-4467-be85-163fbf399485",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, batch_aux, batch_aux2 in zip(train_generator_tqdm, train_generator_aux, train_generator_aux2):\n",
    "    print(batch, batch_aux, batch_aux2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c4acc90-7bb8-4977-bb07-73b7ad605d6b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elmo': tensor([[[259,  85, 105,  ..., 261, 261, 261],\n",
       "          [259, 101, 102,  ..., 261, 261, 261],\n",
       "          [259, 112, 103,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  71, 118,  ..., 261, 261, 261],\n",
       "          [259,  45, 260,  ..., 261, 261, 261],\n",
       "          [259, 100, 112,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  78, 112,  ..., 261, 261, 261],\n",
       "          [259,  45, 260,  ..., 261, 261, 261],\n",
       "          [259,  98, 109,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[259,  88, 106,  ..., 261, 261, 261],\n",
       "          [259, 117, 105,  ..., 261, 261, 261],\n",
       "          [259,  98, 106,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259, 227, 129,  ..., 261, 261, 261],\n",
       "          [259, 102, 119,  ..., 261, 261, 261],\n",
       "          [259, 106, 103,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259, 227, 129,  ..., 261, 261, 261],\n",
       "          [259, 115, 102,  ..., 261, 261, 261],\n",
       "          [259, 106, 111,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]]]),\n",
       " 'tokens': tensor([[   26,   197,     6,  2608,   109,    18,  1414,     6,   585,  4444,\n",
       "              6,   561,     9, 11023,   162,     2,    22,    97,    22,    60,\n",
       "           5919,   112,     4,   291,   208,     2,    30,     4,   370,    10,\n",
       "           6244,     4,  1635,    10,  9477,     6,   763,   509,   799,     9,\n",
       "           7449,  1182,    14,   174,    21,    56,    20,    18,    15,   605,\n",
       "              6,   731,   243,     3,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  546,     2,  1704,    17,     4, 19697,  3675,    90,  5720,  7716,\n",
       "            263,  7275,     9,  2728,    95,  7427,    11,  2738,   530,     9,\n",
       "              4,  2213,   103,     2,    50,    16,  3301,    17,    39,  1468,\n",
       "           7716,   258, 12874,     9,     4,  4835,     2,     5,   278,   215,\n",
       "             50,    16,    42,   596,  1505,   488,   932,     9,   197,     8,\n",
       "           5716,    12,    13,     3,     2,    64,     7,     3,     0,     0,\n",
       "              0,     0],\n",
       "         [  640,     2,   436,  8162,   400,    36,    99,    10,    27,     4,\n",
       "            104,   921,   884,   989,    10,     4,  7400,   456,     6,  3274,\n",
       "              2,    19,  7432,   175,     9,     4,  7219,   989,     8,  5004,\n",
       "             12,    13,     3,    62,     7,     2,     4,  2547,   175,    30,\n",
       "             46,    33,   229,     9,    15,  4188,  1163,  2412,  2034,     8,\n",
       "           5461,    12,    13,     3,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [   35, 37070,  5364,  4256, 37071,  5364,  1949,    15,  7852,     2,\n",
       "            967,  1280,     3,   265,  1238,    25,   192,    11,  6893,  1490,\n",
       "            825,     3,   785,  1238,    25,  1116,   196,  7307,  1490,   825,\n",
       "              3, 12327,  1490,    85,    16,    57,  1741,    68,  9412,     2,\n",
       "            178,  1107,   329,   111,    45,    24,    42,  6112,     9,    15,\n",
       "          26656,  2515,     9,  8538,     8,  9189,    12,    13,     3,   131,\n",
       "              7,     3],\n",
       "         [  640,     2,     4,  2272,   511,    17,     4,   135,  1244,    50,\n",
       "            312,    10,  8311,    15,   149,  1480,  4784,    58,   717,     5,\n",
       "          15603,     8,  4088,    12,    13,     3,     2,   132,     2,  1250,\n",
       "          10690,     7,     2,     5,   736,     2, 10082,  2891,    85,    16,\n",
       "            280,  1100, 10256,     8,  8293,    12,    13,     3,     2,    64,\n",
       "             14,  4017,    12,    13,     3,     2,   123,    14,  4088,    35,\n",
       "              0,     0],\n",
       "         [   72,    41,   251,    10,    63,  9471,    11,   822,     5,  5508,\n",
       "             11,  3198,  1365,     2,   127,     9, 25686,    16,    46,  1035,\n",
       "             23, 22652,  5275,  2087,     2,    32,  8404,     5,  9195,     8,\n",
       "             67,     7,  1574,    22,     4,   118,     6, 10676,  7317,   586,\n",
       "              5,     4,   574,   118,     6,  2141,  1093,    44,   138,   586,\n",
       "              2,   590,     6,    35,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [28776,     8,   126,  3139,     7,     6,     4,   121,  4866,    36,\n",
       "           1157,    28,     4,  2439,    44,   273,   825,   173,  5229,     2,\n",
       "           1064,     9,   128,    73, 13335,     9,  6202,    11, 11673,  6448,\n",
       "              8,  5355,     7,     8,  5273,    12,    13,     3,     2,    62,\n",
       "              7,    18,   143,  1033,     2,     5,   215,  5368,    10, 20369,\n",
       "            339,  1429,    11, 12183,     3,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  695,    24,  3097,     9,  2172,    51,    22,  3950,   938,    18,\n",
       "           1994,  3949,     8,  5713,    12,    13,     3,     2,   515,    14,\n",
       "           3154,    12,    13,     3,     2,  5836,    14,  5001,    12,    13,\n",
       "              3,     2,   515,     7,     2,     5, 10980,     4,   428,   632,\n",
       "             23,  2030,   938,    10,    15,   313,   187,     8,   983,     7,\n",
       "              8,  9839,    12,    13,     3,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [   35,    57,  1081, 15206,     6,  4563,   250,  1984,     4,  1128,\n",
       "            228,   993,     8,  9434,   654,    14, 15207,    12,    13,     3,\n",
       "            439,    14, 19001,    12,    13,     3,   101,    14,  5823,    12,\n",
       "             13,     3,    74,     7,     2,     5, 14498,   110,     6,     4,\n",
       "            629,  4523,   182,   619,  4654,     4,  1128,   228,    18,  8038,\n",
       "            987,     8,  2114,    37,  4655,   142,     7,     3,     0,     0,\n",
       "              0,     0],\n",
       "         [  155,     2,   120,   944,     4,   188,     6,   791,    11, 30758,\n",
       "           1281,    11,  5837,    15,    84,   135,    31,    45,   402,    39,\n",
       "           2330,    38,    15,  1682,    11,   498,     6,   269,    68,   323,\n",
       "            757,     8,  6575,     2, 23585,     2, 25751,     2,  6926,    37,\n",
       "           4824,     2,   303,    14,  6926,     2, 30759,    37,  3048,     2,\n",
       "            266,     7,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [   26,   884,  1230,  1958,   121,   383, 19746,    31,  2714,     5,\n",
       "           2216,    22,   122,   100,     8,  5293,    12,    13,     3,    62,\n",
       "              7,     2,    49,   549,  3922,     6,   256,  2810,     2,   143,\n",
       "           3922,     6,   177,  2810,     8, 19747,     2, 11199,     7,     2,\n",
       "              5,     4, 19748,   171,  4220,  8232,     8,  5859,  4627, 19141,\n",
       "              2, 28798,     2,  4167,     7,     3,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [   35,    23,    32, 39913, 39914,     4, 12601,  1401,     9,   240,\n",
       "             10,  1922,    16,   341,    10,  2013,   277,     9,   185,  7150,\n",
       "              8, 39915,    12,    13,     3,     2,   101,    14, 37445,    12,\n",
       "             13,     3,     2,    88,     2,    62,     7,    17,   184,    27,\n",
       "          13622,    23,   786,    19,    55,   375,  1510,     9,   946,  4268,\n",
       "              8, 39916,    12,    13,     3,     2,    74,    14,    35,     0,\n",
       "              0,     0],\n",
       "         [   93,  1212,    17,     4,   545,  4987,     6,  4903, 12064,     8,\n",
       "          19738,     7,     5,  4505,  8086,     8, 19739,     7,    36,  2333,\n",
       "           1060,    22,   122,    79,     5,  1173,    10,   190,    28,   210,\n",
       "           4505,   608,  2881,  5737,    19,   210,  4903,  5242,     8,  8019,\n",
       "             12,    13,     3,     2,    78,    14,  7924,    12,    13,     3,\n",
       "              2,    80,     7,     3,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [ 1050,     4,  1863,     6,  2948,    10,     4,   348,     6,     4,\n",
       "            356,   770,     6,     4,   992,     6,  7795,     9, 20298,     2,\n",
       "             15,   553,    31,   581,     9,     4,  6059,    81,  3959,  4759,\n",
       "             49,     4,   347,     6, 26824,  2664, 26825,  8974,     2,    15,\n",
       "           9323,     6,     4, 20299,  3883,     8,  4977,    12,    13,     3,\n",
       "             88,    14,  9332,    12,    13,     3,    83,     7,     3,     0,\n",
       "              0,     0],\n",
       "         [   35,   278,   216,     4,   220,   858,    16,    57,  2884,     2,\n",
       "              4,   405,     6,     4,  6603,  2000,  8950,    16,    23,   168,\n",
       "            638,  3819,    14,   108,   320,    16,   258,   497,     2,   108,\n",
       "            966,    24,  7779,     5,  6056,     2,     5,     4,  5313,    28,\n",
       "            337,  2066,   385,     5,   160,  2965,  2906, 19529,     8,  4158,\n",
       "             12,    13,     3,   106,     7,     3,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [   35,    52,     9,     4,   670,     6,     4,   326,  3895,  2552,\n",
       "              4,  6788,  1131,  1585,    18,     4,   113,   153,     6,  3914,\n",
       "              5,   108,  5351,   371,   484,     4,    84, 17858,   530,     9,\n",
       "             39, 20960,     8,  5683,    12,    13,     3,    78,    14,  9303,\n",
       "             37, 16826,    83,    14,  9414,    83,    14,   791, 15504,    12,\n",
       "             13,     3,    83,     7,     3,     0,     0,     0,     0,     0,\n",
       "              0,     0]])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['citation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ec435d7-1a15-414d-bff4-bea8852dd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dict['prediction'] = labels\n",
    "output_dict = {}\n",
    "citation_text = []\n",
    "for batch_text in batch['citation_text']['tokens']:\n",
    "    citation_text.append([vocab.get_token_from_index(token_id.item()) for token_id in batch_text])\n",
    "# output_dict['citation_text'] = citation_text\n",
    "# output_dict['all_labels'] = [vocab.get_index_to_token_vocabulary(namespace=\"labels\")\n",
    "#                              for _ in range(output_dict['logits'].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ed782dd-7a5c-4a41-a8c5-cbe0343c5bf0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'development',\n",
       "  'of',\n",
       "  'mathematical',\n",
       "  'models',\n",
       "  'for',\n",
       "  'evolution',\n",
       "  'of',\n",
       "  'primary',\n",
       "  'quantities',\n",
       "  'of',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'bioreactor',\n",
       "  'systems',\n",
       "  ',',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'their',\n",
       "  'incorporation',\n",
       "  'into',\n",
       "  'the',\n",
       "  'design',\n",
       "  'process',\n",
       "  ',',\n",
       "  'have',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'to',\n",
       "  'accelerate',\n",
       "  'the',\n",
       "  'path',\n",
       "  'to',\n",
       "  'realization',\n",
       "  'of',\n",
       "  'optimal',\n",
       "  'functional',\n",
       "  'outcomes',\n",
       "  'in',\n",
       "  'engineered',\n",
       "  'tissues',\n",
       "  ';',\n",
       "  'see',\n",
       "  '[',\n",
       "  '1',\n",
       "  ']',\n",
       "  'for',\n",
       "  'a',\n",
       "  'review',\n",
       "  'of',\n",
       "  'modeling',\n",
       "  'approaches',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['Furthermore',\n",
       "  ',',\n",
       "  'considering',\n",
       "  'that',\n",
       "  'the',\n",
       "  '12.4',\n",
       "  'kb',\n",
       "  '3',\n",
       "  'enhancer',\n",
       "  'expresses',\n",
       "  'so',\n",
       "  'uniformly',\n",
       "  'in',\n",
       "  'nearly',\n",
       "  'all',\n",
       "  'Ptf1a',\n",
       "  '-',\n",
       "  'expressing',\n",
       "  'regions',\n",
       "  'in',\n",
       "  'the',\n",
       "  'nervous',\n",
       "  'system',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'surprising',\n",
       "  'that',\n",
       "  'this',\n",
       "  'element',\n",
       "  'expresses',\n",
       "  'very',\n",
       "  'sparsely',\n",
       "  'in',\n",
       "  'the',\n",
       "  'pancreas',\n",
       "  ',',\n",
       "  'and',\n",
       "  'even',\n",
       "  'then',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'active',\n",
       "  'until',\n",
       "  'much',\n",
       "  'later',\n",
       "  'in',\n",
       "  'development',\n",
       "  '(',\n",
       "  'Masui',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2008',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['Moreover',\n",
       "  ',',\n",
       "  'although',\n",
       "  'C57',\n",
       "  'mice',\n",
       "  'were',\n",
       "  'shown',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'most',\n",
       "  'sensitive',\n",
       "  'mouse',\n",
       "  'strain',\n",
       "  'to',\n",
       "  'the',\n",
       "  'rewarding',\n",
       "  'properties',\n",
       "  'of',\n",
       "  'morphine',\n",
       "  ',',\n",
       "  'with',\n",
       "  'contrasting',\n",
       "  'effects',\n",
       "  'in',\n",
       "  'the',\n",
       "  'DBA',\n",
       "  'strain',\n",
       "  '(',\n",
       "  'Orsini',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2005',\n",
       "  ')',\n",
       "  ',',\n",
       "  'the',\n",
       "  'opposite',\n",
       "  'effects',\n",
       "  'have',\n",
       "  'also',\n",
       "  'been',\n",
       "  'demonstrated',\n",
       "  'in',\n",
       "  'a',\n",
       "  'conditioned',\n",
       "  'place',\n",
       "  'preference',\n",
       "  'paradigm',\n",
       "  '(',\n",
       "  'Cunningham',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['',\n",
       "  '813',\n",
       "  '',\n",
       "  '82',\n",
       "  '831',\n",
       "  '',\n",
       "  '55',\n",
       "  'a',\n",
       "  'aa',\n",
       "  ',',\n",
       "  'amino',\n",
       "  'acids',\n",
       "  '.',\n",
       "  'b',\n",
       "  'Based',\n",
       "  'on',\n",
       "  'within',\n",
       "  '-',\n",
       "  'vertebrate',\n",
       "  'divergence',\n",
       "  'times',\n",
       "  '.',\n",
       "  'c',\n",
       "  'Based',\n",
       "  'on',\n",
       "  'animal',\n",
       "  '',\n",
       "  'fungus',\n",
       "  'divergence',\n",
       "  'times',\n",
       "  '.',\n",
       "  'invertebrate',\n",
       "  'divergence',\n",
       "  'time',\n",
       "  'is',\n",
       "  'more',\n",
       "  'reliable',\n",
       "  'than',\n",
       "  'theirs',\n",
       "  ',',\n",
       "  'because',\n",
       "  'mitochondrial',\n",
       "  'genes',\n",
       "  'they',\n",
       "  'used',\n",
       "  'are',\n",
       "  'not',\n",
       "  'evolving',\n",
       "  'in',\n",
       "  'a',\n",
       "  'clocklike',\n",
       "  'fashion',\n",
       "  'in',\n",
       "  'vertebrates',\n",
       "  '(',\n",
       "  'Nikoh',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '1997',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['Moreover',\n",
       "  ',',\n",
       "  'the',\n",
       "  'publications',\n",
       "  'suggest',\n",
       "  'that',\n",
       "  'the',\n",
       "  'approach',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'possible',\n",
       "  'to',\n",
       "  'foster',\n",
       "  'a',\n",
       "  '',\n",
       "  'shared',\n",
       "  'responsibility',\n",
       "  'between',\n",
       "  'students',\n",
       "  'and',\n",
       "  'instructors',\n",
       "  '(',\n",
       "  'McLaughlin',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2014',\n",
       "  ',',\n",
       "  'p.',\n",
       "  '242',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  'overall',\n",
       "  ',',\n",
       "  'optimising',\n",
       "  'classroom',\n",
       "  'time',\n",
       "  'is',\n",
       "  'often',\n",
       "  'specifically',\n",
       "  'emphasised',\n",
       "  '(',\n",
       "  'Gannod',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2008',\n",
       "  ';',\n",
       "  'Mason',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2013',\n",
       "  ';',\n",
       "  'McLaughlin',\n",
       "  '',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['2',\n",
       "  'In',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'these',\n",
       "  'spatio',\n",
       "  '-',\n",
       "  'temporal',\n",
       "  'and',\n",
       "  'socio',\n",
       "  '-',\n",
       "  'demographic',\n",
       "  'dynamics',\n",
       "  ',',\n",
       "  'work',\n",
       "  'in',\n",
       "  'GDTs',\n",
       "  'is',\n",
       "  'also',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'teams',\n",
       "  'geographic',\n",
       "  'configuration',\n",
       "  ',',\n",
       "  'which',\n",
       "  'OLeary',\n",
       "  'and',\n",
       "  'Cummings',\n",
       "  '(',\n",
       "  '2007',\n",
       "  ')',\n",
       "  'define',\n",
       "  'as',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'geographically',\n",
       "  'dispersed',\n",
       "  'sites',\n",
       "  'and',\n",
       "  'the',\n",
       "  'relative',\n",
       "  'number',\n",
       "  'of',\n",
       "  'team',\n",
       "  'members',\n",
       "  'at',\n",
       "  'those',\n",
       "  'sites',\n",
       "  ',',\n",
       "  'independent',\n",
       "  'of',\n",
       "  '',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['Aliquots',\n",
       "  '(',\n",
       "  '5',\n",
       "  'mL',\n",
       "  ')',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cell',\n",
       "  'suspension',\n",
       "  'were',\n",
       "  'collected',\n",
       "  'from',\n",
       "  'the',\n",
       "  'mixture',\n",
       "  'at',\n",
       "  'various',\n",
       "  'times',\n",
       "  'after',\n",
       "  'mixing',\n",
       "  ',',\n",
       "  'fixed',\n",
       "  'in',\n",
       "  '4',\n",
       "  '%',\n",
       "  'paraformaldehyde',\n",
       "  'in',\n",
       "  'phosphate',\n",
       "  '-',\n",
       "  'buffered',\n",
       "  'saline',\n",
       "  '(',\n",
       "  'PBS',\n",
       "  ')',\n",
       "  '(',\n",
       "  'Iwatani',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2005',\n",
       "  ')',\n",
       "  'for',\n",
       "  '10',\n",
       "  'min',\n",
       "  ',',\n",
       "  'and',\n",
       "  'then',\n",
       "  'subjected',\n",
       "  'to',\n",
       "  'IIFM',\n",
       "  'without',\n",
       "  'air',\n",
       "  '-',\n",
       "  'drying',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['They',\n",
       "  'are',\n",
       "  'applicable',\n",
       "  'in',\n",
       "  'scenarios',\n",
       "  'such',\n",
       "  'as',\n",
       "  'designing',\n",
       "  'questions',\n",
       "  'for',\n",
       "  'reading',\n",
       "  'comprehension',\n",
       "  '(',\n",
       "  'Du',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2017',\n",
       "  ';',\n",
       "  'Zhou',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2017a',\n",
       "  ';',\n",
       "  'Yuan',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2017',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  'justifying',\n",
       "  'the',\n",
       "  'visual',\n",
       "  'understanding',\n",
       "  'by',\n",
       "  'generating',\n",
       "  'questions',\n",
       "  'to',\n",
       "  'a',\n",
       "  'given',\n",
       "  'image',\n",
       "  '(',\n",
       "  'video',\n",
       "  ')',\n",
       "  '(',\n",
       "  'Mostafazadeh',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'depiction',\n",
       "  'of',\n",
       "  'epidemiological',\n",
       "  'findings',\n",
       "  'supporting',\n",
       "  'the',\n",
       "  'core',\n",
       "  'group',\n",
       "  'hypothesis',\n",
       "  '(',\n",
       "  'Rothenberg',\n",
       "  '1983',\n",
       "  ';',\n",
       "  'Potterat',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '1985',\n",
       "  ';',\n",
       "  'Zenilman',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '1999',\n",
       "  ';',\n",
       "  'Bernstein',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2004',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  'resolves',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'prior',\n",
       "  'ambiguity',\n",
       "  'about',\n",
       "  'what',\n",
       "  'constitutes',\n",
       "  'the',\n",
       "  'core',\n",
       "  'group',\n",
       "  'for',\n",
       "  'STI',\n",
       "  'transmission',\n",
       "  '(',\n",
       "  'Thomas',\n",
       "  '&',\n",
       "  'Tucker',\n",
       "  '1996',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['However',\n",
       "  ',',\n",
       "  'when',\n",
       "  'testing',\n",
       "  'the',\n",
       "  'effect',\n",
       "  'of',\n",
       "  'S',\n",
       "  '-',\n",
       "  'nitroso-',\n",
       "  'L',\n",
       "  '-',\n",
       "  'cysteine',\n",
       "  'a',\n",
       "  'different',\n",
       "  'approach',\n",
       "  'was',\n",
       "  'used',\n",
       "  'since',\n",
       "  'this',\n",
       "  'compound',\n",
       "  'has',\n",
       "  'a',\n",
       "  'half',\n",
       "  '-',\n",
       "  'life',\n",
       "  'of',\n",
       "  'less',\n",
       "  'than',\n",
       "  '30',\n",
       "  's',\n",
       "  '(',\n",
       "  'Myers',\n",
       "  ',',\n",
       "  'Minor',\n",
       "  ',',\n",
       "  'Guerra',\n",
       "  ',',\n",
       "  'Bates',\n",
       "  '&',\n",
       "  'Harrison',\n",
       "  ',',\n",
       "  '1990',\n",
       "  ';',\n",
       "  'Bates',\n",
       "  ',',\n",
       "  'Aldape',\n",
       "  '&',\n",
       "  'Baker',\n",
       "  ',',\n",
       "  '1991',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['The',\n",
       "  'mouse',\n",
       "  'neuronal',\n",
       "  'hybrid',\n",
       "  'cell',\n",
       "  'line',\n",
       "  'MN-1',\n",
       "  'was',\n",
       "  'cultured',\n",
       "  'and',\n",
       "  'transfected',\n",
       "  'as',\n",
       "  'previously',\n",
       "  'described',\n",
       "  '(',\n",
       "  'Drews',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2005',\n",
       "  ')',\n",
       "  ',',\n",
       "  'using',\n",
       "  '50',\n",
       "  'ng',\n",
       "  'of',\n",
       "  'test',\n",
       "  'plasmid',\n",
       "  ',',\n",
       "  '10',\n",
       "  'ng',\n",
       "  'of',\n",
       "  'control',\n",
       "  'plasmid',\n",
       "  '(',\n",
       "  'pRLSV40',\n",
       "  ',',\n",
       "  'Promega',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Fugene',\n",
       "  '6',\n",
       "  'transfection',\n",
       "  'reagent',\n",
       "  '(',\n",
       "  'Roche',\n",
       "  'Molecular',\n",
       "  'Biochemicals',\n",
       "  ',',\n",
       "  'Indianapolis',\n",
       "  ',',\n",
       "  'IN',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['',\n",
       "  'by',\n",
       "  'which',\n",
       "  'DREAM',\n",
       "  'transactivates',\n",
       "  'the',\n",
       "  'GFAP',\n",
       "  'promoter',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'calcium',\n",
       "  'is',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'involve',\n",
       "  'changes',\n",
       "  'in',\n",
       "  'protein',\n",
       "  'conformation',\n",
       "  '(',\n",
       "  'Carrion',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '1999',\n",
       "  ';',\n",
       "  'Osawa',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2001',\n",
       "  ',',\n",
       "  '2005',\n",
       "  ')',\n",
       "  'that',\n",
       "  'could',\n",
       "  'be',\n",
       "  'stabilized',\n",
       "  'by',\n",
       "  'interactions',\n",
       "  'with',\n",
       "  'other',\n",
       "  'proteins',\n",
       "  'bound',\n",
       "  'in',\n",
       "  'close',\n",
       "  'proximity',\n",
       "  '(',\n",
       "  'Rivas',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2004',\n",
       "  ';',\n",
       "  '',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['We',\n",
       "  'demonstrate',\n",
       "  'that',\n",
       "  'the',\n",
       "  'average',\n",
       "  'amplitudes',\n",
       "  'of',\n",
       "  'contralateral',\n",
       "  'PBR',\n",
       "  '(',\n",
       "  'cPBR',\n",
       "  ')',\n",
       "  'and',\n",
       "  'ipsilateral',\n",
       "  'NBR',\n",
       "  '(',\n",
       "  'iNBR',\n",
       "  ')',\n",
       "  'were',\n",
       "  'negatively',\n",
       "  'correlated',\n",
       "  'as',\n",
       "  'previously',\n",
       "  'reported',\n",
       "  'and',\n",
       "  'thought',\n",
       "  'to',\n",
       "  'result',\n",
       "  'from',\n",
       "  'increased',\n",
       "  'ipsilateral',\n",
       "  'inhibition',\n",
       "  'occurring',\n",
       "  'concurrently',\n",
       "  'with',\n",
       "  'increased',\n",
       "  'contralateral',\n",
       "  'excitation',\n",
       "  '(',\n",
       "  'Klingner',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2010',\n",
       "  ';',\n",
       "  'Shmuel',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  ',',\n",
       "  '2002',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['With',\n",
       "  'the',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'contributing',\n",
       "  'to',\n",
       "  'the',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'the',\n",
       "  'negative',\n",
       "  'regulation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'synthesis',\n",
       "  'of',\n",
       "  'flavonoids',\n",
       "  'in',\n",
       "  'grapevine',\n",
       "  ',',\n",
       "  'a',\n",
       "  'search',\n",
       "  'was',\n",
       "  'conducted',\n",
       "  'in',\n",
       "  'the',\n",
       "  'NCBI',\n",
       "  '/',\n",
       "  'GenBank',\n",
       "  'Database',\n",
       "  'using',\n",
       "  'the',\n",
       "  'sequence',\n",
       "  'of',\n",
       "  'Fragaria',\n",
       "  '',\n",
       "  'ananasa',\n",
       "  'FaMYB1',\n",
       "  ',',\n",
       "  'a',\n",
       "  'repressor',\n",
       "  'of',\n",
       "  'the',\n",
       "  'flavonoid',\n",
       "  'biosynthesis',\n",
       "  '(',\n",
       "  'Aharoni',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2001',\n",
       "  ';',\n",
       "  'Paolocci',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2011',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['',\n",
       "  'even',\n",
       "  'if',\n",
       "  'the',\n",
       "  'higher',\n",
       "  'estimate',\n",
       "  'is',\n",
       "  'more',\n",
       "  'realistic',\n",
       "  ',',\n",
       "  'the',\n",
       "  'population',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Udzungwa',\n",
       "  'red',\n",
       "  'colobus',\n",
       "  'is',\n",
       "  'by',\n",
       "  'no',\n",
       "  'means',\n",
       "  'secure',\n",
       "  ';',\n",
       "  'its',\n",
       "  'range',\n",
       "  'is',\n",
       "  'very',\n",
       "  'limited',\n",
       "  ',',\n",
       "  'its',\n",
       "  'populations',\n",
       "  'are',\n",
       "  'fragmented',\n",
       "  'and',\n",
       "  'discontinuous',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'threats',\n",
       "  'from',\n",
       "  'further',\n",
       "  'habitat',\n",
       "  'loss',\n",
       "  'and',\n",
       "  'human',\n",
       "  'disturbance',\n",
       "  'continued',\n",
       "  'undiminished',\n",
       "  '(',\n",
       "  'Rovero',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2012',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@'],\n",
       " ['',\n",
       "  'results',\n",
       "  'in',\n",
       "  'the',\n",
       "  'light',\n",
       "  'of',\n",
       "  'the',\n",
       "  'current',\n",
       "  'debate',\n",
       "  'concerning',\n",
       "  'the',\n",
       "  'probable',\n",
       "  'agents',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'the',\n",
       "  'high',\n",
       "  'level',\n",
       "  'of',\n",
       "  'biodiversity',\n",
       "  'and',\n",
       "  'its',\n",
       "  'geographical',\n",
       "  'distribution',\n",
       "  'across',\n",
       "  'the',\n",
       "  'different',\n",
       "  'biogeographical',\n",
       "  'regions',\n",
       "  'in',\n",
       "  'this',\n",
       "  'continent',\n",
       "  '(',\n",
       "  'Hoorn',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2010',\n",
       "  ';',\n",
       "  'Antonelli',\n",
       "  '&',\n",
       "  'Sanmartin',\n",
       "  '2011',\n",
       "  ';',\n",
       "  'Rull',\n",
       "  '2011',\n",
       "  ';',\n",
       "  'S',\n",
       "  'ersic',\n",
       "  'et',\n",
       "  'al',\n",
       "  '.',\n",
       "  '2011',\n",
       "  ')',\n",
       "  '.',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@',\n",
       "  '@@PADDING@@']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b9a2e-67a7-4bdb-bda8-36a629fccd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38ea13a6-fdf2-4cac-afd3-64660e7ccb22",
   "metadata": {},
   "source": [
    "## Datareader convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e101f4a2-e56c-4ecd-aa7d-21860bec4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data reader for AllenNLP \"\"\"\n",
    "\n",
    "\n",
    "from typing import Dict, List\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from allennlp.data import Field\n",
    "from overrides import overrides\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import LabelField, TextField, MultiLabelField, ListField, ArrayField, MetadataField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer, ELMoTokenCharactersIndexer\n",
    "\n",
    "from scicite.resources.lexicons import ALL_ACTION_LEXICONS, ALL_CONCEPT_LEXICONS\n",
    "from scicite.data import DataReaderJurgens\n",
    "from scicite.data import DataReaderS2, DataReaderS2ExcerptJL\n",
    "from scicite.compute_features import is_in_lexicon\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "from scicite.constants import S2_CATEGORIES, NONE_LABEL_NAME\n",
    "\n",
    "\n",
    "# @DatasetReader.register(\"scicite_datasetreader\")\n",
    "class SciciteDatasetReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    Reads a JSON-lines file containing citations from the Semantic Scholar database, and creates a\n",
    "    dataset suitable for document classification using these papers.\n",
    "\n",
    "    The output of ``read`` is a list of ``Instance`` s with the fields:\n",
    "        citation_text: ``TextField``\n",
    "        label: ``LabelField``\n",
    "\n",
    "    where the ``label`` is derived from the methodology/comparison labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lazy : ``bool`` (optional, default=False)\n",
    "        Passed to ``DatasetReader``.  If this is ``True``, training will start sooner, but will\n",
    "        take longer per batch.  This also allows training with datasets that are too large to fit\n",
    "        in memory.\n",
    "    tokenizer : ``Tokenizer``, optional\n",
    "        Tokenizer to use to split the title and abstrct into words or other kinds of tokens.\n",
    "        Defaults to ``WordTokenizer()``.\n",
    "    token_indexers : ``Dict[str, TokenIndexer]``, optional\n",
    "        Indexers used to define input token representations. Defaults to ``{\"tokens\":\n",
    "        SingleIdTokenIndexer()}``.\n",
    "    reader_format : can be `flat` or `nested`. `flat` for flat json format and nested for\n",
    "        Json format where the each object contains multiple excerpts\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 lazy: bool = False,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 use_lexicon_features: bool=False,\n",
    "                 use_sparse_lexicon_features: bool = False,\n",
    "                 multilabel: bool = False,\n",
    "                 with_elmo: bool = False,\n",
    "                 reader_format: str = 'flat') -> None:\n",
    "        super().__init__(lazy)\n",
    "        self._tokenizer = tokenizer or WordTokenizer() # using WordTokenizer() because config['tokenizer'] not specified \n",
    "        if with_elmo:\n",
    "            # self._token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "            self._token_indexers = {\"elmo\": ELMoTokenCharactersIndexer(),\n",
    "                                    \"tokens\": SingleIdTokenIndexer()}\n",
    "        else:\n",
    "            self._token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "        self.use_lexicon_features = use_lexicon_features\n",
    "        self.use_sparse_lexicon_features = use_sparse_lexicon_features\n",
    "        if self.use_lexicon_features or self.use_sparse_lexicon_features:\n",
    "            self.lexicons = {**ALL_ACTION_LEXICONS, **ALL_CONCEPT_LEXICONS}\n",
    "        self.multilabel = multilabel\n",
    "        self.reader_format = reader_format\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, jsonl_file: str):\n",
    "        if self.reader_format == 'flat':\n",
    "            reader_s2 = DataReaderS2ExcerptJL(jsonl_file)\n",
    "        elif self.reader_format == 'nested':\n",
    "            reader_s2 = DataReaderS2(jsonl_file)\n",
    "        for citation in reader_s2.read():\n",
    "            yield self.text_to_instance(\n",
    "                citation_text=citation.text,\n",
    "                intent=citation.intent,\n",
    "                citing_paper_id=citation.citing_paper_id,\n",
    "                cited_paper_id=citation.cited_paper_id,\n",
    "                citation_excerpt_index=citation.citation_excerpt_index\n",
    "            )\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self,\n",
    "                         citation_text: str,\n",
    "                         citing_paper_id: str,\n",
    "                         cited_paper_id: str,\n",
    "                         intent: List[str] = None,\n",
    "                         citing_paper_title: str = None,\n",
    "                         cited_paper_title: str = None,\n",
    "                         citing_paper_year: int = None,\n",
    "                         cited_paper_year: int = None,\n",
    "                         citing_author_ids: List[str] = None,\n",
    "                         cited_author_ids: List[str] = None,\n",
    "                         extended_context: str = None,\n",
    "                         section_number: int = None,\n",
    "                         section_title: str = None,\n",
    "                         cite_marker_begin: int = None,\n",
    "                         cite_marker_end: int = None,\n",
    "                         sents_before: List[str] = None,\n",
    "                         sents_after: List[str] = None,\n",
    "                         cleaned_cite_text: str = None,\n",
    "                         citation_excerpt_index: str = None,\n",
    "                         venue: str = None) -> Instance:  # type: ignore\n",
    "\n",
    "        citation_tokens = self._tokenizer.tokenize(citation_text)\n",
    "\n",
    "        fields = {\n",
    "            'citation_text': TextField(citation_tokens, self._token_indexers),\n",
    "        }\n",
    "\n",
    "        if self.use_sparse_lexicon_features:\n",
    "            # convert to regular string\n",
    "            sent = [token.text.lower() for token in citation_tokens]\n",
    "            lexicon_features, _ = is_in_lexicon(self.lexicons, sent)\n",
    "            fields[\"lexicon_features\"] = ListField([LabelField(feature, skip_indexing=True)\n",
    "                                                    for feature in lexicon_features])\n",
    "\n",
    "        if intent:\n",
    "            if self.multilabel:\n",
    "                fields['labels'] = MultiLabelField([S2_CATEGORIES[e] for e in intent], skip_indexing=True,\n",
    "                                                   num_labels=len(S2_CATEGORIES))\n",
    "            else:\n",
    "                if not isinstance(intent, str):\n",
    "                    raise TypeError(f\"Undefined label format. Should be a string. Got: f'{intent}'\")\n",
    "                fields['labels'] = LabelField(intent)\n",
    "\n",
    "        if citing_paper_year and cited_paper_year and \\\n",
    "                citing_paper_year > -1 and cited_paper_year > -1:\n",
    "            year_diff = citing_paper_year - cited_paper_year\n",
    "        else:\n",
    "            year_diff = -1\n",
    "        fields['year_diff'] = ArrayField(torch.Tensor([year_diff]))\n",
    "        fields['citing_paper_id'] = MetadataField(citing_paper_id)\n",
    "        fields['cited_paper_id'] = MetadataField(cited_paper_id)\n",
    "        fields['citation_excerpt_index'] = MetadataField(citation_excerpt_index)\n",
    "        fields['citation_id'] = MetadataField(f\"{citing_paper_id}>{cited_paper_id}\")\n",
    "        return Instance(fields)\n",
    "\n",
    "    @classmethod\n",
    "    def from_params(cls, params: Params) -> 'SciciteDatasetReader':\n",
    "        lazy = params.pop('lazy', False)\n",
    "        tokenizer = Tokenizer.from_params(params.pop('tokenizer', {}))\n",
    "        use_lexicon_features = params.pop_bool(\"use_lexicon_features\", False)\n",
    "        use_sparse_lexicon_features = params.pop_bool(\"use_sparse_lexicon_features\", False)\n",
    "        multilabel = params.pop_bool(\"multilabel\")\n",
    "        with_elmo = params.pop_bool(\"with_elmo\", False)\n",
    "        reader_format = params.pop(\"reader_format\", 'flat')\n",
    "        params.assert_empty(cls.__name__)\n",
    "        return cls(lazy=lazy, tokenizer=tokenizer,\n",
    "                   use_lexicon_features=use_lexicon_features,\n",
    "                   use_sparse_lexicon_features=use_sparse_lexicon_features,\n",
    "                   multilabel=multilabel,\n",
    "                   with_elmo=with_elmo,\n",
    "                   reader_format=reader_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02176e8b-bb4e-40df-abb4-d9161130a411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[this, is, a, happy, pancake, !]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_text = \"this is a happy pancake!\"\n",
    "citation_tokens = WordTokenizer().tokenize(citation_text)\n",
    "citation_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62aa8e3c-274b-4bbc-80af-927c6b15f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SingleIdTokenIndexer --> one embedding for each word\n",
    "_token_indexers = {\"elmo\": ELMoTokenCharactersIndexer(),\n",
    "                                    \"tokens\": SingleIdTokenIndexer()}\n",
    "fields = {\n",
    "    'citation_text': TextField(citation_tokens, _token_indexers),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd24d825-1dc5-4a67-acf6-922ffa827e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scicite.training.vocabulary_multitask import VocabularyMultitask\n",
    "\n",
    "params = Params.from_file('experiment_configs/custom_config.json', \"\")\n",
    "serialization_dir = './runs/test'\n",
    "file_friendly_logging = False\n",
    "recover = False\n",
    "vocab = VocabularyMultitask.from_params(\n",
    "        params.pop(\"vocabulary\", {}),\n",
    "        (instance for key, dataset in all_datasets.items()\n",
    "         for instance in dataset\n",
    "         if key in datasets_for_vocab_creation),\n",
    "        instances_aux=vocab_instances_aux\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d284b10d-a352-4671-8131-7c6b98ac44fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da5fac0f-7ee8-4cac-9eeb-ca1249204739",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "as_tensor() missing 1 required positional argument: 'padding_lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-6871ff3d03d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'citation_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: as_tensor() missing 1 required positional argument: 'padding_lengths'"
     ]
    }
   ],
   "source": [
    "fields['citation_text'].as_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1eb31c70-47f8-41b3-9569-0e8f85b0cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  39,   16,   15, 9526,    1, 2933])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indices = fields['citation_text'].as_tensor(fields['citation_text'].get_padding_lengths()).get(\"tokens\").detach().cpu().numpy()\n",
    "token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6836c67d-2124-4fb1-8323-2d65d61e62d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab._index_to_token['tokens'][9526]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05df02-6dc8-4e08-ad61-4d84fde5328d",
   "metadata": {},
   "source": [
    "## TextFieldEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "216bb8f7-7ecd-4069-be0e-ce14b7606041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<allennlp.common.params.Params at 0x7f3f8ea38fd0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.modules import FeedForward, Seq2VecEncoder, Seq2SeqEncoder, TextFieldEmbedder, Embedding, TimeDistributed\n",
    "params = Params.from_file('experiment_configs/custom_config.json', \"\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "72ed4af8-3f43-4d82-b3de-7cbf001e7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = {\n",
    "      \"tokens\": {\n",
    "        \"type\": \"embedding\",\n",
    "        \"pretrained_file\": \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\",\n",
    "        \"embedding_dim\": 100,\n",
    "        \"trainable\": \"false\"\n",
    "      },\n",
    "      \"elmo\": {\n",
    "        \"type\": \"elmo_token_embedder\",\n",
    "        \"options_file\": \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\",\n",
    "        \"weight_file\": \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\",\n",
    "        \"do_layer_norm\": \"true\",\n",
    "        \"dropout\": 0.5\n",
    "      }\n",
    "}\n",
    "text_field_embedder = TextFieldEmbedder.from_params(params.pop('model').pop(\"elmo_text_field_embedder\"), vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f43452f5-e135-448d-9388-2df11cd2bc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicTextFieldEmbedder(\n",
       "  (token_embedder_elmo): ElmoTokenEmbedder(\n",
       "    (_elmo): Elmo(\n",
       "      (_elmo_lstm): _ElmoBiLm(\n",
       "        (_token_embedder): _ElmoCharacterEncoder(\n",
       "          (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "          (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "          (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "          (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "          (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "          (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "          (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "          (_highways): Highway(\n",
       "            (_layers): ModuleList(\n",
       "              (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "              (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (_elmo_lstm): ElmoLstm(\n",
       "          (forward_layer_0): LstmCellWithProjection(\n",
       "            (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "            (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "            (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          )\n",
       "          (backward_layer_0): LstmCellWithProjection(\n",
       "            (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "            (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "            (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          )\n",
       "          (forward_layer_1): LstmCellWithProjection(\n",
       "            (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "            (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "            (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          )\n",
       "          (backward_layer_1): LstmCellWithProjection(\n",
       "            (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "            (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "            (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (_dropout): Dropout(p=0.5, inplace=False)\n",
       "      (scalar_mix_0): ScalarMix(\n",
       "        (scalar_parameters): ParameterList(\n",
       "            (0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "            (1): Parameter containing: [torch.FloatTensor of size 1]\n",
       "            (2): Parameter containing: [torch.FloatTensor of size 1]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedder_tokens): Embedding()\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736434d-f669-454e-ac96-3dd519e577f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f64e1-1132-4491-9b2c-7a2c6a5e485d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c67e9-279f-434e-b6f9-9d450f6a04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ef90c-c3d9-4536-ac7b-37e6ac3e7e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beb97fe3-6af4-4747-b913-ba9cd5debee1",
   "metadata": {},
   "source": [
    "## JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074287da-4cff-45de-9700-7276b6ed99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./scicite_data/dev.jsonl\", encoding=\"utf8\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    lines = [json.loads(x) for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2f9ad-3cd3-4140-93df-e21e5fd028a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc2c82-cb47-4007-86cf-62ac074048f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963242f5-e1a1-4100-b14b-8ff3fdf50896",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./output_pretrained_test.txt\", encoding=\"utf8\") as f:\n",
    "    output_pretrained = f.read()\n",
    "    output_pretrained = \"[\" + output_pretrained + \"]\"\n",
    "    # output_pretrained = [json.loads(x) for x in output_pretrained]\n",
    "    output_pretrained = json.loads(output_pretrained.replace('\\n', ', ')[:-3]+']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b84ac-a3a9-4c8d-bebb-00c09de72fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_predict = pd.DataFrame(output_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e8063-daf2-498b-829d-80e34f9ab00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev_predict.dropna(subset=['prediction'])\n",
    "df_dev_predict = df_dev_predict[~(df_dev_predict['prediction'] == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201539ae-6224-4d51-99db-05e87f357d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev_merged = df_dev.merge(df_dev_predict, how='left', left_on=\"unique_id\", right_on=\"unique_id\").dropna(subset=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f58d0-da6b-4d4c-b778-d2bb377e6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_res(df_row):\n",
    "#     if df_row[\"label\"] == df_row[\"prediction\"]:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffea5cd-3310-4980-a24a-02c75a0b5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev_merged[\"correct_pred\"] = df_dev_merged.apply(compare_res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f65da-cb6d-4775-ae50-aad17a77f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev_merged[df_dev_merged[\"correct_pred\"] == True][\"correct_pred\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc3c6a-57fa-4485-a875-39da2d489f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev_merged[\"correct_pred\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3adf2-b892-46cc-a31e-7a55a99bec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d35d69-0aa4-4b80-a5bb-a7506d4b4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_dev_predict['label'], df_dev_predict['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddd61c-c9e6-43e9-910f-96ffd9111e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(df_dev_predict['label'], df_dev_predict['prediction'], average='macro'))\n",
    "# df_dev_predict['prediction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2283854-8b1d-4d8d-8725-0fff02a09801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev_merged[df_dev_merged['prediction']!= df_dev_merged['prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1444d42b-00a5-4dd7-b095-9f17ba5b7e74",
   "metadata": {},
   "source": [
    "## Experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d9023-d367-4213-99ca-6af09415b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_pairs = [(0,0), (0.05,0.05), (0.1,0.1), (0.1, 0.2), (0.1, 0.3), (0.2, 0.2), (0.3, 0.3)]\n",
    "\n",
    "for lamb in lambda_pairs:\n",
    "    print(lamb)\n",
    "    with open(f\"./experiments-_{lamb[0]}_{lamb[1]}/metrics.json\", encoding=\"utf8\") as f:\n",
    "        metrics = f.read()\n",
    "        metrics = json.loads(metrics)\n",
    "    print(metrics['best_validation_average_F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0e645-bf47-4af7-8bbe-c1caae791a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b2e3a-c2f0-4a6f-981b-0c72c1b5efee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248-scicite-torch",
   "language": "python",
   "name": "cs4248-scicite-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

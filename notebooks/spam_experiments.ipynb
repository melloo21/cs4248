{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-07T17:08:24.525483Z",
     "start_time": "2024-04-07T17:08:17.990481Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.extraction.jsonl_data_reader import JsonlDataReader\n",
    "\n",
    "train_data = JsonlDataReader(file_name='train.jsonl').read()\n",
    "dev_data = JsonlDataReader(file_name='dev.jsonl').read()\n",
    "test_data = JsonlDataReader(file_name='test.jsonl').read()\n",
    "\n",
    "stage_order = ['pretokenizer', 'tokenizer', 'post_tokenizer', 'vectorizer', 'model']\n",
    "stage_order_map = dict(zip(stage_order[:-1], stage_order[1:]))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:08:44.678654Z",
     "start_time": "2024-04-07T17:08:43.475655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.vectorizer.w2v_vectorizer import W2vVectorizer\n",
    "from src.models.abstract_model import AbstractModel\n",
    "from src.vectorizer.lsi_vectorizer import LsiVectorizer\n",
    "from src.vectorizer.sk_count_vectorizer import SkCountVectorizer\n",
    "from src.vectorizer.tfidf_vectorizer import TfidfVectorizer\n",
    "from src.post_tokenizer.phraser_merger import PhraserMerger\n",
    "from src.post_tokenizer.null_post_tokenizer import NullPostTokenizer\n",
    "from src.tokenize.sentence_piece_tokenizer import SentencePieceTokenizer\n",
    "from src.tokenize.null_tokenizer import NullTokenizer\n",
    "from src.tokenize.spacy_tokenizer import SpacyTokenizer\n",
    "from src.preprocessing.simple_preprocessor import SimplePreprocessor\n",
    "\n",
    "stage_config = {\n",
    "    'preprocessing': {\n",
    "        SimplePreprocessor: {\n",
    "            'remove_citations': (True, False),\n",
    "            'remove_duplicates': (True, False),\n",
    "        }\n",
    "    },\n",
    "    'tokenizer': {\n",
    "        SpacyTokenizer: {\n",
    "            # 'merge_nouns': (True, False),\n",
    "            # 'merge_entities': (True, False),\n",
    "            'replace_numbers': (True, False),\n",
    "            'remove_stopwords': (True, False),\n",
    "        },\n",
    "        NullTokenizer: {},\n",
    "        SentencePieceTokenizer: {\n",
    "            'vocab_size': (4000, 8000, 12000),\n",
    "        },\n",
    "    },\n",
    "    'post_tokenizer': {\n",
    "        NullPostTokenizer: {},\n",
    "        PhraserMerger: {\n",
    "            'num_gram': (1, 2, 3),\n",
    "        },\n",
    "    },\n",
    "    'vectorizer': {\n",
    "        TfidfVectorizer: {},\n",
    "        SkCountVectorizer: {\n",
    "            'binary': (True, False),\n",
    "            'ignore_preprocessing': (True, False),\n",
    "        },\n",
    "        W2vVectorizer: {},\n",
    "        LsiVectorizer: {},\n",
    "        # FastTextW2vVectorizer: {},\n",
    "    },\n",
    "    'model': {\n",
    "        AbstractModel: {},\n",
    "    }\n",
    "}"
   ],
   "id": "2639e651e4c335dd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:08:45.387150Z",
     "start_time": "2024-04-07T17:08:45.286148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def run_preprocessing(run_class, args, prev_output, current_state, current_models):\n",
    "    print(f'running preprocessing: {run_class}: {args=}, {current_state=}')\n",
    "    current_obj = run_class(**args)\n",
    "    preprocessed_train = current_obj.preprocess(train_data)\n",
    "    preprocessed_dev = current_obj.preprocess(dev_data)\n",
    "    preprocessed_test = current_obj.preprocess(test_data)\n",
    "    return (preprocessed_train, preprocessed_dev, preprocessed_test), current_obj\n",
    "\n",
    "\n",
    "def run_tokenizer(run_class, args, prev_output, current_state, current_models):\n",
    "    print(f'running tokenizer: {run_class}: {args=}, {current_state=}')\n",
    "    tokenizer = run_class(\n",
    "        **args\n",
    "    )\n",
    "    train, dev, test = prev_output\n",
    "    tokenizer.fit(train)\n",
    "    results = tuple(tokenizer.tokenize(x) for x in prev_output)\n",
    "    return results, tokenizer\n",
    "\n",
    "\n",
    "def run_post_tokenizer(run_class, args, prev_output, current_state, current_models):\n",
    "    print(f'running post_tokenizer: {run_class}: {args=}, {current_state=}')\n",
    "    post_tokenizer = run_class(**args)\n",
    "    train, dev, test = prev_output\n",
    "    post_tokenizer.fit(train)\n",
    "    results = tuple(post_tokenizer.transform(x) for x in prev_output)\n",
    "    return results, post_tokenizer\n",
    "\n",
    "\n",
    "def run_vectorizer(run_class, args, prev_output, current_state, current_models):\n",
    "    print(f'running vectorizer: {run_class}: {args=}, {current_state=}')\n",
    "    vectorizer = run_class(**args)\n",
    "    train, dev, test = prev_output\n",
    "    vectorizer.fit(train)\n",
    "    results = tuple(vectorizer.transform(x) for x in prev_output)\n",
    "    return results, vectorizer\n",
    "\n",
    "\n",
    "def run_model(run_class, args, prev_output, current_state, current_models):\n",
    "    print(f'running model: {run_class}: {args=}, {current_state=}')\n",
    "    models = {\n",
    "        'LR': LogisticRegression(max_iter=2000),\n",
    "        'svm': SVC(kernel='rbf'),\n",
    "    }\n",
    "    train, dev, test = prev_output\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        model_result = {'model_name': model_name}\n",
    "        model.fit(train.vectors, train.label_indices)\n",
    "        y_pred_train = model.predict(train.vectors)\n",
    "        score = f1_score(train.label_indices, y_pred_train, average='macro')\n",
    "        model_result['train_f1'] = score\n",
    "\n",
    "        y_pred_dev = model.predict(dev.vectors)\n",
    "        score = f1_score(dev.label_indices, y_pred_dev, average='macro')\n",
    "        model_result['dev_f1'] = score\n",
    "\n",
    "        y_pred_test = model.predict(test.vectors)\n",
    "        score = f1_score(test.label_indices, y_pred_test, average='macro')\n",
    "        model_result['test_f1'] = score\n",
    "\n",
    "    return results, None\n",
    "\n",
    "\n",
    "def run(stage: str, run_class, args: dict, prev_output=None, current_state=None, current_models=None) -> list[dict]:\n",
    "    if current_state is None:\n",
    "        current_state = dict()\n",
    "    current_state = {**current_state, stage: run_class.__name__}\n",
    "    if current_models is None:\n",
    "        current_models = dict()\n",
    "    results = []\n",
    "    next_stage = stage_order_map.get(stage)\n",
    "\n",
    "    run_func = {\n",
    "        'pretokenizer': run_preprocessing,\n",
    "        'tokenizer': run_tokenizer,\n",
    "        'post_tokenizer': run_post_tokenizer,\n",
    "        'vectorizer': run_vectorizer,\n",
    "        'model': run_model,\n",
    "    }\n",
    "\n",
    "    if not args:\n",
    "        result, model = run_func[stage](run_class, args, prev_output, current_state, current_models)\n",
    "        new_models = {**current_models, stage: model}\n",
    "        if next_stage is not None:\n",
    "            for next_class, next_args in stage_config[next_stage].items():\n",
    "                new_state = current_state\n",
    "                run_result = run(next_stage, next_class, next_args, result, new_state, new_models)\n",
    "                results.extend(run_result)\n",
    "            return results\n",
    "        else:\n",
    "            result_state = [{**current_state, **result_row} for result_row in result]\n",
    "            return result_state\n",
    "\n",
    "    argument_permutations = list(product(*args.values()))\n",
    "    for values in argument_permutations:\n",
    "        new_arg = dict(zip(args.keys(), values))\n",
    "        result, model = run_func[stage](run_class, new_arg, prev_output, current_state, current_models)\n",
    "        new_models = {**current_models, stage: model}\n",
    "        if next_stage is not None:\n",
    "            for next_class, next_args in stage_config[next_stage].items():\n",
    "                new_state = {**current_state, **new_arg}\n",
    "                run_result = run(next_stage, next_class, next_args, result, new_state, new_models)\n",
    "                results.extend(run_result)\n",
    "        else:\n",
    "            result_state = [{**current_state, **result_row} for result_row in result]\n",
    "            results.extend(result_state)\n",
    "    return results\n",
    "\n"
   ],
   "id": "64808093f611525e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:09:21.066368Z",
     "start_time": "2024-04-07T17:08:50.674368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = run('pretokenizer', SimplePreprocessor, {\n",
    "    'remove_citations': (True, False),\n",
    "    'remove_duplicates': (True, False),\n",
    "}, None)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "id": "123d0eca2a1e8331",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running preprocessing: <class 'src.preprocessing.simple_preprocessor.SimplePreprocessor'>: args={'remove_citations': True, 'remove_duplicates': True}, current_state={'pretokenizer': 'SimplePreprocessor'}\n",
      "running tokenizer: <class 'src.tokenize.spacy_tokenizer.SpacyTokenizer'>: args={'replace_numbers': True, 'remove_stopwords': True}, current_state={'pretokenizer': 'SimplePreprocessor', 'remove_citations': True, 'remove_duplicates': True, 'tokenizer': 'SpacyTokenizer'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpretokenizer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSimplePreprocessor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mremove_citations\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mremove_duplicates\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m results_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(results)\n\u001B[0;32m      6\u001B[0m results_df\n",
      "Cell \u001B[1;32mIn[3], line 110\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(stage, run_class, args, prev_output, current_state, current_models)\u001B[0m\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m next_class, next_args \u001B[38;5;129;01min\u001B[39;00m stage_config[next_stage]\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    109\u001B[0m         new_state \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcurrent_state, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mnew_arg}\n\u001B[1;32m--> 110\u001B[0m         run_result \u001B[38;5;241m=\u001B[39m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnext_stage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_models\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    111\u001B[0m         results\u001B[38;5;241m.\u001B[39mextend(run_result)\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "Cell \u001B[1;32mIn[3], line 105\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(stage, run_class, args, prev_output, current_state, current_models)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m values \u001B[38;5;129;01min\u001B[39;00m argument_permutations:\n\u001B[0;32m    104\u001B[0m     new_arg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(args\u001B[38;5;241m.\u001B[39mkeys(), values))\n\u001B[1;32m--> 105\u001B[0m     result, model \u001B[38;5;241m=\u001B[39m \u001B[43mrun_func\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstage\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_arg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprev_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_models\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m     new_models \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcurrent_models, stage: model}\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m next_stage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Cell \u001B[1;32mIn[3], line 23\u001B[0m, in \u001B[0;36mrun_tokenizer\u001B[1;34m(run_class, args, prev_output, current_state, current_models)\u001B[0m\n\u001B[0;32m     21\u001B[0m train, dev, test \u001B[38;5;241m=\u001B[39m prev_output\n\u001B[0;32m     22\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mfit(train)\n\u001B[1;32m---> 23\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mprev_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results, tokenizer\n",
      "Cell \u001B[1;32mIn[3], line 23\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     21\u001B[0m train, dev, test \u001B[38;5;241m=\u001B[39m prev_output\n\u001B[0;32m     22\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mfit(train)\n\u001B[1;32m---> 23\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m prev_output)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results, tokenizer\n",
      "File \u001B[1;32m~\\programming\\CS4248_project\\cs4248\\scicite\\src\\tokenize\\spacy_tokenizer.py:37\u001B[0m, in \u001B[0;36mSpacyTokenizer.tokenize\u001B[1;34m(self, document)\u001B[0m\n\u001B[0;32m     35\u001B[0m tokenized_docs \u001B[38;5;241m=\u001B[39m document\u001B[38;5;241m.\u001B[39mtexts\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mremove_stopwords:\n\u001B[1;32m---> 37\u001B[0m     tokenized_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     38\u001B[0m         \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mis_stop \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mis_punct, doc))\n\u001B[0;32m     39\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mpipe(tokenized_docs)\n\u001B[0;32m     40\u001B[0m     ]\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     tokenized_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mis_punct, doc))\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mpipe(tokenized_docs)\n\u001B[0;32m     45\u001B[0m     ]\n",
      "File \u001B[1;32m~\\programming\\CS4248_project\\cs4248\\scicite\\src\\tokenize\\spacy_tokenizer.py:37\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     35\u001B[0m tokenized_docs \u001B[38;5;241m=\u001B[39m document\u001B[38;5;241m.\u001B[39mtexts\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mremove_stopwords:\n\u001B[1;32m---> 37\u001B[0m     tokenized_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     38\u001B[0m         \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mis_stop \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mis_punct, doc))\n\u001B[0;32m     39\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mpipe(tokenized_docs)\n\u001B[0;32m     40\u001B[0m     ]\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     tokenized_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mis_punct, doc))\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mpipe(tokenized_docs)\n\u001B[0;32m     45\u001B[0m     ]\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\language.py:1618\u001B[0m, in \u001B[0;36mLanguage.pipe\u001B[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001B[0m\n\u001B[0;32m   1616\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m pipe \u001B[38;5;129;01min\u001B[39;00m pipes:\n\u001B[0;32m   1617\u001B[0m         docs \u001B[38;5;241m=\u001B[39m pipe(docs)\n\u001B[1;32m-> 1618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs:\n\u001B[0;32m   1619\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m doc\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\util.py:1703\u001B[0m, in \u001B[0;36m_pipe\u001B[1;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[0;32m   1693\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pipe\u001B[39m(\n\u001B[0;32m   1694\u001B[0m     docs: Iterable[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1695\u001B[0m     proc: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeCallable\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1700\u001B[0m     kwargs: Mapping[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[0;32m   1701\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m   1702\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipe\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1703\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mpipe(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1704\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1705\u001B[0m         \u001B[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001B[39;00m\n\u001B[0;32m   1706\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(kwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:251\u001B[0m, in \u001B[0;36mpipe\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.predict\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\model.py:334\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[0;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\ml\\tb_framework.py:34\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model, X, is_train):\n\u001B[1;32m---> 34\u001B[0m     step_model \u001B[38;5;241m=\u001B[39m \u001B[43mParserStepModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43munseen_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munseen_classes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_upper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhas_upper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m step_model, step_model\u001B[38;5;241m.\u001B[39mfinish_steps\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\layers\\list2ragged.py:25\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, Xs, is_train)\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(InT, model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39munflatten(dYr\u001B[38;5;241m.\u001B[39mdata, dYr\u001B[38;5;241m.\u001B[39mlengths))\n\u001B[0;32m     24\u001B[0m lengths \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39masarray1i([\u001B[38;5;28mlen\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m Xs])\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Ragged(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXs\u001B[49m\u001B[43m)\u001B[49m, lengths), backprop\n",
      "File \u001B[1;32m~\\.conda\\envs\\cs4248_project\\lib\\site-packages\\thinc\\backends\\ops.py:341\u001B[0m, in \u001B[0;36mOps.flatten\u001B[1;34m(self, X, dtype, pad, ndim_if_empty)\u001B[0m\n\u001B[0;32m    339\u001B[0m     padded\u001B[38;5;241m.\u001B[39mappend(xp\u001B[38;5;241m.\u001B[39mzeros((pad,) \u001B[38;5;241m+\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:], dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype))\n\u001B[0;32m    340\u001B[0m     X \u001B[38;5;241m=\u001B[39m padded\n\u001B[1;32m--> 341\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mxp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    343\u001B[0m     result \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39masarray(result, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:09:21.068368Z",
     "start_time": "2024-04-07T17:09:21.067369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.path_getter import PathGetter\n",
    "\n",
    "results_df.to_parquet(PathGetter.get_data_directory()/'experiments.parquet')"
   ],
   "id": "96564c4815c35f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32da3bc80e6280e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0a7c0cf57aae4c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (cs4248 project)",
   "language": "python",
   "name": "cs4248_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

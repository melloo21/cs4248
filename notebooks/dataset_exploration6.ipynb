{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from src.extraction.jsonl_data_reader import JsonlDataReader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T13:36:09.330579Z",
     "start_time": "2024-04-14T13:36:08.222514Z"
    }
   },
   "id": "241064ad2dc2c113",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "seed = 7\n",
    "random_state = RandomState(seed=seed)\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T13:36:09.346579Z",
     "start_time": "2024-04-14T13:36:09.337578Z"
    }
   },
   "id": "ebeafe2eaa284a61",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = JsonlDataReader(file_name='train.jsonl').read()\n",
    "dev_data = JsonlDataReader(file_name='dev.jsonl').read()\n",
    "test_data = JsonlDataReader(file_name='test.jsonl').read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T13:36:12.561632Z",
     "start_time": "2024-04-14T13:36:11.540874Z"
    }
   },
   "id": "7101d588a95c4943",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from src.preprocessing.simple_preprocessor import SimplePreprocessor\n",
    "\n",
    "preprocessor = SimplePreprocessor(remove_citations=True, remove_duplicates=True)\n",
    "preprocessed_train = preprocessor.preprocess(train_data)\n",
    "preprocessed_dev = preprocessor.preprocess(dev_data)\n",
    "preprocessed_test = preprocessor.preprocess(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:14:08.080965Z",
     "start_time": "2024-04-09T16:14:07.970970Z"
    }
   },
   "id": "f2a9766fad954c0b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from src.tokenize.spacy_tokenizer import SpacyTokenizer\n",
    "\n",
    "tokenizer1 = SpacyTokenizer(replace_numbers=True, remove_stopwords=False, merge_nouns=False, merge_entities=False,\n",
    "                            lemmatize=False)\n",
    "tokenized_train1 = tokenizer1.tokenize(train_data)\n",
    "tokenized_dev1 = tokenizer1.tokenize(preprocessed_dev)\n",
    "tokenized_test1 = tokenizer1.tokenize(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:14:44.879965Z",
     "start_time": "2024-04-09T16:14:08.081967Z"
    }
   },
   "id": "2d669b52aab2079b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:51:03.950094Z",
     "start_time": "2024-04-09T16:50:02.415900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.tokenize.spacy_tokenizer import SpacyTokenizer\n",
    "from src.tokenize.spacy_dep_tokenizer import SpacyDepTokenizer\n",
    "from src.tokenize.spacy_pos_tokenizer import SpacyPosTokenizer\n",
    "from src.tokenize.spacy_tag_tokenizer import SpacyTagTokenizer\n",
    "\n",
    "tokenizers = [\n",
    "    SpacyTokenizer(replace_numbers=True, remove_stopwords=False, merge_nouns=False, merge_entities=False,\n",
    "                   lemmatize=False),\n",
    "    # SpacyPosTokenizer(),\n",
    "    # SpacyTagTokenizer(),\n",
    "    SpacyDepTokenizer(),\n",
    "]\n",
    "\n",
    "preprocessed_data = {\n",
    "    'train': preprocessed_train,\n",
    "    'dev': preprocessed_dev,\n",
    "    'test': preprocessed_test,\n",
    "}\n",
    "\n",
    "for tokenizer in tokenizers:\n",
    "    tokenizer.fit(preprocessed_data['train'])\n",
    "\n",
    "tokenized_data = dict()\n",
    "for env, dataset in preprocessed_data.items():\n",
    "    tokenized_data[env] = [tokenizer.tokenize(dataset) for tokenizer in tokenizers]"
   ],
   "id": "f47b78daa14a81cf",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:51:05.943094Z",
     "start_time": "2024-04-09T16:51:03.951095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from src.vectorizer.sk_count_vectorizer import SkCountVectorizer\n",
    "from src.vectorizer.sk_tfidf_vectorizer import SkTfidfVectorizer\n",
    "\n",
    "vectorizers = [\n",
    "    SkTfidfVectorizer(\n",
    "        ngram_range=(1, 2), ignore_preprocessing=False,\n",
    "        analyzer='word', binary=True\n",
    "    ),\n",
    "    # SkCountVectorizer(\n",
    "    #     ignore_preprocessing=False,\n",
    "    #     ngram_range=(2, 4), analyzer='word',\n",
    "    #     binary=False\n",
    "    # ),\n",
    "    # SkCountVectorizer(\n",
    "    #     ignore_preprocessing=False,\n",
    "    #     ngram_range=(2, 4), analyzer='word',\n",
    "    #     binary=False\n",
    "    # ),\n",
    "    SkCountVectorizer(\n",
    "        ignore_preprocessing=False,\n",
    "        ngram_range=(2, 4), analyzer='word',\n",
    "        binary=False\n",
    "    ),\n",
    "]\n",
    "\n",
    "for vectorizer, data in zip(vectorizers, tokenized_data['train']):\n",
    "    vectorizer.fit(data)\n",
    "\n",
    "vectorized_data = dict()\n",
    "for env, dataset in tokenized_data.items():\n",
    "    vectorized_data[env] = [vectorizer.transform(data) for vectorizer, data in zip(vectorizers, dataset)]"
   ],
   "id": "25a797c2977f5aed",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:51:05.974094Z",
     "start_time": "2024-04-09T16:51:05.944097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.schema.vectorized_data import VectorizedData\n",
    "import scipy\n",
    "\n",
    "vectorized_train = VectorizedData(scipy.sparse.hstack([x.vectors for x in vectorized_data['train']]), vectorized_data['train'][0].id,\n",
    "                                  vectorized_data['train'][0].labels)\n",
    "vectorized_dev = VectorizedData(scipy.sparse.hstack([x.vectors for x in vectorized_data['dev']]), vectorized_data['dev'][0].id,\n",
    "                                vectorized_data['dev'][0].labels)\n",
    "vectorized_test = VectorizedData(scipy.sparse.hstack([x.vectors for x in vectorized_data['test']]), vectorized_data['test'][0].id,\n",
    "                                 vectorized_data['test'][0].labels)"
   ],
   "id": "d4ac9f2cc9b10c26",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:51:12.535623Z",
     "start_time": "2024-04-09T16:51:05.976095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, C=10)\n",
    "model.fit(vectorized_train.vectors, vectorized_train.label_indices)\n",
    "y_pred_train = model.predict(vectorized_train.vectors)\n",
    "training_score = f1_score(vectorized_train.label_indices, y_pred_train, average='macro')\n",
    "print(f'{training_score=}')\n",
    "print(confusion_matrix(vectorized_train.label_indices, y_pred_train))\n",
    "print(precision_recall_fscore_support(vectorized_train.label_indices, y_pred_train, average='macro'))\n",
    "\n",
    "y_pred_dev = model.predict(vectorized_dev.vectors)\n",
    "dev_score = f1_score(vectorized_dev.label_indices, y_pred_dev, average='macro')\n",
    "print(f'{dev_score=}')\n",
    "print(confusion_matrix(vectorized_dev.label_indices, y_pred_dev))\n",
    "print(precision_recall_fscore_support(vectorized_dev.label_indices, y_pred_dev, average='macro'))\n",
    "\n",
    "y_pred_test = model.predict(vectorized_test.vectors)\n",
    "testing_score = f1_score(vectorized_test.label_indices, y_pred_test, average='macro')\n",
    "print(f'{testing_score=}')\n",
    "print(confusion_matrix(vectorized_test.label_indices, y_pred_test))\n",
    "print(precision_recall_fscore_support(vectorized_test.label_indices, y_pred_test, average='macro'))"
   ],
   "id": "45235bebaaf78119",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_score=1.0\n",
      "[[4320    0    0]\n",
      " [   0 2191    0]\n",
      " [   0    0 1038]]\n",
      "(1.0, 1.0, 1.0, None)\n",
      "dev_score=0.6281904970097546\n",
      "[[439  70  29]\n",
      " [ 90 153  12]\n",
      " [ 57  14  52]]\n",
      "(0.651285387626194, 0.6129164525846003, 0.6281904970097546, None)\n",
      "testing_score=0.6432170195723672\n",
      "[[791 134  72]\n",
      " [214 361  30]\n",
      " [ 87  39 133]]\n",
      "(0.6554487945714338, 0.6345292896036034, 0.6432170195723672, None)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:16:04.620339Z",
     "start_time": "2024-04-09T16:16:04.606339Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d88e21f540a5d2d3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:16:04.636340Z",
     "start_time": "2024-04-09T16:16:04.621339Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "be3c04389f559a55",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:16:04.652340Z",
     "start_time": "2024-04-09T16:16:04.637339Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e8781b42fbea2199",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:16:04.668339Z",
     "start_time": "2024-04-09T16:16:04.653341Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c188458644acacd9",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cs4248_project",
   "language": "python",
   "display_name": "Python3.10 (cs4248 project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
